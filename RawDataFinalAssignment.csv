Title,Text,,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Accelerated by technological advancements and the recent global pandemic, there is burgeoning interest in digital mental health literacy (DMHL) interventions that can positively affect mental health. However, existing work remains inconclusive regarding the effectiveness of DMHL interventions.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"This systematic review and meta-analysis investigated the components and modes of DMHL interventions, their moderating factors, and their long-term impacts on mental health literacy and mental health.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,We used a random-effects model to conduct meta-analyses and meta-regressions on moderating effects of DMHL interventions on mental health.,,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Using 144 interventions with 206 effect sizes, we found a moderate effect of DMHL interventions in enhancing distal mental health outcomes (standardized mean difference=0.42, 95% CI ?0.10 to 0.73;ÿP<.001) and a large effect in increasing proximal mental health literacy outcomes (standardized mean difference=0.65, 95% CI 0.59-0.74;ÿP<.001). Uptake of DMHL interventions was comparable with that of control conditions, and uptake of DMHL interventions did not moderate the effects on both proximal mental health literacy outcomes and distal mental health outcomes. DMHL interventions were as effective as face-to-face interventions and did not differ by platform type or dosage.ÿDMHL plusÿinterventions (DMHL psychoeducation coupled with other active treatment) produced large effects in bolstering mental health, were more effective thanÿDMHL onlyÿinterventions (self-help DMHL psychoeducation), and were comparable with non-DMHL interventions (treatment as usual). DMHL interventions demonstrated positive effects on mental health that were sustained over follow-up assessments and were most effective in enhancing the mental health of emerging and older adults.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"For theory building, our review and meta-analysis found that DMHL interventions are as effective as face-to-face interventions. DMHL interventions confer optimal effects on mental health when DMHL psychoeducation is combined with informal, nonprofessional active treatment components such as skills training and peer support, which demonstrate comparable effectiveness with that of treatment as usual (client-professional interactions and therapies). These effects, which did not differ by platform type or dosage, were sustained over time. Additionally, most DMHL interventions are found in Western cultural contexts, especially in high-income countries (Global North) such as Australia, the United States, and the United Kingdom, and limited research is conducted in low-income countries in Asia and in South American and African countries. Most of the DMHL studies did not report information on the racial or ethnic makeup of the samples. Future work on DMHL interventions that target racial or ethnic minority groups, particularly the design, adoption, and evaluation of the effects of culturally adaptive DMHL interventions on uptake and mental health functioning, is needed. Such evidence can drive the adoption and implementation of DMHL interventions at scale, which represents a key foundation for practice-changing impact in the provision of mental health resources for individuals and the community.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Worldwide, mental illness is projected to have an economic cost of approximately US $6 trillion owing to poor productivity and negative health functioning [1]. The World Health Organization and World Federation for Mental Health have advocated for increasing global awareness of mental health [1]. To increase global understanding of and address mental health problems, researchers, policy makers, and mental health practitioners have long recognized the significance of individual- and society-level mental health literacy (MHL) [2]. MHL refers to ?knowledge and beliefs about mental disorders which aid their recognition, management, or prevention? [3]. Low MHL in the general public is a key impediment to seeking mental health treatment [2]. A multifaceted construct, MHL comprises (1) understanding how to prevent mental illness, (2) understanding when a disorder is developing, (3) awareness of support and treatments for mental illness, (4) ability to effectively address mild mental health problems, and (5) mental health first aid skills to support others [4]. In more recent work, MHL has been expanded to include knowledge about (1) obtaining and maintaining good mental health, (2) understanding mental illnesses and treatments, (3) reducing mental illness?related stigma, (4) enhancing help-seeking efficacy or behaviors, and (5) enhancing help-seeking attitudes or intentions [5,6].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Unlike the extensive body of work on health literacy and its relationship to positive health outcomes [2,5,7], research on MHL is more recent and less established in how it relates to or affects mental health functioning [2]. Accelerated by technological advancements and the recent global pandemic, there is burgeoning interest in digital mental health interventions that can be delivered at scale and translate to real-world benefits [8,9]. In particular, recent work has highlighted the use of digital platforms (eg, web-based platforms, apps, and social media) as key facilitators for building digital MHL (DMHL), especially among young people [10,11]. Web-based pedagogies; diverse educational content; and timely interactions with peer supporters, trainers, mental health professionals, and people with common lived experiences of mental illness afforded by digital platforms can effectively promote DMHL [10,11]. As a nascent field, research on DMHL has primarily focused on and been incorporated into mental health interventions, with few observational or field studies documenting DMHL in naturalistic settings in relation to mental health functioning [12,13].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Existing work on DMHL interventions is scattered, and findings about the effects of DMHL interventions on mental health are mixed [14]. These inconsistent findings on DMHL interventions stem from how components of DMHL can vary across studies [15,16] and whether interventions assess the impact on proximal literacy outcomes only (facets of DMHL) [17,18], distal mental health outcomes only (mental health symptoms and conditions) [19], or both [15,16]. In particular, some interventions focus on DMHL as the primary intervening component, in which self-help psychoeducation is used to access information and learn about mental health [16,20]. Other interventions combine DMHL psychoeducation with types of treatment such as skills training; peer support; group discussions and activities; exercises such as diary entries and reflection logs; and informal, nonprofessional counselor interactions [15,21]. Digital mental health interventions that use DMHL as a primary or secondary component often include and are compared with other non-DMHL interventions. These non-DMHL interventions include treatment as usual with professional therapies (eg, cognitive behavioral therapy [CBT] and dialectical therapy) and skills training (eg, mindfulness [22,23]). Although receiving professional mental health treatment likely improves knowledge about mental health symptoms and management (eg, MHL), such interventions are not specifically focused on literacy. As such, they are categorized as non-DMHL interventions. Thus, it is unclear whether DMHL psychoeducation is sufficient or whether interventions need to incorporate DMHL with other active treatment components to improve individuals? mental health.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Importantly, interventions with different DMHL components can have differential impacts on proximal and distal mental health outcomes [24,25]. DMHL interventions with DMHL psychoeducation can increase knowledge and beliefs about recognition, management, or prevention of mental disorders (the 5 facets of DMHL described previously) and likely have a greater impact on proximal (eg, knowledge, attitudes, and beliefs) than on distal (eg, improved mental health) [16] mental health outcomes. DMHL interventions coupled with active treatment components, on the other hand, may enhance both proximal and distal mental health outcomes [15]. Meta-analyses have focused on digital mental health treatment interventions such as professional therapies and skill-based training (eg, CBT and mindfulness meditation, respectively) [26]. There are no studies that evaluate the impact of DMHL interventions on both proximal and distal mental health outcomes or that consider psychoeducation alone or in conjunction with treatment. Research effort is required to synthesize findings across studies to draw inferences about the impact of DMHL interventions on mental health?specifically, whether DMHL interventions are fundamentally effective (ie, pretest-posttest DMHL intervention comparisons) and more effective than well-controlled conditions (ie, waitlist control and non-DMHL interventions).",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Scholars have argued that DMHL interventions combine ease of access and cost-efficiency with efficacy and are more effective on mental health [27,28]. DMHL interventions can overcome the shortcomings of traditional face-to-face MHL interventions, including low availability, a high threshold for participation, and substantial delivery costs [27,28]. DMHL interventions have several advantages [27,28]: (1) easy accessibility at any time and place; (2) assurance of anonymity to avoid stigmatization; (3) self-guidance for participants to work at their own pace and review materials as often as they want; (4) ability to reach individuals faster than traditional mental health services and prevent the onset of more severe mental health problems; and finally, (5) easy scalability, requiring only a small increase in resources to reach a greater proportion of the eligible population. Previous work has found that DMHL interventions combine ease of access and cost-efficiency with efficacy [27,28], whereas traditional face-to-face mental health treatment interventions that include DMHL components require close to 8 times more therapist time than digital ones [29].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"DMHL interventions may also help populations that are not reached by existing traditional MHL approaches, particularly young people, whose lives are closely intertwined with digital media and are the primary users of web-based mental health resources [30]. DMHL interventions address 2 critical issues that traditional face-to-face MHL interventions encounter in targeting mental health, especially for youth mental health?concern for anonymity and limited reach [31]. For young people, the increased prevalence of mental health conditions, especially depression and anxiety [32,33], underscores the need to address major barriers to help-seeking behaviors, for instance, access, reach, and stigma [34]. Thus, DMHL interventions may play a particularly important role during adolescence and emerging adulthood as a cost-effective channel to intervene early in preventing mental illness and supporting mental health functioning [35].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"An accumulating body of work indicates that DMHL interventions can reduce the public health burden by decreasing burnout among working professionals and distress among students [36,37]. Poor MHL is a primary factor that hinders the uptake of, engagement in, and adherence to mental health treatment prevention and intervention [2]. DMHL interventions have the potential to not only provide greater access and reach and reduce stigma but also improve MHL among the public [34]. Indeed, research has shown that improved MHL can address self-identifying mental health difficulties and enhance help-seeking intentions and behaviors, which are key to initial engagement in and subsequent adherence to treatment [2]. Thus, DMHL intervention is an upstream form of mental health prevention that can reduce the need for downstream intervention [1]. For instance, incorporating DMHL into mental health initiatives as a regular form of psychoeducation can target psychological readiness for enhancing mental health functioning [38]. DMHL may also function as a mental health resilience factor that protects individuals from and mediates the negative effects of adversity and risk factors for the development of psychopathology [39].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"However, there is no conclusive evidence demonstrating the effectiveness of DMHL interventions compared with traditional face-to-face MHL interventions in bolstering mental health [40,41]. To establish evidence-based practices for DMHL interventions, an integrated and comprehensive investigation of DMHL features and affordances, as well as individual and contextual factors that amplify or attenuate the effectiveness of DMHL interventions on mental health, is needed [8,9]. The primary aim of our systematic review and meta-analysis was to evaluate the effectiveness of DMHL interventions on mental health by targeting several objectives. First, we addressed the lacunae in our current understanding of DMHL interventions by synthesizing findings across studies to ascertain how DMHL interventions compare with traditional face-to-face MHL interventions. Next, we assessed whether and how different DMHL components in DMHL interventions affect mental health outcomes. Third, we investigated the effectiveness of DMHL interventions on proximal MHL outcomes (eg, knowledge, attitudes, and beliefs) and distal mental health outcomes. Fourth, we established whether a strong inference can be drawn about the effectiveness of DMHL interventions?whether they are fundamentally effective (ie, pretest-posttest DMHL intervention comparisons) and more effective than well-controlled conditions. Finally, we amalgamated findings across studies to establish the long-term implications (carryover effects) of DMHL interventions for mental health functioning. A secondary aim was to identify moderating factors that amplify or attenuate the effectiveness of DMHL interventions, particularly DMHL features and affordances (new vs conventional platforms and dosages of intervention) and individual (sex, developmental differences, and severity of preexisting mental health conditions) and contextual (cultural contexts) factors.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"With the burgeoning interest in digital mental health interventions, which combine scalability, translation to real-world benefits, and cost-efficiency with efficacy [8,9], substantive research has been devoted to understanding whether and how digital modes of delivering mental health services, including DMHL, are superior to or comparable with traditional face-to-face delivery [8,9]. Efforts to synthesize studies to compare the mental health impact of DMHL and traditional modes of MHL interventions are warranted to provide conclusive evidence on the effectiveness of DMHL interventions. In particular, research has focused on the implementation and clinical effectiveness of digital mental health interventions broadly (but not on DMHL specifically) by assessing uptake (ie, engagement and adherence) and mental health outcomes [26], respectively. Although there is evidence that digital mental health interventions increase uptake and engagement and that greater intervention uptake enhances mental health functioning [26], similar evidence specific to DMHL is lacking. DMHL studies are scattered in their efforts to understand the impact of DMHL interventions in terms of both uptake and intervening in mental health outcomes and whether intervention uptake affects mental health outcomes.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Drawing from reviews and meta-analyses on digital mental health interventions (in the absence of similar work on DMHL), findings indicate that most interventions are implemented and evaluated in high-income countries (Global North) involving White samples [42-44]. Given existing mental health disparities that are compounded with the mental health costs of marginalization, racial and ethnic minority groups face greater mental health risks, including limited access to and greater barriers to engaging in digital treatment interventions for mental health [42-44]. Such findings underscore the need to attend to the ethnic or racial composition of the samples to understand the overall effectiveness of digital mental health interventions, including DMHL, on uptake and mental health outcomes. In considering impact, scholars and practitioners have called for attention to the long-term mental health implications of DMHL?specifically, the carryover effects of DMHL interventions on mental health functioning [36,45]. For instance, some DMHL interventions demonstrate no carryover effects [46,47], whereas others yield 3, 6, or 12 weeks of carryover effects [48,49]. Such evidence can drive the adoption and implementation of evidence-based DMHL interventions at scale, which represents a key foundation for practice-changing impacts in the provision of mental health resources for individuals and the community.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Our review of the DMHL intervention literature found that DMHL is typically the primary component?specifically, self-help DMHL psychoeducation that involves acquiring knowledge and information on mental health (hereafter referred to asÿDMHL onlyÿ[16,20])?or a secondary component, incorporating DMHL psychoeducation with other active treatment components such as skills training; peer support; group discussions and activities; exercises such as diary entries and reflection logs; and informal, nonprofessional counselor interactions [15,21]. We refer to those interventions with DMHL as a secondary component asÿDMHL plus. To establish the effectiveness of DMHL interventions, it is necessary to consider the DMHL component of each intervention. DMHL interventions have predominantly focused on comparing mental health outcomes through the following DMHL components: (1)ÿDMHL onlyÿ(vs waitlist control [20]), (2)ÿDMHL plusÿ(vs waitlist control [15,16,50]), (3)ÿDMHL onlyÿversusÿDMHL plusÿ[21,51], and (4)ÿDMHL onlyÿorÿplusÿversus non-DMHL (treatment as usual with professional therapies such as CBT and dialectical therapy [28,52]). Although receiving professional mental health treatment likely improves knowledge about mental health symptoms and management (eg, MHL), such interventions are not specifically focused on literacy. As such, they are categorized as non-DMHL interventions. Studies often compare the effectiveness of different intervention components on mental health outcomes with inconsistent findings. To ascertain whether DMHL interventions are fundamentally effective (pretest-posttest comparison) and whether stronger inferences about the effect of DMHL interventions can be drawn?that is, how they compare with control and other intervention conditions?we synthesized findings across three study designs: (1) pre- and postintervention comparison [53,54], (2) intervention group versus (waitlist) control group [49,54], and (3) DMHL intervention versus non-DMHL intervention [28,49].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Findings on the effectiveness of DMHL interventions on mental health outcomes are mixed, with some studies demonstrating positive effects [39,49] and others finding none [28,53]. A possible reason for these inconsistent findings is the contradictory ways of conceptualizing and operationalizing DMHL and mental health outcomes in DMHL interventions. Although most interventions include a DMHL component, few draw on the long-standing MHL paradigm [16,55]. Hence, for most interventions, it is often ambiguous which of the five facets of MHL were examined, including one or some combination of them [15,56]: (1) knowledge about obtaining and maintaining good mental health, (2) understanding mental illnesses and treatments, (3) reducing mental illness?related stigma, (4) enhancing help-seeking efficacy or behaviors, and (5) enhancing help-seeking attitudes or intentions [4].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Traditional face-to-face MHL interventions have found improvements in proximal mental health outcomes, particularly 1 or a combination of the 5 facets of MHL as well as distal mental health outcomes involving mental health conditions and functioning [56,57]. Extrapolating these findings to DMHL interventions, interventions targeting or incorporating different facets of MHL may have differential impacts on proximal and distal mental health outcomes [15,20]. However, there are insufficient DMHL studies that have investigated the 5 facets separately to distinguish their effects on mental health. Most studies have created composite variables of DMHL that comprise different combinations of the 5 facets [15,20]. Thus, with the available research on DMHL interventions, the synthesis of findings across studies is possible as a composite DMHL construct intervening in mental health to provide a conclusive understanding of the mental health impact of DMHL interventions.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Furthermore, DMHL interventions are inconsistent in whether they assess proximal outcomes only [17,18], distal outcomes only [19,54], or a combination of both increased literacy outcomes and better mental health conditions [21,28]. DMHL research often fails to acknowledge how changes in proximal DMHL outcomes factor in the effects of DMHL interventions on distal outcomes?mental health functioning [49,54]. Thus, research that distinguishes the effectiveness of DMHL interventions on both proximal DMHL outcomes and distal mental health outcomes is warranted. In addition, studies have obtained inconsistent findings on the effectiveness of DMHL interventions on the same mental health outcomes, such as depression [49,54], as well as across different mental health outcomes [58,59]. On the basis of the body of work on traditional face-to-face MHL interventions, researchers have argued for the importance of examining MHL with specific mental health outcomes (eg, eating disorders and depression) [2]. However, research on DMHL is in its infancy, and the existing literature contains insufficient estimates to test the impact of DMHL interventions on the range of mental health outcomes.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"To build a strong economic case for investing in digital mental health interventions that have clinical effectiveness (ie, reducing mental ill health and symptoms) broadly and on DMHL specifically, a key consideration is the dosage of the intervention [60]. Intervention durations that are too long or too short can affect its effectiveness [60], and typical digital mental health interventions that include DMHL components have a median dosage of 10 weeks [61,62]. However, it remains ambiguous whether this median of 10 weeks of intervention has a positive impact on mental health [60] and how it applies to the effectiveness of DMHL interventions. Hence, conclusive findings comparing different treatment dosages of DMHL interventions that demonstrate improvements or changes in mental health are necessary. Scholars have also argued that the features and affordances of digital platforms can factor into the effectiveness of digital mental health interventions by influencing users? initial uptake and sustained engagement [8,9]. Accumulating research indicates that technological affordances can vary across platforms, from linear, static websites to more interactive social media platforms and mobile apps [8,9]. Specifically, DMHL interventions are commonly delivered through new and more conventional platforms. New platforms involving mobile apps, web-based or internet applications, and social media afford greater interactivity [20,54], whereas more conventional platforms, including films, videos, multimedia, and emails, afford lower or limited interactivity [17,18]. Thus, this review considered how the duration of the intervention and platform of delivery affect outcomes.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Drawing from meta-analyses and systematic reviews of digital mental health interventions, individual factors related to preexisting physical and mental health conditions can modulate the effectiveness of interventions [8]. Physical illnesses such as rheumatoid arthritis can interact and generate or exacerbate mental health problems and reduce the effectiveness of interventions [63]. The severity of one?s preexisting mental illness can limit intra- and interpersonal resources (ie, motivation and supportive relationships, respectively) for uptake of, engagement in, and adherence to digital mental health interventions, thus reducing their effectiveness [8]. Extending these arguments to DMHL interventions, some research has shown that individual factors, particularly being female and having a mental health problem, are associated with relatively high levels of MHL and reduced effects of DMHL interventions on mental health outcomes (a possible ceiling effect [64]). However, these moderating effects of sex and preexisting mental health conditions on the intervening effectiveness of DMHL interventions are tentative and not consistently documented across studies [64,65]. Thus, the characteristics of individuals need to be considered as important moderators.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Culture is a moderating contextual factor in the effectiveness of digital mental health interventions [66], but there is a dearth of research that investigates different cultures. Existing literature only allows for a comparison of the effects of DMHL interventions across Western and Eastern cultural contexts [67,68]. In more independence-oriented Western cultural contexts, values and norms are focused on developing a healthy sense of self, including positive mental health [67,68]. There is greater public awareness of mental health; less social stigma associated with help-seeking behaviors; and more concerted efforts to build mental health resiliency through the adoption and implementation of digital mental health interventions, including DMHL interventions [67,68]. Thus, in Western cultural contexts, greater MHL and a focus on mental health may amplify the effects of DMHL interventions. In contrast, most collectivistic, interdependence-oriented Asian societies are conservative in addressing mental health [67], and they promote MHL and positive mental health functioning in ways that differ from those of individualistic Western cultural contexts, for instance, cultivating interdependence relationships, relational harmony, and dialectical beliefs and emotions?a balanced state of opposites, including experiencing both positive and negative emotions, which are fused with and change into each other [68]. The increase in awareness of mental health issues is relatively recent, especially in contemporary Asian societies [69,70], which may be associated with weaker impacts of DMHL interventions on mental health [71]. The paucity of reviews and meta-analytic efforts that synthesize findings across international studies on digital mental health interventions makes findings about cultural context tentative and underscores the importance of this consideration in this study.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"To our knowledge, no systematic review or meta-analysis has evaluated the effectiveness of DMHL interventions on mental well-being or the moderating factors between these 2. To this end, our efforts to synthesize findings across studies focused on the main mental health impacts of DMHL interventions. First, we ascertained how DMHL interventions compare with traditional face-to-face MHL interventions in affecting mental health outcomes. Second, we examined the effects of DMHL interventions on the implementation outcome of uptake and the proximal DMHL outcomes and distal mental health outcomes. In addition, we examined whether uptake of DMHL interventions affects the impact on the proximal DMHL outcomes and distal mental health outcomes. Third, we investigated the impact of DMHL interventions on mental health through the following DMHL components: (1)ÿDMHL onlyÿ(self-help DMHL psychoeducation that entails acquiring knowledge and information), (2)ÿDMHL plusÿ(DMHL psychoeducation combined with skills training; peer support; group discussions and activities; exercises such as diary entries and reflection logs; and informal, nonprofessional counselor interactions), (3)ÿDMHL onlyÿversus non-DMHL (treatment as usual through professional therapies such as CBT and dialectical therapy), and (4)ÿDMHL plusÿversus non-DMHL. Fourth, our review and meta-analytic efforts provide evidence for a stronger inference on the effectiveness of DMHL interventions on mental health functioning by combining and comparing results across three study designs: (1) pre- and postintervention comparison, (2) intervention group versus (waitlist) control group, and (3) DMHL intervention versus non-DMHL intervention. Fifth, we addressed the gap in the current literature regarding the long-lasting effectiveness of DMHL interventions on mental health by assessing carryover effects. Finally, we considered potential moderators of treatment effects, including dosage, platform, individual characteristics, and culture.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"In addressing these main effects, our meta-analytic efforts conceptualized and operationalized DMHL as a composite construct to understand its mental health impacts as there are limited studies that have examined all 5 facets of DMHL and mental well-being conjointly and separately. Thus, there are insufficient studies (and number of effect sizes) to determine how the 5 facets of DMHL compare in their impacts on mental health. Although scholars have argued for the study of digital mental health interventions for specific mental health outcomes (eg, depression vs anxiety vs eating disorders [8,9]), the limited number of studies in the literature renders it impossible to study such specific effects, particularly for DMHL interventions. On the basis of the literature reviewed previously, we examined the following research questions (RQs) and hypotheses:",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,1. What is the effect of DMHL interventions on uptake as an implementation outcome? (RQ 1a),,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"2. What are the effects of DMHL interventions on proximal literacy outcomes (ie, DMHL outcomes) and distal mental health outcomes? (RQ 1b)",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,3. Does the uptake of DMHL interventions moderate the effects on proximal literacy outcomes and distal mental health outcomes? (RQ 1c),,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"4. How do DMHL interventions with different DMHL components or conditions compare in their impact on mental health (DMHL only,ÿDMHL plus,ÿDMHL onlyÿvs non-DMHL, andÿDMHL plusÿvs non-DMHL)? (RQ 2a)",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"5. Do DMHL interventions demonstrate a stronger inference on intervening in mental health functioning? Specifically, what are the effects of DMHL interventions in pretest-posttest comparisons, (waitlist) control groups versus intervention groups, and DMHL interventions versus non-DMHL interventions? (RQ 2b)",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,6. Are there sustained or carryover effects of DMHL interventions on mental health? (RQ 3),,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,7. DMHL interventions are as effective as traditional face-to-face MHL interventions in bolstering mental health (hypothesis 1).,,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"8. DMHL interventions administered through new platforms that afford greater interactivity (ie, mobile apps, web-based or internet platforms, and social media) than more conventional platforms (ie, films, videos, multimedia, and emails) have greater positive impacts on mental health (hypothesis 2).",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,9. DMHL interventions with a dosage of 10 weeks are most effective in increasing mental health functioning (hypothesis 3).,,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,10. DMHL interventions demonstrate reduced effects on mental health in female participants compared with male participants (hypothesis 4a).,,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,11. DMHL interventions have a lower impact on mental health in individuals with greater severity of preexisting mental health conditions (hypothesis 4b).,,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"12. DMHL interventions have greater effects in adolescents than in participants at other developmental stages (ie, emerging adulthood and older adulthood; hypothesis 4c).",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,13. The intervening effectiveness of DMHL interventions on mental health is greater in Western than in Eastern cultural contexts (hypothesis 5).,,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,This meta-analysis was conducted according to the guidelines from Quintana [72] and reported based on the latest version of the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines [73]. A protocol was registered a priori following the PRISMA guidelines (PROSPERO registration CRD42023363995).,,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"With the assistance of a staff librarian at the first author?s affiliated institution, 2 research assistants independently used 3 search strategies to systematically identify studies on DMHL and mental health. The 3 search strategies; search terms that were developed using the Population, Intervention, Comparison, and Outcome search strategy; and full search strings are provided in Tables S1 to S3 inÿMultimedia Appendix 1.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Study screening was conducted using the Covidence software (Veritas Health Innovation) [74].ÿFigure 1ÿpresents a flowchart of the study selection process. Of the 42,014 records identified in the initial searches, 20,137 (47.93%) were duplicates. First-stage screening of the 21,879 (52.08%) remaining records entailed checking of titles and abstracts by 2 reviewers, which led to the elimination of 21,459 (98.08%) of the 21,879 records. From the 420 (1.92%) of the 2,1879 records sought for retrieval, 55 (13.1%) of the 420 records were not retrieved due to the lack of an English full-text pdf article. The remaining 367 (87.4%) records selected for full text review were independently screened by another 2 reviewers with any discrepancies resolved through consensus. A third reviewer was contacted if consensus could not be reached. Inclusion and exclusion criteria were established a priori and are included in Tables S1 to S3ÿMultimedia Appendix 1.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"A total of 146 studies with 208 effect sizes were included in our meta-analyses, with 2 (1.4%) field studies reporting relevant correlation coefficients and 144 (98.6%) intervention studies providing sufficient statistics to compute the standardized mean difference (SMD; Cohenÿd), which contributed 2 and 206 effect sizes, respectively. Although DMHL interventions are examined in field studies and as interventions in experimental studies, it is methodologically feasible to examine both field and experimental studies within the same meta-analysis [75,76]. However, we excluded the field studies (2/146, 1.4%) as they contributed only 2 effect size estimates, which are insufficient for a comparison of the relationship between DMHL and mental health across field and intervention studies.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"In total, 2 independent reviewers (2 research assistants) extracted and coded data on multiple aspects (seeÿMultimedia Appendix 2ÿ[77-81] andÿMultimedia Appendix 3ÿ[82,83] on study characteristics and summary and sample characteristics, respectively). The coders achieved 83% agreement on their codes. Any discrepancies in coding were discussed and resolved. Many of the interventions included in our meta-analysis (54/144, 37.5%) did not provide a measure of MHL. The 34% (49/144) of interventions that assessed DMHL outcomes primarily used the Mental Health Literacy Scale [84].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Studies included in the meta-analysis were independently evaluated for quality by 2 reviewers, with differences discussed and resolved. DMHL interventions were assessed using the instrument by Downs and Black [85] and the Cochrane Collaboration risk-of-bias tool [86]. We report these results inÿMultimedia Appendix 2.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"There were several instances in which the studies contributed multiple dependent effect sizes in our meta-analyses. Following the guidelines provided by Quintana [72], we dealt with this issue in 3 ways that we outlined in Figure S1 inÿMultimedia Appendix 4ÿ[82,83].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"A total of 3 analyses were used to ascertain publication bias, and the results are reported in Figure S1 inÿMultimedia Appendix 5.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Data were analyzed using RStudio (version 4.0.0; Post, PBC) with theÿmetaforÿandÿrobumtaÿpackages (version 3.02) [87-89].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Summary and sample characteristics of the included DMHL intervention studies, as well as of traditional face-to-face MHL intervention studies, are presented in Tables S1 and S2 inÿMultimedia Appendix 2. We included a forest plot to visualize the effect sizes and CIs from the included studies with a computed summary effect size (Multimedia Appendix 5). In the following sections, we present the results that address each hypothesis and RQ.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"As hypothesized, DMHL interventions had similar effectiveness to that of traditional face-to-face MHL interventions in bolstering mental health (Qbetween=4.12;ÿP=.18; hypothesis 1; Table S3 inÿMultimedia Appendix 2). Addressing RQ 1a, DMHL interventions versus control conditions had comparable effects on uptake (odds ratio 0.998, 95% CI 0.91-1.03;ÿP<.001; Table S4 inÿMultimedia Appendix 2). For RQ 1b, we found a high effect of DMHL interventions in increasing proximal literacy outcomes (ie, 5 facets of DMHL), with a pooled effect size of SMD=0.65 (95% CI 0.59-0.74;ÿP<.001), and a moderate effect in enhancing distal mental health outcomes, with a pooled effect size of SMD=0.42 (95% CI ?0.10 to 0.73;ÿP<.001). Unfortunately, few studies (2/144, 1.4%) differentiated the 5 facets of DMHL, and thus, we were unable to assess the effects of each DMHL facet on the outcomes. For RQ 1c,ÿwe found that uptake of DMHL interventions did not moderate the effect of the interventions on proximal literacy outcomes (Qbetween=1.07;ÿP=.30). Subgroup comparisons of (1) DMHL interventions with baseline and completer samples that were similar in baseline and demographic characteristics, (2) DMHL interventions that did not provide information on baseline and completer samples? baseline and demographic characteristics, and (3) DMHL interventions with baseline and completer samples that were different in baseline and demographic characteristics indicated no significant difference in impacts on MHL outcomes (Qbetween=1.19;ÿP=.55). Similarly, our results revealed that the uptake of DMHL interventions did not moderate the effect of the interventions on distal mental health outcomes (Qbetween=0.17;ÿP=.68). Subgroup comparisons of (1) DMHL interventions with baseline and completer samples that were similar in baseline and demographic characteristics, (2) DMHL interventions that did not provide information on baseline and completer samples? baseline and demographic characteristics, and (3) DMHL interventions with baseline and completer samples that were different in baseline and demographic characteristics indicated no significant difference in impacts on mental health outcomes (Qbetween=5.21;ÿP=.08).",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"For RQ 2a, we compared DMHL interventions with DMHL alone or with additional aspects (ie,ÿDMHL onlyÿvs waitlist control conditions,ÿDMHL plusÿvs waitlist control conditions,ÿDMHL onlyÿvsÿDMHL plus, andÿDMHL plusÿvs non-DMHL).ÿQÿstatistics analyses comparing these 4 conditions indicated that they differed significantly (Qbetween=9.45;ÿP=.01). The effect size ofÿDMHL onlyÿversus waitlist control was comparable with that ofÿDMHL plusÿversus waitlist control but greater than that ofÿDMHL onlyÿversusÿDMHL plusÿandÿDMHL plusÿversus non-DMHL (Table S1 inÿMultimedia Appendix 3). To address RQ 2b, we synthesized the effect sizes from 44.4% (64/144) of the DMHL interventions to elucidate whether we could draw stronger inferences about the effectiveness of DMHL interventions in increasing mental health.ÿQÿstatistics analyses comparing the effect sizes of pretest-posttest DMHL intervention comparisons, waitlist control conditions versus DMHL interventions, and DMHL versus non-DMHL interventions revealed that they differed significantly (Qbetween=12.09;ÿP<.001), with higher effect sizes for pretest-posttest DMHL intervention comparisons and waitlist control conditions versus DMHL interventions than for DMHL versus non-DMHL interventions. For RQ 3, subgroup comparison of DMHL interventions that assessed mental health outcomes at the postintervention time point and those with follow-up assessments indicated that they did not differ significantly (Qbetween=3.81;ÿP=.06), with the effect sizes for interventions that assessed postintervention effects on mental health and those that assessed follow-up effects being comparable. Consistently, the carryover effects of DMHL interventions on mental health did not attenuate over time (Qbetween=1.65;ÿP=.20; Table S1 inÿMultimedia Appendix 3); the positive effects of DMHL interventions on mental health remained notwithstanding longer follow-up assessments.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"We investigated potential moderators of DMHL interventions on mental health functioning (Table S1 inÿMultimedia Appendix 6ÿ[90]) by performing subgroup analyses using meta-regressions to examine DMHL platform affordances (new interactive platforms, including mobile apps, web-based or internet platforms, and social media, vs conventional platforms, including films, videos, multimedia, and emails) and dosage of DMHL interventions as moderators. For dosage, we compared DMHL interventions of <10 weeks, 10 weeks, and >10 weeks. Contrary to hypothesis 2, DMHL interventions administered through new platforms that afford greater interactivity than more conventional platforms did not differ significantly in their impacts on mental health (Qbetween=2.51;ÿP=.31). In contrast to hypothesis 3, we found that the dosage of the DMHL interventions did not moderate their effectiveness on mental health outcomes (Qbetween=2.13;ÿP=.32), and similar positive intervening effects were found for all 3 dosage categories (Table S1 inÿMultimedia Appendix 3).",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Developmental stages, including adolescence, emerging adulthood, and adulthood; sex, which was measured as the average proportion of participants in the sample who were female; and severity of mental health conditions at baseline were used as continuous predictors in testing their moderating effects. Contrary to hypothesis 4a, sex (Qbetween=2.01;ÿP=.34) did not moderate the impact of DMHL interventions on mental health. Contrary to our hypothesis, DMHL interventions were more effective in enhancing the mental health of emerging and older adults than that of adolescents (hypothesis 4b;ÿQbetween=12.19;ÿP=.001), and the severity of mental health conditions did not attenuate the effect of DMHL interventions on mental health (hypothesis 4c;ÿQbetween=0.29;ÿP=.45; Table S1 inÿMultimedia Appendix 6).",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"The studies included in the meta-analyses involved 23 countries, but there were not enough studies from each country to allow for a comparison of effect sizes among individual countries. Instead, we followed the common approach of comparing Western and Eastern cultures [68,91]. Representatives of Western culture included Australia, Canada, Germany, the Netherlands, the United Kingdom, and the United States, whereas representatives of Eastern culture included China, Hong Kong, Pakistan, Singapore, and Taiwan. In contrast to hypothesis 5, we found that DMHL interventions conducted in Western and Eastern cultural contexts did not differ significantly in their effectiveness on mental health (Qbetween=1.13;ÿP=.64; Table S1 inÿMultimedia Appendix 6).",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"The rise in mental health issues worldwide accelerated during the pandemic, highlighting the need for upstream mental health prevention [1]. A key approach to mental health prevention is to build individuals? resiliency, which can protect them from and mediate the negative impacts of adversity and risk factors for the development of psychopathology [54]. Recent work on digital mental health interventions, particularly with DMHL, provides evidence for DMHL as a resilience factor that might mitigate stress and mental health conditions among working adults and students [36,37]. DMHL interventions combine ease of access with low cost, which has the potential to reduce public burden on a global scale by intervening in the mental health of individuals [27,28]. Overcoming the shortcomings of traditional face-to-face MHL interventions?specifically, low availability, high threshold for participation, and substantial delivery costs [27,28]?DMHL interventions may be more effective in addressing low levels of MHL in the public [2], which is an impediment to the uptake of, engagement in, and adherence to mental health prevention and intervention [2]. However, research on the effectiveness of DMHL interventions is scattered, and findings on their impact on mental health outcomes are inconclusive. This systematic review and meta-analysis is the first to provide empirical findings on the mental health implications of DMHL interventions.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"First, we found that DMHL interventions are as effective as face-to-face interventions in improving MHL (SMD=0.64) and enhancing mental health functioning (SMD=0.42). DMHL interventions greatly improved pretest-posttest proximal DMHL outcomes, which involved various combinations of the 5 DMHL facets?knowledge about obtaining and maintaining good mental health; understanding mental illnesses and treatments; reducing stigma and enhancing help-seeking efficacy and attitudes; and more distal mental health conditions, such as anxiety, depression, loneliness, and distress; and bolstering well-being. Interestingly, we did not find greater uptake of and engagement with DMHL interventions (compared with control conditions), and uptake of DMHL interventions did not moderate the effects on both proximal MHL outcomes and distal mental health outcomes.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Second, our comparison of different DMHL intervention components and conditions, which includedÿDMHL onlyÿ(self-help DMHL psychoeducation) versus waitlist control conditions,ÿDMHL plusÿ(DMHL psychoeducation incorporated as a secondary component in other active treatments) versus waitlist control conditions,ÿDMHL onlyÿversusÿDMHL plus, andÿDMHL plusÿversus non-DMHL (treatment as usual involving client-professional interactions and therapies such as CBT and dialectical therapy), found differential impacts on mental health outcomes. Compared with waitlist control conditions,ÿDMHL onlyÿ(SMD=0.59) andÿDMHL plusÿ(SMD=0.45;ÿP=.02) had similar positive mental health impacts. The effect size ofÿDMHL onlyÿversus waitlist control was significantly greater than that ofÿDMHL onlyÿversusÿDMHL plusÿ(SMD=?0.35;ÿP=.02), which indicates that the effectiveness ofÿDMHL onlyÿinterventions on mental health was significantly lower than that ofÿDMHL plusÿinterventions. On the other hand, the effect size ofÿDMHL plusÿversus waitlist control was similar to that ofÿDMHL onlyÿversusÿDMHL plusÿandÿDMHL plusÿversus non-DMHL (SMD=?0.33;ÿP=.02). In other words, compared with waitlist control conditions,ÿDMHL only, and non-DMHL,ÿDMHL plusÿhad similar positive effects on mental health.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Third, we elucidated whether stronger inferences can be drawn about the intervening effectiveness of DMHL interventions on mental health?whether they are fundamentally effective (pretest-posttest comparison) and more effective than (waitlist) control conditions or other (ie, non-DMHL) interventions. We found larger effect sizes for pretest-posttest DMHL intervention comparisons and waitlist control conditions versus DMHL interventions than for DMHL versus non-DMHL interventions. By comparing immediate and long-term effects, we found the benefits of DMHL interventions to be comparable at postintervention and follow-up assessments, with sustained effects on mental health regardless of longer follow-up assessments. This lack of fade-out of DMHL impacts is important and suggests that being more literate about mental health (recognition, prevention, and management) has long-term benefits for mental well-being. Finally, when considering how individual and contextual characteristics and dissemination methods might moderate the efficacy of DMHL interventions, we found no differences by sex, severity of preexisting mental health conditions, and cultural contexts and only slightly more efficacy in emerging and older adults than in adolescents. Our review and meta-analytic results indicate that digital platform interactivity and dosage of DMHL interventions do not enhance their efficacy. In particular, both new (involving mobile apps, web-based or internet platforms, and social media) and conventional (including films, videos, multimedia, and emails) platforms did not differ significantly in their impacts on mental health. The commonly administered dosage of 10 weeks for digital mental health interventions, including those with DMHL components, demonstrated a similar positive intervening effect on mental health to that of interventions with dosages below and above 10 weeks.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"We found that DMHL interventions had a similar impact on mental health to that of traditional face-to-face MHL interventions. Engagement with DMHL interventions, which was assessed as the percentage of users who completed the intervention, ranged from 13.1% to 100% (dropout of 0% to 86.9%). However, participation in DMHL interventions did not differ from that in the control conditions, and uptake of DMHL interventions did not moderate their impact on proximal (DMHL) or distal (mental health) outcomes. Studies of the facilitators of and barriers to the uptake of digital mental health interventions argue that engagement affects intervening effectiveness on mental health outcomes [8,26]. Our review and meta-analysis found limited work on the implementation effectiveness of DMHL interventions involving engagement and uptake that was focused primarily on attrition, indicating a need for future studies to consider other engagement indicators that demonstrate participation in interventions [8,26]. For instance, studies could consider the extent of content accessed (eg, number of modules completed) or engagement in intervention-related activities (eg, number of log-ins or visits, time spent, specific activities or exercises completed, and number of web-based interactions with therapists or peers) [8,26].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Unlike the well-established research on traditional forms of mental health interventions [2], research on digital mental health interventions that leverage technological advancement is nascent [9,41]. Therefore, our findings make important contributions to the growing body of evidence that the implementation and clinical effectiveness of digital mental health interventions are comparable with, if not superior to, those of their traditional face-to-face counterparts [40]. Our study highlights the need for future research to elucidate the development and deployment practices of DMHL interventions for mental health that are scalable and cost-effective and maximize reach [92,93], which can overcome the shortcomings of traditional face-to-face MHL interventions [27,28]. In addition, our meta-analytic results indicate that DMHL interventions have a moderate effect on enhancing mental health outcomes and a strong effect on literacy outcomes. These findings suggest a mechanism of change involving MHL as a mediator or proximal outcome that in turn affects the distal outcomes of mental health conditions [94]. Given that few studies have examined the 5 facets of DMHL conjointly and separately with mental health functioning [16,55], research is needed to elucidate whether and how the 5 facets of DMHL relate to mental health?in particular whether certain facets are essential (or not) or whether combinations of facets yield stronger impacts.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Our meta-analytic efforts to synthesize and compare findings on interventions with different DMHL components revealed aspects of DMHL interventions that were the most promising or effective in bolstering mental health functioning. In particular,ÿDMHL plus, which incorporated DMHL as a secondary component with other active treatment components such as skills training; peer support; group discussions and activities; exercises such as diary entries and reflection logs; and informal, nonprofessional counselor interactions [15,21], was the most effective. DMHL plus interventions were superior to waitlist control [15,50] andÿDMHL onlyÿconditions [21,51] and comparable with non-DMHL interventions in enhancing mental health functioning [28,52]. Such findings are not surprising given thatÿDMHL plusÿincludes some form of active treatment. However, basic forms of DMHL intervention that involve self-help DMHL psychoeducation that builds MHL can be more effective in bolstering mental health than the absence of such interventions [20,21]. This notion was supported by our findings?DMHL onlyÿinterventions that involved self-help DMHL psychoeducation were more effective than waitlist control conditions in enhancing mental health functioning, with large effect sizes. Beyond fundamental effectiveness, in which mental health increases after as compared with before the intervention, DMHL interventions effectively enhanced mental health as compared with waitlist control conditions [21,51]. DMHL interventions had similar effectiveness to that of non-DMHL interventions such as treatment or care as usual that involved professional therapies [28,52].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Our review and meta-analytic results help reconcile the inconsistent findings on the effect of DMHL interventions on mental health documented in the existing literature that resulted from the comparisons of different DMHL components and study designs [15,16]. Although scholars argue that digital mental health interventions, especially DMHL interventions, have the potential to intervene in the mental health of individuals, the absence of consolidated evidence for DMHL interventions? (clinical) effectiveness presents a roadblock in promoting DMHL as a form of mental health prevention on a global scale [8,9]. Our meta-analytic efforts provide strong support for DMHL interventions achieving mental health effects. DMHL psychoeducation alone or coupled with active treatments is effective in bolstering mental health functioning compared with no intervention. However, for optimal mental health impact, self-help DMHL psychoeducation is not as effective as that provided with other active treatment components, such as skills training; peer support; group discussions and activities; exercises such as diary entries and reflection logs; and informal, nonprofessional counselor interactions. Of note, DMHL interventions that incorporated DMHL into other active treatment components had similar effectiveness to that of treatment as usual and professional therapies (non-DMHL interventions). These findings lend credence to DMHL as a scalable upstream prevention that translates to real-world mental health benefits in bolstering individuals? mental health functioning [8,9].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Our synthesis of findings across studies on the overall effectiveness of DMHL interventions on mental health, combined with current work demonstrating the ease of access and cost-efficiency of DMHL interventions [27,28], supports the adoption and implementation of DMHL interventions at scale. Such efforts are beneficial at the simple level of self-help DMHL psychoeducation but are even more impactful when coupled with other active treatments. Interventions that combined DMHL with other treatments had the same mental health impact as treatment as usual and professional therapies. Such findings underscore the importance of rigorous intervention designs that examine different components. In particular, using randomized controlled trials (RCTs) to compare and distinguish the impacts of DMHL in combination with different active treatment components such as skills training; peer support; group discussions and activities; exercises such as diary entries and reflection logs; informal, nonprofessional counselor interactions; and care as usual in changing mental health functioning is pivotal. Such a nuanced approach can ascertain how DMHL should be supplemented with active treatment as a necessary and sufficient intervening factor and to establish the relationship to proximal literacy outcomes and distal mental health functioning as mechanisms of change [91].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"A key concern regarding digital mental health interventions is their long-lasting impact [36,40]. Particularly for DMHL interventions, the focus on knowledge, beliefs, and attitudes surrounding mental health may render their effectiveness short-lived [46,47]. In contrast, digital mental health interventions such as internet-based CBT are more well established in targeting behavior change and long-term mental health impacts [26]. Our meta-analytic results provide evidence of sustained positive effects of DMHL interventions on mental health. Specifically, studies on DMHL interventions that evaluated immediate postintervention effects and those that assessed carryover effects for as long 34 weeks demonstrated comparable mental health outcomes, particularly in mitigating mental health problems such as depression, anxiety, loneliness, and internalizing and externalizing symptoms [24,25] and bolstering mental well-being, for instance, resilience, life satisfaction, and quality of life [55,95]. More importantly, the sustained effects of DMHL interventions on improved mental health were not attenuated with longer follow-up assessments.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"The long-term effects of DMHL interventions on mental health, which averaged 18.2 (SD 3.49; range 4-34) weeks in this synthesis, suggest that the 5 facets of DMHL may be involved in a chain reaction or cascade effect on mental health [94]. Details as to which facets could not be obtained because of a dearth of research that examined all 5 facets of DMHL and mental well-being conjointly and separately. Thus, there are insufficient studies (and number of effect sizes) to determine how the 5 facets of DMHL compare regarding their impacts on mental health. By building knowledge, beliefs, and attitudes regarding mental health, DMHL interventions may have adaptive functions that influence other domains or levels of function (eg, behavior change in treatment uptake and adherence) that spread over time to promote positive mental health development [94]. Future research should unravel the role of the 5 facets of DMHL in well-timed and targeted interventions that promote positive mental health cascades.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"The effect of DMHL interventions on mental health holds across new interactive platforms and more conventional, less interactive platforms. Although there are numerous studies examining affordances of digital platforms, such as asynchronicity, anonymity, and social interactions [9], we have a limited understanding of how specific platform affordances interact with mental health?whether they bolster positive mental health or generate and exacerbate mental health problems. Specific to our study, we investigated the interactivity afforded by new and conventional digital platforms in moderating the impact of DMHL interventions on mental health as there are limited studies on DMHL interventions that tap into the full range of digital modalities [9]. Studies investigating social media platforms note different types of affordances that vary across platforms [96]. Importantly, the additive and interactive effects of different affordances in a specific platform could amplify users? emotional experiences and expressions, resulting in heightened emotional lability and susceptibility to mental health conditions [96]. However, empirical work on whether and how the affordances of social media and other digital platforms affect the effectiveness of digital mental health interventions, including DMHL interventions, is lacking. Future work on DMHL interventions should consider specific platform affordances and their interactions when modulating intervention effectiveness.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Unexpectedly, our synthesis did not find dosage effect. Although other studies have found the median dosage or duration of interventions to be approximately 10 weeks [60], our meta-regressions indicated that DMHL interventions with a dosage of 10 weeks had similar impacts on enhancing mental health as dosages below and above 10 weeks. Our amalgamated findings suggest that the 10-week dosage that is commonly adopted by digital mental health interventions may not be optimal for DMHL interventions [61,62]. More research involving RCTs on digital mental health and DMHL interventions alike that examine the effects of varying dosages of interventions on mental health outcomes is warranted. However, our findings are promising given the challenges with mental health services and MHL intervention retention found in many countries [97,98]. Collectively, our meta-analysis and meta-regressions on the moderating role of DMHL intervention features provide important insights into best practices in DMHL that enhance mental health. Consistent with global efforts to raise mental health awareness and improve poor MHL in the public [1], this synthesis advances our understanding of DMHL by building a conceptual model of MHL [4] that could inform the design and implementation of evidence-based DMHL interventions [8].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"DMHL intervention effects in this synthesis were comparable across sex and severity of mental health conditions. Other studies have found that female participants have higher levels of MHL [64,65], which can moderate the effects of DMHL interventions on mental health outcomes. When controlling for pre- and postintervention levels of MHL, we found that DMHL interventions had equivalent effects on increasing the mental health functioning of both male and female participants. Contrary to findings on the reduced effectiveness of digital mental health interventions in individuals with mental illness or with physical ill health [8], we found that the severity of mental health conditions did not attenuate the effectiveness of DMHL interventions on the mental health of healthy populations. We expected DMHL interventions to demonstrate greater effects on adolescents than on emerging and older adults given that adolescents are the primary users of digital platforms such as social media, mobile apps, and web-based mental health resources [30]. However, DMHL interventions appear to be most effective in emerging and older adults. The conceptual model of MHL describes the 5 facets of DMHL as positively associated with maturity, cognitive advancement, and educational attainment in adulthood [4]. As such, this helps explain why DMHL interventions had a greater impact on emerging and older adults? mental health. With increasing mental health concerns in adolescence [32,33], future research needs to illuminate whether and how some facets of DMHL are applicable to bolstering adolescent mental health and target these facets in the design and implementation of DMHL interventions for youth mental health.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"In contrast to our hypothesis, the impact of DMHL interventions did not differ between Western and Eastern cultural contexts. Most Asian societies with collectivistic cultural characteristics are conservative in the way in which they address mental health concerns and often promote MHL and positive mental health functioning in ways that differ from those of Western cultural contexts with individualistic cultural characteristics. For instance, cultivating interdependence relations, relational harmony, and dialectical beliefs and emotions may be more common in Eastern cultures [68]. Furthermore, the Asian community as a whole, including policy makers, mental health professionals, and the public, is only beginning to embrace the notion of digital mental health interventions [99,100]. On the other hand, studies on digital mental health interventions, especially DMHL interventions, are conducted predominantly in Western cultural contexts in high-income countries (Global North) [8,9], where there is greater public awareness of and less stigma associated with mental health conditions and greater focus on developing a healthy sense of independent self, including positive mental health [67,68].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Consistent with most mental health research [42-44], Western cultural contexts were overrepresented in the DMHL interventions, particularly countries in the Global North such as Australia, the United States, and the United Kingdom. Comparatively, there are limited studies conducted in the Global South that involve Eastern cultural contexts in Asian countries and scant research on DMHL interventions from South American and African countries, limiting assessments of DMHL intervention effectiveness in the Global South. Furthermore, most studies on DMHL interventions included in this review did not provide information on the ethnic or racial composition of their samples, and those that provided this information had samples that were predominantly White with limited racial or ethnic diversity. Our findings reinforce existing research on digital mental health interventions broadly that indicated that these interventions were designed for and evaluated on implementation and clinical effectiveness with largely homogeneous samples that are disproportionately White, from the Global North, and likely cissex [42-44]. Findings from our review and meta-analysis on DMHL, coupled with those on digital mental health interventions [42-44], highlight the need for more consideration of diversity in research but broadly support the utility of DMHL interventions.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"In general, there is lower MHL, greater mental health stigma, and fewer services provided in the Global South [42-44]. DMHL interventions may be an important and accessible mental health resource that could not only provide greater access and reach and reduce stigma but also improve MHL among the public [42-44]. Our review found that DMHL interventions are implemented and evaluated mainly in Western cultural contexts in high-income countries [42-44] and some contemporary Asian societies [99,100]. Our results call for greater research attention to the design, implementation, and evaluation of culturally appropriate DMHL interventions in Asian, South American, and African countries, as well as more diversity in research in the Global North. Contextual stressors associated with racial and ethnic marginalization and mental health disparities, including lower access to and greater barriers to engaging in digital mental health interventions, underscore the need for future work on DMHL interventions specifically and digital mental health interventions broadly that target racial or ethnic minority groups [42-44].",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Our systematic review and meta-analysis highlights 4 major limitations in the broader literature on DMHL interventions. First, there is a lack of a clear conceptualization that distinguishes the DMHL components assessed in the interventions. Our review of existing literature and efforts to synthesize findings on the effectiveness of DMHL interventions suggest that, conceptually,ÿDMHL onlyÿinterventions refer to those that implement DMHL as a self-help psychoeducation component. In contrast,ÿDMHL plusÿinterventions incorporate DMHL as a secondary component with other active treatment components that are nonprofessional and informal in nature, for instance, skills training; peer support; group discussions and activities; exercises such as diary entries and reflection logs; and informal counselor interactions, and non-DMHL interventions refer to treatment as usual that involves client-professional visits, interactions, and therapies. Although receiving professional mental health treatment likely improves knowledge about mental health symptoms and management (eg, MHL), such interventions are not specifically focused on literacy. As such, they are categorized as non-DMHL interventions. These conceptual distinctions in DMHL interventional components have yet to be acknowledged in the current research despite the fact that all DMHL interventions included in our meta-analysis examined various conditions that could be classified asÿDMHL only,ÿDMHL plus, and non-DMHL.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Second, DMHL interventions are not always clear about the facet of DMHL examined and rarely refer to the theoretical framework of DMHL that distinguishes five literacy facets [5,6]: (1) knowledge about obtaining and maintaining good mental health, (2) understanding mental illnesses and treatments, (3) reducing mental illness?related stigma, (4) enhancing help-seeking efficacy or behaviors, and (5) enhancing help-seeking attitudes or intentions. We recommend that future research recognize the conceptualization of DMHL facets and be clear about the facet of DMHL that demonstrates a positive relationship to or efficacy in enhancing mental health. Such an approach would facilitate a comprehensive and converged understanding of the conditions under which DMHL most strongly relates to and effectively increases mental health functioning. On a similar note, DMHL interventions do not always include both proximal literacy outcomes and distal mental health outcomes, which are important in establishing mechanisms of change with proximal literacy outcomes as possible mediators. As the field of DMHL interventions is nascent [8,9], studies have primarily focused on examining mental health outcomes (clinical outcomes) [8,9], and a major gap remains in understanding implementation effectiveness involving uptake and engagement. Drawing from work on digital mental health interventions, user uptake and engagement can vary across different indicators and affect intervening effectiveness on mental health outcomes [8,26]. Extant research on digital mental health interventions, including DMHL, largely focuses on attrition as an indicator of uptake and engagement. Future DMHL interventions should consider other engagement indicators to demonstrate the extent of intervention use and potential key features for effectiveness.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Third, the features of DMHL interventions, such as dosage and platform affordances, warrant greater attention given that research on digital mental health interventions has demonstrated how these features can influence user engagement and the effectiveness of the intervention [8,9]. This synthesis was limited to sex comparisons involving cissex individuals even though transsex and nonbinary individuals are at greater risk of mental health issues. Future work needs to expand the consideration of sex beyond binary operationalizations. We did not find evidence for the role of the commonly endorsed dosage of 10 weeks of digital mental health interventions that included DMHL components and of platform interactivity affordances in amplifying the mental health impact of DMHL interventions. Future work should examine varying dosages of DMHL interventions and different affordances and their additive and interactive effects through empirical examination using an RCT study design.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Finally, most DMHL interventions (56/76, 74%) were found in Western cultural contexts, especially in high-income countries (Global North), and most studies on DMHL interventions (36/76, 47%) did not report information on the racial or ethnic composition of their samples. Among those that did, the samples were predominantly White with limited racial or ethnic diversity. As such, our findings may not be generalizable to other geographic regions or demographic groups. In light of contextual stressors associated with racial and ethnic marginalization and mental health disparities, future work on DMHL interventions that target racial or ethnic minority groups, particularly the design, adoption, and evaluation of the effects of culturally adaptive DMHL interventions on uptake and mental health functioning, is needed [42-44]. Collectively, our review and meta-analysis of DMHL and mental health makes important theoretical and practical contributions. For theory building on DMHL, we found evidence for the fundamental effectiveness of DMHL interventions that increased postintervention mental health and strong inferences for DMHL interventions? effectiveness in bolstering mental health as compared with waitlist control conditions. However, DMHL interventions confer optimal effects on mental health when DMHL psychoeducation is incorporated with informal, nonprofessional active treatment components such as skills training and peer support, which demonstrates comparable effectiveness with that of treatment as usual involving client-professional interactions and therapies. However, none of the interventions in this review considered the mechanism of action regarding how DMHL affects proximal outcomes that in turn affect distal mental health conditions. The large effect size of DMHL interventions on MHL outcomes indicates that literacy may serve as a mediating mechanism for enhancing mental health functioning. Thus, the MHL framework needs to unpack and incorporate different components of DMHL, especially in how they relate to the 5 DMHL facets, and consider their interplay with various active treatment components. More importantly, proximal and distal factors involved in the mechanism of action of DMHL and mental health need to be examined to build and expand the MHL framework.",,,,,
The Effect of Digital Mental Health Literacy Interventions on Mental Health: Systematic Review and Meta-Analysis,"Our review and meta-analysis found that DMHL interventions are as effective as face-to-face interventions. Basic DMHL interventions with self-help DMHL psychoeducation had similar effectiveness to that of interventions that incorporated DMHL as a secondary component with other active treatment components in bolstering mental health functioning. These findings are practically meaningful and underscore the feasibility and promise of digital modalities for improving mental health. DMHL interventions greatly increased literacy outcomes and moderately improved mental health functioning by reducing depression, anxiety, loneliness, and internalizing and externalizing symptoms and enhancing quality of life and resilience. Importantly, these effects, which did not differ by platform type or dosage, were sustained over time. Future research is needed to test our findings on the circumstances in which DMHL interventions are the most effective in enhancing mental health?specific DMHL components, dosage, extent of carryover effects, platform affordances, and individual and contextual factors?to aid policy makers, mental health professionals, and social services in establishing high-performance DMHL interventions that enhance mental health in the community.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"Social media use (SMU) and other internet-based technologies are ubiquitous in today?s interconnected society, with young people being among the commonest users. Previous literature tends to support that SMU is associated with poor sleep and mental health issues in youth, despite some conflicting findings. In this scoping review, we summarized relevant studies published within the past 3ÿyears, highlighted the impacts of SMU on sleep and mental health in youth, while also examined the possible underlying mechanisms involved. Future direction and intervention on rational use of SMU was discussed.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"Both cross-sectional and longitudinal cohort studies demonstrated the negative impacts of SMU on sleep and mental health, with preliminary evidence indicating potential benefits especially during the COVID period at which social restriction was common. However, the limited longitudinal research has hindered the establishment of directionality and causality in the association among SMU, sleep, and mental health.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"Recent studies have made advances with a more comprehensive understanding of the impact of SMU on sleep and mental health in youth, which is of public health importance and will contribute to improving sleep and mental health outcomes while promoting rational and beneficial SMU. Future research should include the implementation of cohort studies with representative samples to investigate the directionality and causality of the complex relationships among SMU, sleep, and mental health; the use of validated questionnaires and objective measurements; and the design of randomized controlled interventional trials to reduce overall and problematic SMU that will ultimately enhance sleep and mental health outcomes in youth.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"Youth population, which typically refers to individuals between the ages of 15 and 24, experience substantial changes in their neurobiology, physical development, behavior, and emotions, making it a vulnerable stage for the development of both sleep and mental health problems [1?3]. In Hong Kong, approximately 64.5% of adolescents sleep less than 8ÿh during weekdays [4] and 29.2% have reported insomnia symptoms [5]. Both cross-sectional and longitudinal studies have demonstrated that sleep loss and disturbances in youth lead to significant personal distress, increase risk of psychiatric illnesses, and risky behaviors such as drug abuse and dangerous driving [5,ÿ6]. In addition to sleep disturbances, mental health problems are highly prevalent among the youth population. Evidence suggested that nearly 75% of psychiatric illnesses have their age onset during adolescence [7,ÿ8].",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"There are multiple risk factors that commonly contribute to sleep and mental health problems, including being female, heavy school workload, physical inactivity, and worse general health [9]. Recently, a growing number of studies indicate that social media use (SMU) is associated with both sleep and mental health problems in youth [10?]. In particular, identity development and peer acceptance during adolescence are important developmental needs, at which social media may apparently serve as a convenient means to meet these needs. A previous study reported that over 80% of adolescents (16?19ÿyears) use electronic devices near bedtime [11]. On the other hand, excessive SMU can have detrimental health effects [12,ÿ13], and contribute to various negative repercussions such as cyberbullying [14], gender stereotypes [15], self-objectification [16], and exposure to inappropriate content, such as unsolicited violent and sexual contents [17]. The effect becomes more prominent in young people who are considered as digital native [18]. Nevertheless, SMU also comes with some potential benefits [19] such as increased self-esteem [20], increased social capital [21], identity presentation and sexual exploration [22], and social support [23].",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"Despite the emerging evidence supporting the link among SMU, sleep, and mental health, the relationship and directionality are complex and inconsistent. For example, two recent studies did not find significant associations among SMU, sleep, and mental health [24,ÿ25?]. Nonetheless, a US study reported that greater SMU was significantly associated with sleep disturbances [26], and some also reported bidirectional relationship at which poor sleepers tend to use electronic devices as a sleep aid [27]. In general, it is believed that youth are at a higher risk of experiencing the negative impacts of SMU as they are more susceptible to peer pressure and fear of missing out (FOMO). FOMO refers to the perception of missing out on enjoyable experiences, followed up with a compulsive behavior to maintain these social connections with others to avoid being excluded from those experiences [28?30]. Hence, understanding the association and directionality among SMU, sleep, and mental health is crucial for developing public health strategies on how to cultivate healthy SMU habits and develop effective interventions targeting inappropriate and excessive SMU.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"This scoping review summarized recent studies on SMU, sleep, and mental health in youth (Fig.ÿ1) and explored the potential underlying mechanisms of how SMU affects sleep and mental health in youth (Fig.ÿ2). Finally, we have put forward several potential avenues for future research and recommendations in this area. Search terms including #adolescent, #social media, #sleep, and #mental health were used to search for relevant studies that were published between January 2020 and July 2023 in MEDLINE. A summary of the study attributes, such as the authors, the country/region where the study was conducted, study design, the number of participants, sample age range, characteristics, as well as the measures used to assess SMU, sleep, and mental health are listed in Tableÿ1.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"SMU refers to the act of engaging with online platforms specifically designed for social interaction, whereas electronic media use (or digital use, digital media, internet use, screen time) is a broader term that encompasses various forms of media delivered electronically, including but not limited to social media. In this scoping review, we focus on SMU.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"Over the past decade, subjective measures have been the primary tool to investigate individual perceptions, opinions, or personal experiences of SMU. For example, a self-report scale was developed to assess compulsive use of social media and its severity [31]. Besides, there are several platform-specific scales for social media addiction features such as salience, mood modification, tolerance, withdrawal, conflict, and relapse. The Bergen Facebook Addiction Scale, for instance, focuses specifically on addiction to Facebook [32?], while the Bergen Social Media Addiction Scale has emerged to examine a broader scope, including social media platforms beyond Facebook [33?,ÿ34]. Indeed, more researchers used general metrics to measure SMU across multiple platforms collectively such as the Social Media Disorder Scale which measures aspects of social media addiction features, such as preoccupation with social media, excessive time spent, withdrawal symptoms, and negative consequences [35?37]. Other SMU experiences are also captured including social comparison on social media and negative experiences such as bullying, FOMO, and extensive negative feedback [32?].",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"In addition, the duration and timing of SMU also have significant implications for sleep and mental health, as excessive or inappropriate use of social media at certain timing, for example at bedtime, can potentially contribute to negative biopsychosocial effects. The Socio-Digital Participation Inventory includes four items to measure the frequency of SMU on a seven-point frequency scale (1?=?never, 2?=?a couple of times a year, 3?=?monthly, 4?=?weekly, 5?=?daily, 6?=?multiple times a day, 7?=?all the time) [25?]. The total time spent on SMU (in daytime and night-time) are usually captured by questionnaires and social media time use diary [38?]. In view of the limitation of self-reported measures, there has been a shift towards incorporating more objective measures in addition to subjective self-report scales. Increasing number of studies used time tracker via specific apps (installed on participants? devices used for online activity) to reduce recall bias [33?]. Other objective features, such as the number of followers, likes, comments, shares, bookmarks, and total interactions, which can be retrieved from various social media platforms [39?] were also used to reflect social medica engagement. In addition, the content (e.g., educational vs non-educational) posted, read, and shared on social media platforms plays a significant role in shaping user experiences, engagement levels, and the overall impact of SMU. It is worth to note that no included studies attempted to measure multi-device SMU as it can be challenging due to the wide range of devices that people use to access social media platforms. Traditional research methods often rely on self-reporting, surveys, or tracking software installed on specific devices, which may not capture the full extent of multi-device usage. Some individuals may switch between multiple devices throughout the day, making it challenging to track their overall social media engagement accurately.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"A total of 33 studies were included in this scoping review, with 26 of them were cross-sectional in nature, indicating a snapshot overview of the relationship between SMU, sleep, and mental health. Moreover, only a few studies utilized representative samples [35,ÿ36,ÿ40,ÿ41], as outlined in Tableÿ1. It is also worth noting that the sample sizes varied significantly across studies, ranging from 54 to 195,668 participants.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"In terms of the measurement of SMU, all studies used either self-developed questionnaires (e.g., ?in a typical school week, how often do you check social media?? and ?on a normal weekday, how many hours you spend on social medias, write blogs/read each people blogs, or chat online??) or validated self-report questionnaires (e.g., the 26-item Chinese Internet Addiction Scale-Revised and the Online Civic Engagement Behavior Construct). Different dimensions of SMU were measured such as overall and night-time SMU, problematic SMU, emotional investment in social media, racial discrimination, and racial justice civic engagement on social media. Only a limited number of studies incorporated more reliable measurements such as ecological momentary assessment [42] and total message count [43].",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"In terms of sleep outcome assessment, most of these studies employed subjective instruments such as sleep diary [32?], self-developed self-report questionnaires (e.g., ?How many hours did you sleep over the past week??) [43], and validated self-report questionnaires (e.g., the Pittsburgh Sleep Quality Index and the Insomnia Severity Index) [44,ÿ45?] to measure different sleep outcomes including sleep quality, sleep duration, sleep displacement, bedtime, and sleep-onset latency. In addition to these subjective instruments, 3 studies have utilized objective devices such as actigraphy and other wearable devices to capture objective sleep data [43,ÿ46,ÿ47]. While for mental health aspects, depression and anxiety are the main outcomes. Most of the recent studies utilized standardized questionnaires such as the Short Mood and Feelings Questionnaire, the Depression Anxiety Stress Scales 21, and the Suicidal Behaviors Questionnaire-Revised to measure the symptoms of depression and anxiety.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"Both longitudinal and cross-sectional studies tend to support the association between SMU and sleep disturbances (Tableÿ1). A total of 17 cross-sectional studies observed an association between SMU and various sleep parameters in youth. Of these studies, a total of 16 reported a significant association between different dimensions of SMU (internet addition, duration of screen use, inappropriate time use (near bedtime), with one additionally measure parent control of technology) and poor sleep outcomes (both subjectively and objectively measured sleep parameters, such as bedtime, sleep-onset latency, sleep duration, and sleep quality) [31,ÿ32?,ÿ35,ÿ36,ÿ40,ÿ42?44,ÿ45?,ÿ47?53]. Nevertheless, a study of 101 undergraduate students did not find that bedtime SMU was detrimental to sleep [46]. However, in the subgroup analysis, the authors found that youth with increased levels of depressive symptoms are at higher risk of experiencing negative impacts of bedtime SMU on sleep [46].",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"Among the three cohort studies, two indicated that higher levels of SMU predicted later bedtime and shorter sleep duration in youth after 1?2ÿyears of follow-up [37,ÿ54]. These studies revealed that both frequent and problematic use of SMU could result in later bedtime [37,ÿ54]. In addition, Richardson and colleagues further found that SMU predicted greater daytime sleepiness in adolescence [54]. In addition, adolescents with evening chronotype preference and shorter sleep duration were found to have longer usage of social media, suggesting a potential bidirectional relationship between SMU and sleep duration [54]. Another cohort study conducted by Maksniemi and colleagues did not find a significant association between SMU and bedtime among 426 youth aged between 13 and 19 [25?]. Interestingly, subgroup analyses indicated that significant associations were only observed in early adolescence (at age 13 and 14), but not in middle (at age 14 and 15) nor late adolescence (at age 17 and 18) [25?]. This finding highlights the importance of considering the developmental stages of youth in order to unravel the complex relationship between SMU and sleep [55].",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"A total of 9 cross-sectional studies examined the relationship between SMU and mental health [33?,ÿ34,ÿ38?,ÿ39?,ÿ56?,ÿ57?60]. A greater amount of time spent on social media was associated with an increased risk of depression, self-harm, and lower self-esteem. On the other hand, adolescents who exhibited mental health issues tended to spend more time on social media platforms, suggesting a potential bidirectional relationship between SMU and mental health. However, it is important to point out that despite appealing hypotheses, actual effect size estimates of SMU on various mental health outcomes (e.g., self-esteem, life satisfaction, depression, and loneliness) were of small-to-medium magnitude as reported in previous meta-analytic studies, ranging from???0.11 to???0.32 [61?,ÿ62].",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"Four longitudinal cohort studies reported mixed findings between SMU and mental health [41,ÿ63,ÿ64?,ÿ65]. Two cohort studies conducted in the USA and China reported that frequent and problematic SMU were significantly associated subsequent mental health issues [64?,ÿ65]. Interestingly, the authors identified substantial sex differences in the mental health trajectories, with only girls showing a deteriorating linear trend (??=?0.23,ÿp?<?0.05) [64?]. On the contrary, the other two longitudinal studies conducted in Sweden and UK reported that although frequent SMU was associated with increased levels of mental problems at a single timepoint, there was no longitudinal association [41,ÿ63], which suggests that SMU may be only an indicator for mental health instead of a risk factor.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"A total of 7 studies measured both sleep and mental health outcomes [31,ÿ45?,ÿ46?48,ÿ50,ÿ59]. Five of these studies reported significant associations among SMU, sleep, and mental health outcome [31,ÿ45?,ÿ46,ÿ50,ÿ59]. It was reported that SMU was significantly associated with poor sleep quality and increased mental health issues [31,ÿ45?,ÿ46,ÿ50,ÿ59], and sleep was found to mediate the negative impacts of SMU on mental health and emotional symptoms in adolescents [45?]. Poor sleep was also shown to be significantly associated with mental health outcomes [31,ÿ50,ÿ59]. Furthermore, adolescents with higher level of depressive symptoms were at higher risk of experiencing negative impacts of bedtime SMU on sleep outcomes [46]. Indeed, these findings preliminarily unveiled the complex interplay among SMU, sleep, and mental health.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"Nevertheless, it is essential to highlight that recent research has also recognized the positive impacts of SMU on mental health, particularly in the context of the COVID-19 pandemic, at which physical social interactions were significantly disrupted [56?,ÿ58]. Adolescents in Australia and UK were found to use social media as an active coping strategy to relieve external stressors (e.g., exam pressure), to seek support for suicidal ideation or self-harm behavior, and to support others via social media [56?,ÿ58].",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"This scoping review synthesized recent publications from the past 3ÿyears that investigated the impact of SMU on sleep and/or mental health outcomes in youth. The majority of the studies provide supporting evidence for an association between SMU, poor sleep quality, and adverse mental health outcomes. Problematic SMU or addiction, as well as the duration of SMU, were identified as the most prevalent aspects of social media examined in the included studies. Sleep duration, bedtime, and insomnia emerged as the most commonly assessed sleep problems, while depression and anxiety were the most frequently measured mental health outcomes. However, it is important to note that despite the significant associations identified among these variables, the directionality of the relationship remains unclear in view of inconsistent findings across studies.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"Numerous mechanisms have been proposed to elucidate the relationship between social/digital media usage and sleep quantity and quality [66]. Hyperarousal, a core mechanism in explaining insomnia [67], plays a role in explaining how night-time SMU disrupts sleep. Active engagement in media activities can directly induce physiological and psychological arousal, leading to longer sleep onset latency [68]. This effect is particularly noticeable when individuals actively engage in interactive digital media, such as social messaging and social media, as opposed to passive media consumption like television viewing [69?], likely due to the heightened arousal associated with interactive activities [70]. Interestingly, a study found that engaging in phone conversations near bedtime was associated with longer sleep duration, while the use of social media and texting displayed a negative association [71]. It has been hypothesized that conversing with a friend may positively influence emotional well-being, thereby promoting sleep [72]. However, social networking, despite its potential for fostering friendships, may also trigger FOMO and social media stress. In addition to the psychological arousal induced by electronic media usage, the light emitted from device screens is another hypothesis explaining the detrimental effects of digital media on sleep. Specifically, the light emitted by electronic devices, especially blue light (at a wavelength of 480ÿnm), has a significant impact on the suppression of melatonin, a hormone that promotes sleep [73]. Moreover, a recent study indicated that high-risk adolescents whose parents with bipolar affective disorder have lower level of nocturnal melatonin secretion. It might be possible that adolescents with certain risk factors (even without psychopathologies) may be particularly hypersensitive and vulnerable to light suppression of melatonin secretion [74], which are considered as high-risk group that require early intervention. Furthermore, it is plausible that an interaction or interplay might exist between arousal and light exposure, and the combination of these conditions could potentially heighten the risk of sleep disturbances. Additionally, the direct displacement of sleep resulting from engagement in social media activities may also lead to shorter sleep duration. Although initial evidence suggests a negative impact of both content and light emitted by electronic devices on sleep, the precise underlying mechanism remains poorly established. Last but not least, some preliminary studies have also investigated other sleep- and circadian-related factors such as chronotype preference and daytime sleepiness in mediating and/or moderating the relationship between SMU and sleep [32?,ÿ44,ÿ54], albeit the findings have been inconclusive. Future studies are warranted to thoroughly explore the role of these factors in the interplay between SMU and sleep.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"It has been suggested both behavioral and cognitive factors mediate the impact of SMU on mental health. Among the behavioral factors, sleep has been identified as one of the notable mediators of the association [31,ÿ44,ÿ45?,ÿ46,ÿ50,ÿ59,ÿ75]. Physiologically, prolonged SMU before bedtime delays sleep onset, reduces sleep duration, and mediates the association between eveningness and sleep as well as daytime sleepiness [44], which have been identified as risk factors for mental illness [76?78]. This complex interplay between sleep and mental health has also been documented in interventional studies. Our previous clinical trial demonstrated that a brief insomnia prevention program, adapted from cognitive-behavioral therapy for insomnia, significantly decreased the severity of depressive symptoms in adolescents at 12-month follow-up [79], suggesting the potential mediating role of sleep in mental health. While for the cognitive factors, FOMO has been recognized as a possible mediator. In particular, Elhai et al. reported that FOMO mediated relationship between anxiety and smartphone use frequency, as well as problematic SMU [80]. Besides FOMO, recent literatures have also identified several other cognitive factors that mediate the relationship between SMU and mental health, such as self-esteem [38?], body satisfaction [57], and emotional investment [59].",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"In addition to these behavioral and cognitive factors, cyberbullying is also one of the important mediators of SMU and mental health in youth [81]. Cyberbullying has become a prevalent phenomenon worldwide, with victimization rates in children and adolescents ranging from 14 to 57.5%, and lifetime perpetration rates ranging from 6.0 to 46.3% [82,ÿ83]. Previous meta-analytical study demonstrated that cyberbullying significantly increased the risks of developing depression, self-harm, suicidal attempts, and ideation [84]. Moreover, over the COVID-19 pandemic, stressors associated with disasters have also been reported to potentially exacerbate the negative effects of SMU on mental health, thereby increasing the risk for mental health issues [85,ÿ86].",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"In summary, there have been significant developments in recent years in understanding the magnitude and mechanisms that underlie the association between SMU and mental health. However, most of the studies employed a cross-sectional design, which prevented from a thorough understanding of the causality. Experimental and interventional studies are warranted to better comprehend the underlying mechanisms, establish causality, and improve the negative outcomes.",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"There are several potential avenues for future investigation. Firstly, prospective cohort studies using representative samples are needed to elucidate the magnitude and directionality of relationships among SMU, sleep, and mental health, which is of clinical practice implication for precision intervention. To capture the varying dynamics among SMU, sleep, and mental health across different age groups of adolescents (early and late adolescents), it is recommended that prospective studies may need to have a follow-up period that will better cover the entirety of adolescence period [41]. Secondly, the lack of consistency in the methodologies employed by different studies measuring SMU has been a major contributing factor to the conflicting findings found in the current literature. It is imperative to use validated questionnaires to measure the SMU. More importantly, objective measurements (e.g., screen time monitors on smartphones [87], ecological momentary assessments [88], and wearable devices [89]) should also be incorporated. Apart from timing, it is equally important to capture the content, and number of devices that subjects engage with. Thirdly, future research should consider conducting randomized controlled trials at different levels (e.g., individual, school, and family) to reduce overall and problematic SMU and to ultimately improve sleep and mental health outcomes in youth. The design of the intervention may benchmark to existing guidelines such as the American Academy of Paediatrics recommendations 2016 on media use [90], and the WHO guidelines on physical activity and sedentary behavior [91], in which both guidelines recommend limiting the amount of recreational screen time, and avoiding SMU 1ÿh before bedtime. Intervention formats may consider psychoeducation, cognitive and behavioral techniques, and motivational interviewing. Finally, priority may be given to conduct observational and interventional studies on SMU in vulnerable populations, such as youth experiencing mood or sleep problems, as well as those who are high-risk offspring of parents with sleep and mood disorders, as these populations are more susceptible to experience significant negative impacts from inappropriate and excessive SMU [92].",,,,,
The Impact of Social Media Use on Sleep and Mental Health in Youth: a Scoping Review,"Despite the heterogeneity observed in the recent studies, both cross-sectional and cohort studies highlight the impact of SMU on poor sleep and mental health, albeit there are some inconsistent findings. Research has progressed from focusing solely on ?screen time? to exploring the social, emotional, and cognitive dimensions of SMU. When measuring sleep outcomes, researchers have investigated the sleep duration and quality and also consider factors such as chronotype and pre-sleep arousal, which will enable a better understanding of how social media impacts sleep in a broader context. Similar advancements have also been made in the field of SMU-related mental health research. Recognizing the interconnections among SMU, sleep, and mental health is crucial for public health and will contribute to improving sleep and mental health outcomes while promoting rational SMU. Future studies should evaluate the effectiveness of interventions on reducing SMU, with ultimate goal to improve sleep and mental health.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Perineural invasion (PNI) of intrahepatic cholangiocarcinoma (ICC) is a strong independent risk factor for tumour recurrence and long-term patient survival. However, there is a lack of noninvasive tools for accurately predicting the PNI status. The authors develop and validate a combined model incorporating radiomics signature and clinicoradiological features based on machine learning for predicting PNI in ICC, and used the Shapley Additive explanation (SHAP) to visualize the prediction process for clinical application.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"This retrospective and prospective study included 243 patients with pathologically diagnosed ICC (training,ÿn=136; external validation,ÿn=81; prospective,ÿn=26, respectively) who underwent preoperative contrast-enhanced computed tomography between January 2012 and May 2023 at three institutions (three tertiary referral centres in Guangdong Province, China). The ElasticNet was applied to select radiomics features and construct signature derived from computed tomography images, and univariate and multivariate analyses by logistic regression were used to identify the significant clinical and radiological variables with PNI. A robust combined model incorporating radiomics signature and clinicoradiological features based on machine learning was developed and the SHAP was used to visualize the prediction process. A Kaplan?Meier survival analysis was performed to compare prognostic differences between PNI-positive and PNI-negative groups and was conducted to explore the prognostic information of the combined model.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Among 243 patients (mean age, 61.2ÿyears ñ 11.0 (SD); 152 men and 91 women), 108 (44.4%) were diagnosed as PNI-positive. The radiomics signature was constructed by seven radiomics features, with areas under the curves of 0.792, 0.748, and 0.729 in the training, external validation, and prospective cohorts, respectively. Three significant clinicoradiological features were selected and combined with radiomics signature to construct a combined model using machine learning. The eXtreme Gradient Boosting exhibited improved accuracy and robustness (areas under the curves of 0.884, 0.831, and 0.831, respectively). Survival analysis showed the construction combined model could be used to stratify relapse-free survival (hazard ratio, 1.933; 95% CI: 1.093?3.418;ÿP=0.021).",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"We developed and validated a robust combined model incorporating radiomics signature and clinicoradiological features based on machine learning to accurately identify the PNI statuses of ICC, and visualize the prediction process through SHAP for clinical application.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"In a retrospective and prospective study of 243 patients with intrahepatic cholangiocarcinoma, the radiomics signature based on computed tomography images could identify the Perineural invasion status.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"The combined model incorporating radiomics signature and clinicoradiological features was more accurate and robust, and can be used to stratify relapse-free survival.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,The visualization prediction process through the Shapley Additive explanation is helpful for personalized clinical decision-making.,,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Intrahepatic cholangiocarcinoma (ICC) accounts for 10?15% of primary liver cancers, showing a gradual increase in incidence and mortality rate globally1. Surgical resection is the primary treatment for patients with ICC. However, the recurrence rate is relatively high, ~57.9?73.4%, which is the main cause of postoperative death2. Due to the lack of effective treatment, the overall prognosis of resected patients remains dismal, with a 5-year survival rate of only 20?40%3.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Perineural invasion (PNI) is characterized by the infiltration of tumour cells along the nerves and/or within the neuronal sheath?s epineural, perineural, and endoneurial regions, encompassing at least one-third of the nerves circumference4. As a potential route of tumour spread, it has been proposed as a strong independent risk factor for tumour recurrence and long-term survival in ICC5,6, and the ICC patients with PNI may benefit from a wide resection margin7,8. Therefore, preoperative PNI prediction is important for making treatment decisions, helping develop individualized treatment plans, and improving the prognosis of patients with ICC.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Computed tomography (CT) is a common noninvasive imaging method important for ICC diagnosis and preoperative evaluation. However, it is challenging for radiologists to assess the PNI status based on macroscopic CT images. Radiomics converts medical radiologic images into high-throughput quantitative features, thus providing information about tumour pathophysiology. It has shown great potential in characterizing tumour phenotypes and improving cancer diagnosis, prognosis, and treatment response9. Traditional machine learning often lacks interpretability, leading to the ?black box? problem, which is not conducive to clinical application. The Shapley additive explanation (SHAP), an emerging interpretability method, can explain the ?black box? problem from both global and local domains10,11. To our knowledge, the noninvasive PNI prediction in ICC using clinicoradiological features and CT radiomics based on interpretable machine learning has not been well established in the literature.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"This multicenter study aimed to develop and validate a robust combined model incorporating radiomics signature and clinicoradiological features based on machine learning for predicting PNI in patients with ICC. Additionally, the combined model will utilize SHAP to intuitively interpret the predicted process for clinical application.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"This study included two retrospective cohorts and one prospective cohort from three institutions: Shunde Hospital, Southern Medical University (institution I); the Sixth Affiliated Hospital, South China University of Technology (institution II); and and the First People?s Hospital of Foshan (institution III). This study was approved by the institutional review board of Shunde Hospital, Southern Medical University. Written informed consent was obtained from each prospectively enroled participant. For retrospective cohorts, the requirement of informed consent was waived. This study had been reported in line with the REMARK criteria12.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Between January 2012 and May 2023, preoperative contrast-enhanced CT images and clinical data from 497 patients with pathologically confirmed ICC were collected from three institutions in China. Of these, 243 were included in the final analysis. Ninety-four and 42 patients from institutions I and II were recruited as a total of 136 patients in the training cohort. Eighty-one patients were recruited as an external validation cohort from institution III. Twenty-six patients were recruited as a prospective cohort from institution III. Data were censored on 2 June 2023. The inclusion criteria were: (a) patients with pathologically confirmed ICC and (b) patients who underwent preoperative contrast-enhanced CT. The exclusion criteria were: (a) patients who did not receive curative resection, (b) incomplete clinical or pathological data, (c) received previous treatment, (d) poor image quality with obvious artifacts, and (e) CT examination performed more than 1 month before surgery. The inclusion and exclusion processes are illustrated in Fig.ÿ1.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"The following clinical data of each patient were recorded from the medical record archives of participating institutions: age, sex, chronic hepatitis, cirrhosis, clonorchis sinensis infestation, alpha-fetoprotein (AFP, ug/l), carcinoembryonic antigen (CEA, ug/l), cancer antigen 12-5 (CA12-5, U/ml), carbohydrate antigen 19-9 (CA19-9, U/ml), alanine aminotransferase (ALT, U/l), aspartate aminotransferase (AST, U/l), gamma-glutamyl transferase (GGT, U/l), neutrophil-to-lymphocyte ratio (NLR), platelet to lymphocyte ratio (PLR), and Child-Pugh classification. Preoperative TMN stage was evaluated by CT, MRI, and/or whole-body PET/CT, basing on the 8th edition of the American Joint Committee on Cancer (AJCC) staging system.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Considering sufficient follow-up time, the patients in institution III were followed up every 3?6 months after surgery by enhanced ultrasound, CT or MRI until recurrence or the end of 31 December 2022. Relapse-free survival (RFS) was defined as the time from surgery date to the date of first recurrence, metastasis or last follow-up.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"The histologic sections from three institutions were evaluated using the same criteria by two experienced pathologists from institution I without knowledge of the patients? clinical data. They made comprehensive judgments based on gross specimens or radiographic images, combined with microscopic histopathological examination13. A third senior pathologist was consulted in the event of inconsistencies. According to the definition4, PNI was divided into positive (+) and negative (?) groups.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"The CT scanners and scanning parameters for each institution are shown in Supplement Table 1, Supplemental Digital Content 1,ÿhttp://links.lww.com/JS9/B281. For each patient, a triple-phase CT scan was performed, including a plain scan and arterial and portal venous phases. Using bolus tracking technique, arterial and portal venous phase images were acquired at 30 and 60 s, respectively. The contrast agents (Ioversol 320 iodine/ml, Jiangsu Hengrui Medicine Corp. Ltd.; or Omnipaque 300ÿmg iodine/ml, GE Healthcare) were injected at a speed of 3.0?4.0ÿml/s with a high-pressure pump syringe.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Two radiologists with eight (Reader 1) and 15 (Reader 2) years of experience in abdominal diagnosis were selected to independently assess CT image features; they were aware that the lesions were ICC but were blinded to all other clinical and histopathologic information. Discrepancies were resolved by consensus after reevaluating the images. Inter-reader variation of semantic features was measured with ?-statistic (?>0.75 was considered excellent agreement; 0.40ó?ó0.75, good; ?<0.40, poor). In patients with multiple tumours, the largest tumour size was analyzed. The following CT image features were evaluated: (a) tumour size; (b) tumour morphology; (c) tumour number; (d) tumour location; (e) tumour capsule; (f) intrahepatic bile duct dilatation; (g) intrahepatic bile duct calculus; (h) satellite nodules; (i) surface retraction; (j) peritumoral arterial hyperenhancement; (k) arterial phase enhancement; (l) dynamic enhancement pattern. The evaluation of CT image features is shown in Supplement Figure 1, Supplemental Digital Content 1,ÿhttp://links.lww.com/JS9/B281, and a more detailed description in Supplement Method.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"All original CT images were appropriately pre-processed to minimize the centre effect from different institutions and scanners14. To standardize the voxel spacing, images were isotropically resampled to a voxel dimension of 1?1?1ÿmm3ÿ(x, y, z). To reduce noise and discretize intensities, the Hounsfield units were set to 25 bins15?17. A radiologist with five years of abdominal diagnosis experience (Reader 3) segmented the tumour using three-dimensional Slicer (version 4.10.2;ÿhttp://www.slicer.org). The tumour volume of interest (VOIÿtumour) was manually drawn on each transverse section from the arterial and portal venous phases. In reference to previous peritumoral radiomics studies18,19, the peritumoral VOI (VOIÿ10ÿmm) was defined as 10ÿmm. The entire VOI (VOIÿtumour+10ÿmm) included the tumour and the peritumoral VOIs. The segmentation results were validated by a senior radiologist with ten years of abdominal diagnosis experience (Reader 4) who randomly selected 30 samples from a cohort. The reproducibility of the extracted features was evaluated by the inter-class correlation coefficient. Finally, the VOIÿtumour, VOI10ÿmm, and VOIÿtumour+10ÿmmÿwere saved for subsequent quantitative feature extraction.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Feature extraction was performed using the open-source pyradiomics package in the three-dimensional Slicer extension manager, which included shape, first-order, and texture features16. All radiomics features were standardized using z-scores and ComBaTool, a free online application (https://forlhac.shinyapps.io/Shiny_ComBat/)20,21. Principal component analysis was used to visualize the correction of batch effects on these features by ComBats. We followed a four-step procedure to identify robust radiomics features in the training cohort. First, features with high stability (inter-class correlation coefficient >0.75) in the test-retest settings were retained for further analysis. Second, univariate statistical analysis was performed on the features, with a significance ofÿP<0.05. Third, we used Pearson?s or Spearman?s correlation analyses (|r|>0.80) to ensure low collinearity. Finally, to prevent overfitting of the model, ElasticNet was used to select the final radiomics risk factors of the PNI22. The penalty parameter tuning was conducted by 10-fold cross-validation, and the mixing parameters were set to (?=?1.80, à=0.5). The radscore was determined by weighting the feature coefficients of the model using logistic regression. The radiomics analysis process is illustrated in Fig.ÿ2.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"In the training cohort, individual factors were analyzed for significant differences using the Student?sÿt-test or Mann?Whitney U test and the ?2ÿtest or Fisher?s exact test, as appropriate. Univariate and multivariate analyses were used to identify the significant clinical and radiological factors with PNI, which were selected by stepwise logistic regression based on the Akaike information criterion.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"We examined clinical, radiological, radiomics, and combined PNI prediction models to demonstrate the clinical value of the radiomics model. A combined model was built by incorporating radscore and clinicoradiological risk features.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"To select the optimal prediction model, four machine-learning algorithms were used to build combined models: logistic regression (LR), eXtreme Gradient Boosting (XGBoost), random forest (RF), and support vector machine (SVM). Each model?s performance was evaluated using the receiver operating characteristic (ROC) curve and area under the curve (AUC) values, accuracy, F1 score, sensitivity, and specificity. The DeLong?s test was used to compare the AUC differences. Furthermore, the incremental difference between the combined and single models was compared using the net reclassification index (NRI), and the net benefit was determined using decision curve analysis (DCA). Based on the study results, we used SHAP to visualize and analyze the prediction process of the PNI model. Finally, to verify the predictive model?s generalizability, external validation, and prospective cohorts were used to validate the prediction performance.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Statistical analyses were performed using Python (version 3.7.3;ÿhttps://www.python.org/) and R software (version 4.0.4;ÿhttps://www.r-project.org/). The quantitative statistics conforming to the normal distribution were presented as mean ñ (SD), and those not conforming to the normal distribution were presented as median [interquartile range]. Qualitative data are expressed as numbers and percentages (N, %). Survival curves were drawn using the Kaplan?Meier method and compared using the log-rank test. Odds ratio (OR) was used for logistic regression, and hazard ratio (HR) was used for Cox regression, and 95% CI were set for evaluation and analysis. Statistical significance was set atÿPÿless than 0.05.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Among 243 patients (mean age, 61.2 years ñ 11.0 (SD); 152 men and 91 women), 108 (44.4%) were diagnosed with PNI (+). Among these, 38.3% (36/94), 54.8% (23/42), and 45.8% (49/107) were in institutions I, II, and III, respectively. We combined institutions I and II into a training cohort, with PNI incidence rates of 43.4% (59/136). Furthermore, institution III conducted external validation and prospective cohorts chronologically, with PNI prevalence rates of 51.9% (42/81) and 26.9% (7/26), respectively. The clinical data and CT imaging features of the different cohorts are presented in Tableÿ1. The two radiologists (Readers 1 and 2) showed a consistent analysis of qualitative CT features, as the kappa values were all greater than 0.600 (0.650?1.000,ÿP<0.001, Supplement Table 2, Supplemental Digital Content 1,ÿhttp://links.lww.com/JS9/B281).",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Univariate analysis showed sex, chronic hepatitis, cirrhosis, GGT, PLR, tumour morphology, tumour location, tumour capsule, intrahepatic bile duct dilatation, intrahepatic bile duct calculus, peritumoral arterial hyperenhancement, arterial phase enhancement, and dynamic enhancement pattern were significantly related to the PNI (allÿP<0.05, Supplement Table 3, Supplemental Digital Content 1,ÿhttp://links.lww.com/JS9/B281). Multivariate analysis showed that PLR (OR 1.007; 95% CI 1.001?1.013;ÿP=0.018), tumour location (OR 4.351; 95% CI 1.759?10.763;ÿP=0.001), and arterial phase enhancement (OR 6.570; 95% CI 1.744?24.753;ÿP=0.005) were independent predictors of PNI (Supplement Table 4, Supplemental Digital Content 1,ÿhttp://links.lww.com/JS9/B281).",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"For feature extraction, 107 radiomics features (14 shape features, 18 first-order features, and 75 texture features) were extracted from each three-dimensional segmentation, yielding 642 features for every lesion (VOIÿtumour, VOIÿ10ÿmm, and VOIÿtumour+10ÿmmÿin the arterial and portal venous phases). Supplement Figure 2, Supplemental Digital Content 1,ÿhttp://links.lww.com/JS9/B281ÿshows that ComBat normalization aggregated the data distributions of the three institutions, which were scattered before eliminating the centre effects. For feature selection, first, based on the test-retest settings, 125 features were removed, and 517 features were retained. Second, 76 features were roughly selected using an independent-samplesÿt-test or Mann?Whitney U test, and 14 low-correlation features were retained using Pearson or Spearman correlation analysis. Finally, the ElasticNet regression analysis determined seven predictive radiomics features (six peritumoral features and one entire feature). Details of the radiomics features selection is illustrated in Supplement Table 5, Supplemental Digital Content 1,ÿhttp://links.lww.com/JS9/B281ÿand supplement Figure 3, and the radscore formula is as follows:",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"The AUC, accuracy, F1 score, sensitivity, and specificity of each model are presented in Tableÿ2. The performance of the radiomics model (AUCs of 0.792, 0.748, and 0.729 in the training external validation, and prospective cohorts, respectively) was superior to that of the clinical model (AUCs of 0.660, 0.601, and 0.586, respectively; DeLong?s test, allÿP<0.05) but comparable to that of the radiological model (AUCs of 0.796, 0.826, and 0.726, respectively; DeLong?s test,ÿP=0.196?0.981). The combined model included four commonly used machine-learning models (LR, XGBoost, RF, and SVM), with AUCs exceeding 0.796, 0.755 and 0.714 in training, external validation, and prospective cohorts, respectively. In the training cohort, the XGBoost model outperformed the RF and SVM models (DeLong?s test, allÿP<0.05), but showed no significant difference compared to the LR model (DeLong?s test,ÿP=0.083). In the external validation cohort and prospective cohort, there were no significant differences observed between the XGBoost model and the other three machine-learning models (DeLong?s test,ÿP=0.059-0.740). However, XGBoost exhibited improved accuracy and robustness in all cohorts based on comprehensive predictive metrics. Therefore, we selected the XGBoost model as the optimal combined model (AUCs of 0.884, 0.831, and 0.831, respectively), (Figureÿ3).",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"To better illustrate the potential clinical value of the combined model, the incremental differences between the XGBoost combined model and the single model were compared using the NRI, and the net benefit was determined using DCA. Although there was no statistical difference in AUCs between the XGBoost combined model and the single model in some cohorts, NIRs were greater than 0 in the vast majority of cohorts, indicating that the XGBoost combined model had an improvement, suggesting that its predictive ability was better (Supplement Table 6, Supplemental Digital Content 1,ÿhttp://links.lww.com/JS9/B281). DCA graphically demonstrated that the XGBoost combined model provided a larger net benefit across the range of reasonable threshold probabilities compared to the single model in all cohorts (Supplement Figure 4, Supplemental Digital Content 1,ÿhttp://links.lww.com/JS9/B281).",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"We calculated the overall and individual Shapley values for the XGBoost combined model interpretation and clinical application. In the overall visualization, the SHAP bar chart (Fig.ÿ4A) shows the weights of the four most important characteristics (radsocre, PLR, arterial phase enhancement, and tumour location) of the model. The average Shapley values were 0.38, 0.28, 0.28, and 0.25, respectively, with the radscore having the highest weight. The SHAP bees-warm plot (Fig.ÿ4B) shows each feature?s positive or negative effects on the prediction probability in red and blue. In predicting the probability of positive PNI expression, the radscore, tumour location, and PLR had a positive effect, while arterial phase enhancement had a negative effect. The SHAP heatmap plot (Fig.ÿ4C) shows each feature?s direction and intensity of influence in all model cases, whereas the SHAP decision plot (Fig.ÿ4D) shows the impact process of each significant feature on the final predicted probability. In the individual visualization, Fig.ÿ5ÿshows four typical examples of correctly predicted PNI positivity and negativity. The SHAP effort plot shows each feature?s positive and negative effects on predictive outcomes in a single case. The base value represents the basic prediction probability of the model, and f (x) represents its final prediction probability.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"In institution III, 65 patients were successfully followed up. The overall RFS rate was 75.4% (49/65 patients). The median RFS rate of PNI (+) and PNI (?) was 8.0 (range: 2?45ÿmonths) and 12.5 months (range: 2?55ÿmonths), respectively. Statistically significant differences in RFS between PNI (+) and PNI (?) patients were observed (HR, 1.925; 95% CI: 1.070?3.460;ÿP=0.025) (Fig.ÿ6A). To evaluate the prognostic stratification value of the combined model, patients were divided into predicted PNI (?) (XGBoost <0.413) and PNI (+) (XGBoost >0.413) groups based on the combined model cut-off value by maximizing their Youden index values. Kaplan?Meier survival analyses (Fig.ÿ6B) showed that the combined model could successfully stratify RFS (HR, 1.933; 95% CI: 1.093?3.418;ÿP=0.021).",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"In this study, we established a PNI radiomics signature based on 136 arterial phase- and portal venous phase-enhanced CT images, combined clinical and radiological features to construct a comprehensive model, and compared four commonly used machine-learning models to determine the optimal performance model for predicting PNI in patients with ICC. Its performance was successfully verified in external (81 patients), and prospective cohorts (26 patients). Meanwhile, we compared RFS between PNI from institution III and attempted to evaluate the predictive value of the combined model for RFS. Finally, we used SHAP to visualize the entire model prediction process, from the overall to the individual levels. These results indicate that the combined model incorporating radiomics signature and clinicoradiological features is a feasible tool for evaluating PNI status and can be used for prognostic stratification, with XGBoost machine learning being more accurate and robust.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"In this multicenter study, heterogeneity was observed in the datasets from various institutions. To ensure the robustness of the subsequently established models for the different datasets, we created two additional designs. First, according to previous studies, the incidence rate of PNI varies widely, about 21.8?80%5,23,24. The incidence rate of PNI in the three institutions in our study was also unbalanced (38.3%, 54.8%, and 45.8%, respectively), and we merged institutions I and II to ensure the consistency of their PNI incidence rate with the institution III (43.4%, 45.8%). Second, the CT scanning models and parameters at each institution differed. In addition, data heterogeneity was reduced throughvoxel resampling and grey-level discretization pre-processing. We also used the ComBat method to eliminate potential centre effects. This is a relatively novel method for image standardization9,20,21.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Seven radiomics features, including six peritumoral features and one entire feature, successfully demonstrated the feasibility of CT radiomics features to predict PNI pathological information. Interestingly, seven radiomics features all involved the liver region surrounding the tumour. This might reflect an aggressive tendency to invade the tumour capsule and protrude into the peritumoral non-neoplastic parenchyma. The radiomics features of the peritumoral region can reflect the tumour microenvironment. Recent studies have demonstrated that neuromodulation is important in remodelling the immune microenvironment4,25,26. Mengÿet al.27ÿalso found that the PNI-positive status of ICC was associated with decreased NK cells and increased neutrophils. In addition, peritumoral radiomics features contain some important characteristics related to treatment and prognosis, confirmed in cervical28, breast29, and liver cancers19,30. Our study demonstrates the significant importance of radiomics, especially peritumoral radiomics, in predicting PNI. It may help elucidate whether PNI occurs more frequently in the tumour-periphery region and whether there is a specific association with the immune microenvironment and prognosis. These aspects warrants further investigation in our future studies.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"We also evaluated preoperative clinical and radiological factors. Our results showed that PLR, tumour location, and arterial phase enhancement were independent variables associated with the PNI. PLR and NLR are commonly used peripheral blood inflammatory markers. These inflammatory factors can stimulate tumour blood vessels formation, leading to a higher invasiveness of the tumour and being associated with poor prognosis31,32. We speculate that PNI-positive ICC exhibits greater invasiveness, leading to a more pronounced peripheral inflammatory response. Our results recapitulate previous findings that the perihilar ICC is closely correlated with the PNI33; poor histological differentiation of perihilar ICC, which is more invasive, or the rich distribution of the nerve plexus around the hepatic portal may explain this34. Diffuse arterial hypoenhancement is another important PNI predictor. According to previous studies, tumours contain abundant fibrous stroma, leading to low enhancement in the arterial phase, which is associated with more aggressive biological behaviour and a poor prognosis35,36, and may provide a bridge for tumour cell progression and migration, making it more likely to invade blood vessels and nerves.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Radiomics? capacity to characterize tumour size and heterogeneity may explain why the radiomics model outperformed the clinical model (DeLong?s test, allÿP<0.05). However, the radiomics model was comparable to the radiological model (DeLong?s test,ÿP=0.196?0.981), and the main reason for this result may be that the CT feature-tumour location emerged as an important independent predictive factor in this study, which was not reflected by radiomics. This finding emphasizes the complementary nature of radiological features and radiomics, highlighting the importance of constructing a combined model for a comprehensive assessment of PNI status. Our results show that the combined model is better than a single model. We constructed four machine-learning models based on radscore and clinicoradiological features, and the results showed that the XGBoost model was more accurate and robust. The satisfactory results of the prospective validation cohort further demonstrated the applicability and reliability of the model. We further explored the prognostic information of the combined model, and preliminary results of this study indicate that the combined model of PNI can predict tumour recurrence stratification (HR, 1.933; 95% CI: 1.093?3.418;ÿP=0.021). Previous studies have also demonstrated the high predictive power of the XGBoost model37,38. Recently, interpretable machine learning has solved the ?black box? phenomenon. SHAP, a highly practical machine-learning interpretation tool, can visualize each feature?s overall or individual contribution and promote the clinical application of models, boosting clinicians? confidence in using predictive models11. The weights and effects of four independent prediction features in the combined model we have built are shown through SHAP. Case analysis demonstrates the contributions of these four features in the case and calculates the final Shapley value, thereby obtaining the final prediction probability and achieving personalized prediction.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"Our study had several limitations. Firstly, this was a retrospective and prospective study, which may have led to an information selection bias. Secondly, although this was a multicenter study, the relatively low incidence of ICC limited the sample size. Therefore, a larger sample size is required to validate the efficacy of our prediction models in future studies. Thirdly, the manual segmentation of ICC tumours was time-consuming; however, ongoing research in automated segmentation is expected to substantially reduce this workload in the future. Fourthly, the biological interpretability of radiomics remains a significant challenge, and further research is necessary to uncover the underlying connections between radiomics and genomics/proteomics. Finally, despite pathology being considered the gold standard, ICC can sometimes be indistinguishable from perihilar cholangiocarcinoma, potentially introducing bias.",,,,,
Noninvasive prediction of perineural invasion in intrahepatic cholangiocarcinoma by clinicoradiological features and computed tomography radiomics based on interpretable machine learning: a multicenter cohort study,"We developed and validated a noninvasive and robust combined model incorporating CT radiomics signature and clinicoradiological features based on machine learning to identify patients? PNI status and stratify RFS. The SHAP provides a bridge for personalized prediction, which may aid clinical decision-making for the individualized treatment of ICC.",,,,,
"Editorial: Mental health, epidemiology and machine learning","Globally, one in eight people live with a mental health condition, contributing to approximately 16% of disability-adjusted life years (1,ÿ2). The significant impact of mental disorders on quality of life and life expectancy is well established and highlights significant health inequalities.2ÿHowever, despite this, progress in mental health has lagged behind other medical fields, hindered by social stigma, cultural barriers, resource constraints, and the intrinsic complexity of mental health conditions (2).",,,,,
"Editorial: Mental health, epidemiology and machine learning","Accessing data for mental health research is inherently challenging, due to the relevance of social and environmental factors beyond traditional health systems. Advances in data collection and linkage?including the integration of electronic health records with data from education, employment, and criminal justice?has enabled more comprehensive studies on these determinants (3,ÿ4). However, this new data landscape presents unique analytical challenges. The DATAMIND initiative (https://datamind.org.uk/) aims to optimise the use of UK?s rich mental health data, coordinating research efforts and fostering multidisciplinary collaboration.",,,,,
"Editorial: Mental health, epidemiology and machine learning","Machine learning (ML) has emerged as a promising tool to address these new challenges, offering the power to work with large-scale data resources and produce new insights. However, ML applications in mental health must be rooted in sound epidemiological practices to ensure clinical relevance and to gain the trust of both healthcare community and the public. Our opinion piece (DelPozo-Banos etÿal.) discussed some of these challenges, particularly: (i) the risk of losing sight of mental health objectives in favour of technical performance; (ii) underlying biases and heightened privacy requirements; and (iii) the difficulties of building, validating and approving ML-enabled clinical devices for mental health disorders with insufficiently clear underlying mechanisms. These ideas, and the setting up of the DATAMIND hub provided impetus for the current Research Topic, titled ?Mental Health, Epidemiology, and Machine Learning.? With it, we aimed to highlight ML?s potential role in mental health research and to illustrate clinically and epidemiologically sound ML applications in mental health, making the most of novel data sources and linkages.",,,,,
"Editorial: Mental health, epidemiology and machine learning","One of the most evident applications of ML in mental health is in diagnosing complex conditions, enhancing early detection and decision support.ÿWright-Berryman etÿal.ÿdeveloped NLP models to identify depression, anxiety, and suicide risk in clinical records; these understandably performed better in cases where symptoms were severe or well-documented.ÿOh etÿal.ÿalso proposed NLP for depression diagnoses, but their model analyzed the emotional content in patient-psychiatrist interviews. They found that the expression of ?disgust? prominently helped to distinguish patients with depression, highlighting the utility of linguistic analysis for capturing emotional markers in mental health diagnostics.ÿChen etÿal.ÿpresented a decision support tool for ADHD diagnosis, integrating ML with clinical knowledge and processing not only related symptoms, but also comorbid conditions. Their approach pointed to specific features in the Diagnostic Interview for ADHD in Adults that help distinguish ADHD from other conditions, and crucially, their model also identified and flagged complex ADHD cases for expert review. Finally,ÿMerhbene etÿal.ÿconducted a systematic review on ML for eating disorder detection, revealing challenges such as insufficient data quantity and quality, alongside a lack of representation of minority groups, reduced clinical involvement in development, and culturally driven heterogeneities. Overall, the number and heterogeneity of symptom presentations makes clinical diagnoses a highly complex task in mental healthcare (5), and these papers highlight how ML might be of value to professionals in this regard.",,,,,
"Editorial: Mental health, epidemiology and machine learning","ML can also help to personalise mental health services and treatments to better meet patients? individual needs.ÿBernard etÿal.ÿapplied ML clustering to identify usage patterns among young users of a digital mental health platform, with a battery of sensitivity analyses across clustering methods. Their results, validated through hypothesis testing, indicated that user engagement profiles change over time, highlighting the importance of adaptive digital services tailored to changing user behaviors.ÿGarriga etÿal.ÿdeveloped an ML model that tailors monitoring duration for psychiatric patients with a depression crisis. For over 20% of patients, their model prescribed monitoring beyond the standard one-week period, suggesting that a ?one-size-fits-all? approach may overlook important individual needs. Additionally,ÿYao etÿal.ÿanalysed the satisfaction levels of Chinese psychotherapy patients, identifying cultural factors as critical determinants. While the use of ML for personalised psychiatry is not new (6), it is still under-explored. For example, in their systematic review,ÿRollmann etÿal.ÿfound only four papers investigating ML applications in psychodynamic psychotherapy, but these foundational models suggest that ML could support tailored treatments, predict treatment responses, and match therapists to patients more effectively. The need for additional research is clear, especially as personalised approaches are critical to improving therapeutic outcomes.",,,,,
"Editorial: Mental health, epidemiology and machine learning","Suicide risk assessment and crisis prediction are areas where ML-driven personalized psychiatry can make a difference in both clinical practice and research.ÿChou etÿal.ÿevaluated multiple ML models in a suicide risk identification task based on data from a Japanese population. They found trauma-related emotional distress and functional impairment to be important factors, demonstrating the importance of culturally contextualized risk profiles.ÿDutta etÿal.ÿandÿWright-Berryman etÿal.ÿassessed suicide risk using NLP, the former on routinely collected electronic patient records from a mental health service, and the latter on 5-to-10-minute semi-structured interview data. Overall, although ML models may enhance our risk assessment capabilities, they should only be used as complements and not replacements for comprehensive clinical evaluations of patient needs.",,,,,
"Editorial: Mental health, epidemiology and machine learning","Finally, ML can also drive the discovery of new insights on the social and environmental influences on mental health, helping to inform policies and practices.ÿMason etÿal.ÿfirst used NLP to extract indicators of violence from routinely collected clinical notes of a mental healthcare provider. They fed these indicators to an ANN to identify actual experiences of violence. They found that violence-related records were more common among women, mid-life adults, ethnic minorities, and those with PTSD or schizophrenia, highlighting the intersection between demographic and clinical factors.ÿQasrawi etÿal.ÿshowed that children in violent environments exhibit cognitive and mental health patterns that align with general findings on trauma?s developmental impacts.ÿCastillo-Toledo etÿal.ÿused NLP to study public perceptions of cocaine use on a large sample of social media posts, providing insights into the way some healthcare professionals openly discussed cocaine?s perceived benefits. These studies demonstrate ML?s capacity to identify and analyze social factors critical to mental health, contributing insights that can shape public health strategies.",,,,,
"Editorial: Mental health, epidemiology and machine learning","In summary, the studies in this Research Topic demonstrate manifold ways in which ML might be of benefit to the field of psychiatry. They maintained a clinical focus and helpfully went beyond simple reporting and comparison of ML performance metrics. They studied the behaviour of such algorithms across varied sub-populations (e.g., by disorder severity) and tried to extract novel clinical insights, aided by additional classical statistical methods. They also openly acknowledged and discussed the limitations of their ML models and sought to validate their findings through traditional epidemiological methods.",,,,,
"Editorial: Mental health, epidemiology and machine learning","Putting all of the above into perspective isÿSpeechley and McTernan?sÿcentral work, an opinion piece authored by people with mental health lived experience. In it, they reflected on how ML might help make sense of their lives. They highlighted the need for researchers to foster public trust, cautioning against language that could exacerbate health inequalities and stigma, and emphasizing the need to inform the public that ?[their] data saves lives? and how.",,,,,
"Editorial: Mental health, epidemiology and machine learning","Our hope is that this Research Topic serves as a catalyst for deeper conversations on ML?s appropriate role in mental health research and clinical care. Most importantly, researchers must ensure that ML?s transformative potential remains a positive force, advancing mental health research and clinical practice in ways that are ethical, inclusive, and grounded in real-world needs.",,,,,
"Editorial: Mental health, epidemiology and machine learning","The author(s) declare financial support was received for the research, authorship, and/or publication of this article. All authors were funded by the Medical Research Council and Health Data Research UK (Grant DATAMIND: Data Hub for Mental Health INformatics research Development, with Ref.: MR/W014386/1). RS is additionally part-funded by: i) the NIHR Maudsley Biomedical Research Centre at the South London and Maudsley NHS Foundation Trust and King?s College London; ii) the National Institute for Health Research (NIHR) Applied Research Collaboration South London (NIHR ARC South London) at King?s College Hospital NHS Foundation Trust; iii) the UK Prevention Research Partnership (Violence, Health and Society; MR-VO49879/1), an initiative funded by UK Research and Innovation Councils, the Department of Health and Social Care (England) and the UK devolved administrations, and leading health research charities.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Over the past two decades, whole food supplementation strategies have been leveraged to target mental health. In addition, there has been increasing attention on the ability of gut microbes, so called psychobiotics, to positively impact behaviour though the microbiota-gut-brain axis.ÿFermented foodsÿoffer themselves as a combined whole food microbiota modulating intervention. Indeed, they contain potentially beneficial microbes, microbial metabolites and other bioactives, which are being harnessed to target the microbiota-gut-brain axis for positive benefits. This review highlights the diverse nature of fermented foods in terms of the raw materials used and type of fermentation employed, and summarises their potential to shape composition of the gut microbiota, the gut toÿbrainÿcommunication pathways including theÿimmune systemÿand, ultimately, modulate the microbiota-gut-brain axis. Throughout, we identify knowledge gaps and challenges faced in designing human studies for investigating the mental health-promoting potential of individual fermented foods or components thereof. Importantly, we also suggest solutions that can advance understanding of the therapeutic merit of fermented foods to modulate the microbiota-gut-brain axis.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"?Long is the calmÿbrainÿactive in creation; Time, only, strengthens the fine fermentation?.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,Johann Wolfgang von Goethe,,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Keeping the brainÿactive in creationÿas referenced by Goethe relies on a variety of intrinsic and extrinsic signals. Over the past two decades, there has been a growing appreciation that the gut microbiota is a key mediator with respect to responding to external signals and triggering intrinsic functions within the body. The microbiota-gut-brain axis consists of a diverseÿmicrobial communityÿcontained in the intestinal environment that is in constant communication with theÿcentral nervous system, and vice versa. The gut microbial community is influenced by a variety of factors ranging from diet (Latorre-Prez et al., 2021,ÿQin et al., 2022,ÿAsnicar et al., 2021), age (Yatsunenko et al., 2012,ÿGhosh et al., 2022), medication use (Ghosh et al., 2022), sex (Cuesta-Zuluaga et al., 2019), ethnicity (Ang et al., 2021,ÿDwiyanto et al., 2021) and geographical location (Bai et al., 2022,ÿKabwe et al., 2020) and other factors, with diet playing a particularly important role in influencing the microbiota and the metabolites they produce. These microbes and their metabolites influence the hosts intestinal (Del Bo et al., 2021,ÿPeron et al., 2021), immunological (Longhi et al., 2021,ÿWastyk et al., 2021,ÿBisgaard et al., 2016,ÿLi et al., 2016) and neural components (Shi et al., 2021,ÿTessier et al., 2021,ÿRibeiro et al., 2022) of the microbiota-gut-brain axis. In parallel, meta-analyses examining the relationship between mental health and dietary patterns have hinted at the promise of dietary intervention strategies to influence the cognitive wellbeing of an individual (Abbott et al., 2019,ÿOcklenburg and Borawski, 2021,ÿTaylor et al., 2021). Thus, as a consequence of a combination of these advances, there is a growing interest in targeting the microbiota via diet so as to confer mental health benefits to the host (Berding et al., 2021b). The majority of microbiota-targeted interventions involveÿprobioticsÿ(Long-Smith et al., 2020),ÿprebioticsÿ(Mrkl et al., 2020), fibres (Berding et al., 2021a), polyphenols (Rodr¡guez-Daza et al., 2021), fatty acids (Silva et al., 2020), or, more broadly via changes in habitual dietary consumption (Ghosh et al., 2020,ÿMillman et al., 2021,ÿValls-Pedret et al., 2015). Whole food based dietary interventions are increasingly applied to study mental health (Berding et al., 2021a). These interventions are usually lifelong and are integrated into the habitual diet of the patient. Recently studies have investigatedÿfermented foodsÿas a potential avenue of microbiota-targeted intervention strategy (Marx et al., 2020). Although ancient in origin,ÿfermented foodsÿare now seen as conduits for introducing beneficial microbes and molecules. Moreover, fermented foods are applicable therapeutics across various socioeconomic sectors given their potential affordability and cross-cultural accessibility.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Food fermentationÿwas traditionally employed to enable longer storage/shelf-life of food substrates that would otherwise spoil quickly, which was crucial in times of scarcity (Amato et al., 2021,ÿBorremans et al., 2020,ÿRoss et al., 2002), whilst concurrently enhancing flavour profile (Liu et al., 2019b,ÿCai et al., 2019,ÿMandha et al., 2022,ÿPeraza and Perron, 2022), reducing the toxicity of raw materials/controlling pathogenic microorganisms and simultaneously allowing for their digestion (Reddy and Pierson, 1994,ÿMaixner et al., 2021). Fermented foods are mainly classified into categories based on the substrate used, e.g., cereal, dairy, meat, fish, vegetable and legume (Tamang et al., 2020), which differ with respect to their primary food substrate and type of fermentation (e.g., definedÿstarter culture, spontaneous or back-slopped culture).ÿTable 1ÿin this review highlights the diverse nature of fermented foods that is referred to in this review along with the substrate category and the nature of fermentation employed in its production. The microbial community present in a fermented food is associated with a number of factors, including the type of substrate (Achi and Asamudo, 2019,ÿLeech et al., 2020), geographical location (Van Reckem et al., 2019,ÿJung et al., 2018,ÿZhong et al., 2016,ÿLi et al., 2017), pH (Yang et al., 2020) and method of preparation (Lee et al., 2021,ÿVan Reckem et al., 2019) (SeeÿFig. 1). Fermented foods are a rich source ofÿbeneficial microorganismsÿ(potential probiotics) (Okada et al., 2018,ÿWang et al., 2022) as well asÿbioactive peptidesÿ(Chaudhary et al., 2021),ÿphytochemicalsÿand vitamins (Septembre-Malaterre et al., 2018,ÿShahbazi et al., 2021b). As researchers increasingly investigate the impact of different dietary intervention strategies and habitual dietary practices on sculpting the gut microbiota (Losasso et al., 2018,ÿTanes et al., 2021,ÿStege et al., 2022) and, consequently, their metabolites (Wu et al., 2016,ÿChen et al., 2022), it is not surprising that fermented foods receive particular attention. This is in no small way related to their capacity to modulate the composition and/or diversity of the gut microbiota (Bellikci-Koyu et al., 2019,ÿLe Roy et al., 2022,ÿWastyk et al., 2021) and/or the production of microbial metabolites, such asÿshort chain fatty acidsÿ(SCFA), polyphenolic (Johnson et al., 2019,ÿZorraqu¡n-Pe¤a et al., 2021),ÿtryptophanÿand bile metabolites (Scott et al., 2020) and, as a result, can modulate the pathways that relay information from gut to the brain.ÿTable 2ÿprovides a primer on the nomenclature of various microbial components and bioactive components along with consensus statement that aptly captures their function. The frequent, yet incorrect, description of fermented food-associated microorganisms as probiotics in the literature and by industrial stakeholders has led the International Scientific Association for Probiotics and Prebiotics (ISAPP) to establish a consensus statement regarding terminology that is frequently used in microbiota based therapeutic strategies.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Table 1.ÿCompilation of fermented foods that are frequently referred to in this review and the type of fermentation process most commonly employed in their production. The methods of fermentation might be subjected to variation in their production, geographical location, cultural practices and are not strictly confined the method specified in the table.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Here, we review the components of fermented foods that can exert beneficial effects to the individual with a particular focus on mental health. We also summarise existing literature from preclinical and clinical research relating to the impact of fermented foods on individual components of the microbiota-gut-brain axis. Lastly, we discuss the current challenges associated with preclinical and human studies aimed at understanding the beneficial effects of fermented foods as a potential intervention strategy targeting mental health.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"The microbiota-gut-brain axis facilitates a constant bidirectional relay of information from the intestine via theÿenteric nervous systemÿ(ENS) and from the intestinal milieu consisting ofÿmicrobial communities, microbial metabolites, gut associatedÿlymphoid tissueÿ(GALT), peripheral immune cells and cytokines to theÿbrainÿand vice versa via the sympathetic/parasympathetic nervous system,ÿneurotransmittersÿand the circulatoryÿimmune systemÿ(Cryan et al., 2019). Fermented foods are rich in microbes and their metabolites. In addition to theÿphytochemicals, these metabolites can take the form of neurotransmitters, neuroactives and neuromodulators (Yu et al., 2020), and thereby stimulate the connecting pathways of the microbiota-gut-brain axis: immune, neuroendocrine, enteric nervous andÿcirculatory system. Upon digestion, they can result in the production of microbial metabolites that can modulate the permeability of the intestinal barrier (Scott et al., 2020) and theÿblood brain barrierÿ(BBB) (Stachulski et al., 2022,ÿAngelino et al., 2019). Before we discuss the effects of fermented food supplementation on mental health, we outline the current evidence of the ability of fermented foods to modulate the individual components of the microbiota-gut-brain axis so as to exploit them for future microbiota-targeted therapeutics.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Microbial metabolites are capable of regulating the immune system (Lavelle and Sokol, 2020) via systemic circulation (Colombo et al., 2021) or by theÿvagus nerveÿ(Bluthe et al., 1996,ÿNamgung et al., 2022,ÿHuffman et al., 2019). Growing evidence on the presence of receptors for bacterialÿcell wall componentsÿandÿimmunostimulantsÿsuch asÿpeptidoglycanÿandÿlipopolysaccharidesÿin the brain depict the far reaching ability of the gut microbiota on the brain and behaviour of the host (Wheeler et al., 2023,ÿArentsen et al., 2017,ÿTillinger and Mravec, 2021). This microbiota-gut-immune-brain connection is influenced by different dietary and lifestyle choices across lifespan (Bostick et al., 2022,ÿRatsika et al., 2023). Fermented foods, a subset of dietary intervention strategies can therefore be leveraged to boost this bidirectional communication.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Several components of fermented foods are being individually studied for their ability to modulate the immune system. The bacterial cellular components of fermented foods have shown the ability to instigate the release of IL-10 from dendritic cells and CD4?+?T cellsÿ(Kim et al., 2019). Other components, such as fermented foodÿexopolysaccharidesÿ(EPS) are also being explored for their modulatory effects on the immune system, as seen with kefiran, an EPS product produced byÿLactobacillusÿkefirofaciensÿ(Bourrie et al., 2016). Microbial metabolites produced in fermented food also have immunomodulatory abilities. For example,ÿoleamide, a microbial metabolite produced byÿPenicilliumÿcandidum,ÿis present in products such asÿcamembert cheese. Oleamide has been shown to suppress TNF-à release fromÿmicrogliaÿby acting as anÿagonistÿfor the P2Y andÿcannabinoid receptorsÿ(Kita et al., 2019).",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"A potential mechanism by which fermented foods are able to exert immunomodulatory effects is through activation of the hydrocarboxylic acid receptor (HCA3R), as a consequence of consumingÿlactic acid bacteriaÿ(LAB) fermented food.ÿSauerkraut, also rich in LAB upon consumption is shown to elicit a chemotactic response fromÿmonocytesÿvia D-Phenylacetic acid, a potent HCA3R receptor agonist (Peters et al., 2019). Large scale genome wide association analysis have revealed the LAB found in human gut likely to be from foods (Pasolli et al., 2020). Interestingly, a humanÿobservational studyÿon the TwinsUK cohort showed elevation inÿB. animalis subsp. lactisÿwith yogurt consumers that positively correlated with 3-hydroxyoctanoate levels, which is an agonist for HCA3 and could be potentially implicated in host immunoregulation (Le Roy et al., 2022). Further studies on the hydrocarboxilic receptor revealed only humans and great apes to possess three hydrocarboxylic receptors, as opposed to the two (HCA1R, HCA2R) seen in other organisms, indicating the development of evolutionary adaptations to accommodate the consumption of fermented foods (Peters et al., 2019).",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Microbial surface molecules and microbial metabolites are implicated in the integrity of the intestinal epithelial barrier (Spiljar et al., 2017,ÿLiu et al., 2020b) and the blood brain barrier (Knox et al., 2022a).ÿSCFAÿ(Knox et al., 2022b), methylamines (Hoyles et al., 2021),ÿbile acidÿmetabolites (Lajczak-Mcginley et al., 2020) andÿamino acidÿmetabolites (Scott et al., 2020,ÿStachulski et al., 2022) are some of the metabolites produced by the hostÿmicrobiomeÿthat can influence the intestinal and BBB integrity of the host. Fermented foods are a rich source of microorganisms and on consumption can result in production of microbial metabolites that can elicit an immunological response, thereby influencing the integrity of these physiological barriers.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Several studies have examined the impact of fermented food products on intestinal integrity in the context of Inflammatory Bowel Disease (IBD).ÿMurine modelsÿof IBD when supplemented withÿBacillus subtilisÿfermented milkÿshowed rescue in intestinal morphology as well as elevation in tight junction protein level as opposed to the disease control (Zhang et al., 2021b). This restoration of intestinal tight junction proteins has also been observed using in-vitro and murine models of IBD supplemented with fermented barley and soybean (Woo et al., 2016c). Studies have also measured rescue of intestinal integrity via measurement of bacterial translocation. As the microbial community resides within the gut, translocation can indicate a compromise to intestinal integrity. The translocation of microbes and their cellular components can activate the peripheral immune system resulting in the release of cytokines that can ultimately trigger altered BBB integrity and neuroinflammation (Maes et al., 2013,ÿVujkovic-Cvijin et al., 2022). Indeed, pre-treatment ofÿmiceÿwith milk fermented usingÿLacticaseibacillus paracasei subsp. paracaseiÿlowered intestinal permeability as visualised by the reduced translocation ofÿSalmonella typhimuriumÿ(Acurcio et al., 2020). Although less frequently studied, downstream reinforcing effects of fermented food on BBB integrity was observed followingÿkimchiÿandÿkefirÿsupplementation, which increased expression of BBB tight junction proteins along with a sex-specific reduction of mRNA levels of IL-1? and TNFà in the pre-frontal cortex andÿhippocampusÿin murine models (Kim et al., 2022b,ÿMurray et al., 2019).",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Beyond their influence on barriers, fermented foods are also studied with respect to their role on central/peripheralÿimmunomodulation. Preclinical studies assessing the impact of fermented foods on the immune system have either studied effects on the baseline unperturbed immunological state of the host or when the host is subjected to an immune challenge that mimics a pathological condition. For instance with respect to the latter,ÿLactobacillus delbrueckiiÿandÿStreptococcusÿthermophilusÿfermented yogurt supplementation in a recurrent model of IBD in murine models, decreased levels ofÿTLR4?+?and IL-17 along with elevation of IL-10 andÿTLR9?+?cells in the colon (Chaves et al., 2011). Similar reductions in the levels of inflammatory cytokines, especially IFN-? and TNF-à, were observed in the colon of mice receiving milkÿkefirÿpost-infection withÿGiardiaÿintestinalisÿ(Franco et al., 2013). These effects could be due to the ability of some kefirs to upregulate mRNA levels of IL-17 and downregulate IL-6, TNF-à, and IFN-? when subjected to immune challenge in mice (Acurcio et al., 2020). Moreover, repeated treatment with other milk kefirs in mice has been shown to increase levels ofÿTregÿand IL-10 cells coupled with an attenuation of the elevatedÿneutrophilsÿandÿCXCL1ÿlevels induced by the stress of repeated oral gavage (Van De Wouw et al., 2020). Further studies have highlighted that this potential peripheral immunomodulation observed in kefir could be attributed to IgA-stimulatingÿLactobacillus kefiriÿthatÿreduces expression of pro-inflammatory cytokines in the mesentericÿlymph nodesÿand increases anti-inflammatory cytokines, CXCL-1 and expression of mucin-6 genes. Other strains of the same species were also associated with a lowered expression of IL-6 in the ileum and colon post-LPS exposure (Carasi et al., 2015). It should be noted that studies focusing on a single strain isolated from fermented food aid in the discovery of potentialÿprobioticÿstrains and can give insights into the mechanisms via which a fermented food may confer a health benefit. However, these studies do not capture the broader bioactive potential of fermented foods that include more complex mixtures of bacterial strains,ÿbioactive peptides, microbial metabolites, fibres and other components that can impart beneficial biological effects on the individual (Vieira et al., 2021).",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Studies are increasingly shifting towards understanding the far-reaching effects of fermented foods on neuroinflammation. A spatial observation of the immunomodulatory effects of fermented foods on the brain revealed that hippocampal and cortical regions of the brain exhibit lower levels of mRNA expression pertaining to IL-6, TNF-à, TLR4 receptor and MCP1 protein, which was significantly upregulated in mice fed a high-fat diet (Kim et al., 2022b). This was also observed in the hypothalamic regions of the brain and serum in mice subjected to chronic unpredictable mild stress when supplemented with fermented rice germ (Batsukh et al., 2022). Future work is needed to explore the impact of fermented foods at each compartment of the microbiota-gut-brain-immune axis, particularly the effects of microbial metabolites on the intestinal barrier, peripheral immune system, BBB and central immune system. This information would provide valuable insight into understanding the molecular underpinnings of the microbiota-gut-brain-immune axis.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Importantly, some of the aforementioned findings relating to the immunomodulatory effects of fermented foods have translated to human studies, albeit only a few studies have also concurrently looked at the gut microbiome profile. For instance, in a study conducted with healthy volunteers, a 10-week fermented food-based intervention resulted in decreased circulating cytokine levels, especially IL-6, IL-10 and IL-12b, along with a concurrent reduction of activation proteins from 4 major immune cell types: CD4+, CD8+, T and B cells (Wastyk et al., 2021). The study also revealed a correlation between faecalÿbutyrateÿand lower circulating B cells (Wastyk et al., 2021), mirroring the preclinical findings of an interplay between microbial metabolite and host immune status. Furthermore, a reduction in circulating cytokine levels such as IL-4, IL-10, IL-12 and MCP-1 was observed in IBS patients supplemented with kimchi for a period of 12 weeks (Kim et al., 2022a). This is however not replicated in other studies that have looked at the impact of fermented, unfermented andÿpickled vegetablesÿfor 6 weeks (Galena et al., 2022). The study showed no difference in their serum C - reactive protein (CRP) and TNF-à profile, when measured at the end of the intervention. Similarly, a fermented food enriched diet, when administered for a duration of 4 weeks, did not show any alteration in serum cytokines (Berding et al., 2023).ÿEpidemiological studiesÿhave also revealed no associations between the consumption of fermented and unfermented dairy with circulating CRP levels (Voutilainen et al., 2022). It is therefore surprising that a recent meta-analysis onÿfermented dairy productsÿsuch as yogurt, fermented milk and kefir revealed lowered CRP and elevated IFN-? with no significant effect on IL-12, IL-10 and IL-6 (Zhang et al., 2023). It is clear that the effects of fermented foods on circulatory inflammatory cytokines cannot be generalised given the varied responses observed with intervention strategies. A potential reason for this could be due to the heterogeneity of food substrates and microorganisms present in the fermented food and duration of the dietary intervention. The immunological response observed is highly tailored to the fermented food that is being studied and could be influenced by the microbial community it hosts (Spindler et al., 2022) and is addressed in greater detail in the final section of the review. It is also to be acknowledged that sex plays a critical role in modulating microbiota-gut-brain-immune axis communication (Jaggar et al., 2020,ÿKlein and Flanagan, 2016). Some studies have only looked at fermented food supplementation in male (Schoen et al., 2009,ÿBourrie et al., 2023) and female volunteers (Han et al., 2015,ÿGalena et al., 2022). One study, however, examined sex differences on moderate beer consumption and observed that women had higher CD3+ÿcounts than male volunteers, with both groups showing an overall reduction in the IFN-?/IL-10 ratio when compared to their baseline abstinent phase (Romeo et al., 2007). However, there is a general dearth of human studies that explore sex-selective immunomodulatory responses associated with the consumption of fermented foods and its effects on the overall health of the individual.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"The HPA axis is a key regulator of mood and behaviour and forms the neurohormonal component of the microbiota-gut-brain axis. Dysregulation of the HPA axis and its interplay with the immunological system is implicated in multiple neuropsychiatric disorders (Wingenfeld and Wolf, 2011,ÿRinne et al., 2002,ÿCruz-Pereira et al., 2020). Cortisol, the main stress hormone of the HPA axis, has been shown to modulate the immune system (Bellavance and Rivest, 2014), BBB permeability (Varanoske et al., 2022) and intestinal barrier integrity (Zhao et al., 2019,ÿKarl et al., 2017). The latter is responsible for sustainingÿhomoeostasisÿin the gut micro-environment (Amini-Khoei et al., 2019,ÿUren Webster et al., 2020) and can be influenced by the neurological state of the host.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"In murine models, the impact of the HPA axis on various behavioural parameters such as appetite, aversion and cognition are studied by using a multitude of tests such as forced suspension, and immobilisation (despair related behaviour), sucrose water preference (depression-like behaviour), elevated plus maze (anxiety-like behaviour) and startle reflex (responsiveness) and many others (Packard et al., 2016). Consumption of fermented foods including red beanÿtempeh, cheese and fermented plant (Laminaria japonica) as assessed by murine models, was shown to reduce anxiety-like behaviours andÿcorticosteroneÿlevels when subjected to stress (Chen et al., 2020a,ÿChen et al., 2021b,ÿFourman et al., 2021a,ÿJung et al., 2020). Similar attenuations in depression and anxiety-like phenotype accompanied by lowered plasma corticosterone and inflammatory markers such as NF- ?b, TNF-à and IL-6 were observed in the colon of mice supplemented with fermentedÿginsengÿextract for a period of 5 days (Han et al., 2020). In a comparable manner, fermented porcine placenta supplementation for a 21-day period, which showed lowered cortisol along with creatinine kinase and lactate. The study also showed concurrent lowering of circulating cytokines- IL-6, TNF-à, IL-1?, IL-4 and IFN-? (Kim et al., 2016). All of the mentioned studies report a strong interplay between the immune system and the HPA axis. A potential mechanism by which fermented foods are able to modulate cortisol release could be via blunting the response peripheral immune challenge by causing a reduction in circulating cytokines and other inflammatory markers which are responsible for activating neuronal projectionsinto the PVN (Bellavance and Rivest, 2014). Interestingly, a study on mice subjected to restraint stress and receiving milk kefir treatment, reported the probiotic containing fermented food was able to block HPA axis dysregulation by attenuating the altered expression ofÿglucocorticoid receptorsÿin the PVN, when compared to mice receiving unfermented milk. The study also hinted at the HPA axis dysregulation to be highly sex specific and a potential connection between IL-6 and glucocorticoid receptor expression (Smith et al., 2021). Such interesting exploratory efforts could shape our understanding of the multifaceted role played by fermented foods in modulating the microbiota-gut-immune-brain axis.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Fermented foodÿinterventions in human cohorts have been limited and conflicting. An 8-week intervention of fermented porcine placenta resulted in lower serum cortisol levels along with concurrent reduction in the mRNA expression of IL-1? following treadmill stress testing (Yoon et al., 2020). Similarly, reductions in salivary cortisol was observed in students receivingÿLacticaseibacillus casei strain Shirotaÿand subjected to examination stress. The same strain was also shown to blunt the release of corticosterone in rats subjected to water avoidance stress (Takada et al., 2016). Conversely, some studies reported no effects of fermented foods on post-stress cortisol levels (Jaatinen et al., 2014,ÿMarcos et al., 2004), potentially due to the small quantity, diverse nature of fermented food being consumed, and short duration of intervention.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Theÿenterochromaffin cellsÿin the intestine are major producers of serotonin (Lund et al., 2018). Gut-derived serotonin is shaped by host diet (Bruta et al., 2021,ÿHorn et al., 2022), baseline microbiota composition (Reigstad et al., 2015a,ÿYano et al., 2015,ÿHata et al., 2017) and microbial metabolites produced as a consequence (Reigstad et al., 2015a,ÿYano et al., 2015). Although serotonin cannot pass the BBB, it can influence fundamental aspects of the gastric system, such as regulating secretion, motility and tonicity. There are a growing number of studies focusing on the influence of fermented foods on serotonin secretion with special emphasis onÿtryptophanÿmetabolites. Tryptophan metabolites are critical precursors for serotonin andÿmelatoninÿbiosynthesis and also lead to the production of indole and kynurenine-related metabolites, all of which are increasingly being appreciated for their neuroactive role in addition to maintaining gut health.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Preclinical studies report lowered serotonin turnover in the colon of mice supplemented with milk kefir compared to unfermented controls (Van De Wouw et al., 2020), which was also reflected in mice subjected to immobilisation stress and supplemented with fermented Chinese medication such as fermentedÿMentha arvensisÿand fermentedÿCornus officinalisÿ(Tian et al., 2018,ÿTian et al., 2020). Other preclinical models have demonstrated the ability of fermented soy-based food such asÿtempehÿto modulate the level of serotonergic genes. Tempeh-fed zebrafish showed upregulation in genes involved in transportation, synthesis and signalling of serotonin, namelyÿtph1b, tph2ÿandÿslc6a4aÿgenes in the brain (Chen et al., 2021b). The ability of fermented foods to modulate peripheral serotonin levels could be attributed to the presence of endogenous bacteria within the food, which are capable of producing these metabolites as a result of the fermentation process (Jeong et al., 2021,ÿGallardo-Fern ndez et al., 2022,ÿKumar et al., 2022). The ability of fermented foods to modulate gut health could also be credited toÿsynbioticÿcomponents present in the food. A study of a murine model of constipation employed a synbiotic yogurt containingÿkonjac mannanÿoligosaccharideÿ(prebiotic) andÿBifidobacterium animalisÿspp lactisÿ(probiotic). The study reported an increase in levels of acetylcholine,ÿsubstance Pÿand upregulation ofÿmotilin,ÿvasoactive intestinal peptide receptorÿ(VIPR-4) and 5-HT4 receptors in colonic tissue upon intervention with the synbiotic containing yogurt (Li et al., 2021b).",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Despite these developments, there remains a shortage of human studies that have extensively explored the involvement of fermented foods in modulating the serotonergic landscape. In one instance, daily consumption of a fermentedÿmilk productÿcontainingÿLactobacillus caseiÿfor 8 weeks showed increased faecal serotonin and decreased abdominal discomfort without changes in serumÿtryptophan,ÿkynurenine, salivary cortisol and IgA levels compared to participants receiving unfermented controls (Kato-Kataoka et al., 2016). Other studies onÿwhite wineÿconsumption have shown lowered myogastric electrical activity, variation in plasma serotonin and dopamine profiles (Boyer et al., 2004,ÿLevanon et al., 2002). Peripherally produced serotonin cannot cross the BBB but downstream metabolic products of tryptophan metabolism can cross the BBB and influence neurological state of the host. In recent years, research has been dedicated towards understanding the effects of tryptophan metabolism, especially theÿkynurenine pathway, on host behaviour and health. A meta-analysis ofÿprebioticÿand probiotic supplementation on tryptophan metabolism revealed significant decrease in kynurenine and kynurenine:tryptophan ratio with probiotic supplementation (Purton et al., 2021). Indeed,ÿmetabolomicÿanalyses of fermented foods have revealed that they are reservoirs for tryptophan metabolites (Y?lmaz and Gkmen, 2020), revealing that it could be interesting to see how peripheral supplementation of tryptophan metabolites can affect mood and behaviour modulated by the gut microbiota.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"The enteroendocrine system (EES) is capable of secreting molecules that can influence the afferent vagus nerve, and receptors of these molecules are expressed higher up in the nucleus tractus solitarius (NTS) and hypothalamic regions of the brain. These regions undermine energy expenditure, food preferences and satiety of the host thereby mediating feeding behaviour (Latorre et al., 2016,ÿHolst, 2013). Functioning of the EES is also influenced by microbial metabolites that are introduced through dietary intake. The EES primarily hosts a network ofÿgut hormonesÿsuch as serotonin, neuropeptide-Y, GLP-1,ÿghrelin,ÿpeptide YYÿ(PYY), motilin andÿsomatostatinÿthat continuously relay information to the enteric nervous system (ENS). The impact of each of these gut hormones and peptides on the microbiota-gut-brain axis has been described in detail across multiple extensive reviews (Richards et al., 2021,ÿWachsmuth et al., 2022,ÿSun et al., 2020). In brief, the hormones of the EES regulate motility, appetite, release of insulin and bile acids (Sun et al., 2020). The submucosal and the myentric plexsus of the ENS communicate with each other via a small collection of neurotransmitters and neuropeptides, which can be secreted and modulated by the fermented food microbiome, microbial metabolites and co-occurring active principles.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Theÿenteroendocrine cellsÿ(EEC) receive multiple stimuli ranging from nutrients, toxins and microorganisms present in fermented and unfermented food and respond by releasing peptides and hormones. Modulating the levels of GLP-1 is being used to attain improved glucose homoeostasis (Yadav et al., 2013) as well as to target obesity (Aldawsari et al., 2023) resulting in the development of wide array of GLP-1 analogues aimed at managing obesity (Dailey and Moran, 2013) and type 2 diabetes mellitus (Maselli and Camilleri, 2021). Dietary intervention strategies are also being employed to target circulating levels of GLP-1 peptides in patients diagnosed with type 2 diabetes (Di Mauro et al., 2021) and abdominal obesity (Fuglsang-Nielsen et al., 2021). This recent exploration in the use of dietary strategies to combat type 2 diabetes mellitus has resulted in the identification of microbial metabolites, predominantlyÿSCFAÿthat can improve production of GLP-1 and peptide YY, both of which are implicated in regulation of insulin release. (Zhao et al., 2018). Fermented foods as a potential source of prebiotics and probiotics to shape the gut microbiota and its metabolites are also being explored to manipulate the levels of gastric peptides that are implicated in satiation and insulin release (Manaer et al., 2015,ÿFallah et al., 2018).",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Both unfermented and fermented foods contain bioactive components that can influence the secretion ofÿincretinsÿsuch as GLP ??1, a gut hormone implicated in satiety (Johnson and De Mejia, 2016). It is therefore necessary for studies focusing on the impact of fermented foods on the enteric environment to concurrently account for the effect of unfermented controls on EEC secretion profiles. The patterns of endogenous and exogenous release of GLP-1 have been well reported in murine models and human studies (Flint et al., 1998,ÿTerrill et al., 2019,ÿChen et al., 2021a) and therefore can be adopted to study the effects of fermented foods on satiation. Interestingly, in-vitro studies on kippuku-cha, a fermented Japanese beverage, was found to activate GPR-120 and stimulate the release of GLP-1 via phosphorylation of the Erk1/2ÿ(p42/44ÿMAPÿkinase) pathway (Nagasawa et al., 2020). Similarly, phenol andÿpolysaccharideÿextracts fromÿquinoaÿyogurt fermented withÿstarter culturesÿofÿS. thermophilusÿandÿLactobacillus bulgaricusÿstimulated the release of GLP-1 and influenced expression ofÿproglucagonÿmRNA, CCK and c-FOS along with DDP-1?V inhibitory potential (Obaroakpo et al., 2020). The study revealed that the fermented product elevated concentrations of GLP-1 and proglucagon than the unfermented controls. Such studies assessing the incretin release profile using in-vitro studies must be interpreted with caution, as their effects can be inflated when compared to in-vivo conditions. For example, fermented dairy-based products such as whey possess the ability to stimulate the release of GLP-1 and CCK (Chaudhari et al., 2017,ÿS nchez-Moya et al., 2020), however these effects were not translated to in-vivo studies (Kondrashina et al., 2018). The study stated that this lack of translatability between in-vitro to in-vivo models could be due to the action of gastrointestinal enzymes, which may reduce the GLP secretogogue capacity ofÿfermented dairy productsÿunless enterically protected (Kondrashina et al., 2018).",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Human studies often adopt self-reported questionnaires to gauge the effect of intervention strategy on satiety and hunger. In humans, fermented dairy, fermented dairy alternates and fermented bread are predominantly studied for their ability to modulate satiety in the individual, but only a few studies investigated circulating GLP profiles. For example, consumption ofÿsourdough breadÿby Swedish adults resulted in pronounced satiety compared to consumption of unfermented wholeÿgrainÿand yeast fermented controls. However, the effects of sourdough on insulin release and satiety has not been replicated in two other clinical trials (Shah et al., 2020,ÿIversen et al., 2018). The GLP-1 release profiles across all the cohorts were unaffected, suggesting fermented foods enhance satiety via mechanisms independent of GLP-1 (Zamaratskaia et al., 2017). Apart from sourdough, high levels ofÿvinegarÿsupplementation has been associated with increased satiety and lower postprandialÿblood glucoseÿ(Ostman et al., 2005). Researchers have hypothesised that the satiating effect ofÿvinegarÿand some sourdough could be due to the acid content of the fermented product. The inconsistent results observed on satiety profiles across studies could be attributed to factors such as sex, sample size, duration of intervention, method of sourdough preparation (including species and strain level differences) and quantity of sourdough consumed (Ribet et al., 2023).",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Desacyl ghrelin and acyl ghrelin areÿorexigenicÿhormones that are the predominant forms of circulating ghrelin and are implicated in the regulation of appetite and itsÿneuroprotective effectsÿ(Lach et al., 2018,ÿRhea et al., 2018,ÿHuang et al., 2019). Unlike serotonin, ghrelin is released in the periphery and can cross the BBB, thereby binding to several targets associated with food reward including corticolimbic,ÿamygdala, insula and orbitofrontal cortex (Zanchi et al., 2017,ÿFarokhnia et al., 2019). Leptin, an anorexigenic hormone produced by adipocytes andÿenterocytes, is shown to activate several regions of the brain such as theÿbrain stem, parahippocampal gyrus, middle frontal gyri, middle temporal gyrus, rightÿhypothalamusÿand lingual gyrus (Zanchi et al., 2017). Several detailed reviews have highlighted the role of gut hormones in regulating food reward-motivated behaviour in the host and also in contributing towards the conversation between the gut and the brain (Lach et al., 2018,ÿZanchi et al., 2017,ÿDecarie-Spain and Kanoski, 2021). It is therefore essential to also understand if fermented foods can alter levels of ghrelin/leptin in circulation and consequently affect the food reward-motivated behaviour of the host.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Preclinical murine models have addressed this topic by showing a reduction in plasma ghrelin levels post-intervention with fermented goat and cow milk and mixed results with respect to impacts on plasma leptin andÿadiponectinÿlevels (Diaz-Castro et al., 2017,ÿMu¤oz Alfrez et al., 2020). Moreover, rats receiving a fermented whey beverage alongside a high-fat diet showed no difference in leptin and ghrelin profiles, despite a decrease inÿfood intake, compared to high-fat diet controls (Hong et al., 2015). Some studies have included unfermented controls and have reported a greater reduction in serum leptin (Lu et al., 2021) and ghrelin levels (Liu et al., 2019a) upon consuming the fermented counterparts. Such reports serve as an important reminder to interpret other studies that lack critical controls with caution, so as to prevent inflating the potential health benefits associated with fermented food intake. A number of human studies have tried to ascertain if the satiating effects of fermented food are due, at least partially, to protein content. In one randomisedÿcrossover study, the diets of participants were supplemented with fermented and unfermented tempeh (protein control) for a period of two weeks. The group receiving the fermented product showed a reduction in circulating acyl-ghrelin levels by 30% with concurrent reduction in circulating insulin compared to unfermented controls (Noer et al., 2021,ÿDiaz-Castro et al., 2017). Other clinical studies have reported varied gastric hormone responses depending on the fermented product consumed. The effects have ranged from an increase in ghrelin after moderate beer consumption without changes in leptin levels (Beulens et al., 2008) to almost no differences in the level of leptin and ghrelin release amongst different fermented dairy products (Hansson et al., 2020) and no effect onÿsensationÿof satiety post-intervention withÿred wineÿdespite lowering of plasma ghrelin levels (Ismail et al., 2022). These results provide evidence of the highly individualistic enteric hormone release profiles towards the consumption of fermented foods along with potential involvement of other pathways/gut hormones, in driving satiation.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Another gut hormone associated with satiety is somatostatin, which has long been implicated in satiety and hunger. Activation of somatostatin positive neurons in the brain shows increased preference towards high-calorie foods and may be implicated in the development of metabolic conditions such as obesity (Kumar and Singh, 2020); but it is important to note that somatostatin has alsobeen shown to regulate the release of gastric enzymes, increasedÿgastric emptyingÿand mediating inflammatory response. The stomatostatin release profile after consumption of fermentedÿsoyÿbean (natto) was demonstrated in mice subjected to gastric mucosal injury. The mice receiving the fermented soy bean showed higher levels of somatostatin, vasoactive intestinal polypeptide, and motilin (Suo et al., 2015) and concurrently showed lowered levels of serum cytokines. Microbial metabolites are also being studied for their participation in modulating satiety of the host. Several studies exploring the effects of SCFAs have shown that feeding behaviour can also be influenced by these bi-products of bacterial fermentation (Brooks et al., 2017). For example, yogurt supplementation to rats reduced weight and elevated faecal SCFAs (Qu et al., 2018). Similarly, a type 2 diabetes model of mice receivingÿkombuchaÿlowered fasting blood glucose and increased faecal SCFAs compared to unfermented tea (Xu et al., 2022). However, both interventions maintained intestinal permeability and restructured the gut microbiome by increasing the abundance ofÿLactobacillus, ButyricicococcusÿandÿLachnospiraceaeÿwith a concurrent increase in the levels of GLP-1 and PYY secretion. A potential mechanistic explanation for this could be the stimulating action of SCFA on the mRNA for POMC, AgRP, CART in the hypothalamus (regions of the brain implicated in feeding and energy expenditure) (Pichiah et al., 2016), a pattern which is in agreement with targeted peripheral administration of acetate (Frost et al., 2014). Together, these studies hint at a potential crosstalk between gut microbiota, microbial metabolite profiles and the ENS/CNS within the individual. Most of the discussed pre-clinical studies have included only a single time point post-intervention with the fermented food. The analysed parameters include only a subset of the phenotypical traits such asÿbody weight, feeding pattern andÿadiposity. In addition to this, molecular markers implicated in understanding satiety and feeding behaviour is also being incorporated. This method of experimental design might be insensitive in capturing transient changes in the gut microbiota and microbial metabolite composition, and gut hormone profile, and can therefore be resolved by sampling at multiple time points.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"The gut microbial community produces metabolites that can modulate host health and reinforce/reduce the integrity of the intestine and BBB thereby modulating the levels of pro-inflammatory triggers reaching systemic circulation and eventually the brain. It is therefore important to understand the impact of fermented food on the intestinal milieu and intestinal health, as they continuously relay information to the peripheral immune system, enteric andÿcentral nervous system.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"In addition to the modulation of the gut microbiota, preclinical studies have also looked at the impact of fermented dairy products on intestinal permeability (Putt et al., 2017), microbial metabolites (Gao et al., 2021) and peripheral cytokine profile (Du et al., 2022). Frequently studied microbial metabolites, SCFA?s were elevated in interventions containing fermented plant-based products such as fermented carrot juice (Liu et al., 2021,ÿYu et al., 2022,ÿMa et al., 2021),ÿfermented beveragesÿcontaining fruits and vegetables (Wang et al., 2019), and fermented raspberryÿpomaceÿenriched withÿlactic acid bacteriaÿ(Wu et al., 2021). SCFA?s are implicated in the maintenance of intestinal barrier integrity (O'riordan et al., 2022) and might be the driving force in increasing the expression of tight junction proteins thereby reinforcing the permeability of the intestine (Zorraqu¡n-Pe¤a et al., 2021,ÿTaladrid et al., 2021).",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"It is to be noted that sex is a critical factor that can influence the composition of the gut microbiome (Bridgewater et al., 2017). Studies exploring the sex-selective effects on gut microbiome composition have been conflicting, and this may be due to small sizes of study population,ÿbody mass index, xenobiotic use, diverse dietary patterns, pathological condition, inconsistencies in tools and pipelines employed to study microbiota composition, diverse ethnicities and strains of models employed in preclinical studies (Kim et al., 2020). The aforementioned factors influence the gut microbiome to a greater effect than sex in humans (Kolde et al., 2018,ÿJaggar et al., 2020,ÿLloyd-Price et al., 2017). Murine models, however, seem to show a much more pronounced difference in gut microbiota profile than human studies (Mcgee and Huttenhower, 2021), which has led to differential responses to dietary intervention strategies (Bridgewater et al., 2017). Considering this sexual dimorphic nature of the gut microbiota, a recent study of dietary fibre supplementation for 20 weeks to mice revealed sex-specific responses in the gut microbiome and faecalÿmetabolome. Female mice on a high inulin-based diet showed increased abundance of Bacteroidota and a decline in Faecalibaculum andÿLactococcus, the latter of which is exaggerated in diets rich in dietary fibre (Lloyd-Price et al., 2017). The sexually dimorphic nature of the microbiota in mice along with the differences in the gonadal hormone profile results in a distinctÿhumoral response. As a result, there is a marked increase in genes pertaining to inflammation in the hippocampus and hypothalamus profile in a sex-specific manner when subjected to probiotic intervention (Yahfoufi et al., 2023). Fermented foods being a possible source of prebiotics and probiotics, as previously described, have resulted in a sex-selective responseÿ(Murray et al., 2019). Therefore, preclinical murine models should be controlled for sex-selective variations in the gut microbiome and downstream immunological profiles.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Several literature works have documented the capacity of fermented foods to restructure the gut environment and modulate host health (Stiemsma et al., 2020,ÿLeeuwendaal et al., 2022,ÿSelhub et al., 2014,ÿMelini et al., 2019,ÿAslam et al., 2020,ÿCosta et al., 2021,ÿMoreno-Arribas et al., 2020), hinting at the potential capacity of fermented foods to influence microbiota gut-brain-axis communication. Some of the modulatory components are produced as a result of the fermentation process. For instance, fermented beverages can contain a percentage of alcohol and other volatile components that can influence the composition of the gut microbiota. The impact of the alcoholic fraction of fermented food on the gut microbiome has been reported in murine (Lee et al., 2020) and human studies (Marques et al., 2022). The alcoholic portion of the fermented food has to be accounted for as it has been recently implicated for its ability to confer a neurological benefit to the food consumer. A retrospectiveÿcohort studyÿanalysing the impact of alcohol consumption and changes in their intake frequency with risk of dementia revealed its potential neuroprotective activity. The study reported mild and moderate drinkers had a lower risk of all-cause dementia compared to non-drinkers whereas heavy drinkers were posed to have a higher risk of all cause dementia (Jeon et al., 2023). In fact, recentÿsystematic reviewsÿhave revealed that low to moderate percentage intake of alcohol in several of the fermented foods and beverages have been linked with lowered risk of Alzheimer?s disease and dementia (Porras-Garc¡a et al., 2023). For this reason, it is also important to control for the effect of alcohol on the gut microbiota and gut brain communicatory pathways. Fermented foods can also alter metabolite production in the gut even without altering the microbial composition or diversity in some circumstances. This can be due to the presence of dietary fibres and bioactive components that are intrinsically present in the food (Zhou et al., 2019,ÿWang et al., 2021). Fermented foods can also be rich in phytochemicals and other bioactive agents, though some of these originate from the food substrate and hence are also present at similar concentrations in the unfermented counterparts. In light of this, it is important to include unfermented controls in preclinical and human study design, so as to accurately understand the components of fermented foods driving the change on the intestinal milieu and on cognitive health.ÿSupplementary table 1ÿprovides a non-exhaustive compilation of important phytochemicals present in both fermented and unfermented foods that can influence microbiota-gut-brain communication. Fermented foods also contain a variety of potentially health-promoting microorganisms that can confer better gut health in addition to contributing towards the restructuring of the gut microbiota. Indeed, strains isolated from fermented camels? milk, pickledÿChinese cabbageÿ(LAB fermented), fermented yogurt when formulated into a probiotic cocktail (Lactobacillusÿspecies) all showed the ability to restore the colonic microbial community in antibiotic-treated mice and shift the gut microbiota at a phyla level from a Pseudomonadota-dominated environment to a profile similar to the control group (Shi et al., 2018).",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"In other instances, it would seem that the beneficial impacts are not attributable to a single strain but rather a combination of factors, including the introduction of multiple microbes, metabolites and substrates that confer benefit to the host. This was evident in mice receiving fermented barley juice, which resulted in an altered faecal metabolomic profile in a manner that was distinct from the group receivingÿLactobacillus plantarumÿalone (Zhu et al., 2021). It should be noted that the ability of fermented foods to shape the gut microbiome in preclinical models does not necessarily translate to human studies (Nguyen et al., 2015,ÿHugenholtz and De Vos, 2018). To address this, many studies have explored the impact of fermented foods on the gut microbiome in humans. For instance, observational studies reveal high alpha gut microbiome diversity in Korean participants who habitually consumed high amounts of fermented legumes,ÿfermented vegetables, tea, seaweed and nuts (Noh et al., 2021). Similarly, self-reported fermented food consumption patterns in 130 participants from northern Spain also revealed that fermentedÿdairy consumptionÿcorrelated with higher levels ofÿAkkermansiaÿand low levels ofÿBacteroidesÿwith concurrent high levels of SCFA such as propionate and butyrate, a pattern that was also observed among cheese consumers when compared to non-consumers (Gonz lez et al., 2019). Greater beta diversity has been seen in regular fermented food consumers than occasional consumers with the former displaying higher proportions ofÿFaecalibacterium prausnitzii,ÿPrevotellaÿspp,ÿPseudomonasÿspp,ÿClostridiales,ÿEnterobacteriaceae, LachnospiraceaeÿandÿBacteroides sppÿ(Taylor et al., 2020). On the other hand, the effects of fermented foods on gut microbiome diversity are inconsistent between intervention and observational study designs with studies reporting little to no change in the diversity metric after intervention with fermented food (Alvarez et al., 2020,ÿBerding et al., 2023,ÿLe Roy et al., 2022,ÿGonz lez et al., 2019). The conflicting nature of these studies could be attributed to the gut microbiome being predominantly resistant to change over time (Faith et al., 2013). It could also be due to the study duration being too short to capture subtle changes, diverse nature of fermented foods being incorporated into the study design, high degree of interindividual-variability of baseline gut microbiome amongst participants warranting need for crossover studies with sufficient washout period. Other factors include studies employing 16?S rRNA gene sequencing as opposed to shotgunÿmetagenomicsÿsequencing, thereby lacking species and further strain level resolution that can significantly contribute towards understanding the subtle changes in microbiota composition along with variation in functional capabilities of microbiome.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"The ability of fermented foods to influence the major communication pathways involved in gut to brain signalling has been foundational in its adoption to target mental health. To identify fermented foods that modulate the microbiota-gut-brain axis, it is important to know the current ways by which fermented foods are able to alter communication pathways that are involved in relaying information from the gut to the brain. The priming of theÿimmune systemÿand the restructuring of the gut microbiota and microbial metabolites via fermented food supplementation has been extensively studied. In addition to the immune system, theÿENS, along with its gastric peptides and hormones, is also being shaped by fermented food supplementation.ÿTable 3ÿprovides a summary of the current understanding of fermented foods on communication pathways between the gut and brain derived fromÿSection 2.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Preclinical models used to study the modulation of microbiota-gut-brain axis by fermented foods typically include drosophila, zebrafish, murine and porcine models. Each of these models possess different advantages ranging from being high throughput to having a gut anatomy that resembles that of humans, thereby increasing the likelihood that beneficial impacts, if observed, could be translated.ÿFermented dairy productsÿhave been studied most extensively using these preclinical approaches. Indeed, different fermented dairy products have impacted the gutÿmicrobiome, microbial metabolites, inflammatory profile and behavioural phenotypes, resulting in distinct variations compared to normal controls. Behaviourally, administration of specific fermented dairy products has resulted in attenuated anxiety (Oh et al., 2020,ÿHan et al., 2020) and depressive-like (Van De Wouw et al., 2020,ÿChen et al., 2021c) phenotypes and improved performance in memory associated tasks (Van De Wouw et al., 2020,ÿVan De Wouw et al., 2021,ÿLiu et al., 2020a). These studies have also reported, in some but not all instances, differences between the microbial communities of groups administered fermented food and those that were administered unfermented controls (Han et al., 2020,ÿVan De Wouw et al., 2020,ÿVan De Wouw et al., 2021). Fermentedÿsoyÿfoods in the forms of tofu,ÿtempeh,ÿmiso, fermentedÿsoy milk,ÿnattoÿand chungkookjang were the next most extensively studied food in pre-clinical models. Fermented soy-based products were found to alter the gut microbiome at family level, modulate the levels of various molecular messengers involved in maintenance of permeability (Chen et al., 2020a,ÿSingh et al., 2021,ÿDai et al., 2019), raise the level ofÿanaerobesÿ(Bedani et al., 2010) and improve intestinal integrity (Kawahara et al., 2015,ÿJeong et al., 2020a). Notably with respect to this review, the studies also revealed that interventions with fermented soy were associated with significant improvements in memory (Kridawati et al., 2016,ÿWoo et al., 2016b,ÿGo et al., 2016,ÿYang et al., 2015). Fermented sugar-based products such asÿkombuchaÿand other fruit juices have shown the ability to improve exploratory behaviour, hippocampal memory as well as reinforce intestinal barrier by increasing the levels of SCFA, tight junction proteins and lowering expression of inflammatory cytokines (Cataldo et al., 2020,ÿChen et al., 2019,ÿPakravan et al., 2019,ÿZorraqu¡n-Pe¤a et al., 2021,ÿHartmann et al., 2000). The longest duration of an intervention involved the administration of a specific wine toÿmiceÿfor 28 weeks, which resulted in attenuation of cognitive decline. Importantly, the effects of alcohol were accounted for through the use of an ethanol control. They reported no difference in behavioural tests (Barnes maze) and amyloid plaque formation pattern between control and ethanol controls, indicating the neurological benefit of wine was independent of alcohol percentage (Wang et al., 2006). Other substrate categories include diverse fermented plant products such as fermented seaweed, fermented peanut meal, fermented Chinese herbs such asÿC. lanceolata,ÿspirulina maximaÿand rice peptides, which have shown improvements in learning and memory inÿmurine modelsÿ(Reid et al., 2018b,ÿDing et al., 2021,ÿWeon et al., 2014,ÿCorpuz et al., 2019,ÿChoi et al., 2018).",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Fermented dairy intervention in humans have yielded mixed results, ranging from an absence of differences between the intervention and placebo groups in mini-mental status exam (MMSE) scores (Beauchet et al., 2019,ÿSuzuki et al., 2019) to a mixed trend with respect to circulating BDNF (Chung et al., 2014,ÿSuzuki et al., 2019,ÿNev et al., 2021) andÿCRPÿ(Chen et al., 2019,ÿKuroda et al., 2007,ÿGonz lez et al., 2019) levels. Similarly, when a fermented food enriched diet is considered, especially while employing multiple fermented foods of varied substrate categories, an increased gut microbiota diversity was observed (Wastyk et al., 2021), a feature that was not observed in a 4 week fermented food based dietary intervention study when compared to the arm receiving control diet (Berding et al., 2023). A potential explanation for this could be the variation in fermented foods categories employed in both studies along with duration of the dietary intervention.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"In general, observational studies relating to the consumption of fermented dairy products on the gut microbiome mirrored longitudinal intervention based human studies (Tessier et al., 2021,ÿLe Roy et al., 2022,ÿSuzuki et al., 2017). Observational studies that analysed the consumption of a broad collection of fermented food in participants showed a clear separation of gut microbiota profiles between consumers and non-consumers, along with lowered anxiety in the former (Taylor et al., 2020,ÿHilimire et al., 2015a,ÿKarbownik et al., 2022b). Moreover, observational studies investigating the impact of fermented soy-based products such as tofu,ÿtempeh,ÿmiso,ÿnattoÿandÿsoy sauceÿrevealed that higher consumption of soy-based products correlated with better cognitive function in women (Nakamoto et al., 2018b) and was also associated with attenuation of age-associated memory (Porras-Garc¡a et al., 2023) and cognitive decline (Lin et al., 2018). Theÿisoflavoneÿcomponents of fermentedÿsoy productsÿcan exert oestrogen-like protective effects and may contribute to the neuromodulatory effects of fermented soy-based products in women (Nakamoto et al., 2018a). Studies have also have reported negative consequences associated with the consumption of tofu, which is implicated in worse cognitive outcomes in several cross sectional observational studies (Xu et al., 2015,ÿHogervorst et al., 2008a,ÿWhite et al., 2000). It has been hypothesised that the formaldehyde used in the production of tofu for maintaining freshness could cause oxidative damage thereby contributing to cognitive decline (Hogervorst et al., 2008a). When we look at meta-analysis on microbiota targeted intervention strategies on global cognition, fermented food based intervention strategies revealed a greater degree of promise than prebiotics and probiotics. The study also reported no significant alteration in memory by prebiotics, probiotics and fermented food intervention (Marx et al., 2020). The study attributed these findings to heterogeneity in cognitive tasks included in the analysis and studies being under-powered to test a hypothesis, in addition to an overall lack of studies (N?=?22) that are geared towards understanding the impact of microbiota-targeted interventions with cognitive readouts.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"The production of fermented foods is influenced by various environmental conditions and processing parameters. Indeed, the analysis of a large collection ofÿfermented milkÿsamples, predominantly yogurt, koumiss, cheese and fermented yak milk from Mongolia, China and Russia, shows a distinct clustering based on geographical origin (Zhong et al., 2016). The presence of a region-specific microbiota was also observed in Mongolian fermented cow milk samples from Chita and Kalmykia in Russia (Liu et al., 2015) and Airag samples from Mongolia (Choi, 2016). Theÿgenetic polymorphismsÿof starter cultures containingÿSaccharomyces cerevisiaeÿobtained from Manipur (Indo-Burma) and Sikkim (Himalayan) also varied in a manner that reflected geographical origins (Jeyaram et al., 2011). Scale of production and manufacturing conditions could partially explain the variation in fermented food microbiome as a consequence of geographical location, as was the case withÿfermented meat productsÿobtained from France, Italy and Spain compared to products obtained from Belgium and Germany. The fermented meat product showed distinctÿLABÿcommunities segregated by geographical zone of production and the use of different starter cultures (Van Reckem et al., 2019). This was mirrored in other fermented foods, such as Kochujang (Nam et al., 2012,ÿBal et al., 2017) and also onÿLABÿfermented pickles from China, wherein foods made through commercial fermentation contained more LAB than those generated through artisanal fermentation (An et al., 2021). Emerging research suggests the presence of a distinct coreÿmycobiota, as seen with Chinese traditional dough starters, fermentedÿrice wineÿand Chinese grape wine (Huang et al., 2021,ÿBartram et al., 1994,ÿLiu et al., 2020d) and even the viral community being more indicative of geographical location inÿkimchiÿsamples (Jung et al., 2018). However, this does not hold true across all studies of fermented foods. Indeed, a large study of sourdough starter cultures (n?=?500) revealed homogeneity and only weak influence of geography on shaping the fermented food microbiome (Landis et al., 2021). Nonetheless, geographical location and scale of production are of critical importance as artisanal/traditionally fermented foods may possess a different microbial community that is critical for the production of bioactive metabolites, which may be absent from commercially produced strains. An example of this is observed in milkÿkefir, wherein traditionally fermentedÿkefirÿshows the potential to lower cholesterol in metabolic models of obesity in mice. Consequently, the same effects were not observed in specific commercial kefir beverages (Bourrie et al., 2018). The taxonomic composition driving variation in biological effect is also observed in kombucha samples sourced from artisanal and commercial sources (Villarreal-Soto et al., 2020). In fact, these subtle variations in taxonomic compositions between commercial and traditionally prepared fermented foods have recently been revealed to elicit different circulatory cytokines profile in a randomised crossover trial in humans in that, traditionally prepared kefir showed a greater reduction in CRP, sVCAM, IL-18 and TNF-à compared to commercial kefir (Bourrie et al., 2023). It is important to consider such factors when implementing fermented food based interventions targeting microbiota-gut-brain-axis modulation.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Another feature that has a driving influence in shaping fermented food microbiota is the type of substrate that constitutes the fermented food. Various substrate categories of fermented foods are highlighted inÿTable 1. An extensive study on fermented food showed dominance of LAB in brine,ÿAcetobacterÿin sugar-based fermented foods and similarities in the microbiotas across dairy based fermented food (Leech et al., 2020). The driving influence of substrate on fermented food microbiome has been shown to also be reflected in the community composition profiles of naturally fermented milk samples, namely koumiss, which differed in the type of milk used (Zhong et al., 2016). Similar observations were made in a study analysing the effect of different sugar substrates in the production of Argentinean kefir (Gamba et al., 2021) andÿfermented meat productsÿobtained from the Inuit community (Campbell et al., 2022). Preparatory conditions such as duration of fermentation, fermentation salinity, pH (Llf et al., 2021) andÿmoisture contentÿ(Chen et al., 2023) also influence the microbiome of fermented food. Processing conditions such as ripening time influences the microbial community present in fermented food (rezac et al., 2018,ÿJingkai et al., 2020), and these changes were attributed to lowering of the pH and changes in the active enzymes present in the fermented food. In the case of one such example, Taga cheese showed a gradual lowering of mesophilic and psychotropic bacteria at the end of the ripening process. This was accompanied by an increase in the levels of yeasts and moulds along with a gradual increase inÿlong chain fatty acidsÿ(Criste et al., 2020). Shaping of the microbial community by such environmental factors manifest also into shaping the functional capabilities of food, with certain food substrates and fermentation production practices enriching for the presence of biosynthetic gene clusters (BGCs)(Du et al., 2023). BGCs are increasingly being studied for their ability to produce specialised metabolites that can influence the health of the host. All of these factors could be exploited in the manufacturing process to coincide with harvest times when foods possess the greatest bioactive potential.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"The highly malleable microbial community present in fermented foods is difficult to standardise and poses a critical challenge (Mukherjee et al., 2022). Although theÿCodex Alimentariusÿaids in providing guidelines and standards, with a considerable focus on fermented dairy products (Alimentarius, 2003), other fermented food categories have not been extensively explored. However, such consensus or regulatory guidelines require an element of cultural sensitivity that is considerate of the origin and traditional practices involved in fermented food production (Campbell et al., 2022). The increased application of next generation ?omics? techniques has aided the process of standardisation by identification of various community members and their complex relationships. This has led to the development of extensive data archives (Zinno et al., 2022,ÿWhon et al., 2021,ÿChaudhary et al., 2021). These repositories are valuable sources of information and can be used as reference sources to obtain a preliminary hypothesis on the type of microbial community or bioactive molecule(s) that could be present in the fermented food, which could be harvested for therapeutic benefit. However, there is much that is left to be explored given the diverse nature of fermented foods.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Human studies aiming to understand the impact of microbiota-targeted therapy need to consider a few key points that are discussed in this section, which can add value with respect to investigating the impacts of fermented food consumption on microbiota-gut-brain axis communication.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Accounting for controls:ÿFermented foods can contain a variety of components withÿbioactive properties. However, these agents are also present in unfermented controls.ÿSupplementary table 1ÿcontains information from a non-exhaustive collection of studies relating to the bioactive agents present in fermented foods and the corresponding unfermented substrates. This is of particular importance as the beneficial effect conferred may not always be a result of the fermentation process. Ultimately, studies assessing the effects of fermented foods require the inclusion of suitable unfermented controls. This is also highlighted in theÿTable 2,ÿTable 3ÿ(preclinical) andÿTable 4,ÿTable 5ÿ(clinical), which focus on the delineation of cohorts to account for the effect of unfermented controls. Ideally, the participant should be blinded, though this is not always possible and depends somewhat on the fermented food under investigation.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Measuring fermentedÿfood intake:ÿOne of the challenges in employing fermented foods as a supplementation strategy in human studies is to accurately and conveniently quantify intake, especially when participants are asked to increase their fermented food consumption. This is a challenge when patients are recommended to incorporate a diverse range of fermented foods with their diet as opposed to single food/beverage, which can be consumed as an entire serving. Non-invasive methods of measuring dietary adherence by the participant include employment of 24-hour food recall (Karbownik et al., 2022a,ÿKarbownik et al., 2022b), food diaries andÿfood frequency questionnairesÿthat are geared towards capturing the diverse nature of fermented foods (Taylor et al., 2020,ÿLi et al., 2020). These methods are often disadvantaged by not being all-encompassing, subject to respondent fatigue, limited to human memory (Das et al., 2022) but are low cost and easy in their employment, thereby being commonly used for reporting the consumption of fermented food (Ribeiro et al., 2022). Fermented food frequency questionnaires (FFQ?s) must also be tailored to different environments to account for ethnic/racial minorities and must accommodate various culturally distinct populations so as to accurately capture their consumption. The information provided by FFQ can be supplemented with other methods of measuring dietary intake, albeit their respective shortcomings of being logistically and economically difficult to implement. These methods include: evaluation of biomarkers in plasma and urine, digitalised assessment of dietary compliance via food images and smart phone applications that capture the food intake.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Biomarkers: Identification and measurement of biomarkers exclusively associated with intake of a specific fermented food can be of tremendous importance as it can accurately measure fermented food consumption in a clinical atmosphere. It is a much more accurate measure compared to dietary questionnaire counterparts that are used to register food intake. Biomarkers can be of critical clinical relevance, especially when diverse fermented foods are being consumed. However, since fermented foods and other food products might share the same core substrate profile, they might result in overlapping biomarker profiles. This requires the need for identifying biomarkers that can be accurately associated with the consumption of the fermented food. Advancements such as plant metabarcoding offers a unique solution, wherein genomic sequences from human digest and faecal samples act as unique fingerprints in identifying food consumed especially when multiple food are part of the regimen (Petrone et al., 2023). A recent systematic analysis has revealed certain biomarkers that show a high degree of fidelity towards fermented foods such as wine, beer,ÿsourdough bread, cheese and tea (Li et al., 2021a). Biomarkers can then be used as a proxy to titrate the frequency of consumption of a given intervention in participants thus becoming a part of the next generation of tools employed for precise dietary assessment. The study by Li et al. also revealed biomarkers forÿfermented vegetables, fish, fruit and meas consumption were less explored, and as a result a dearth of information on microbial metabolites as well as other host derived metabolites related to these substrate categories (Li et al., 2021a). Follow up studies have furthered the use of biomarkers to titre for food consumption of a given substrate category and also their potential correlation to cardiometabolic health (Li et al., 2023). This information could be curated/extrapolated to mental health and can be used to formulate an optimised fermented food dosage regimen by which the foods are able to confer mental health benefit to the individual.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Employing appropriate methods to capture microbiome: Most of the studies investigating the causal impact of the microbiome on host health utilise 16?S rRNA gene sequencing to capture the residents in the gut environment. Although metabarcoding approaches are cost effective and comprise of well-established pipelines that are less computationally intensive, they drastically reduce the degree of granularity required in understanding the key microbial members and functional underpinnings of the microbiome along with their influence on host health (Shankar, 2017). In fact, immunological responses towards microbes are highly tailored at a strain level, as also seen with metabolism of xenobiotics (Anderson and Bisanz, 2023), thereby justifying the need for greater degree of resolution offered by shotgunÿmetagenomicsÿtechniques. Metatranscriptomic andÿmetaproteomicÿtechniques are increasingly being used to identify the genes expressed by the microbial community and proteins produced as a consequence of a given microbiota-targeted intervention. Though these techniques are computationally expensive and difficult to integrate into traditional microbiome analytic pipelines, they are increasingly being recognised as the way forward in understanding the functional potential of the gut microbiome.",,,,,
Fermented foods: Harnessing their potential to modulate the microbiota-gut-brain axis for mental health,"Fermented foods can have a considerable impact on health by virtue of the variety of different microbial strains, metabolites and other bioactives that can be present therein. These components can be optimised to offer maximal neural and mental health benefits to the individual. This in-depth review has highlighted the individual components of the microbiota-gut-brain axis that, on the basis of clinical and pre-clinical studies, can be modulated by fermented foods and/or components thereof. While noting the increasing body of research that has been generated in recent years, it also reveals the critical need for additional human studies with unfermented controls to truly identify beneficial impacts that act on the microbiota-gut-brain axis. Understanding the factors that mould the fermented food microbiome and microbial metabolites will help to reveal the impact these factors can have on the biological benefit conferred by the fermented food. Finally, although there are many obstacles and considerations that need to be accounted for, fermented foods form a vital part of the next generation of microbiota-based therapeutics targeting mental health. It is hoped that, in the words of Goethe ?time will only, strengthens the fine fermentation?.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","Generative artificial intelligence (GenAI) shows potential for personalized care, psychoeducation, and even crisis prediction in mental health, yet responsible use requires ethical consideration and deliberation and perhaps even governance. This is the first published theme issue focused on responsible GenAI in mental health. It brings together evidence and insights on GenAI?s capabilities, such as emotion recognition, therapy-session summarization, and risk assessment, while highlighting the sensitive nature of mental health data and the need for rigorous validation. Contributors discuss how bias, alignment with human values, transparency, and empathy must be carefully addressed to ensure ethically grounded, artificial intelligence?assisted care. By proposing conceptual frameworks; best practices; and regulatory approaches, including ethics of care and the preservation of socially important humanistic elements, this theme issue underscores that GenAI can complement, rather than replace, the vital role of human empathy in clinical settings. To achieve this, an ongoing collaboration between researchers, clinicians, policy makers, and technologists is essential.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","The continued development of generative artificial intelligence (GenAI) and large language models (LLMs) shows potential in many fields, including high-stakes areas such as education, judicial work, security, and health. Utilizing this potential responsibly requires thoughtful deliberation and consideration and the creation of guidelines and conceptual frameworks that encompass the complexities of some of these fields.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","The name of this theme issue reflects its focus??Responsible Design, Integration, and Use of Generative AI in Mental Health.? The current abilities of GenAI models for language generation and image synthesis already demonstrate their ever-growing potential use in personalized mental health psychoeducation, diagnosis, treatment planning, and interventions. However, integrating any of these applications within the mental health care realm requires careful examination, given the sensitive nature of mental health data, research, and interventions and the various capacities that may be expected of these models in these realms, to be considered of acceptable professional standard. Recent studies highlight the significant ethical challenges posed by GenAI, emphasizing the need for robust governance frameworks to mitigate risks and enhance the trustworthiness of these technologies [1-3].",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","This theme issue unites diverse stakeholders in exploring and adding a critical building block for the global challenge of conceptualizing and operationalizing responsible GenAI in mental health. It includes a collection of articles that examine the advantages, challenges, and potential risks associated with deploying GenAI models in mental health care while also proposing guidelines and best practices for their ethical and responsible implementation. Several papers discuss the application of GenAI in clinical settings; the ethical implications of artificial intelligence (AI)?driven mental health interventions; and the development of new frameworks to ensure the alignment of GenAI systems with human values, virtues, and ethical standards. These include transparency, accountability, and fairness in AI applications; privacy and data security [4]; and authenticity and congruence [5].",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","The exploration of GenAI?s role in mental health is particularly timely, given its rapid adoption and the evolving landscape of digital health technologies. Recent research has highlighted the transformative potential of GenAI in creating personalized mental health interventions that can enhance care delivery and patient outcomes. For instance, GenAI models are already used to generate therapeutic content, simulate dialogues for therapy, and even predict mental health conditions based on language patterns and sentiment analysis [6]. However, this potential is accompanied by significant ethical and practical challenges, such as ensuring the accuracy and reliability of AI-generated content and preventing the misuse of these technologies [7]. This theme issue provides a platform for in-depth discussions on these topics and proposes actionable insights for the responsible integration of GenAI in mental health care.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","We begin by exploring GenAI?s capabilities and limitations in mental health applications. Although the ever-evolving capacities explored in any research are, by definition, representatives of the time and models examined, the conceptual and normative-related discussions could have longer-term implications and relevance. The first paper, ?Capacity of Generative AI to Interpret Human Emotions From Visual and Textual Data: Pilot Evaluation Study? [8], evaluates the ability of ChatGPT-4 and Google Bard to interpret human emotions from both visual and textual data. Using the Reading the Mind in the Eyes Test and the Levels of Emotional Awareness Scale, the study found that ChatGPT-4 performed well in both visual and textual emotion recognition, aligning closely with human standards. Google?s GenAI Bard, however, showed limitations in visual emotion interpretation. This paper emphasizes the need for inclusive data and stringent oversight to ensure accurate and reliable emotional recognition by AI systems.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","The second paper, ?Comparing the Perspectives of Generative AI, Mental Health Experts, and the General Public on Schizophrenia Recovery: Case Vignette Study? [9], compares the perspectives of GenAI models, mental health professionals, and the public on schizophrenia recovery. The findings show that some AI models align closely with professional views, while others, like ChatGPT-3.5, demonstrate pessimism that could negatively impact patient motivation. The study highlights the potential and limitations of AI in providing clinical prognoses and underscores the need for rigorous validation of AI applications in mental health.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","The third paper, ?Suicide Risk Assessments Through the Eyes of ChatGPT-3.5 Versus ChatGPT-4: Vignette Study? [10], examines the capability of ChatGPT models to assess suicide risk based on vignettes. The findings indicate that ChatGPT-4?s assessments align more closely with those of mental health professionals compared to ChatGPT-3.5, which often underestimates suicide risk. These findings highlight the potential of advanced AI models to support mental health professionals but also underscore the necessity for further research and careful implementation to ensure accurate and safe use in clinical settings.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","The paper ?Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: Benchmark Study? [11] evaluates the performance of state-of-the-art LLMs in summarizing therapy sessions. By introducing the Mental Health Counseling-Component?Guided Dialogue Summaries dataset and assessing task-specific LLMs, like MentalLlama, Mistral, and MentalBART, the study demonstrates their promise while emphasizing their current limitations in terms of clinical applicability. Expert assessments revealed the need for further refinement and validation before such tools can be integrated into practice.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","Another key contribution, ?Large Language Models Versus Expert Clinicians in Crisis Prediction Among Telemental Health Patients: Comparative Study? [12], compares GPT-4?s performance with that of senior clinicians in predicting suicide crises based on intake data. Although GPT-4 approached clinician-level performance in some metrics, its reliability was limited by sensitivity and bias issues. The study underscores the potential such tools have for augmenting crises prediction but highlights the need for additional safety measures and validation.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","Herein, we delve into the ethical and humanistic considerations of GenAI in mental health.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","In ?Exploring Bias(es) of Large Language Models in the Field of Mental Health ? A Comparative Study Investigating the Effect of Gender and Sexual Orientation in Anorexia Nervosa and Bulimia Nervosa Case Vignettes? [13], the authors showed that LLMs assigned lower mental health?related quality of life scores to men compared to women with a similar eating disorder severity, with no real-world epidemiological evidence for such a pattern. This may reflect historical underrepresentation and societal biases in the data used for training the model and raises questions about how such biases can be mitigated by users as well as developers.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","Next, we address the ethical implications of humanizing AI and the importance of empathy in therapeutic contexts.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","The paper ?The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals With Depression: A Critical Analysis? [14] explores the use of LLMs, such as OpenAI?s ChatGPT-4, in mental health care. It highlights their potential to offer personalized therapeutic support for patients with depression through context-aware interactions. However, it also identifies significant ethical and technical challenges, including the risks of humanizing LLMs and their lack of contextualized robustness. Humanization can lead to unrealistic expectations and overtrust, while inadequate robustness may cause inconsistent and potentially harmful responses. The authors recommend clear communication of AI limitations, fine-tuning with high-quality data, and interdisciplinary research to responsibly integrate LLMs in mental health care, thereby enhancing patient support while minimizing risks.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","The paper ?The Machine Speaks: Conversational AI and the Importance of Effort to Relationships of Meaning? [15] explores the implications of using conversational AI in place of human effort in interpersonal relationships. The authors emphasize that effort in relationships conveys intrinsic value and meaning, which can be lost when machines take over these interactions. They discuss the importance of maintaining human effort in therapeutic contexts to preserve the meaningful engagement and personal growth that come from human-to-human interactions. This paper encourages a critical examination of the potential losses in meaning and opportunities for self-understanding when relying on GenAI.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","Following this, the paper ?Considering the Role of Human Empathy in AI-Driven Therapy? [16] addresses the critical role of empathy in therapy. It evaluates whether AI-driven therapy can replicate empathic interactions. The authors define different aspects of empathy, compare the empathic capabilities of humans and GenAI, and discuss when human empathy is most needed in therapeutic settings. They call for ongoing research and dialogue to ensure that AI-mediated therapy maintains the essential human element of empathy, which is crucial for effective therapeutic outcomes.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","In ?The Artificial Third: A Broad View of the Effects of Introducing Generative Artificial Intelligence on Psychotherapy? [17], the authors introduce the concept of the ?artificial third? in psychotherapy, following Freud?s theory of narcissistic blows. They argue that GenAI represents a significant shift in how we perceive society, interrelationships, and self. They raise important questions about transparency, autonomy, and the irreplaceable human elements in therapy, suggesting that with ethical consideration, the artificial third can enhance but not replace the human touch in therapeutic relationships.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","Finally, we consider the alignment of GenAI with human values and regulatory perspectives.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","The study ?Assessing the Alignment of Large Language Models With Human Values for Mental Health Integration: Cross-Sectional Study Using Schwartz?s Theory of Basic Values? [18] evaluates whether LLMs align with human values, using Schwartz?s theory of basic values. The authors found that while this framework can characterize value-like constructs within LLMs, there are significant divergences from human values, raising ethical concerns. They call for standardized alignment processes to ensure that LLMs are integrated into mental health care in a way that respects and reflects diverse human values.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","Another important contribution is the article ?Regulating AI in Mental Health: Ethics of Care Perspective? [19], which argues that the dominant responsible AI approach is insufficient because it overlooks the impact of AI on human relationships. The author proposes an ethics of care approach to AI regulation, which addresses AI?s impact on human relationships and establishes clear responsibilities for developers. They highlight the potential for emotional manipulation and the risks involved, proposing a series of considerations grounded in the ethics of care for developing AI-powered therapeutic tools.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","Finally, the article ?An Ethical Perspective on the Democratization of Mental Health With Generative AI? [20] explores the historical context of democratizing information and argues that GenAI technologies represent a new phase in this movement, offering improved accessibility to mental health knowledge and care. However, it also highlights the significant risks and challenges that need careful consideration. The paper proposes a strategic questionnaire for assessing AI-based mental health applications, advocating for an approach that is both ethically grounded and patient-centered.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","The papers comprising this special issue make essential and exciting contributions to the field of digital mental health, specifically focusing on the responsible integration and use of GenAI. These studies showcase the already remarkable abilities of LLMs and allude to the potential of integrating GenAI in mental health diagnosis, treatment, rehabilitation, and recovery while also raising awareness of technical, clinical, philosophical, and ethical challenges related to safety and efficacy.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","This theme issue is merely one stepping stone that is part of an ongoing global effort. Responsible AI frameworks for mental health must be adapted and integrated into local and international governance frameworks, thereby acknowledging that the current extraordinary opportunity also presents a profound professional and societal challenge. By fostering ongoing dialogue and collaboration among researchers, clinicians, ethicists, policy makers, and technologists, we can harness the benefits of GenAI to enhance mental health care while upholding principles, values, and virtues fundamental to humanistic care.",,,,,
"Responsible Design, Integration, and Use of Generative AI in Mental Health","Together, we can ensure that this technology serves as a tool for doing good, augmenting human capabilities while avoiding harm and respecting and retaining the socially important humanistic elements of empathy, authenticity, and connection.",,,,,
Editorial: Artificial intelligence and mental health care,"Advancements in machine learning (ML) and artificial intelligence (AI) offer significant potential to transform mental health care. These technologies have been utilized for various purposes, such as early detection of mental disorders, optimizing personalized treatments tailored to individual patient characteristics, improving the characterization of disorders that negatively impact mental wellbeing and quality of life, better predicting their progression over time, and developing new treatments and diagnostic tools for mental health care. Despite their considerable potential and occasional breakthroughs, ML and AI have not yet fully realized these objectives in mental health care.",,,,,
Editorial: Artificial intelligence and mental health care,This Research Topic aimed to provide innovative examples of how ML and AI applications can be practically implemented in standard mental health care. The particular focus of this Research Topic was to provide examples of how to use ML and AI to enhance public health by lessening the impact of chronic disorders that adversely affect wellbeing and improving quality of life.,,,,,
Editorial: Artificial intelligence and mental health care,"This Research Topic was open between November 10th, 2022, and November 1st, 2023. There were 14 submissions, 12 of which were accepted after peer review, from 64 different authors. While open, the topic had 26,973 views, 19,768 article views, 5,845 article downloads, and 1,360 topic views.",,,,,
Editorial: Artificial intelligence and mental health care,"Alsaqqa and Alwawiÿconducted a scoping review on the characteristics of studies, related concepts, and recommendations for implementing digital interventions in public health. It highlighted the importance of addressing structural inequalities, ensuring personal agency, and social connectedness. The study also emphasized the importance of iterative optimization during study design, involving stakeholders, and using contextual indicators to enhance the effectiveness of digital interventions. An important aspect of the review was the call for more patient and public involvement and the suggestion to adopt standardized metrics to improve research quality and application of digital health interventions.",,,,,
Editorial: Artificial intelligence and mental health care,"Morita et al.ÿexplored the application of large language models like ChatGPT in public health through SWOT and PESTLE analyses. The identified strengths include personalized health support and data analysis capabilities, weaknesses such as potential miscommunication and data privacy issues, opportunities in improving healthcare access and disease surveillance, and threats including misinformation and bias. The PESTLE analysis identified factors like government policies impacting investment and data governance, cost-effectiveness and job impact considerations, public trust and cultural attitudes toward AI, integration with health systems and algorithmic transparency, privacy laws and ethical guidelines, and the environmental impact of AI infrastructure's energy consumption and carbon footprint.",,,,,
Editorial: Artificial intelligence and mental health care,"Wen et al.ÿused 2D gait videos for automatic anxiety assessment among graduate students. By analyzing gait features from time-series data, the authors created anxiety assessment models via machine learning. The study found that dynamic time-frequency features significantly enhance model performance, particularly for women. The models demonstrated reliability and validity, suggesting that 2D gait analysis could be a practical, non-invasive method for real-time anxiety assessment and should be further investigated and evaluated in clinical samples.",,,,,
Editorial: Artificial intelligence and mental health care,"Huisman et al.ÿexamined the validity of automated sentiment analysis in interpreting emotional content from therapy session notes of patients with eating disorders, comparing it to human raters. The study analyzed 460 records and found moderate agreement between automated analysis and human raters. The findings suggest the potential for automated sentiment analysis in clinical settings but emphasize the need for further refinement before applying the algorithm in clinical settings, particularly by incorporating ED-specific terminology and establishing more relevant benchmarks for validation.",,,,,
Editorial: Artificial intelligence and mental health care,"Franken et al.ÿinvestigated the ability of ML to predict improvement in patients using real-world longitudinal data from specialized outpatient mental health treatment. Different ML models were trained and compared with traditional logistic regression. The models showed moderate predictive ability in an independent test set, with slightly better performance when early change scores were included as predictors. Machine learning algorithms did not outperform simpler logistic regression models. Early change during treatment was a crucial predictor for longer-term outcomes.",,,,,
Editorial: Artificial intelligence and mental health care,"Li et al.ÿalso aimed to leverage the advantages of an ML approach over traditional statistical methods to predict the risk of depression in people with obstructive sleep apnea hypopnea syndrome using data readily available from the NHANES database. Several features predictive of depression were identified, including demographic, health and lifestyle-related, and socio-economic factors. Interestingly, like in the study byÿFranken et al., the simple logistic regression model was not inferior?and even superior?to more complex ML models.",,,,,
Editorial: Artificial intelligence and mental health care,"Kim et al.ÿused ML methods to examine the performance of classifying states of stress and non-stress using biosignal data measured by a smartwatch. In contrast to the previous studies, this study used an experimental setup where participants were instructed to perform stress-inducing and relaxation tasks. The top 9 features extracted from the heart rate and photoplethysmography data were able to classify stress with an accuracy of >80% with, again, the logistic regression classifier showing the best performance.",,,,,
Editorial: Artificial intelligence and mental health care,"Delgadillo et al.ÿperformed a study during the COVID-19 pandemic using Bayesian network analyses and modeling interactions between risk and protective factors for suicidal ideation in Austria and the UK. The models achieved high predictive accuracy (AUC ò 0.84 within-sample and AUC ò 0.79 out-of-sample), explaining nearly 50% of suicidal ideation variability. Seven consistent factors, including depressive symptoms, loneliness, and anxiety, were identified in both countries. This study shows the potential to predict suicidal risk accurately using these factors.",,,,,
Editorial: Artificial intelligence and mental health care,"Jovi? et al.ÿaddressed the challenge of comparing ADHD scores across different scales used by various research consortia. They harmonized scores from the Child Behavior Checklist (CBCL) and Strengths and Difficulties Questionnaire (SDQ) using various test equating and machine learning methods on 1,551 parent reports of children aged 10?11.5 years. The study found that methods utilizing item-level information and treating outcomes as interval measurements, such as regression, were most effective for harmonizing scores.",,,,,
Editorial: Artificial intelligence and mental health care,"Pavicic et al.ÿused iterative Random Forests to identify geographic, environmental, and sociodemographic predictors of suicide attempts among U.S. veterans. Analyzing data from 405,540 patients, the model incorporated 1,784 features, including climatic factors, population demographics, and the density of firearms and alcohol vendors. Key findings indicated that areas with higher concentrations of married males have lower suicide attempt rates, while areas with renting and males living alone have higher rates.",,,,,
Editorial: Artificial intelligence and mental health care,"Bremer-Hoeve et al.ÿinvestigated predictors of treatment dropout in patients with post-traumatic stress disorder (PTSD) due to childhood abuse, using elastic net regression. Analyzing data from 121 patients undergoing two different Eye Movement Desensitization and Reprocessing (EMDR) therapy protocols, they identified key dropout predictors: male gender, low education, suicidal thoughts, emotion regulation issues, high general psychopathology, and lack of benzodiazepine use.",,,,,
Editorial: Artificial intelligence and mental health care,"Guo et al.ÿexplored causal factors of non-suicidal self-injury (NSSI) in children using computational causal analysis. They identified nine key factors: life satisfaction, depression, family dysfunction, sugary beverage consumption, positive youth development (PYD), internet addiction, COVID-19 PTSD, academic anxiety, and sleep duration. The research highlighted four main causal pathways and emphasized the roles of pandemic-induced lifestyle changes, screen time, adolescent development, and family dynamics in NSSI risk, advocating for targeted interventions addressing these diverse factors.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Machine learning (ML) has emerged as a promising tool to enhance suicidal prediction. However, as many large-sample studies mixed psychiatric and non-psychiatric populations, a formal psychiatric diagnosis emerged as a strong predictor of suicidal risk, overshadowing more subtle risk factors specific to distinct populations. To overcome this limitation, we conducted a systematic review of ML studies evaluating suicidal behaviors exclusively in psychiatric clinical populations. A systematic literature search was performed from inception through November 17, 2022 on PubMed, EMBASE, and Scopus following the PRISMA guidelines. Original research using ML techniques to assess the risk of suicide or predict suicide attempts in the psychiatric population were included. An assessment for bias risk was performed using the transparent reporting of a multivariable prediction model for individual prognosis or diagnosis (TRIPOD) guidelines. About 1032 studies were retrieved, and 81 satisfied the inclusion criteria and were included for qualitative synthesis. Clinical and demographic features were the most frequently employed and random forest, support vector machine, and convolutional neural network performed better in terms of accuracy than other algorithms when directly compared. Despite heterogeneity in procedures, most studies reported an accuracy of 70% or greater based on features such as previous attempts, severity of the disorder, and pharmacological treatments. Although the evidence reported is promising, ML algorithms for suicidal prediction still present limitations, including the lack of neurobiological and imaging data and the lack of external validation samples. Overcoming these issues may lead to the development of models to adopt in clinical practice. Further research is warranted to boost a field that holds the potential to critically impact suicide mortality.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"The prediction of suicide has been a challenge for decades, and to date, a method for anticipating individual suicides or stratifying patients according to suicide risk is still lacking [1]. Suicide is a worldwide phenomenon and ranks as the second most frequent cause of premature mortality in individuals between 15 and 29 years (preceded only by traffic accidents), and as the third in the age group 15?44 years [2].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Alarmingly, recent studies suggest that the detection of risk factors and the implementation of interventions are inadequate [3]. The majority of individuals who have attempted suicide are reported to consult with physicians prior to the attempt, suggesting that a possibility to intervene might be possible in these help-seeking subjects. The difficulty in predicting suicidal behaviors relies on the lack of clear psychiatric biomarkers and the poor predictive power of individual risk factors [4]. Suicidal behaviors, as many other psychiatric phenomena, are likely the result of the complex relationship between several environmental and trait variables interacting to modify the actual risk rate [4,ÿ5]. Well-recognized risk factors for suicide encompass mental disorders, previous suicide attempts, early trauma, negative life events, and vulnerable periods, with important differences among sexes in terms of ideation and lethality [6,ÿ7]. However, traditional suicide risk factors have only limited clinical predictive value and show a relatively poor clinical utility in predicting suicide occurrence [8,ÿ9], even in high-risk population, such as depressed patients [10].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"That is, to date, a method for anticipating suicides or stratifying patients according to risk for suicidal behaviors remains elusive, and no biomarkers have been yet established [9,ÿ11].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Over the last decades, machine learning (ML) techniques emerged as a potential new tool to improve the management of complex problems in psychiatry [12]. This form of multimodal learning has shown to improve prognostic/predictive performance in various fields of medicine, e.g., cardiology and neurology [13,ÿ14]. As a matter of fact, ML can be used to process high-dimensional sets of variables and determine the optimal model for classification. Importantly, such techniques allow predictions at the individual level, therefore representing a promising tool to accurately characterize the complex nature of suicidal behavior.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"In the last few years, several algorithms and procedures have been used to predict suicidal behaviors in different populations [11,ÿ15?17]. Given that suicide is considered a transdiagnostic feature, a number of studies have been conducted in the general population, sometimes with very large and heterogeneous samples [6,ÿ18]. One of the most solid findings emerging from studies focusing on the general population is that a formal psychiatric diagnosis is a strong predictor of suicidal risk in different samples across countries [1,ÿ6,ÿ18,ÿ19]. This is not surprising, as up to 90% of all suicides occur in psychiatric populations [1,ÿ20?22], with mood disorders being considered the leading cause of suicidality among mental disorders [23,ÿ24].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Therefore, the inclusion of both healthy individuals and psychiatric patients into large sample ML studies may prevent the identification of more subtle risk factors specific to distinct psychiatric disorders by merely taking into account a previous psychiatric diagnosis as the driving factor for the analysis. Instead, by targeting vulnerable populations only, ML could uncover predictors of suicidal behaviors specific to distinct disorders and help in better stratifying patients according to the actual risk. This would translate into useful information that can be more easily applied in clinical and forensic settings [25].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"In this context, in this work, we provide a systematic review of the results from ML studies in psychiatric clinical populations and discuss crucial issues in ML literature, including employed algorithms, features, and samples, with the aim of providing meaningful considerations to future research in the field of suicide prevention.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,The current systematic review followed the preferred reporting items for systematic reviews and meta-analyses (PRISMA) guidelines [26].,,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"A systematic literature search was performed for articles published from inception through November 17, 2022 on PubMed, EMBASE, and Scopus, using the following search terms adapted for each database:",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,(suicid* AND (machine learning OR support vector machine OR deep learning OR neural network OR random forest OR xboost OR gradient boosting OR regression tree OR elastic net) AND (psychiatr* OR schizophren* OR depress* OR obsessive OR bipolar OR mania OR manic OR anxiety OR borderline OR personality),,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Database searches were supplemented by hand-search, which encompassed an extensive search through the reference list of included papers, previous reviews, and the ?Similar Articles? sections in PubMed (reported in Fig.ÿ1ÿas ?Other sources?).",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Two authors (A.P. and G.D.) independently performed the literature search. Documents were assessed according to the following inclusion criteria: (1) journal article available in English, (2) original investigation, (3) employment of ML methodology, (4) evaluation of a suicide risk outcome or self-harm; (5) evaluation of a psychiatric population. Also, we included studies if (a) the sample was composed of individuals with a confirmed psychiatric diagnosis, irrespective of the specific diagnosis and disease severity, and (b) used multiple psychiatric diagnoses or a transdiagnostic framework. The absence of a control group of healthy individuals was not considered an exclusion criterion. To be included, studies must have used ML as a primary or secondary analysis method to predict suicide attempt, suicide risk, or to stratify patients according to risk. No restriction of age was applied. If controversies emerged in the screening processes, they were resolved by discussion between the two authors (A.P. and G.D.) with a third party (P.B.).",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Exclusion criteria were the following: (1) non-original investigations (reviews, expert opinions, meta-analyses); (2) article not in English; (3) employment of a methodology other than ML (logistic regression was excluded, except when it was compared to other ML approaches); (4) evaluation of outcomes other than suicide; (5) exclusive evaluation of non-psychiatric populations (e.g., general population, neurologic patients, high-risk populations, emergency department patients). Given that suicidal behaviors are reported across all ages, age-related variables were not considered an exclusion criterion.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"We also excluded studies in which the sample was composed by ?suicide attempters? without further differentiation in terms of the presence or absence of psychiatric diagnoses. A PRISMA flowchart (Fig.ÿ1) (Page et al., 2021) was created to graphically depict the inclusion/exclusion of studies.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"A preliminary data extraction form was designed by A.P.; it was then pilot-tested on five randomly selected studies and fine-tuned accordingly. The search was rerun on a weekly basis, and data from the newly included studies were added to the database accordingly.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"For each article, the following variables were extracted:",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"General information (author, year of publication).",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Sample characteristics (demographics, numerosity, clinical data).",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,Type of ML algorithm(s) employed.,,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,Number and characteristics of features employed for prediction.,,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"ML performance metrics (AUC, Accuracy, Sensitivity, Specificity).",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,Number of psychiatric diagnoses assessed.,,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,Type of psychiatric disorders assessed.,,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,Findings regarding the prediction of suicide or the classification of risk.,,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Given the different types of features and algorithms employed, the data were not homogeneous enough to be included in a quantitative meta-analysis. Descriptive analyses were employed to analyze study findings by key design characteristics such as the employed features, sample size, and ML algorithms.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,An assessment for bias risk was performed using the Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis (TRIPOD) guidelines [27] (see Supplementary Materials for more details; see Supplementary Tableÿ3ÿfor risk bias results).,,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Based on the search strings and after the removal of duplicates, 745 unique studies were retrieved and screened for eligibility from direct database search and 109 from other sources (Fig.ÿ1).",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"During this screening phase, 82 studies were rejected because they failed to fully meet the inclusion criteria. Subsequently, we reviewed the full texts of the remaining 663 studies plus 109 from other sources. Six hundred studies were further excluded since they did not meet the inclusion criteria (see Fig.ÿ1ÿfor a complete description).",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"As a result, the remaining 81 studies were included in the qualitative synthesis of the review, whose information are summarized in Tableÿ1.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Regarding the predicted outcome, 41 (51%) studies used ML to predict lifetime suicide attempts (e.g., retrospective assessed past attempts), while only 16 (19.7%) longitudinally assessed the risk of suicide using future risk/attempts as an outcome. Specifically, five studies [28?32] predicted the attempts/death at 1 month after the actual evaluation, the study by Chen and colleagues [33] predicted suicide attempts at both one and 3 months from the assessment, while three studies [34?36] predicted suicide risk at three months, and Nock and colleagues [37] predicted suicide between 1 and 6 months. Three studies [38?40] predicted suicide attempts at 12 months, and one study [41] stratified suicide risk at 12 months after the actual assessment. Finally, three studies [42?44] predicted future hospitalization for suicide or future suicide attempts without defining a precise temporal window.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Moreover, 14 studies predicted suicide ideation alone [45?55] or in combination with suicide attempts [56?60]. Finally, other studies predicted self-harm [61?64], suicide risk [38,ÿ55,ÿ65?70], the number of suicide attempts [71], and the presence of a familiar history of suicide [72].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Regarding the number and type of ML approaches employed in the studies, 46 (57%) of the retrieved papers used a single ML algorithm, while 35 (43%) employed more than one. Among those employing more than one ML method, the average number of ML algorithms used was 3.8, with a range from 2 to 7. The most used algorithms were random forest (RF) and support vector machine (SVM), which were employed 29 times each, followed by neural networks-based approaches and decision tree-based approaches, employed 22 and 18 times, respectively. Other ML approaches were used more scarcely: elastic net eight times, Bayesian-based approaches six times, and clustering methods only four times.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Among studies adopting only one ML algorithm, neural networks were used 12 times, SVM 11, RF 5, tree-based approaches 4 times, and elastic nets three times.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"In the studies that compared more than one algorithm, ML methods always performed better than LR. Moreover, RF [32,ÿ57,ÿ73] and SVM [74,ÿ75] resulted among the best-performing algorithms, often with comparable results [65,ÿ76], when compared to other methods. Finally, when present, CNN outperformed other ML methods [49,ÿ50,ÿ62,ÿ77], including SVM and RF (please see Supplementary Tableÿ4ÿfor further details).",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Sample sizes varied substantially across studies, ranging from 37 [42] to 10,120,030 [61] individuals, with an average of 230,074.5 and a standard deviation of 1,392,637. More in detail, twelve studies (14.8%) enrolled less than 100 participants, 27 studies (33.3%) enrolled between 100 and 500 individuals, 12 studies (14.8%) between 500 and 1000, 15 studies (18.5%) between 1000 and 10,000 and the remaining ten studies (12.3%) more than 10,000 subjects. For six studies, it was not possible to retrieve the exact number of participants included in the analysis.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Given the relatively low prevalence of the event of interest (i.e., suicide), most of the samples were unbalanced in terms of the number of subjects in each group. For instance, in the studies conducted by Fan and colleagues [57] and Wang and colleagues [77], the difference in size between the suicidal group and the non-suicidal control group was tenfold (i.e., 205 subjects in the ?suicide? group and 2963 in the ?no suicide? group). Similarly, the difference in Xu et al. [41] was 20-fold, with 2323 patients reporting self-harm and 46,460 patients with no self-harm characteristics. It is important to note that, on the one hand, very large differences in sample size require significant corrections in the predictive algorithm (e.g., the weighting of the hyperplane for uneven group sizes), whereas, on the other hand, they reflect real data, as the prevalence of suicidal events in the assessed population is typically low.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Regarding the psychiatric diagnoses, 45 studies (55.5%) included more than one diagnosis in their sample and assessed the risk of suicide in a transdiagnostic manner, whereas 36 studies (45.5%) focused on patients with a single specific diagnosis. Not all the studies reported full details regarding the diagnostic status of the included sample, with some of them only referring to ?psychiatric patients? to describe the sample.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Among reports detailing patients? diagnosis, mood disorders were prevalent in 64 studies (79%). Specifically, major depressive disorder (MDD) was studied in 37 investigations, and bipolar disorder (BD) in 21 publications. Six studies simply reported ?mood disorders? to characterize the sample. Patients affected by schizophrenia were included in 14 studies, whereas four enrolled patients diagnosed with schizoaffective disorder and five simply reported ?psychosis? as a sample description. Thirteen studies focused on anxiety disorders, eight on substance-use disorders and four on obsessive-compulsive disorders.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Finally, among studies focusing on a single diagnosis, MDD was the most represented one (16 times), followed by BD, schizophrenia, and substance-use disorders represented three times each.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"The number of features employed in the prediction of suicidal behaviors varied considerably across studies, ranging from 10 [71] to 190,919 [64]. Specifically, 20 studies (24.7%) predicted suicide with less than 50 features, seven studies (8.6%) employed between 50 and 100 features, 11 (13.6%) between 100 and 200, ten (12.3%) between 200 and 500, and, lastly, 11 studies (13.6%) employed more than 500 features. In addition, 22 studies (27.1%) did not report the exact number of features being fed to the algorithm for suicide prediction.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"As far as the feature types are concerned, the majority of the studies (54, 66.6%) used clinical and sociodemographic variables. Among these, ten studies were based on electronic health records (EHR), which are becoming an important source of data in the last few years [78].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Ten studies employed brain imaging data to predict suicide: seven studies used resting-state MRI (rsMRI) [54,ÿ55,ÿ60,ÿ68,ÿ69,ÿ79,ÿ80], two used both rsMRI and structural MRI [58,ÿ81], three used diffusion tensor imaging (DTI) [49,ÿ59,ÿ82], and one structural MRI in combination with clinical and demographic data [53], and one single study employed measures from spectroscopy [47]. Eight studies (13.6%) analyzed the text obtained from interviews and EHR using natural language processing (NLP).",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Only four studies (4.9%) focused on genetics and epigenetics features in order to predict suicide, and a single study [46] explored the predictive value of the human metabolome, employing 123 plasma metabolites, to predict suicide. Lastly, three studies [36,ÿ51,ÿ83] used blood biochemistry in association with clinical and sociodemographic data.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"A total of 62 studies (76.5%) reported at least the accuracy or the area under the curve (AUC) of their prediction, while the remaining studies reported different metrics (e.g., positive predictive value, sensitivity F1 score [84]), also because of the methods employed (e.g., clustering and neural networks [41,ÿ68]).",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Interestingly, 87% of studies (i.e., 54 out of 62) focusing on either prediction accuracy or AUC reported values above 70% or 0.70, respectively. Specifically, eleven studies reported an accuracy between 70 and 80%, 14 between 80 and 90%, and six studies above 90%. Regarding AUC, 14 studies showed AUC between 0.70 and 0.80, 16 between 0.80 and 0.90, and eleven studies reported AUC above 0.90. The AUC of selected studies is reported in Fig.ÿ2ÿas a function of sample sizes and number of features. Nonetheless, besides a few notable exceptions [38,ÿ42,ÿ43], no studies tested their prediction on independent validation samples. However, it is noticed that in highly unbalanced samples, the lack of an independent validation sample greatly reduces the overall generalizability. Therefore, these findings are likely to suffer from overfitting and should be regarded with caution [85].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Studies employing clinical and sociodemographic variables confirmed previous suicide risk factors. Previous suicide attempts, suicidal behaviors, or self-harm acts were among the strongest and most replicated predictors [28,ÿ32,ÿ33,ÿ37?39,ÿ61,ÿ63,ÿ71,ÿ73,ÿ75,ÿ86?90]. Similarly, the type and severity of the psychiatric diagnosis seem to be associated with an increased risk of suicide. In detail, diagnosis and severity of MDD [4,ÿ33,ÿ56,ÿ86,ÿ88,ÿ89,ÿ91], psychotic features alone or accompanied by mood disorder [4,ÿ63,ÿ91], borderline personality disorder [33,ÿ86,ÿ89] and previous psychiatric hospitalizations [91,ÿ92], ranked among the most relevant features. Moreover, also comorbidity with alcohol or substance use or abuse emerged as relevant features, irrespectively of the initial diagnosis [28,ÿ57,ÿ71?73,ÿ90?93]. Interestingly, a significant effect on suicide prediction was reported for the use and dosage of psychiatric pharmacotherapy, specifically antipsychotics [33,ÿ63,ÿ64] and antidepressants, especially tricyclics [33,ÿ64,ÿ73]. Moreover, variable importance analysis in a sample of 390,000 US veterans showed that 51.1% of model performance was driven by psychopathological risk factors, 26.2% by social determinants of health, 14.8% by prior history of suicidal behaviors, and 6.6% by physical disorders [87].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"In line with this result, other ML studies highlighted the importance of socio-occupational status and well-being [56,ÿ63,ÿ65,ÿ87,ÿ93]. Similarly, non-psychiatric health issues have been reported among the features able to predict suicide [38,ÿ56,ÿ94]; moreover, one study reported the use of commonly prescribed opioids (e.g., Fentanyl) as a relevant feature in the prediction [57].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Regarding demographic variables, sex, and age differences also emerged. Sex resulted in a significant predictor in five studies, showing either increased risk for males [39,ÿ63,ÿ92] or more complex relationships between biological sex and risk factors [29,ÿ73]. Moreover, age ranked among the most predictive features in five studies [38,ÿ39,ÿ63,ÿ71,ÿ73,ÿ94], with Lopez-Castroman and colleagues [71] also suggesting that the risk increases until middle-aged, but then tends to decrease in the elderly. Lastly, only two studies [72,ÿ93] reported family history of suicide among the most relevant features assessed, whereas criminal or violent behavior were listed as predictive in two other investigations [28,ÿ39].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Regarding the studies that assessed the predictive power of brain imaging data, the thickness and volume of the orbitofrontal, the anterior and posterior cingulate, and the temporal areas were selected by the algorithm as best predictors of suicide attempts in a group of young individuals and MDD patients [53], while in late-life depression sample, frontal areas and precuneus emerges as the strongest predictors [58]. Moreover, measures of functional connectivity [69] of frontolimbic [79,ÿ81] and fronto-temporal circuits, as well as of the default mode network (DMN) [54,ÿ68,ÿ81], the amygdala, the parahippocampus and the putamen [54,ÿ81], attained classification accuracies above 70%.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Regarding clinical predictors in MDD populations, Ilgen and colleagues [92] reported that co-occurring substance use, male sex, and previous psychiatric hospitalizations increased the risk of suicide. Similarly, in a more recent publication [89], hospitalization, previous suicide attempts, and co-diagnosis with a personality disorder resulted in the most relevant features to predict suicide, yielding an accuracy above 80%. Moreover, thyroxine plasma level and the severity of depression (measured via the Hamilton scale for depression - HAMD) were able to predict suicide with an accuracy of 70% [51].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"In studies that involved a broader spectrum of diagnoses of mood disorders (including MDD, BD and also anxiety disorders), previous history of suicide or suicidal thoughts [56,ÿ63], presence of psychotic features [63,ÿ91], and socio-occupational functioning [56,ÿ63,ÿ65] ranked among the most important features in the prediction (all scoring above 70% accuracy). Lastly, Passos and colleagues [91] showed a significant contribution of substance use or dependence and of the number of previous hospitalizations to suicide risk, whereas Iorfino and colleagues [63] found that treatment with antipsychotics, sex, and age were relevant features in the prediction. A brief summary of the most important features is reported in Supplementary Tableÿ5.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"The objective of our review was to summarize the results of ML studies in predicting suicidal behaviors in psychiatric clinical populations. Although the earliest publication in our review dates back to 1998, more than half of the reports were published between 2019 and 2022, ultimately suggesting that ML approaches in psychiatry, and especially in suicide prediction, are becoming more and more frequent nowadays. It is, therefore, important to constantly update the literature evaluation in order to keep pace with an exponentially increasing field. This translates into the opportunity to critically guide the nascent field and address key gaps in the existing literature. Compared to previous literature [95], our review focused only on psychiatric samples, in order to reduce the bias given by the diagnoses in general population. When focusing on broader samples, studies tend to find the presence of a psychiatric diagnosis as one of the most predictive features. Since it is well-known that the psychiatric population are at higher risk for suicidal behaviors, using general population often does not add knowledge in suicide prevention, while on the other side might mask more subtle risk factors. Moreover, compared to previous reviews in the field [95], we gave a more in-depth analysis of predictive features and also employed two different scoring ranking especially designed for ML studies (see Supplementary materials), in order to give the most precise overview of the literature. Critically, all these aspects might serve as a starting point for future studies.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Regarding our results, most studies classified lifetime suicide attempts, and fewer assessed suicidal attempts in a follow-up time window [28?32,ÿ38,ÿ39,ÿ96]. Moreover, some studies classified their sample for death by suicide [44], suicidal ideation [45,ÿ46,ÿ48?51,ÿ56,ÿ57], or risk stratification [38,ÿ41,ÿ65?69]. Differences in the outcomes and in the definition of risk pose a problem for the interpretation of the results, as risk factors for suicide are reported to be different from those for self-harm and suicidal ideation [1,ÿ97]. In addition, studies also varied in terms of sample selection. Indeed, while most of the publications assessed suicide as a transdiagnostic outcome [38,ÿ40,ÿ63,ÿ66,ÿ67,ÿ81,ÿ98], only a few authors focused on patients with a specific diagnosis, mostly mood disorders [46,ÿ51,ÿ53,ÿ58,ÿ68,ÿ75,ÿ89,ÿ92]. These differences limit the translation of the findings into clinical practice. Prediction models will likely improve prediction accuracy and inform clinical decisions if tailored not just for specific diagnostic groups but also on a dimensional approach to psychiatric disorders [16], as every diagnosis has a different and specific type of assessment and disease trajectory. This means that different patients? groups might have different predictive features, with probable overlaps between diagnoses. Therefore, a focus on specific diagnostic groups should not divert attention from a comprehensive evaluation of the patient, given that both physical and psychiatric (especially substance abuse disorder) comorbidities proved among the most important predictive features.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Furthermore, another main issue regarding the reviewed studies is the imbalance between the prediction groups, given the low prevalence of the event of interest, with some studies including a larger control group, even tenfold bigger, than the suicidal group [41,ÿ57,ÿ77]. Although an imbalance is intrinsic to this kind of studies, given the prevalence of suicide in psychiatric disorders, some methods can be deployed to reduce the risk of false positive. Fan and colleagues [57] opted for an oversampling in the training phase, a procedure that creates new samples by connecting inliers and outliers from the original dataset. This technique allows the creation of dummy subjects to balance the sample, to foster the reliability of the ML analysis. Other analytical procedures to overcome the issue of imbalanced samples imply weighting of the hyperplane for uneven group sizes, selecting a specific ?weight? based on the difference between the groups.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Notably, in most of the cases, the variables employed as predictors were clinical and sociodemographic [48,ÿ57,ÿ87]. Several of the strongest predictors in ML studies are well-known risk factors for suicide, such as previous suicide attempts, previous hospitalizations, and severity of depression [28,ÿ38,ÿ51,ÿ89,ÿ91,ÿ94,ÿ96,ÿ99]. Moreover, the presence of psychosis and a higher amount of pharmacological treatments, especially antipsychotics, resulted to be highly predictive features in many investigations [4,ÿ63,ÿ64,ÿ91,ÿ100,ÿ101]. Interestingly, also presence of psychiatric comorbidities was one of the most valuable predictive features, in particular substance or alcohol use disorders [57,ÿ61,ÿ71,ÿ72,ÿ92]. These results emphasize the importance of a comprehensive evaluation of psychiatric patients and of the burden that comorbidities represent, also given their frequent occurrence [102]. This is particularly important for the comorbid use of alcohol and drug abuse, since they can reduce compliance to treatments [103] and increase impulsive behaviors [104], which in turn may act as risk factors for suicide. Besides the well-known suicide risk factors (i.e., history of suicide attempts, hospitalizations, etc.), more subtle risk factors emerged from the reviewed studies. More in detail, comorbidities resulted in important features in different studies, suggesting that not only psychiatric comorbidities but also physical health is important. Similarly, the use of specific drugs (i.e., antipsychotics), illness severity, and psychosis seemed to be highly predictive of suicide attempts. Finally, some studies suggested that also laboratory tests, such as thyroid hormones, might play a role in predicting suicidal behaviors, even at a subclinical level [51,ÿ83].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Although most of the significant features identified by ML are well-known risk factors for suicide [6,ÿ7], ML demonstrate a greater predictive ability when compared with classical univariate statistics (i.e., logistic regression) and clinician assessment of risk factors [8,ÿ9]. In particular, ML attained higher accuracies as compared to logistic regression [46,ÿ49,ÿ57,ÿ61,ÿ63,ÿ67,ÿ69,ÿ87,ÿ105]. These results suggest that advanced methods may inform the clinical decision-making processes in a more precise manner, likely overcoming the poor predictive value provided by classical statistics and expert assessment of the same risk factors [8,ÿ9]. Interestingly, when present, CNN seemed to perform better than other ML algorithms, including SVM and RF. This might indicate the possibility of using deep learning to better stratify suicide risk, at the cost of a slight loss of interpretability.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Lastly, only a few studies employed biological features, such as genes, SNPs, epigenetic loci [42,ÿ43,ÿ98,ÿ106], and neuroimaging measures [47,ÿ49,ÿ53,ÿ68,ÿ69,ÿ79,ÿ81] to predict suicide. Surprisingly, just a single study [53] combined brain imaging with clinical data to predict suicidal behaviors. As one of the major strengths of ML is the possibility to combine data obtained through different modalities (e.g., genetics, brain imaging, clinical features) to increase prediction accuracy, this approach should be exploited in future suicide research, since it is already occurring in other field of medicine [14].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"A number of limitations should be highlighted. Methods varied widely across studies in terms of ML approach, sample selection, features employed, and preprocessing pipeline. Moreover, distinct investigations focused on a variety of different outcomes, from lifetime attempts to death by suicide, from cross-sectional to longitudinal evaluations. Such differences call for increased uniformity in the assessment of suicidal behaviors and in the design of ML protocols to enhance predictions of risk that may translate into clinical practice.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"For instance, the decision to use either a specific and unique ML framework or different algorithms should be motivated: the testing of several approaches at once seems confusing and rather exploratory, especially in the absence of an external validation dataset. Regarding the different algorithms, it is noteworthy to mention that, from our results, it emerged that deep learning methods (such as CNN) performed better than other ML algorithms in direct comparisons. Although important from a research point of view, deep learning algorithms tend to be less interpretable (more ?black boxes?), and this aspect might prove crucial in the further development of AI techniques in medicine and psychiatry. This is true, especially in the field of mental health and suicide prediction, where AI tools should assist clinicians and not introduce further complexity. For an AI to become useful in clinical practice, it should prove to be trustworthy, therefore not only valid and reliable, but also easily understandable [107]. In the last years, the concept of explainable AI (?XAI?) emerged, as a possibility to close the gap between the algorithms and the clinicians, creating a human-understandable correspondence between inputs and outputs of the black-box model either through intrinsic transparency of the model or through post-hoc techniques. Given that clinical applications are high-stakes, we require understandability from the prediction tools, or either AI tools will grow in distrust [107].",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Moreover, features should be accurately selected, and their number should not be excessive (e.g., curse of dimensionality), as in some of the studies [44,ÿ61]. Collecting such a huge amount of data could be feasible only in university centers, thus reducing the translational value of the results. This comprehensive review should also help in the choice of the right type and number of features. For example, pharmacological treatments, especially antipsychotics, were among the most important features in those studies who included them in the models. However, the pharmacological status of patients is often not reported (see Tableÿ1), and in most cases type and dosage of different drugs are not included in the models. Based on the results of our review, it might be beneficial to include data related to pharmacological therapy in the models, since it could potentially enhance the predictive power and clinical applicability of these models. Moreover, the inclusion of pharmacological information might also help in defining protective features, not just risk factors, as suggested by studies showing that some stabilizers and antidepressants might actually reduce the risk of suicide [64]. Also, both psychiatric and physical comorbidities seem to have a predictive role in the presented models; especially, substance abuse as a comorbid disorder resulted to be highly predictive. This aspect suggests a comprehensive evaluation of the patient in order to define the clinical risk.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"In addition, most of the studies addressed the prediction of suicide using a cross-sectional approach, disregarding the temporal aspects. Yet, time may represent a crucial feature for predictive models of suicide [17]. In this regard, defining in advance one or more prediction windows after the assessment is fundamental, as the prediction of short-term suicide risk may rely on different features as compared with long-term risk. Similarly, the temporal characteristics of a feature with respect to the assessment point might impact differentially the accuracy of prediction. For instance, suicide attempts in the year prior to the assessment, but not those that occurred several years before, may be a stronger predictor for new short-time suicidal behaviors.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Finally, despite the high heterogeneity, most of the studies (>80%) obtained a good accuracy, namely 70% or higher. However, many studies did not report additional key metrics (e.g., PPV, F1-score) that are paramount to interpret the actual usefulness of prediction models. Moreover, only few studies tested their prediction on external validation samples; therefore, caution is needed when interpreting these findings, since it is possible that they suffer from overfitting.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"Finally, it is evident the importance of further studies also examining the role of neurocognitive variables, dimensions of social support, loneliness, extent and type of medical comorbidity and associated disability, the type of pharmacological interventions used in the context of specific diagnoses as well as the presence of psychotherapies and their combination with medications on suicidal risk. Similarly, a call for a more consistent use of ML is of paramount importance. CNN, RF, and SVM proved to perform better against other algorithms, but these results should be further tested in the future.",,,,,
Machine learning and the prediction of suicide in psychiatric populations: a systematic review,"The results that emerged from the reviewed studies lead to the conclusion that ML approaches attain greater accuracies in predicting suicidal behaviors across a variety of psychiatric disorders as compared to classical analysis methods. From the reviewed ML studies, well-known risk factors for suicide emerged as relevant predictors, along with new subtle aspects, such as physical and psychiatric comorbidities, presence of psychotic symptoms, and subclinical lab tests, that should be further analyzed and confirmed in future studies. However, additional work is needed to improve the predictive strength of ML algorithms, resolve the systemic lack of external validation, and finally make them become of use in clinical psychiatry. To do so, ML should integrate genetics, neurobiological, brain imaging, psychometric and clinical data to achieve better predictions. Then, algorithms should be presented in an intuitive way for both psychiatrists and patients to foster their adoption and easiness of use in the clinical setting. Although some attempts have been made, to date, ML approaches are not routinely part of clinical practice in psychiatry. We believe ML development should aim to gain the trust of clinicians, by proving to be valid, reliable, and understandable, to be realistically included in decision processes. Our review proved they can be valid in the context of suicide risk stratification; future studies should demonstrate that ML tools are reliable and, even more importantly, easy to understand by clinicians. Multifactorial disorders require multifaceted approaches, and ML could really help in this aspect; however, AI tools should not introduce further complexity in the decision processes, and therefore explainable AI will be a crucial point in further clinical development of predictive tools.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Parkinson's disease is a neurodegenerative movement disorder associated with motor and non-motor symptoms causing severe disability as the disease progresses. The development of biomarkers for Parkinson's disease to diagnose patients earlier and predict disease progression is imperative. As artificial intelligence and machine learning techniques efficiently process data and can handle multiple data types, we reviewed the literature to determine the extent to which these techniques have been applied to biomarkers for Parkinson's disease and movement disorders. We determined that the most applicable machine learning techniques are support vector machines and neural networks, depending on the size and type of the data being analyzed. Additionally, more complex machine learning techniques showed increased accuracy when compared to less complex techniques, especially when multiple machine learning models were combined. We can conclude that artificial intelligence and machine learning techniques may have the capacity to significantly boost diagnostic capacity in movement disorders and Parkinson's disease.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Parkinson's disease (PD) is the second-most common major neurodegenerative disorder, affecting about 2ÿ% of adults globally (U.S.A.: ?1,000,000 people over 45 years of age; Canada: >100,000 people; China: ?22,000,000 people over 65 years of age) [1?3]. PD is the most frequent cause of parkinsonism, which is characterized by a combination of bradykinesia and other motor symptoms such as resting tremor and muscular rigidity. During the course of the disease, patients may manifest a decline in cognitive abilities [4]. It can also result in other non-motor symptoms such as depression and constipation [5]. As such, the identification of biomarker tools to diagnose and predict the progression and onset of PD is imperative.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,,,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"A biomarker is a ?characteristic that is measured as an indicator of normal biological processes, pathogenic processes, or biological responses to an exposure or intervention, including therapeutic interventions [6].? Types of biomarkers are determined by their utility. For instance, diagnostic biomarkers are used to assess the presence of a disease or identify a patient's subtype, while prognostic biomarkers can identify the likelihood of disease progression/recurrence and clinical events. By contrast, susceptibility biomarkers can determine the potential of a healthy patient to develop a disease [6,7]. Thus, it appears clear that multiple biomarkers may be necessary for a better characterization of the disease profile.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Yet, there is still no standard metric to diagnose PD [8?10]. While no specific neuroimaging method is recommended for routine use, clinical research supports the use of certain pre-synaptic dopaminergic radiotracers to confirm the diagnosis in more challenging and questionable cases [11,12]. However, sometimes neuroimaging scans can be inconclusive on their own, so more reliable methods to increase the capacity of diagnostics for PD are necessary [13,14].",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"We created multiple searches through the PubMed database (https://pubmed.ncbi.nlm.nih.gov/) to determine the existing research on movement disorders and PD involving biofluids and neuroimaging as biomarkers and the use of artificial intelligence in movement disorders. Our first search, which resulted inÿNÿ=ÿ4613 English language articles pertaining to humans, aimed to provide context and background for the study. Few articles from our initial search focused on biofluids or neuroimaging as diagnostic, classification, or predictive biomarkers, which prompted subsequent searches. The second search (Nÿ=ÿ146) was limited to require artificial intelligence, machine learning, or deep learning, and the third search (Nÿ=ÿ39) was further limited to articles discussing neuroimaging. The search keywords for the three searches are described inÿTable 1. Articles from the second and third searches were critically analyzed, and relevant articles were verified for scientific integrity by evaluating their place in subsequent literature and determining corroboration and support for claims. The inclusion criteria for eligible studies were as follows: 1) published in English; 2) used a sample of human subjects, including those who were clinically diagnosed with PD, atypical parkinsonism, or a movement disorder; and 3) investigated changes in neuroimaging, biofluids, or clinical symptoms with the aim of differentiating subjects with PD, atypical parkinsonisms, and/or a movement disorder from other subjects and HC. The articles from the second and third searches that passed these inclusion criteria were critically investigated and discussed in this study.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Diagnostic accuracy can be often challenging because of the lack of reliable biomarkers. Machine learning may be able to overcome these challenges if proper metrics are applied to interpret the variety of biomarkers, including clinical, neuroimaging, and biofluid-based biomarkers.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,,,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"The metrics most typically used to assess performance of machine learning models are sensitivity and specificity. Sensitivity is defined as the number of positive cases that a diagnostic tool correctly determines to be positive, while specificity is the number of negative cases that a diagnostic tool correctly determines to be negative. Based on prior research on these metrics, a sensitivity or specificity of 70ÿ% is required as minimum for a test to be fairly sensitive or specific, respectively. In comparison, a sensitivity or specificity of 80ÿ% indicates the test has a fairly good sensitivity or specificity [15]. A sensitivity of 100ÿ% indicates that all positive cases are detected by the tool and there are no false negatives, while a specificity of 100ÿ% indicates that all negative cases are detected by the tool and there are no false positives [16]. The adequate sensitivity and specificity values for an analysis must consider the sample size; a smaller sample size requires higher sensitivity/specificity values for the results to be significant and for researchers to conclude that a test performs well. Another metric frequently used is the area under the receiver operating curve (AUC). This metric uses various thresholds for the variable being used for classification to determine the sensitivity and specificity. For instance, a threshold of 0 for a variable ranging from 0 to 1 aimed to diagnose PD would result in no subjects being classified as having PD, and therefore a sensitivity of 0ÿ% and specificity of 100ÿ%. By comparison, a threshold of 1 would indicate all subjects were classified as having PD, so the sensitivity would be 100ÿ% and the specificity would be 0ÿ%. Sensitivity and (1-specificity) are plotted to create the receiver operating curve, and the area under this curve can be used to measure the model performance. Because of this mechanism, the AUC can be more accurate than sensitivity and specificity, as multiple iterations are used to calculate the metric.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Linear regression is the simplest machine learning technique and uses existing data to plot a linear relationship between two or more variables. Because of this, this technique is best for continuous data that follows a linear relationship. Logistic regression is similar to linear regression. Logistic regression is mainly used in application to discrete variables and classification and uses a sigmoidal curve to estimate probability [17]. A general linear model or generalized linear model (GLM) is a machine learning technique that performs multiple linear regressions to determine the output along with statistical methods such as ANOVA and the two-sampleÿt-test [18]. This technique has been frequently applied to movement disorders, including PD, for statistical analysis. For instance, Wang et al. [19] applied a multivariate GLM to predict the longitudinal progression of MDS UPDRS I and MDS UPDRS II scores. This analysis reported an area under the receiving operator characteristic curve (AUC) of 0.996, with improved performance when using MDS-UPDRS scores. Additionally, Fereshtehnejad et al. [20] performed a cluster analysis along with a GLM to group PD subjects by severity using a combination of cognitive and motor scoring. The researchers were successfully able to categorize PD through this combined analysis, and correlations between the subtype and disease severity were stable after follow-up.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,,,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"A decision tree is a method of supervised learning that is primarily used for classification problems but can also be used for regression. Beginning with a set of data, a decision tree uses the input variable that is best to split the data into the output classes and uses this variable to split the data into subsets. This decision can either lead to another decision to split the data further or to a set of data that predicts the class. Random forests are an extension of decision trees where a subset of the input variables is used to create different decision trees, and the majority vote from these trees is used to generate a classification [17]. One subtype of decision trees is a gradient-boosting decision tree, such as XGBoost or CatBoost. The main difference between gradient-boosting decision trees and decision trees is that while the decision tree aggregates group results at the end of the process, the gradient-boosting decision tree aggregates results after each step and determines error to correct for error in the next step using a loss function. This approach reduces bias and variance [21].",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Support vector machine (SVM) is a machine learning technique which uses data points to determine a nonlinear plane that best separates the data. Due to this mechanism, SVM is primarily used to classify between two different groups, but it has the capacity to discriminate between three or more groups through training separate SVMs [22]. In most classification problems, SVM outperforms linear and logistic regression because it has the capacity to transform data into higher dimensions and separate data in a non-linear plane [17]. SVMs compute the boundary between groups midway between the closest points of the group. While this is useful in small datasets with low dimensionality, such as a small number of features, SVM can be prone to overfitting in with higher dimensionality and larger datasets.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,,,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Because of issues similar to overfitting caused by numerous features being evaluated, feature extraction can be implemented to reduce the number of features used in later analysis. Principal component analysis (PCA) is a technique used to reduce dimensionality in data and reduce the number of variables without removing the original information. To achieve this, PCA determines the pair of variables that causes the maximum variance and removes it, then determines a second pair that causes the maximum of the remaining variances and removes it, and repeat. After this procedure, PCA computes the eigenvalues for these pairs, which represent the total amount of variance that can be explained by one of the pairs. The pairs of features that have eigenvalues greater than one are included, while the rest are excluded. Linear discriminant analysis (LDA) is a similar technique in classification problems for two groups that aims to reduce dimensionality and increase separability between groups. Its method of doing this is to maximize the between-group scatter matrix while minimizing the within-group scatter matrix [23]. Recursive feature elimination (RFE) is an iterative method that removes the variable with the lowest rank from the analysis until there are no variables left to sort the variables by utility [24].",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"The simplest neural network (NN) or artificial neural network (ANN) uses a feed-forward nature, where information flows in one direction. When an input is entered, the input is passed to all nodes in each layer. It is most powerful in complex problem solving, including prediction analysis, and it can work with incomplete data. While simple NNs typically have 0?3 hidden layers with an output layer, deep neural networks can contain hundreds of hidden layers, which contribute to the complexity of the model. Convolutional neural networks (CNN) are a type of ANNs that are suited specifically for image processing. While each input from an image into an ANN is an individual pixel and connections between pixels are lost, CNNs can pass parts of images to specific nodes (convolutional filters) instead of all nodes, so spatial features and connections are accounted for [17]. Radial basis function neural networks (RBFNN) are rarer than CNNs and ANNs and use radial basis functions as the activation function. As these functions are skilled at prediction, RBFNNs tend to train faster than other neural networks [25]. CNNs and ANNs can be used in conjunction for image analysis. One application of this is deep learning. First, convolutional filters from deep CNNs are used to note features of interest on a feature map, which can be passed as an input for the next layer. This process repeats until a final feature map can be created and passed into an ANN to classify the image based on the extracted features. This process can be applied for both image classification and segmentation [17]. Neural networks and deep learning algorithms can handle large amounts of data with high dimensionality better than SVM. Both SVMs and NNs have utility depending on what type of data is being analyzed.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"In Chien et al. [26], SVM and NN classifiers were compared in separation of atypical parkinsonisms (APs) and PD using DAT-SPECT imaging. While the NN was trained from imaging directly, the SVM was trained from the striatal bind ratio (SBR) and asymmetry index (metrics obtained from the images). The NN performed much better than the SVM, which may have resulted from the metrics used by the SVM. In most other studies using SVM in application to neuroimaging data, the classification is based on values obtained from imaging, and the classifier does not assess the images themselves [27?33]. This may restrict analysis to certain values or compromise accuracy. One way to avoid this is to use a feature extraction/elimination technique to ensure that the important features are used by SVM [34]. In some models combining machine learning techniques (defined as ensemble models), models for feature extraction, such as PCA and LDA, are combined with classification or regression models, such as SVM and NN, to limit analysis to fewer features.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,,,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"As many researchers have shown that ensemble models can perform better than single models, this method may increase efficacy. Additionally, ensemble models increase in accuracy when results from multiple machine learning algorithms are combined [26,33]. In future analyses, machine learning algorithms can be analyzed separately to determine individual potential, and from the high-performing algorithms, an ensemble model can be formed. From this analysis, neural networks and algorithms such as SVM and XGBoost should be applied to identification and differentiation of movement disorders.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"A number of studies (nÿ=ÿ8) have explored the broad use of artificial intelligence (AI) to detect and differentiate PD symptoms. Specifically, previous studies have explored the capacity of non-motor clinical data to improve on diagnostic models. Yu et al. [35] created a model combining data from cerebrospinal fluid (CSF) and non-motor clinical aspects (such as olfactory data) that distinguished HC (nÿ=ÿ138) and PD subjects (nÿ=ÿ290). However, the researchers did not report any use of training or testing set, cross-validation, or independent set testing. This indicates that the models were tested on the same data they were trained on, which may have caused overfitting and/or erroneous model performance. When differentiating PD subjects from HC, the model combining the UPSIT scale (a clinical metric for olfactory data) with CSF data (specifically concentration of alpha-synuclein) reported a significant increase in AUC, sensitivity, and specificity compared to when CSF scores were used alone (AUC of 0.927, sensitivity of 89.7ÿ%, and specificity of 80.4ÿ%, as compared to AUC of 0.5982, sensitivity of 42.8ÿ%, and specificity of 76.6ÿ%). Based on the minimal difference in accuracy metrics between the combined and UPSIT-based models, the addition of alpha-synuclein did not have much of an impact on model performance. However, the combined model showed a noticeable decrease in specificity, which suggests that the addition of alpha-synuclein led to more subjects being classified as PD (regardless of whether they were PD or HC subjects) (seeÿTable 4).",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"One study, which explored keystroke data to determine whether a subject had PD (nÿ=ÿ88) or was a HC (nÿ=ÿ30), found that a model using feature selection, which limited the number of features from 378 to 5, combining the most popular features of machine learning algorithms (feature ensemble) provided an accuracy of 91.73ÿ?ÿ100 %. In comparison, a model not using feature selection and combining the results of multiple machine learning algorithms by majority vote (model ensemble) provided accuracy of 81.08ÿ?ÿ100 % [36]. The researchers used leave-one-out cross-validation (LOOCV), which is a version ofÿk-fold cross-validation whereÿkÿis the size of the dataset. Therefore, the model was trained 118 times and a different subject's data was used as a test set each iteration. The feature ensemble was shown to have more consistent results across 14 different data samples compared to the model ensemble. This model ensemble used approximately 378 features, and the model accuracy improved to 89.18?97.50ÿ% when the number of features was limited to five. No confidence interval was reported. Both the feature and model ensembles reported sensitivity of 97.73?100ÿ%, and for specificity, the feature ensemble reported 90?96.67ÿ% and the model ensemble reported 96.67?96.67ÿ% [36] (seeÿTable 2). The disease duration for PD subjects ranged from 0 to 26 years, and the distribution of disease duration was not indicated by the researchers. This model may be most applicable for subjects with late-stage PD.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Another study, which focused on finger movement data while typing, found that PD subjects (nÿ=ÿ48) had lower typing frequency and velocity compared to HC (nÿ=ÿ49), and that typing error and repetition rates were significantly higher in PD subjects' more affected hands compared to their less affected hands [37]. No feature selection techniques were reported, but based on the features reported by the researchers, there were only 9 features. When this data was used to create a machine learning model using the decision tree technique, it was able to distinguish PD from controls with an accuracy of 70ÿ%, sensitivity of 77ÿ%, and specificity of 65ÿ%. No confidence interval was reported. It's possible that the model accuracy reported by the researchers does not reflect the utility of typing data, as models created using cross-validation techniques [17] show high accuracy metric values (seeÿTable 2). It is important to note that no training or testing sets were created from the data sample, indicating that the same data were used to train and test. Purk et al. [38] proposed a model using the Parkinson's Disease Non-Motor Scale (PDNMS) and spiral drawing tasks (which were drawn on a touchscreen tablet) to evaluate motor symptoms more objectively. The study consisted of three comparisons: PD (nÿ=ÿ24) - HC (nÿ=ÿ27), movement disorder (including APs, tremor, ataxias, multiple sclerosis, and essential tremor) (MD) (nÿ=ÿ26) - HC, and PD-MD [38]. The results included accuracies for each model (PDNMS, spiral-drawing tasks, ensemble model) in each comparison (PD-HC: 88.2ÿ%, 84.5ÿ%, and 94ÿ%, respectively; MD-HC: 77.7ÿ%, 68.8ÿ%, and 89.4ÿ%, respectively; PD-MD: 60.0ÿ%, 70.0ÿ%, and 72ÿ%, respectively) [38]. The researchers implemented stratified five-fold cross-validation. No confidence interval was reported. As there were 13 features extracted from the patient data, no feature selection was necessary to reduce error and chance of overfitting. A feature importance analysis was completed for each comparison, showing that for the PD-HC and MD-HC comparisons, the most important predictor was the number of questions answered with ?yes? on the PDNMS [38]. All three comparisons showed increased accuracy when both metrics were included in the model, suggesting both that the combination of different metrics assists in diagnosis, and that AI increases the accuracy of models (seeÿTable 2).",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Neuroimaging has frequently been investigated using machine learning techniques. For instance, Gaurav et al. [39] focused on neurodegeneration in the substantia nigra and created an automated artificial intelligence-based framework to segment the substantia nigra and quantify nigral neuromelanin levels and distinguish subjects with PD (nÿ=ÿ144) from HC (nÿ=ÿ55). 54 subjects were used as training, and 6 were used for validation. The researchers compared the AUC of the automated segmentation with that of the manual segmentation for the corrected volume, uncorrected volume, normalized signal intensity, and contrast-to-noise ratio. When both the training and testing cohorts were combined, the automated method's AUCs were 0.85, 0.83, 0.79, and 0.77 and the manual method's AUC values were 0.76, 0.74, 0.78, and 0.76, respectively. Despite this, the researchers did not report the AUC values for the testing set alone, which would be the most precise measurements. Based on the figure showing the ROC curves in the training set and in the testing set and the reported AUCs for the training set alone, it could be assumed that the AUCs for the testing set are at least 0.10 less than the AUCs reported for training and testing. Even though the AUCs for the testing set were not reported, the ROC curves for testing show that the automated method performed better than the manual method. From this observation, this study supports that the application of AI and machine learning techniques aids in the determination of neuroimaging-based biomarkers (seeÿTable 3).",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"A similar study aimed to apply a CNN to differentiate PD subjects (nÿ=ÿ115) from HC (nÿ=ÿ115) [40]. The researchers explored the efficacy of the CNN on four different diffusion analyses (diffusion tensor imaging-weighted (DTI-weighted); diffusion kurtosis imaging-weighted (DKI-weighted); neurite orientation dispersion and density imaging-weighted; and g-ratio-weighted connectome matrices) in differentiation. It is known that DKI is an extension of DTI, involving additional properties of water diffusion. Machine learning-based models that involve multiple contributing variables (such as the DKI model) tend to perform better than models that are based on fewer characteristics. The researchers used five-fold cross-validation in the process of training the models. The reported AUC values based on the best metric from each analysis were 0.733, 0.895, 0.801, and 0.836. Their finding that the DKI model achieved the highest AUC supports that diagnostic models should use multiple biomarkers to ensure validity and accuracy [40]. However, as each diffusion analysis may have multiple features extracted from it, it is important to use a feature selection algorithm to reduce error and improve model performance. The researchers did not mention the number of features extracted or whether a feature selection was applied (seeÿTable 3).",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Some researchers aimed to apply a combination of different biomarkers to achieve high diagnostic capacity. Prashanth et al. [27] explored machine learning's ability to distinguish HC (nÿ=ÿ183) and PD subjects (nÿ=ÿ401) early in their progression using REM sleep disorder symptoms, loss of olfactory ability, and SPECT and CSF data. 70ÿ% of the sample data was used to train the models, and the remaining 30ÿ% was used to test the model. This was repeated 100 times with different partitions of training and testing sets, and the average accuracy metrics from the training and testing sets were reported. The researchers found that when an SVM classifier was used, accuracy, sensitivity, specificity, and AUC values were 96.40ÿ%, 97.03ÿ%, 95.01ÿ%, and 0.9888 in the testing set, respectively. 11 of out 13 features were determined to be statistically significant. Of these features, the most important biomarkers, as reported by Prashanth et al. [27], were the SBR in the putamen and caudate, UPSIT scores, and the total tau/beta-amyloid ratio (seeÿTable 4).",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Similarly, a study combined neuroimaging data in the thalamic subnuclei and clinical motor data (UPDRS III and presence of motor symptoms) to distinguish PD subjects (nÿ=ÿ131) from HC (nÿ=ÿ69) [28]. 70ÿ% of the data was used for the training set, and the other 30ÿ% was used for the test set. Additionally, five-fold cross-validation was used to train the model. At least 100 features were extracted from the data, so feature selection was performed on the training set. 11 clinical features and an unreported number of neuroimaging-based features were retained. When these features were used, the accuracy, sensitivity, specificity, and AUC values were 95ÿ%, 97.44ÿ%, 90.48ÿ%, and 0.9756 (seeÿTable 4) [28].",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Overall, these results seem to support the evidence that combining different biomarkers can improve model performance in diagnosing PD, and that machine learning techniques, including neural networks, can be applied in determining viable biomarkers.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"A number of studies (nÿ=ÿ4) have investigated the use of machine learning techniques to differentiate stages of disease progression of PD. For instance, Schalkamp et al. [41] created five different models from genetic, lifestyle, blood biochemistry, prodromal, and accelerometric biomarkers to distinguish prodromal PD (nÿ=ÿ113) from established PD (nÿ=ÿ153). The researchers implemented nested five-fold cross-validation with a five-fold split for the inner and outer split. About 168 features were used to train and test the models; no feature selection methods were reported. The accelerometric model outperformed the other four models with an AUC of 0.84ÿñÿ0.04 when trained on the general population. Additionally, when the accelerometric data was applied to differentiate prodromal PD and established PD from HC, the model achieved mean AUCs of 0.86ÿñÿ0.06 and 0.74ÿñÿ0.04, respectively. A 95ÿ% confidence interval was used to compare different models. Further, this study created a model combining the most predictive features of the initial five models, which performed similar to the accelerometric model. As accelerometric data records movement during sleep, this study suggests that including accelerometry in further prediction may supplement prodromal data in the prediction of PD onset (seeÿTable 4) [41].",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Based on the evidence that motor extremities are implicated in PD, studies have analyzed the use of metrics derived from motor extremities to determine disease severity and diagnose PD. Sun et al. [42] explored creating a model that analyzed plantar pressure for this purpose. The proposed mathematical model relied on the separation of the foot into five sub-regions to classify subjects as PD (nÿ=ÿ93) with mild or moderate severity or HC (nÿ=ÿ73). Ten-fold cross-validation was used. Feature extraction was done using a dynamics feature extractor (DFE), but the study did not report the number of features used and did not apply feature selection. In comparison to various other recent studies, Sun et al. [42] reported an accuracy, sensitivity, and specificity of 100.00ÿ% in distinguishing PD from HC and an accuracy, sensitivity, and specificity of 95.89ÿ%, 95.00ÿ%, and 97.50ÿ% in classifying disease severity. No confidence interval was reported. The researchers compared combining different machine learning techniques to create the final high-performing model. Based on the metrics reported, performance increased by at least 4ÿ% in PD diagnosis and at least 12ÿ% in the severity assessment when the DFE was applied. Additionally, the metrics reported from the final model outperformed models created in other studies using similar data samples (seeÿTable 2).",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"A model created by Severson et al. [43] used clinical metrics such as tremors, bradykinesias, and neuropsychiatric measures to define and identify disease stages in PD. Five-fold cross-validation was applied to the training data (nÿ=ÿ333), and the testing data included 83 subjects. No feature selection techniques were implemented. The model, created using the hidden Markov model (HMM) structure, identified eight disease stages of PD. This research suggests that AI and machine learning techniques may be used to recognize and separate disease stages and severity through clinical measures, and that these technologies may be applied to the diagnosis of movement disorders and prediction of worsening symptoms (seeÿTable 2).",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Other studies have also showcased AI's capacity to process multiple data sources in application to PD. Almgren et al. [29] aimed to predict cognitive decline in subjects with PD (nÿ=ÿ213) when provided with clinical cognitive test scores (including the Montreal Cognitive Assessment (MoCA)), CSF biomarkers (including tau, and beta-amyloid), neuroimaging-based volumetric data, and genetic variant data. 69 features were initially included; feature selection reduced the number of features to 12 [29]. Ten-fold cross-validation was used while training the model. Statistically significant positive correlations were found between MoCA scores and beta-amyloid (pÿ=ÿ0.018), while statistically significant negative correlations were found between MoCA scores and baseline cognition (pÿ=ÿ0.00004), total tau (pÿ=ÿ0.049), anxiety scores (pÿ=ÿ0.042), and autonomic dysfunction (pÿ=ÿ0.005). Additionally, a nearly statistically significant correlation was found between MoCA scores and phosphorylated tau levels (pÿ=ÿ0.052). The correlations between MoCA scores and beta-amyloid and tau are justifiable, as these proteins are found at abnormal levels in Alzheimer's disease (seeÿTable 4) [29].",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,Results from these studies suggest that using a combination of biomarkers from a variety of sources allows high model efficacy to be achieved and for PD to be predicted and differentiated more efficiently.,,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"APs such as PSP and MSA share numerous similarities with PD, but a misdiagnosis can be devastating for a patient. As such, the determination of biomarkers to distinguish APs from PD is necessary. Here, we reviewed studies that applied machine learning-based models to differentiate PD from APs (nÿ=ÿ5).",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Song et al. [44] defined a model to distinguish subjects with PD (nÿ=ÿ551) from those with APs (nÿ=ÿ222). Specifically, subjects with progressive supranuclear palsy ? Richardson's syndrome (PSP ? RS) (nÿ=ÿ38), multiple system atrophy ? cerebellar subtype (MSA ? C) (nÿ=ÿ71), and ataxia (nÿ=ÿ113) were included under the APs group. About 80ÿ% of the dataset was used for 4-fold cross-validation (split in 3:1 ratio). To evaluate performance, the remaining 20ÿ% was prepared for independent hold-out validation, where the data was randomly partitioned into four parts and validation was performed 4 times. In the final model, holdout cross-validation was performed with the last 20ÿ% instead. The model reported high AUC and specificity, but lower sensitivity, which suggests that the model was moderately reliable (average AUC of 0.971ÿñÿ0.028, average sensitivity of 73.6ÿñÿ17.9ÿ%, and average specificity of 94.6ÿñÿ3.3ÿ%). A confidence interval was not specified. Given the standard deviation for sensitivity, between 306 and 504 of 551 PD subjects were accurately classified. In comparison, between 202 and 217 of 222 APs subjects were accurately classified. Based on this, the model was reliable at classifying subjects with APs, but had worse performance when classifying PD subjects. It is important to note that the accuracy of diagnosis performed by nonspecialists with a variety of clinical presentations (including PD and APs) was 73.8ÿ%, so it is possible that the model created by this study may be used as a supplement (seeÿTable 2).",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Archer et al. [30] investigated the use of a machine learning-based model combining free-water (FW) and fractional anisotropy (FA) metrics obtained from diffusion-weighted imaging (DWI) in differentiating APs (nÿ=ÿ213) from PD (nÿ=ÿ511), and in differentiating MSA (nÿ=ÿ84) from PSP (nÿ=ÿ129). Approximately 80ÿ% of the data was used for the training set, and the other 20ÿ% was used for the test set. In the training process, five-fold cross-validation was implemented. The researchers compared the results from the DWI-based model with a model using the MDS UPDRS III scale, a widely used clinical scale for diagnosing PD. AUC values were significantly higher when using DWI metrics (0.955 and 0.926) compared to the MDS UPDRS III scale (0.775 and 0.582) when distinguishing PD from APs and MSA from PSP, respectively. The researchers additionally created a model combining both DWI and MDS UPDRS III measurements, and both comparisons exhibited increases in AUC for this model compared to the other models (0.962 for PD-APs and 0.897 for MSA-PSP). The PD-APs comparison still displayed a higher AUC value than the MSA-PSP comparison. A feature importance assessment was completed for both comparisons, and the top ten features in both lists included regions pathologically involved in PD [30]. The large differences in the efficacy of the MDS UPDRS III measurements can be in part attributed to the specialization of the MDS UPDRS III scale to PD; additionally, results in DWI may be more similar between MSA and PSP than between PD and APs (seeÿTable 4) [30].",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Chien et al. [26] created an ANN to differentiate APs (including MSA, PSP, spinocerebellar ataxia (SCA), dementia with Lewy bodies (DLB), vascular parkinsonism, and other causes of parkinsonism) (nÿ=ÿ122) from PD (nÿ=ÿ140) using DAT-SPECT imaging. Approximately 90ÿ% of the initial set of subjects (nÿ=ÿ205) were used to train the model, and the final 10ÿ% was used for validation. The model was tested using an external dataset, with 22 PD and 35 APs subjects, and PCA was used for feature extraction and selection. The ANN reported an AUC of 0.76, accuracy of 86.0ÿ%, a sensitivity of 81.8ÿ%, and a specificity of 88.6ÿ% when specifically using the striatal region in the model. This was compared with a shallow pipeline (SVM), which reported an accuracy of 68.4ÿ%, sensitivity of 31.8ÿ%, and specificity of 91.4ÿ%. When the ANN was assessed using whole-brain imaging, the accuracy and specificity decreased (68.4ÿ% and 60.0ÿ%) [26]. The researchers did not specify what specific APs were included in the external dataset; it is possible that DAT-SPECT imaging may have differences in performance when PD and MSA/PSP are differentiated compared to when PD and other types of parkinsonisms (seeÿTable 3).",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Another study investigated the use of subcortical volume (SC volume) and number of streamlines (NOS: a measure of connectivity between areas) derived from tractography in distinguishing MSAÿ(nÿ=ÿ31) from PDÿ(nÿ=ÿ65) and MSA from HC (nÿ=ÿ54) [31]. LOOCV was used to avoid overfitting during feature selection, which resulted in 5 features for fractional anisotropy and 6 features for mean diffusivity. The researchers reported that in the MSA-HC comparison, the combination of NOS and SC volume achieved the highest accuracy, sensitivity, and specificity (NOS: accuracy of 79ÿ%, sensitivity of 84ÿ%, specificity of 74ÿ%; SC volume: accuracy of 85ÿ%, sensitivity of 77ÿ%, specificity of 93ÿ%; NOS and SC volume: accuracy of 89ÿ%, sensitivity of 84ÿ%, specificity of 94ÿ%). Meanwhile, in the MSA-PD comparison, the combination of NOS and subcortical volume achieved the same accuracy, sensitivity, and specificity as the subcortical volume-based model (NOS: accuracy of 79ÿ%, sensitivity of 71ÿ%, specificity of 86ÿ%; SC volume: accuracy of 84ÿ%, sensitivity of 74ÿ%, specificity of 94ÿ%; NOS and SC volume: accuracy of 84ÿ%, sensitivity of 74ÿ%, specificity of 94ÿ%) [31]. This research supports that the application of multiple metrics assists in increasing model accuracy (seeÿTable 3).",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Nigro et al. [32] applied track density imaging to assess white matter changes between PSP subjects (nÿ=ÿ67), PD subjects (nÿ=ÿ36), and HC (nÿ=ÿ37) using a machine learning-based model. The researchers did not mention any cross-validation techniques or differences between training and test sample, which may have caused overfitting. In PSP-P subjects (nÿ=ÿ31), when compared to HC and PD subjects, decreased track density was reported in the cerebellum, midbrain, superior cerebellar peduncle, and corticospinal tract. The whole-brain model created from track density metrics was able to distinguish PSP-P subjects from PD subjects with an AUC of 0.90 and PSP-RS subjects (nÿ=ÿ36) from PD subjects with an AUC of 0.94. When the model was restricted to the superior cerebellar peduncle, the AUC, when distinguishing PSP-RS from PD, rose to 0.96, while the AUC decreased to 0.86 when distinguishing PSP-P from PD [32]. This suggests that fewer differences are present between PD and PSP-P than between PD and PSP-RS within the superior cerebellar peduncle (seeÿTable 3). Similarly, researchers creating a model using T1-weighted MRI reported differences in the midbrain, thalamus, pons, and corpus callosum between PD (nÿ=ÿ28) and PSP (nÿ=ÿ28) subjects [34]. PCA was used for feature extraction, and LOOCV was used during the model training process. The model generated to differentiate PSP and PD subjects exhibited high accuracy, sensitivity, and specificity (88.9ÿ%, 89.5ÿ%, and 88.5ÿ%, respectively). Additionally, when differentiating PSP subjects and HC (nÿ=ÿ28), accuracy, sensitivity, and specificity were slightly higher (89.1ÿ%, 89.5ÿ%, and 89.1ÿ%, respectively) (seeÿTable 3) [34]. This indicates that MRI can be applied in differentiating types of parkinsonism and diagnosing APs.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"These results further support the evidence that the combination of multiple biomarkers from different data sources may contribute towards model performance. As machine learning can efficiently identify information from multiple data sources and can be used to determine which sources of data are useful for a specific comparison, these techniques may be applied to uncover and validate biomarkers for PD.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"The capacity of machine learning techniques in diagnostics is also evident in other movement disorders. Movement disorders such as dystonia and essential tremor have shown promise in the application of machine learning techniques. Research in these movement disorders was reviewed to analyze these results (nÿ=ÿ3). For instance, Valeriani and Simonyan [33] created a deep learning algorithm to identify a microstructural neural network biomarker from structural MRI data and classify participants as either dystonia subjects (nÿ=ÿ329) or HC (nÿ=ÿ220). Prior research has shown that 50ÿ% of dystonia cases are misdiagnosed; specific biomarkers for dystonia are not easy to obtain as whole-brain changes are observed over the disease course.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"The training set used 160 HC and 160 dystonia patients. Two independent test sets were used: one with 60 HC and 60 dystonia patients, and the second with patients who had three types of dystonia (59 laryngeal dystonia; 54 blepharospasm; 59 cervical dystonia). A deep learning pipeline (DystoniaNet) was developed using raw T1-weighted MRI, and features were extracted and selected within this pipeline. The researchers compared DystoniaNet against three shallow pipelines (LDA, SVM, and a one-layer ANN). After generalizability, a test dataset independent of the training data was applied to the DystoniaNet algorithm, which reported an overall accuracy of 98.8ÿ% in diagnosing three types of dystonia and referred 3.5ÿ% of the subjects for further examination. When the three shallow pipelines were applied, AUC, sensitivity, and specificity values were significantly lower compared to the DystoniaNet algorithm. The reported AUC, sensitivity, and specificity values were 0.829, 60.0ÿ%, and 83.3ÿ% for the LDA; 0.812, 65.0ÿ%, and 85.0ÿ% for the SVM; and 0.740, 50.0ÿ%, and 80.0ÿ% for the ANN, respectively. No statistically significant difference between the shallow pipelines? AUCs was reported (seeÿTable 3) [33]. These results indicate that the complexity of a machine learning pipeline may correlate with model performance.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"A similar article on dystonia investigated the use of machine and deep learning to predict the efficacy of BoTX in four types of dystonia [45]. As treatment efficacy differs based on the symptoms and dysfunction a patient experiences and what a treatment addresses, machine learning could be invaluable in determining the best treatment for a patient. A deep learning algorithm was created (DystoniaBoTXNet) to differentiate subjects with dystonia who benefited from BoTX (nÿ=ÿ173) from subjects with dystonia who did not benefit from BoTX (nÿ=ÿ82). The training included 106 BoTX-benefiting subjects and 59 BoTX-non-benefiting subjects, who all had laryngeal dystonia. Three independent test sets were used to evaluate DystoniaBoTXNet. The first independent test set had 29 BoTX-benefiting subjects and 15 BoTX-non-benefiting subjects, all with laryngeal dystonia and the second independent test set had 38 BoTX-benefiting subjects and 8 BoTX-non-benefiting subjects, with blepharospasm, cervical dystonia, or writer's cramp. The third independent test set had 29 BoTX-nave subjects to predict whether these subjects would benefit from BoTX. No feature selection algorithms were implemented; feature extraction was included in the DystoniaBoTXNet framework. The number of features was not reported. DystoniaBoTXNet achieved accuracy of 94.9ÿ%, AUC of 93.8ÿ%, sensitivity of 100ÿ%, and specificity of 84.6ÿ% in the first independent set. When the second independent test set was applied, DystoniaBoTXNet achieved accuracy of 97.7ÿ%, AUC of 92.4ÿ%, sensitivity of 100ÿ%, and specificity of 87.5ÿ%. The performance of the model in this independent set shows that the DystoniaBoTXNet framework is generalizable. Of the 29 subjects in the third independent test set, 7 of them received BoTX. DystoniaBoTXNet had predicted that all 7 subjects would experience a benefit; 5 subjects benefited, and 2 subjects did not benefit. The median probability that the subjects would benefit that the model reported for the 5 subjects who benefited was 99.99ÿ%, whereas the median probability was 90.8ÿ% for the 2 false positive subjects. Overall, DystoniaBoTXNet achieved an accuracy of 96.3ÿ%, with a sensitivity, specificity, and referral rate of 100ÿ%, 86.1ÿ%, and 7.8ÿ% respectively (seeÿTable 3) [45].",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Essential tremor's (ET) causes and disease pathology are still unknown, and studies that aim to determine where dysfunction resides are inconclusive. As machine learning may efficiently determine structural and functional damage, Sacc et al. [46] aimed to investigate the use of a support vector machine with resting-state fMRI to identify functional differences between ET subjects (nÿ=ÿ18) and HC (nÿ=ÿ19). The researchers considered 14 networks that covered the whole brain in differentiating ET and HC. RFE was used to select and rank the networks based on their importance. Ten-fold cross-validation was used to gain a robust estimate of the model performance. The reported AUC was 0.75, with a sensitivity of 70ÿ% and specificity of 40ÿ%, and the four most important networks were the language, primary visual, cerebellar, and attention networks [46]. Based on the sensitivity and specificity values, 12 of 18ÿET subjects and 7 of 19 HC were correctly identified (seeÿTable 3). Bianco et al. [47] differentiated subjects with ET (nÿ=ÿ33) and subjects with essential tremor from resting tremor (rTR) (nÿ=ÿ30) from HC (nÿ=ÿ45). Five-fold cross-validation was used in training, and repeated stratified five-fold cross-validation was used to measure the model performance. 358 features were obtained from the initial feature extraction, but no feature selection methods were used, which may have affected the model performance. However, a feature importance analysis was completed, which indicated that the most important feature for distinguishing ET from rTR and rTR from HC was cortical volume in the left pars opercularis and cortical roughness of the left paracentral lobule, respectfully [47]. The researchers reported that when differentiating rTR and HC, the highest-performing model was derived from cortical roughness. This model achieved an AUC of 0.85ÿñÿ0.09, a sensitivity of 69ÿñÿ20ÿ%, and a specificity of 89ÿñÿ11ÿ% [47]. In comparison, when differentiating rTR and ET subjects, the most accurate model used cortical thickness metrics and achieved an AUC of 0.865ÿñÿ0.11, sensitivity of 78ÿñÿ19ÿ%, and specificity of 83.4ÿñÿ13ÿ% [47]. No models differentiating ET subjects from HC were reported, as the accuracy was less than 80ÿ% (seeÿTable 3). The research from Sacc et al. [46] and Bianco et al. [47] supports that machine learning models may contribute to determining the utility of metrics for analysis and differentiation of ET, other APs, and HC.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"In dystonia, differences in accuracy have been observed when comparing the application of machine learning to the lack of machine learning. This suggests that misdiagnoses and wait time for proper diagnosis can be minimized through machine and deep learning techniques [33,45]. Research in ET suggests that machine learning techniques may be able to determine which metrics contribute to disease pathology, however larger sample sizes are necessary to gain insight into whether machine learning techniques can be used [46,47]. The significantly low specificity reported by Sacc et al. may be attributed to the low sample size, but the researchers additionally acknowledged that the algorithm used may not have been able to detect subtle differences in functional connectivity between ET subjects and HC. Additional research comparing which machine learning techniques provide accurate results for an analysis is essential so that appropriate techniques and data can be applied to diagnosis of APs and PD.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"Artificial intelligence can efficiently process large amounts of data. In fact, in the previously discussed Valeriani and Simonyan [33] study, the researchers reported that through machine learning techniques, each patient's neuroimaging scan took an average of 0.36ÿs to process, which is clearly a substantial improvement compared to manual methods. The machine learning algorithms applied in Yao et al. [45] may be extended to clinical and biofluid-based biomarkers. As indicated above, studies have reached higher accuracy when multiple data types are integrated [27?29,35]. This suggests that accuracy may be increased through aggregating different types of biomarkers, and that machine learning models perform better when multiple biomarkers affecting a disease are factored into analysis and prediction. Further, machine learning algorithms that have more layers tend to perform better than shallow pipelines, suggesting that deep neural networks and deep learning algorithms may contribute to the development of diagnostic and predictive biomarkers and increase efficiency [33]. The evidence from recent research suggests that machine learning techniques can be applied to diagnosis, prediction, and biomarker detection in movement disorders and in PD.",,,,,
The role of AI and machine learning in the diagnosis of Parkinson's disease and atypical parkinsonisms,"A current limitation of these studies is that there are a limited number of reports focusing on various biomarkers, thus potential variability in outcome based on metrics and machine learning techniques is still an issue. Future directions of these studies should involve applying machine learning techniques to a variety of biomarkers to distinguish subjects with PD from APs and HC.",,,,,
Deep Learning and Geriatric Mental Health,"The goal of this overview is to help clinicians develop a basic proficiency with the terminology of deep learning and understand its fundamentals and early applications. We describe what machine learning and deep learning represent and explain the underlying data science principles. We also review current promising applications and identify ethical issues that bear consideration. Deep Learning is a new type of machine learning that is remarkably good at finding patterns in data, and in some cases generating realistic new data. We provide insights into how deep learning works and discuss its relevance to geriatric psychiatry.",,,,,
Deep Learning and Geriatric Mental Health,"Geriatric psychiatry is a study of human and medical complexity. Mental health in late-life represents the cumulative outcome of a number of factors that include changes to the brain (both age-related and pathological), changes in the body, evolving social circumstances, and psychological factors (both protective and detrimental). It can be impacted by biological determinants present at birth (e.g., genetic risks) and highly situational circumstances (e.g., bereavement). Moreover, there is growing recognition that treatment outcomes can be quite heterogeneous, many factors can impact medication response and successful psychotherapy requires tailoring. The process of providing care in this domain is thus immersed in complexity.",,,,,
Deep Learning and Geriatric Mental Health,"When imagined through the lens of data science, geriatric mental health care represents a process of gathering and incorporating a diverse set of streams of data (e.g. behavioral assessments, cognitive evaluation, medical examination, psychosocial context, imaging, genetic, passively sensed, and laboratory tests) and making both situational and longer-term decisions. With the ever-growing availability of tools to support clinical decision-making, the field of geriatric mental health should be seen as a fertile ground for incorporating data processing and predictive analytics into clinical workflow. There are many ways in which advances in computational science may help manage this complexity - from processing brain images to providing in-the-moment access to medical knowledge. The challenge is to develop proficiency in the use of these increasingly sophisticated tools while prioritizing the human aspect of care that is a foundational element of care in older adults1. It is increasingly clear that the future of medical science will require proficiency in the use of a new generation of Artificial intelligence (AI)-based tools, but in order for these tools to achieve their potential, they should be used to augment, rather than replace, the human element of care. A relatively clear way in which this can be accomplished is by using these tools to help clinicians simplify the complexity inherent in late-life mental health care.",,,,,
Deep Learning and Geriatric Mental Health,"Our intent in this review is to provide an overview and perspective on the clinical use of an especially compelling branch of AI ? deep learning. We are currently experiencing a ?deep learning revolution?2. In this revolution, computers have become so good at finding patterns in big data that solutions are being found for questions we did not know we had. For instance, using the popular smart-phone app made by iNaturalist (https://www.inaturalist.org/pages/seek_app) one can now point their phone at a plant or animal to identify the species. However, multiple critical questions remain unanswered, including where the most useful applications of these tools may be, what steps need to be taken to ensure ethical development and use of these tools (including the data used to create them), and what regulatory frameworks may be necessary. The process of answering these questions will call for unprecedented dialogue and collaboration between fields and experts who may not typically collaborate ? including patients, clinicians, data scientists, data visualization and design experts, ethicists, and regulators. A field like geriatric mental health which is inherently proficient at working with interdisciplinary perspective is thus ideally placed to lead this process.",,,,,
Deep Learning and Geriatric Mental Health,"The goal of this overview is to help clinicians develop a basic proficiency with the terminology of deep learning, understand its fundamentals and the early applications. We We first describe what machine learning and deep learning represent, Next, we discuss how and why considerations of sample size differ between machine learning and deep learning. Next, we present sections that aim to familiarize readers with foundational mathematical principles that underlie deep learning and touch on how deep learning represents a new tool to help evolve our understanding of complex philosophical principles such as linguistics and theory of mind. Finally we review how early clinical applications are being determined based on deep learning.",,,,,
Deep Learning and Geriatric Mental Health,"At the very outset, it is critical to acknowledge that in an emerging field like deep learning that relies on gathering vast amounts of data, there are certain to be complex ethical questions. The full scope of these challenges is unlikely to be understood at this time and a comprehensive discussion of the ethics of deep learning and artificial intelligence (AI) is beyond the scope of this review. We discuss this further in the Future Directions section",,,,,
Deep Learning and Geriatric Mental Health,"Machine learning is a component of the umbrella term artificial intelligence (AI). Artificial intelligence is the overall quest of having computers act intelligently3. Machine learning algorithms are those AI techniques that focus on the intelligent task of learning. In this case, machine learning refers to the process of having a computer find a pattern from seeing positive and negative examples of that pattern. The most common form of machine learning is referred to as supervised learning, because the examples involved include both the features (e.g., clinical, imaging, or demographic characteristics) under consideration for predicting an outcome of interest and the values for that outcome variable. Features can be unprocessed raw observed data, such as the medical image or recorded audio, or it can be fully processed and extracted variables. Examples of processed features that can be used for learning include regional atrophy measures extracted from the MRI or summary behavior rating scores, such as the Montgomery Asberg Depression Rating Scale. These features, paired with the observed outcomes, are used to guide the learning process.",,,,,
Deep Learning and Geriatric Mental Health,"Supervised learning typically falls into one of two categories: regression, when the outcome is numerical (e.g., depression score), or classification, when the outcome is a class label or group membership (e.g., type of dementia)4. The machine learning program uses these labeled examples to train a model (i.e., a type of prediction algorithm) that can be used to predict outcomes for new observations (observations not previously seen by the algorithm). This basic model is used for finding patterns in, for example, images, in patient clinical data, and from internet searches that are useful in predicting outcomes of interest. For instance, learning to predict the age of the patient based on their brain MRI, from seeing many examples of brain MRIs labeled with the age of each individual. In traditional machine learning, the algorithm finds a concise expression of the features, such as a decision tree, to describe how to classify new examples.",,,,,
Deep Learning and Geriatric Mental Health,"More and more, unsupervised and semi-supervised machine learning techniques are also being utilized. In unsupervised learning, algorithms learn patterns from unlabeled data5. That is, all the variables used in the analysis are used as inputs, thus, the techniques are suitable for creating the labels in the data. For example, unsupervised learning techniques might be used to classify individuals diagnosed with a particular disease into previously unknown subtype classes based on different observed features. Semi-supervised models use a hybrid approach.",,,,,
Deep Learning and Geriatric Mental Health,"However, foundational to deep learning is the concept of the Artificial neural network (ANN). ANNs are machine learning models that are designed to emulate the human brain and are characterized by one or more layers of interconnected nodes (neurons) that generate non-linear representations of the input features which are useful for supervised, unsupervised, or semi-supervised problems. Deep learning simply corresponds to those ANNs with multiple layers of interconnected nodes. In the context of supervised learning, fitting ANN models with more layers (i.e., deeper models) has the potential to lead to better prediction accuracy and this is one of the main reasons that deep learning has recently received considerable attention.",,,,,
Deep Learning and Geriatric Mental Health,"Deep learning differs from more traditional machine learning (e.g., logistic regression, random forests, and support vector machines) in several ways. As noted above, deep learning can be described by the complexity of the learner (i.e., depth of the ANN). Therefore, one way in which deep learning models can be distinguished from traditional machine learning models is by their need for a lot of examples.",,,,,
Deep Learning and Geriatric Mental Health,"Deep learning can also be distinguished from more traditional machine learning approaches by how it does feature selection. Traditional machine learning typically uses already pre-processed, or selected features. This can require manual selection of features (i.e., feature engineering). This entails experts identifying and extracting meaningful features for the algorithm to learn. Deep learning, when it works, is able to leverage the power of ANNs to automatically learn features and hierarchies of features from the raw data. This property of generating new data-driven features can be contrasted with manual feature engineering that is used more commonly in traditional machine learning. New advances using deep learning include Generative Adversarial Networks7, which play a key role in deepfakes8ÿ, and multi-head attention9ÿ(the transformer), which underlies large language models like ChatGPTÿ10ÿ.",,,,,
Deep Learning and Geriatric Mental Health,"To illustrate the difference between traditional machine learning and deep learning, consider an analogy in which both methods attempt to learn the concept of ?dog.? Traditional machine learning, like classification and regression trees, can be likened to learning about dogs through a description of their attributes. In this scenario, the algorithm is provided with a list of features such as ?has fur,? ?domesticated,? and ?mammal.? The learner then uses these features to construct a rule. The left panel ofÿFigure 1ÿshows a classification tree as an example of a traditional machine learning method. This process involves identifying a pattern within the features that can distinguish which settings for the features defines being a dog. The result is a model capable of classifying an object as a dog based on the presence or absence of these predefined features. While deep learning models can be developed that also use this same list of features to develop a model for classifying an observation as a dog or not a dog, one of the major strengths of deep learning is that such derived feature lists are not necessary to develop a well-performing classifier. (Figure 1)",,,,,
Deep Learning and Geriatric Mental Health,"Rather than using a list of derived features, deep learning, can also take as its input, for example, images of dogs and non-dogs and learn features that can be used to distinguish dogs from non-dogs. Unlike traditional machine learning, where the learner is explicitly provided with features, in this case characteristics of the animal, the deep learning approach can extract features from the raw image data. It uses the images, rather than the extracted features. This is achieved through the use of deep (highly parameterized and flexible) networks of artificial neuron-like units. The connection strengths (i.e., weights, which are akin to slopes in regression models) between the units are adjusted to make the network improve its ability to correctly classify an image as a dog or non-dog from each labeled example.",,,,,
Deep Learning and Geriatric Mental Health,"A major challenge in the historical development of artificial neural networks was coming up with a computationally efficient way to modify the weights. The development of back-propagation, helped to make efficient estimation of deep learning models possible and this has led to widespread use of these models in many application areas. For a full description, we refer reader to Chapter 8 of an early classic book in AI and artificial neural networks11.",,,,,
Deep Learning and Geriatric Mental Health,"As noted above, one of the very attractive features of deep learning models is that they are highly flexible. That is, they are able to capture more detail (or nuances) of a concept, like the detail in a realistic face. This flexibility is due to the extremely large number parameters, potentially numbering in the millions, that define them. In clinical scenarios, fitting such models typically requires very large sample sizes. However, in geriatric psychiatry research, large sample sizes are just not that common ? owing to a number of factors (e.g., the complexity of collecting data from geriatric patients, the time-consuming effort needed for preprocessing neuroimaging data, etc.).",,,,,
Deep Learning and Geriatric Mental Health,"An exciting recent development has been the use of ?generative? deep learning methods to handle the problem of small sample size. This class of deep learning methods augment (artificially increase) the available training examples by synthesizing new examples from the distribution of the observed examples ? thus increasing the effective sample size on which the deep learning model is trained12. A way of understanding the difference between generative AI and traditional ML is that generative AI is capable of creating new data, whereas traditional ML is limited to identifying patterns and making predictions from existing data only. In essence generative AI leverages large amounts of data, which we have on a small number of people, to learn with fewer examples. This is exemplified in the deep learning approach of few-shot learningÿ6, which shows how learning can occur with very small sample sizes. In certain ways this can be seen as analogous to how a child is able to learn very deeply what a dog is even from knowing just one dog very well. Similarly, in medical school one can learn anatomy very well from one cadaver. One challenge with generative AI is that it can lead to certain biases in the generated sample. A recent paper showed how large language models, such as ChatGPT, may become biased towards normal appearing data, and lose representation of uncommon events that occur in the tails of the distributions13.",,,,,
Deep Learning and Geriatric Mental Health,"Because generative AI is creating new examples, it can be seen to learn deep associations that we would not expect. With images it can create realistic faces of no one in particular. In large language models it may make up a reference for a study that does not exist. The AI gives the closest answer it can come up with for the question, which might be a fabricated reference14. The fabrications are sometimes referred to as a type of AI hallucination. These fabricated results in generative AI are expected and reflect the depth of the model. In the appropriate context, the fabrications are very helpful. However, if used naively, generative AI can easily be misleading.",,,,,
Deep Learning and Geriatric Mental Health,"With Deep Learning still a very nascent entity, particularly as it applies to geriatric mental health, there is an opportunity for clinicians and researchers to understand the mathematical foundations of the field. This may support a more sophisticated understanding of the explosion of research in this space that is inevitable. Here, we present a very broad overview of philosophical and historical questions that underlie the evolution of AI. One way to understand machine learning is through the lens of Computing Theory15. These principles describe the inherent limits of information processing. They are used in understanding and developing machine learning approaches. One way to appreciate the contributions of the theory of computing is through its impact on cryptography (i.e. the mathematics of data security)16. The ability to create secure encryption (i.e., recoding in a new language) relies on defining the number of steps needed in an algorithm. If allowed to simply try all examples, deciphering passwords, would be easy. But, the more complex the password, the exponentially higher the number if attempts needed. This number can quickly become unimaginable, even for simple encryption problems. Thus, certain computational problems (like breaking cryptographic codes) are infeasible. However, other tasks such as identifying common patterns, and parsing certain languages can be done efficiently with a circumscribed number of steps.",,,,,
Deep Learning and Geriatric Mental Health,"The math behind computing theory relies on the assumption that the set of possible algorithms is theoretically countable , as opposed to an infinity that is so large it cannot be counted. In this case, countable means that we can explicitly describe the steps of the algorithm (sometimes referred to as the ?machine?). As long as we can describe these steps, we can classify and organize them. This assumption has also been applied to neuroscience and is the basis for models of how circuits within the brain may operate. For a much deeper dive into these principles, we direct readers to the influential 1979 Pulitzer Prize winning book on the subject,ÿGodel, Escher, Bach: an Eternal Golden Braidÿwritten by D. Hofstadtler17.",,,,,
Deep Learning and Geriatric Mental Health,"The application of the computing theory principles to learning18ÿis referred to as Computational Learning Theory (COLT)19. In COLT, the generic problem of ?learning? is the focus, and the properties of learning are determined by proving related theorems. Supervised machine learning is defined using parameters to circumscribe performance. An effective learning algorithm shouldÿprobablyÿfind anÿapproximateÿrule. This is referred to as the Probably Approximately Correct (PAC) formalization of supervised learning20. It assumes a passive sampling of the distribution. Generative AI, on the other hand, allows for the asking of questions and an active sampling of the distribution (SeeÿTable). Thus generative AI adds query learning to the standard example-based learning framework21.",,,,,
Deep Learning and Geriatric Mental Health,"In general, it is not currently possible to determine the sample size needed to obtain a well-performing deep learning predictive model in the same way that one can compute the required sample size for estimating and testing effects under a hypothesis testing framework. Application of deep learning or any machine learning methods in geriatric psychiatry will likely require the learning of complex relationships between features derived from multiple modalities (e.g., behavioral, environmental, genetic, imaging). Having the ?right? data to begin with is obviously extremely important. If one is not measuring features that are relevant for predicting responses, then neither a large sample size nor an optimal deep learning or machine learning algorithm will lead to predictions that are of any clinical relevance. We direct reader to reviews of deep learning methods and their applications in psychiatry, with detailed discussions about sample size considerations by Koppe 2019 and Koppe 202122,23. (Table)",,,,,
Deep Learning and Geriatric Mental Health,"Deep learning can sometimes be approached as black box, where one focuses only on the input and output and ignores what happens in between. A field within deep learning is Representational Learning, which highlights the structure of the internal representation. This is similar to the latent space or principal components that are used to determine model fit in traditional statistics. However, in deep learning, the model uses hundreds of millions of parameters to form the fit. This means that deep learning is capable of finding non-linear combinations of features and the ?deep learning? representation space can therefore exhibit properties seen in complex dynamic systems (like nuclear physics). This can facilitate aspects of deep understanding, perhaps related to meaning and even empathy. In deep learning, when the input features are recoded in particularly complex ways, it is referred to as grokking25. The term comes from the bookÿStranger in a Strange Land26ÿby Robert Heinlein where it refers to deep empathy. Deep Learning may therefore be capable as language that allows exploration of questions of meaning and end of life, often central to geriatric mental health.ÿ27.",,,,,
Deep Learning and Geriatric Mental Health,"Societal understanding of computer processing has had profound impacts on our current ?theory of mind.? People understand themselves with computer analogies, e.g., short and long-term memory like a computer28. Deep Learning provides a more creative and flexible framework than the traditional computer model and can profoundly change ?theory of mind?.",,,,,
Deep Learning and Geriatric Mental Health,"The theory of computing, as discussed above, provides a language for discussing psychological theories of mind. Prior theories have touched on related concepts of multiple agent learning or a broader sense of distributed locus of control. Prior uses include the theory of multiple intelligences29ÿand society of mind30. Marks-Tarlow31ÿuses the related mathematical language of fractals as a framework for understanding transpersonal psychology. In studying how rules for information processing are followed by computers, our brains, and our minds, we can create transdisciplinary approaches where neuroscience and computational research can inform each other28.",,,,,
Deep Learning and Geriatric Mental Health,"There are, however, crucial difference. For example, Noam Chomsky, the father of computational linguistics recently described the distinction between ChatGPT and human language. Chomsky and colleagues describe that these large language models do not model the current state the way people do. Rather they focus on superficial associations. This is a key distinction between human and artificial intelligence. Chomsky demonstrated that languages and machines are essentially identical. A simple Chomsky normal form grammar is equivalent to a push down automata15. The mathematical proofs highlight the use of a small number of ?hidden? states as a canonical framework for representing language. ChatGPT and other large language models use a different approach that is more brute force for modeling language. They learn by estimating superficial associations between many features, rather than using a hidden state-based model. The current AI is based on what Chomsky describes as a superficial model of causality; therefore he does not see it as competing with human intelligence.",,,,,
Deep Learning and Geriatric Mental Health,"Passive sensing refers to the collection of data from various sensors embedded in everyday devices, such as smartphones and wearables, without requiring any active involvement from the user. It allows for digital phenotyping32. Smartphones, in particular, can be used to continuously collect a wide range of passive sensing data, including accelerometers, gyroscopes, GPS, ambient light sensors, microphones, typing patterns, and more. Using deep learning with passive sensing data allows for the analysis of the ?big data? coming from passive monitors, and for the development of potentially meaningful insights from these passive sensing technologies. Deep learning is particularly well-suited for analyzing passive sensing data due to its ability to automatically learn hierarchical representations from complex and high-dimensional data. Deep learning models can effectively capture patterns, relationships, and dependencies within this data, enabling accurate predictions and insightful analysis. For example, Apple has integrated these tools into its devices to help with health promotion.",,,,,
Deep Learning and Geriatric Mental Health,"Deep learning applied to passive sensing data has numerous practical applications in geriatric mental health research, such as gait analysis and fall detection, emotion detection, suicide prediction, monitoring and tracking cognitive changes, health monitoring, sleep analysis, social engagement, and much more. Furthermore, deep learning approaches have been applied to sensor data with the ability to map motion. This has included a range of sensors, including infrared motion sensors, sensors on doors, sleeping mat sensors, wearable actigraphs, cameras, and radio-wave based sensors33?37. A growing body of literature demonstrates how this approach has proven effective for a number of precise clinical applications in dementia care. This ranges from detecting activated behaviors such as agitation, passive behaviors such as apathy, tracking the therapeutic impact of medications such as antidepressants and antipsychotics, and monitoring the side effects of these medications. Applications also include the detection of falls and fall risk based on gait analysis. In the broader domain of neurodegenerative disorders, applying deep learning to motion detection has been demonstrated as a marker for early detection and diagnosis of Parkinson?s disease38. This approach has significant potential implications for developing early behavioral markers for Alzheimer?s disease, since behavioral impairments can manifest years before cognitive impairment39.",,,,,
Deep Learning and Geriatric Mental Health,"Researchers have applied deep learning to typing patterns on a smartphone keyboard (notÿwhatÿyou type, butÿhowÿyou type it) in several different neuropsychiatric populations and extracted distinctive keystroke dynamics. Further, these patterns have been found to identify unique typing signatures ? or digital biomarkers ? of cognition and mood. In one study that evaluated over 86,000 typing actions from 147 users (Veset et al), keyboard dynamics data demonstrated that more severe depression was related to more variable typing speed, shorter session duration, and lower typing accuracy. Typing dynamics data has also been shown to predict future changes in mood40ÿ41.",,,,,
Deep Learning and Geriatric Mental Health,"There are several research groups examining natural language processing (NLP) and automated speech analysis in mild cognitive impairment and Alzheimer?s disease to see if NLP can be used as a biomarker for Alzheimer?s risk. It is also a potential marker for late-life depression42?45. An NLP method was developed that recognized both behavioral activation and depressive symptoms in numerous texts exchanged among patients and therapists; behavioral activation may serve as a mediator of change in depression in patients receiving psychotherapiesÿ46. GPS mobility data has been identified as a digital biomarker for negative symptoms in schizophreniaÿ47,48, and there are several other examples. Ultimately, the insights derived from passive sensing data can enable personalized health interventions and real-time behavior monitoring systems.",,,,,
Deep Learning and Geriatric Mental Health,"There is growing literature on deep learning in neuroimaging49. It is being used to identify specific imaging patterns predictive of diagnosis or of treatment response. Deep learning algorithms leverage the large within subject data to synthesize new data that has similar patterns. A growing open-science community specific for machine learning in AI (https://monai.io) makes many of these tools more accessible to the growing research community. In geriatric mental health, this has been particularly effective in identifying accurate models of the aging brain50, dementia51, and response to treatment52.",,,,,
Deep Learning and Geriatric Mental Health,"Deep learning is a rapidly growing field and has much potential for impact in geriatric mental health beyond what we reviewed here. There are other somatic treatment approaches we did not discuss (e.g., neurostimulation) as well as additional behavioral interventions. For instance, there is the opportunity for integration of deep learning with Ecological Momentary Assessments (EMA). ChatGPT (https://chat.openai.com/chat) and other large language models are based on the same DL approach discussed here. ChatGPT can provide very useful guidance on a wide range of topics. However, it uses generative AI, which involves synthetic data, and thus it can also make up things that are not true.",,,,,
Deep Learning and Geriatric Mental Health,"Overall, deep learning provides many opportunities and challenges for geriatric mental health care. NIH has identified deep learning as a target research area and describes a new era of data science (https://www.hhs.gov/about/strategic-plan/index.html). Industry (e.g., Meta, Amazon, Apple, Alphabet, Netfix) are currently leading research in this area. Thus, academic-industry collaborations will become essential. For many reasons there is growing recognition and concern about the ethics of developing deep learning. There are significant privacy issues in collecting the data, as well as issues around improving the informed consent process to ensure participants are appropriately informed and able to understand what data is being captured, where their data is stored, who has access, and if their data will eventually be sold. A government regulatory framework is being worked out53. There are also emerging ethical concerns in the use of AI54. The way deep learning can make things up with generative AI allows for propagation of misinformation. Continued discussions will benefit from wider understanding of deep learning and its implications.",,,,,
Deep Learning and Geriatric Mental Health,"As reviewed here, geriatric mental health can be understood using insights from deep learning. Software using deep learning offers options in mental health treatment and prevention. As we state in the Introduction, the potential for ethical challenges and bias in deep learning approaches must be considered in parallel with its potential. The risks are many and include inequitable representation of populations in data used for training models, inadequate protections of data privacy, the possibility that repurposing existing data for developing deep learning algorithms exceeds the scope of the informed consent for the original gathering of data, the potential for loss of confidentiality, and the potential for deep learning approaches being used for profitability55. Many of these risks have been identified in domains of medicine such as radiology and oncology where the application of deep learning is more developed. The complexities of behavioral health combined with cognitive impairment frequently seen in late life raises the potential for even more complex ethical questions. These must be acknowledged transparently and addressed directly to maintain trust in these tools as they evolve.",,,,,
Taking a trauma and adversity perspective to climate change mental health,"The European Journal of Psychotraumatology has had a long interest in advancing the science around climate change and traumatic stress. In this special issue, we include papers that responded to a special call in this area. Six major themes emerge from these papers and together they contribute to trauma and adversity model of the mental health impacts of climate change. We argue that, in addition to individual vulnerability factors, we must consider the (i) cumulative trauma burden that is associated with exposure to ongoing climate change-related impacts; (ii) impact of both direct and indirect stressors; (iii) individual and community protective factors. These factors can then guide intervention models of recovery and ongoing resilience.",,,,,
Taking a trauma and adversity perspective to climate change mental health,"In recent years, there has been increasing attention devoted to understanding and mitigating the impacts of climate change on mental health (Berry et al.,ÿ2010; Charlson et al.,ÿ2021; Cianconi et al.,ÿ2020; Doherty & Clayton,ÿ2011; Olff,ÿ2023). This attention is the result of the increasing frequency and severity of climate change-related events (Basu et al.,ÿ2018; Edwards et al.,ÿ2024; Thompson et al.,ÿ2023) as well as the growing anxiety over the existential threat posed by climate change on human health and well-being to future generations (Heeren & Asmundson,ÿ2023; Usher,ÿ2022). TheÿEuropean Journal of Psychotraumatologyÿhas had a long interest in this issue (Olff,ÿ2017,ÿ2019) and in 2020 put out a call for studies advancing research in the area of climate change and traumatic stress (see Olff,ÿ2022). The papers included in this special issue of theÿEuropean Journal of Psychotraumatologyÿdraw from, and contribute to, a trauma-informed perspective on this topic. The central theme of this special issue is that trauma and adversity are central to our understanding of the mental health impacts of climate change. In this editorial, we argue that taking a trauma focus to this understanding is essential in order to evolve our thinking of resilience and recovery.",,,,,
Taking a trauma and adversity perspective to climate change mental health,"The 15 papers included in this special issue represent six major themes drawn from research on traumatic events directly associated with climate change (e.g. hurricanes, floods, wildfires) as well as events associated with other environmental stressors (e.g. earthquakes): (1) the complexity of climate change related mental health outcomes; (2) the impacts of exposure to multiple or simultaneous climate change-related events and stressors; (3) the moderators and mediators of vulnerability to climate change-related mental health outcomes; (4) individual and community resilience and protective factors; (5) the impacts of traumatic forms of climate change on child and adolescent mental health; and (6) the development and implementation of interventions designed to prevent or mitigate these impacts. Together they contribute to trauma and adversity model of the mental health impacts of climate change (Figure 1).",,,,,
Taking a trauma and adversity perspective to climate change mental health,"When describing climate change-related events and their mental health impacts, researchers tend to categorise disaster events based on their time course or chronicity. For example, events have been labelled asÿacute extreme weather eventsÿthat last for days such as wildfires, hurricanes and floods;ÿsub-acute eventsÿthat last for months such as droughts and heat waves; andÿlasting environmental changesÿsuch as sea level rises, and permanently altered environments (Palinkas & Wong,ÿ2020). Similarly, disaster response frameworks often classify psychosocial interventions based on their position in time relative to a single emergency event ? i.e. addressing mental health symptoms in the aftermath of a disaster, versus building mental health preparedness and resilience for future disasters (Mrazek & Haggerty,ÿ1994). While this way of categorising events is useful, a trauma-informed perspective would also have us recognise the importance of cumulative events. As the global effects of climate change continue to worsen, not only are natural disaster events increasing in frequency, communities are increasingly more likely to be impacted by multiple and overlapping disaster events (Cowlishaw et al.,ÿ2023; Leppold et al.,ÿ2022). In this Special Issue, Agyapong et al. (2022) found that the number of traumatic disasters experienced a five-year period (including COVID, wildfire and flood events) was associated with both the prevalence and severity of mental health conditions including posttraumatic stress disorder (PTSD), major depression episode and generalised anxiety disorder. We can expect that the global burden of mental health problems will continue to escalate as the climate crisis worsens and cumulative disaster exposure becomes the norm, and that these impacts will be disproportionately felt by minority communities more directly affected by climate change (Pearson et al.,ÿ2023). As such, there is a clear need for researchers, policy makers and disaster response agencies to consider the compounding mental health impacts of exposure to multiple or simultaneous climate change-related events and stressors.",,,,,
Taking a trauma and adversity perspective to climate change mental health,"A range of mental health outcomes has been associated with the impacts of climate change-related disaster events. Although disaster events are frequently traumatic in nature and are most typically associated with the emergence of posttraumatic stress symptoms (Agyapong et al.,ÿ2022; Chen et al.,ÿ2023; Massazza et al.,ÿ2022; van der Does et al.,ÿ2023), the mental health sequelae of disasters are complex and may also include symptoms of anxiety (Agyapong et al.,ÿ2022; Richez et al.,ÿ2022), depression (Agyapong et al.,ÿ2022; Chen et al.,ÿ2023), and general psychological distress (Pardon et al.,ÿ2024; Zhang et al.,ÿ2022). Further, a scoping review article in this Special Issue indicated that amongst individuals, lasting environmental changes associated with climate change (particularly heat and heatwaves) result in increased mortality risk, suicide and suicidal behaviours, and psychiatric morbidity amongst individuals with mental health conditions (Massazza et al.,ÿ2022). It is therefore clear that the mental health impacts of climate change extend beyond the acute effects of natural disasters, and that long-term alterations to the environment caused by climate change will continue to worsen mental health outcomes over time.",,,,,
Taking a trauma and adversity perspective to climate change mental health,"A trauma lens also provides important information when considering who is vulnerable to poor mental health outcomes following the impacts of climate change. In a longitudinal study, Liang et al. (2023) found a cumulative, dose-related relationship between childhood trauma/stressful life events, and the later mental health response to disaster events. While social support had a buffering effect, this effect was not seen for those with a high stress load. It is also well demonstrated that there are demographic disparities that moderate the health effects of climate change (Benevolenza & DeRigne,ÿ2019), particularly among vulnerable populations such as low-income individuals (Tekin et al.,ÿ2023) and racial and ethnic minorities (Berberian et al.,ÿ2022). Pertinently, in addition to individual pre-existing vulnerabilities, the financial stressors emerging directly from extreme disaster events are a core mediator between these events and their adverse mental health outcomes. For example, economic factors such as damage to homes and infrastructure, threats to livelihood and employment, and the associated financial stressors (Berry et al.,ÿ2010,ÿ2018; Hayes et al.,ÿ2018) are all contributors to negative mental health outcomes beyond the direct effects of trauma exposure and physical danger (Zhang et al.,ÿ2022). Accordingly, a trauma-informed perspective on the mental health outcomes of climate change must consider both pre-existing vulnerabilities and post-disaster stressors which mediate the effects of disasters and other climate change events.",,,,,
Taking a trauma and adversity perspective to climate change mental health,"Studying the protective factors which promote mental health resilience in the face of adversity and trauma ? both at the individual and community levels ? is essential to informing preparedness and response to climate change events. Frameworks of post-disaster resilience highlight that community systems and social support are central ecological resources that buffer against the negative mental health effects of climate change and related disasters (Ungar & Theron,ÿ2020). In this Special Issue, Bakic and Ajdukovic (2021) found that interpersonal and community resources, including social support from loved ones and the community; as well as individual resources, such as psychological resilience; were associated with greater mental health and life satisfaction in members of flood-affected communities in Croatia. Similarly, Liu et al. (2021) found greater social support increases self-compassion and posttraumatic growth in the aftermath of trauma; as well as increasing prosocial and reducing antisocial behaviours. Individual-level psychosocial resources are also critical protective factors against negative mental health outcomes, with Tekin et al. (2023) finding that in survivors of Hurricane Katrina, factors such as hope for the future, efficient coping strategies, and acceptance of the situation were associated with recovery trajectories of posttraumatic stress, reflected in improvements in individuals? symptoms over time. While the cumulative impacts of climate change are severe, this evidence points to a number of individual- and community-level protective factors which may buffer the negative mental health effects of climate change-related disaster events and lasting environmental changes.",,,,,
Taking a trauma and adversity perspective to climate change mental health,"Childhood and adolescence are critical developmental periods characterised by complex neurodevelopmental changes. Exposure to childhood trauma is associated with disruptions in normative cognitive and biological (i.e. genetic, neurodevelopmental, and hormonal) functioning that confer risk for psychiatric illness (McKay et al.,ÿ2021). In this Special Issue, there was a particular focus on mechanisms that underpin the emergence and maintenance of mental health problems in children and adolescents exposed to climate change-related natural disasters. In a longitudinal study of Chinese children and adolescents exposed to the Zhouqu debris flow, Liang et al. (2023) identified that depressive symptoms were stable over the two-year study period, with feelings of self-hate, loneliness and sleep disturbance most central to the enduring experience of depression over time. Given the multifaceted developmental processes occurring in this period, it is notable that one study also found that the clinical expression of mental health responses to natural disasters diverged by age group. In children exposed to a violent storm in France (Richez et al.,ÿ2022), acute stress responses amongst 0?5-year-olds were more typically characterised by agitation and developmental regression, whereas 6?11-year olds were more likely to report experiencing anxiety.",,,,,
Taking a trauma and adversity perspective to climate change mental health,"It is worth noting that factors influencing mental health outcomes post-disaster are not restricted to individual-level personal characteristics, but also include higher-level factors concerning the disaster itself or the community?s subsequent response. Factors such as the severity of disaster and level of exposure to the event can confer further vulnerability for mental health problems (Khan et al.,ÿ2023). Indeed, after the 2011 Great East Japan earthquake (Ohnuma et al.,ÿ2023), exposure to television media coverage of the victims was associated with greater psychopathology among children and greater psychological distress among their parents.",,,,,
Taking a trauma and adversity perspective to climate change mental health,"As well as identifying factors which confer risk for mental health problems in children and adolescents post-disaster, this Special Issue also sheds light on a number of factors that support resilience and adaptive functioning in a post-disaster environment. Liu et al. (2021) demonstrated that in Chinese teenagers exposed to the Ya?an earthquake, greater social support had a positive impact on prosocial behaviours, both directly and indirectly via increasing self-compassion and posttraumatic growth; as well as reducing antisocial behaviour. The importance of social support, particularly from parents and caregivers, was echoed by a narrative review examining the potential impact of the Turkey?Syria earthquake on the psychological well-being of the affected children and adolescents (Khan et al.,ÿ2023). The review also highlights the need for long-term mental health support services ? co-designed by affected communities, to ensure their cultural appropriateness and effectiveness and encourage help-seeking ? so that children and adolescents can receive ongoing mental health support after the initial acute disaster event.",,,,,
Taking a trauma and adversity perspective to climate change mental health,"The psychosocial needs of communities post-disaster are highly complex, and the specific needs of individuals can vary greatly. Although effective psychological interventions for disaster-related mental health problems exist, the scarcity of mental health workers limits the practicality of trained mental health professionals delivering sustained care to individuals and communities affected by disaster. Task-shifting approaches, which shift service delivery from highly qualified health workers to individuals with lower qualifications (Seidman & Atun,ÿ2017), may be one way of increasing community capability to respond to the mental health needs post-disaster.",,,,,
Taking a trauma and adversity perspective to climate change mental health,"In this Special Issue, two studies investigated the efficacy of a skills-based psychosocial intervention that adopted a task-shifting model to address psychological distress following climate change disasters. The Skills fOr Life Adjustment and Resilience (SOLAR) programme (O?Donnell et al.,ÿ2020) was found to reduce psychological distress and posttraumatic stress symptoms in cyclone-affected communities in the Pacific Island nation of Tuvalu (Gibson et al.,ÿ2021), relative to Usual Care. Similarly, the SOLAR programme was found to significantly reduce anxiety, depression and posttraumatic stress symptoms relative to an active Self-Help condition in a sample of individuals affected by compound disasters in rural and regional Australia (Cowlishaw et al.,ÿ2023). Interestingly, the findings from this randomised controlled trial highlighted the need to consider the cumulative events, with the authors suggesting booster sessions would be useful to maintain treatment effects when ongoing stressors occur. These findings highlight that flexible, scalable low-intensity psychosocial interventions delivered by laypeople could form a critical part of post-disaster recovery by allowing for more optimised allocation of mental health resources, so that the diverse mental health needs of individuals can be most effectively addressed. Importantly, the SOLAR programme provides skills to manage exposure to traumatic events, which as this editorial argues, is an essential part of understanding and addressing the mental health impacts of climate change.",,,,,
Taking a trauma and adversity perspective to climate change mental health,"The growing evidence that communities impacted by disasters are increasingly impacted by multiple disasters blurs the question of when the most appropriate time is to intervene with an intervention like the SOLAR programme. For a single disaster event, the idea of 3?12 months post disaster is a useful time to consider utilising interventions targeted to psychosocial distress. However, for communities impacted by multiple disasters over time, this is less clear. It may be that an intervention like the SOLAR programme which is conducted in the aftermath of a particular disaster (as a recovery response) becomes a part of a preparedness response for a future disaster. It is essential that research and policy agendas consider systems being impacted by multiple disasters, and recognise that communities may be simultaneously engaging in preparedness, response and recovery phases relating to different disaster events.",,,,,
Taking a trauma and adversity perspective to climate change mental health,"Although the trauma and adversity focus represented in this special issue is largely derived from the experience of acute climate change related events, it offers the potential for illuminating the causes and consequences of mental health outcomes typically associated with the existential and long-term threats of climate change to human health and well-being. Governments and emergency response organisations are increasingly looking to the research community to guide them on how to foster both individual and community psychosocial resilience and recovery in the face of climate change-related impacts. This sits as a challenge to the research field, and we must bring our trauma expertise to these important questions. To this end, we applaud efforts for global research collaborations in this area such as the climate change theme of the Global Collaboration on Traumatic Stress (www.global-psychotrauma.net/climate). As each year continues to surpass the preceding year as the hottest on record, and as the number of people exposed to these events continues to rise, the urgency of conducting such collaborations and research will only continue to increase.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Text-based digital media platforms have revolutionized communication and information sharing, providing valuable access to knowledge and understanding in the fields of mental health and suicide prevention.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review",This systematic review aimed to determine how machine learning and data analysis can be applied to text-based digital media data to understand mental health and aid suicide prevention.,,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","A systematic review of research papers from the following major electronic databases was conducted: Web of Science, MEDLINE, Embase (via MEDLINE), and PsycINFO (via MEDLINE). The database search was supplemented by a hand search using Google Scholar.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Overall, 19 studies were included, with five major themes as to how data analysis and machine learning techniques could be applied: (1) as predictors of personal mental health, (2) to understand how personal mental health and suicidal behavior are communicated, (3) to detect mental disorders and suicidal risk, (4) to identify help seeking for mental health difficulties, and (5) to determine the efficacy of interventions to support mental well-being.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Our findings show that data analysis and machine learning can be used to gain valuable insights, such as the following: web-based conversations relating to depression vary among different ethnic groups, teenagers engage in a web-based conversation about suicide more often than adults, and people seeking support in web-based mental health communities feel better after receiving online support. Digital tools and mental health apps are being used successfully to manage mental health, particularly through the COVID-19 epidemic, during which analysis has revealed that there was increased anxiety and depression, and web-based communities played a part in reducing isolation during the pandemic. Predictive analytics were also shown to have potential, and virtual reality shows promising results in the delivery of preventive or curative care. Future research efforts could center on optimizing algorithms to enhance the potential of text-based digital media analysis in mental health and suicide prevention. In addressing depression, a crucial step involves identifying the factors that contribute to happiness and using machine learning to forecast these sources ofÿhappiness. This could extend to understanding how various activities result in improved happiness across different socioeconomic groups. Using insights gathered from such data analysis and machine learning, there is an opportunity to craft digital interventions, such as chatbots, designed to provide support and address mental health challenges and suicide prevention.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Text-based digital media platforms have revolutionized communication and information sharing, offering valuable opportunities to gain insights into various domains, including mental health and suicide prevention.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Social media platforms have become significant sources of data for studying mental health and suicide prevention, where researchers have explored the potential of using platforms such as X (X Corp), formerly known asÿTwitter (Twitter, Inc) and Facebook (Meta Platforms, Inc) to gain insights into individuals? mental well-being, detect mental health concerns, and identify suicide risk factors. For example, Coppersmith et al [1] developed a machine learning model to detect signals related to depression in user posts on Twitter, achieving promising results. In addition, De Choudhury et al [2] analyzed Facebook posts to identify individuals at risk of depression, demonstrating the feasibility of using social media data for mental health monitoring. Research methods involve various techniques, including sentiment analysis, topic modeling, and natural language processing (NLP), to analyze large volumes of data and identify patterns and trends. For instance, Park et al [3] applied sentiment analysis to examine suicide-related tweets and identified specific linguistic features associated with suicidal ideation. Sik et al [4] used topic modeling to identify mental health?related topics in web-based forums, facilitating targeted interventions and support. In addition, Burnap et al [5] used NLP techniques to analyze web-based content and identify individuals expressing suicidal ideation, which could enable timely interventions.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Data analysis and machine learning techniques have been used for detecting mental health issues and identifying individuals at risk of suicide, where these sophisticated techniques could enhance clinical decision-making in relation to suicide [6]. Some researchers have explored the use of predictive models to assess suicide risk factors and facilitate early intervention. For example, O?Dea et al [7] developed a predictive model using machine learning algorithms to identify suicide attempt risk among social media users, highlighting the potential for targeted prevention strategies. Data analysis can also be used to provide a valued understanding of factors associated with suicide and mental health, which are not easily identifiable. These insights can then be used to develop strategies for prevention and intervention. For example, data analysis can identify potential underlying causes and risk factors associated with suicide, which can then lead to the development of interventions for susceptible groups. Finally, data analysis can also be used to analyze the effectiveness of current prevention efforts to improve targeted interventions and strategies.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","With the rise in the use of smartphones, digital interventions have been able to offer a solution to address the increasing demand for mental health services [8] and to relieve certain barriers in mental health provision, such as the stigma around accessing psychological health services and geographic isolation [9]. This paper presents a systematic review of the research on the application of machine learning and data analysis to text-based digital media data in relation to mental health and suicide prevention to help answer the following research question: How can machine learning and data analysis be applied to text-based digital media data to understand mental health and aid suicide prevention?",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","A systematic literature search was performed for articles published from January 1, 2013, to July 10, 2023, and was conducted using 4 databases, namely Web of Science, MEDLINE, Embase (via MEDLINE), and PsycINFO (via MEDLINE), using the following search terms, which were adapted for each database: (mental health OR depression OR suicide) AND (machine learning OR deep learning OR artificial intelligence) AND (text analysis OR text mining OR data analysis) AND (digital intervention OR digital mental health). Retrospective searches were conducted (using the same criteria) using both PubMed and Scopus databases to extend the research to bigger databases. However, no new relevant papers were detected. The complete search strings are included inÿMultimedia Appendix 1. CS performed the literature search. EE, MDM, and RB discussed and verified the inclusion or exclusion criteria. TheÿStudy Selectionÿsection identifies how articles were included in or excluded from this review. These database searches were supplemented by hand-search techniques. An additional manual search was run using advanced search within Google Scholar (date: July 10, 2023). The first 5 pages of search results (n=50 records) were screened based on title, as per PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines [10].",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","A total of 27 records were identified according to the search methods explained in theÿSearch Strategyÿsection. An additional 50 records were identified by searching Google Scholar articles. Of the 71 unique articles, 45 (63%) were excluded after abstract screening. A full-text review was performed for the remaining 26 (37%) articles according to study inclusion criteria, after which 19 (73%) of these articles were included (Figure 1;ÿMultimedia Appendix 2ÿ[10]). A total of 7 reports failed to meet the stated inclusion criteria. These included papers (1/7, 14%) analyzing NLP methods in a non-English language; papers (5/7, 71%) with a wrong study type, such as qualitative analysis of the use of social media in mental health and teaching mental health intervention in schools or feasibility study or review of previous studies; and papers (1/7, 14%) that did not relate to data analysis.ÿFigure 1ÿshows a flowchart of the study inclusion process.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review",An assessment for bias risk was performed using the TRIPOD (Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis) guidelines [11].ÿMultimedia Appendix 3ÿprovides more details relating to how the TRIPOD checklist was used and the TRIPOD ratio calculated for the articles relating to prediction and classification (refer to Table S1 inÿMultimedia Appendix 3ÿfor risk bias results).,,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","This review aimed to determine how machine learning and data analysis can be used to assess text-based digital media data in relation to mental health and suicide prevention. Regarding the type of analysis and outcome measures used within the publications reviewed in this study, machine learning and text-based data analysis were used in 4 (21%) of the 19 studies [12-15]. A total of 3 (16%) studies performed some sort of analysis on survey or questionnaire data [16-19], and 3 (16%) papers analyzed the value of text-based digital media [20-22]. The analysis of digital interventions was the main type of analysis used by Onyeaka et al [23], Vermetten et al [24], and Van Gemert-Pijnen et al [25]. The remaining types of investigations included the analysis of forum or discussion data [26] and longitudinal analysis [27]. Where machine learning was used for prediction within the studies, the outcome metrics were also listed in the table. These include the study by Roy et al [28], who investigated how machine learning approaches could be used to predict suicidal ideation from social media data. They trained a random forest model using neural networks to predict suicide ideation status with an area under the curve of 0.88. Gu et al [29] used convolutional neural network for text for classifier training and classification, which produced the following scores: precision=0.84, recall=0.84, andÿF1-score=0.84. Oyebode et al [30] used 5 different machine learning methods to evaluate mental health apps based on user reviews. The 5 models produced similar scores, with the stochastic gradient descent showing the best performance of the 5 classifiers (Table 1).",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Another study [12] used logistic regression, with a 73% accuracy of the logistic model in detecting cognitive distortions. Linear regression was another method used in predicting depressive symptoms and yielded a significant model as a significant predictor of depression [25]. Machine learning was also used in a psychotherapy research study, where the model that used therapist text and extracted features using term frequency?inverse document frequency performed the best overall, with a mean squared error of 0.67 and Spearman rank correlation coefficient of 0.15 (P<.001) [15]. Association rule mining was used in analyzing survey data [19], where the top rule identified an association between strong disappointment with missing events and missing friends in person (support=0.286, confidence=0.671, and lift=1.454) due to the COVID-19 pandemic.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Sentiment was measured for various studies; it was measured as positive for a web-based community platform for mental health [26], and text had a positive score, which correlated with the number of likes [20] of the posts. Another survey [23] found that respondents with anxiety or depression were generally more likely to report that their smart device had helped them in their discussions with their health care providers, compared to respondents that did not have anxiety or depression (42.7% vs 35.3%;ÿP=.03). Furthermore, a negative tone was observed in 66% of conversations among Hispanic populations compared to 39% of conversations among non-Hispanic populations [13], and the total causal effect of disability acquisition on mental health was estimated to be a 4.8-point decline in mental health [16]. Moreover, there was a negative trajectory in sentiment scores from a longitudinal analysis of Twitter data during the COVID-19 pandemic [27]. Another study [14] reported a higher percentage of adults with epilepsy showing a defeatist attitude compared to teenagers with epilepsy (42% vs 4%). In a family well-being study, 53% of respondents thought seeking help would negatively affect their career, and 63% were afraid to ask for help [18]. The results of a questionnaire to establish the mental health of Chinese web-based networkers found that with an increase in socioeconomic status, depression decreased by a margin of ?0.52 (P<.001) [17].",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Having identified the 19 papers for further analysis, we attempted to identify any themes within these papers. This involved an initial in-depth review to become familiarized with the text, and using simple coding to highlight sections of the texts that best describe the content, we were able to identify shorthand labels or codes, for example, prediction and detection of mental disorders and suicide risk. From the coding, we were then able to identify 5 themes as to how machine learning and data analysis techniques could be applied. The themes are outlined with the number of papers per theme inÿTable 2.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Details of the 19 papers that were reviewed, including the author, year, title, population studied, data volume, and main themes, are provided inÿTable 1. The themes are further expanded in the subsequent sections.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Personal mental health can be influenced by various factors, such as employment status and income, and various analytical tools have been used to determine sentiment or other predictors of personal mental health. Research by Aitken et al [16] sought to determine the extent to which alterations in employment and income impact mental health. They used logistic regression models specifically for employment and income, considering their conditional relationship with disability acquisition. The analysis technique focused on evaluating the significance of text-based digital media; their findings indicated that 10.6% of the effect of disability acquisition on mental health was explained by changes in individuals? employment status, but no similar effect was observed through changes in income. This underscores the importance of measures for addressing disability-related mental health disparities, specifically the equalization of employment rates between individuals with and individuals without disabilities to reduce disability-related mental health inequalities.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Research by Xiao et al [17] sought to examine survey data to measure the prevalence of depression symptoms and their correlation with an individual?s socioeconomic status and lifestyle during the COVID-19 pandemic in China. The methodology involved statistical analyses using SPSS (IBM Corp) to evaluate survey data. The findings revealed a noteworthy impact of the pandemic, indicating that respondents experienced more severe mental symptoms when their residential communities were more exposed to SARS-CoV-2. The implications drawn from these findings suggest that mental health conditions among survey respondents varied based on the level of the COVID-19 pandemic severity. Notably, residents in communities with a high severity of the pandemic exhibited more pronounced symptoms of depression and anxiety.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Khattar et al [19] conducted a web-based survey study with the goal of understanding the day-to-day experiences and mental well-being of young students in India during the COVID-19 pandemic. They analyzed survey responses using R (The R Foundation) and Python (Python Software Foundation) to evaluate the mental health of diverse populations during the ongoing COVID-19 pandemic. Their findings revealed that approximately 19.2% of the students expressed weariness with phone use, while 42.9% reported feeling a mix of frustration, profound boredom, anxiety, overwork, and depression. Conversely, 37.9% indicated experiencing emotions such as relaxation, peace, optimism, calmness, hopefulness, and love. This suggests a crucial role for teachers and mentors in providing emotional support to students. They also used association rule mining to analyze the survey data, where the top rule identified an association between strong disappointment with missing events and missing meeting friends in person (support=0.286, confidence=0.671, and lift=1.454) due to the pandemic.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Valdez et al [27] investigated the extent of social media use at the onset of the COVID-19 pandemic to uncover emerging themes from tweets related to COVID-19 and to examine whether sentiments changed in response to the COVID-19 crisis. They used the latent Dirichlet allocation method for topic modeling and the Valence Aware Dictionary and Sentiment Reasoner for sentiment analysis. Their findings indicated that sentiment scores were initially high and stable but exhibited a significant decrease over time, indicating reduced sentiment over the long term.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Various data analysis techniques have been applied as predictors of personal mental health, where the effect of disability acquisition on mental health, for example, was explained by changes to people?s employment but not by changes to income [16]. In relation to the COVID-19 pandemic, the overall emotional state of students during lockdown showed a mix of various moods, with feelings ranging from frustration to boredom to anxiety to depression [17]. In addition, themes emerged from tweets about COVID-19 to highlight the extent to which social media use increased during the onset of the COVID-19 pandemic [19] and how the sentiment changed in response to the pandemic [27]. The pandemic has had a significant impact on mental health, where respondents had more serious mental symptoms when their residential communities exhibited a greater exposure to the spread of SARS-CoV-2 [17].",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Machine learning can be used in the detection of cognitive distortions, which may fuel anxiety, and in the detection of those at risk of suicide. Roy et al [28] developed a model capable of predicting individuals at risk and assessing the likelihood of experiencing suicidal thoughts within a specific time frame. This involved using a random forest model that used output from neural networks to predict binary suicidal ideation status when there is a match with at least one of the word patterns in the ordered word screening, for example, ?feeling suicidal.? This study found that the neural network models successfully predicted suicidal ideation even before individuals articulated explicit thoughts of suicide. These findings suggest that there may be potential for predicting suicidal ideation before individuals explicitly express such thoughts, offering opportunities for early intervention and support.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Simms et al [12] demonstrated that machine learning could also be applied to detecting cognitive distortions (eg, the user would be thinking negatively and discounting the positive) from personal blogs. Through the use of the Linguistic Inquiry and Word Count software, this study found that it is feasible to automatically detect cognitive distortions from personal blogs with a relatively high accuracy of 73%. The implications drawn from these findings underscore the potential benefits of continued work in this area for mental health care and psychotherapy. This progress has the potential to lead to lower costs, earlier detection, and more efficient use of counseling time.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","These findings show that it is possible to detect cognitive distortions automatically from personal blogs with an accuracy of 73% [12], and this could lead to an earlier detection of anxiety and possible intervention at an earlier stage. Neural network models, which are powerful machine learning tools, have been shown to successfully detect mental disorders and suicidal risk, where certain models were shown to predict suicide ideation even before suicidal thoughts were articulated [28].",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","When attempting to understand how personal mental health and suicidal behavior are communicated, machine learning has been used to explore big data from open-source digital conversations with regard to suicidality. The aim of the research by Castilla-Puentes et al [13] was to delve into big data derived from open-source digital conversations among Hispanic populations to determine attitudes toward depression, comparing Hispanic and non-Hispanic populations. The methodology involved the analysis of tone, topic, and attitude relating to depression using machine learning and NLP. This study revealed a notable disparity in attitudes, beliefs, and treatment-seeking behavior between the 2 groups, providing insights into the mindset and attitudes toward depression from a previously unexplored vantage point.

Falcone et al [14] investigated big data derived from open-source digital conversations among teenagers and adults with epilepsy with regard to suicidality. They used NLP and text analytics to reveal that a higher percentage of teenagers, compared to adults, expressed a fear of ?the unknown? due to seizures (63% vs 12%), concern about the social consequences of seizures (30% vs 21%), and desire for emotional support (29% vs 19%). In contrast, a significantly higher percentage of adults exhibited a defeatist (?given up?) attitude compared to teenagers (42% vs 4%). The implications of this study suggest that teenagers engage more frequently in web-based conversations about suicide than adults and that there are notable differences in attitudes and concerns between the 2 groups. These distinctions may have implications for the treatment of younger patients with epilepsy.

Liu and Kong [20] sought to identify the factors influencing the number of likes and reposts within a web-based community dedicated to depression. This involved using a combination of text mining and empirical analysis to delve into the factors affecting user engagement, specifically the number of likes and reposts. They found that users within web-based mental health communities exhibit a higher level of attention to topics related to social experiences and emotional expressions. These findings emphasize that understanding the factors influencing the number of likes and reposts in web-based mental health communities can be advantageous for users, facilitating greater support and providing a sense of relief and comfort within the community.

Feuston and Piper [21] integrated manual data collection with digital ethnography (study of human interaction through the internet technologies used) and semistructured interviews to explore how various modes of expression (eg, visual, textual, and oral) contribute to the overall understanding of mental health. By evaluating the value of text-based digital media, they found that individuals adopt a diverse range of practices and use Instagram (Meta Platforms, Inc) features to render their experiences with mental health and illness visible to others. This would have implications for the analysis of user interactions, suggesting an information flow from one person to the next.

Golz et al [26] used the inCLOUsiv platform to identify and interpret the communication patterns and verbal expressions of the users of the platform during the initial lockdown in 2020. The methodology involved analyzing discussions in forums and live chats using text mining, frequency analysis, correlation analysis, n-gram analysis, and sentiment analysis. Their analysis found that the communication behavior of users on the inCLOUsiv platform was characterized by generosity and support, with 72% of the identified sentiments being positive. Users actively engaged with topics such as corona, anxiety, and crisis, sharing coping strategies, which suggest that positive and supportive interactions within mental health?related virtual communities, emphasizing the potential impact of such interactions on the well-being of community members.

When it comes to understanding how personal mental health and suicidal behavior are communicated, it was found that teenagers engage more frequently in web-based conversations about suicide than adults [14] and that the communication behavior of users on a digital exchange platform was supportive and sentiments were mostly positive [20]. Data analysis was also shown to reveal that individuals use a variety of practices and features of social media to make experiences with mental health and illness visible to others [21] and that users of web-based mental health communities were found to be more attentive to the topics of social experience and emotional expressions [20]. Furthermore, help seeking was shown to vary between different populations, where the attitudes, beliefs, and treatment-seeking behavior toward depression showed great disparity between Hispanic and non-Hispanic populations [13]. Finally, in relation to a specific illness, epilepsy, a higher percentage of teenagers were fearful of ?the unknown? due to seizures and concerned about the social consequences of seizures, while a significantly higher percentage of adults showed a defeatist (?given up?) attitude compared to teenagers [14].",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","An analysis of survey data has been shown to identify help seeking for mental health difficulties. Research by Waddell et al [18] sought to examine survey data to gain insights into the dynamics of help-seeking relationships within veteran families. The findings of the study brought to light that family members of veterans play a significant role in both the initial and ongoing processes of seeking help. However, the study also revealed substantial barriers to help seeking, primarily linked to the military culture. These barriers included the belief that mental health concerns could be self-managed (if recognized), highlighting concerns about potential impacts on careers and the fear of judgment by others. Educating families about identifying early signs of mental health problems is crucial to inform families about the potential mental health risks associated with military careers. This knowledge can then contribute to fostering a supportive environment and breaking down barriers to help seeking within veteran families.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","The effectiveness of interventions to support mental well-being has also been analyzed using machine learning. Gu et al [29] used NLP technology to identify psychological cognitive changes. Using an emotion dictionary along with Word2vec semantic training, a model was trained to transform labeled text into a vector matrix, and the convolutional neural network for text was used for classifying the labeled text. The findings of the study indicated that posts signaling cognitive change tended to have longer word lengths. In addition, support seekers who had not undergone cognitive change tended to express themselves more in web-based replies. This highlights the potential for supporting individuals with mental health problems, promoting the development of web-based mental health communities, and constructing web-based psychological chatbots.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Research by Goldberg et al [15] used NLP and machine learning techniques to predict one of the most studied process variables in psychotherapy: therapeutic alliance. The methodology involved using Sent2vec to map sentences to vectors of real numbers, and linear regression was then used as the prediction model. The findings of the study revealed that across the 1235 alliance ratings, the mean rating was 5.47 (SD 0.83), indicating a negative slant often found in the assessment of therapeutic alliance. The implications drawn from these findings suggest that machine learning holds promise for predicting observable linguistic behaviors, these models could be trained using human coding as the gold standard, and thorough testing should be conducted using large data sets.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Oyebode et al [30] used sentiment analysis and other machine learning approaches to evaluate 104 mental health apps available on Google Play (Google LLC) and App Store (Apple Inc). By integrating NLP and the term frequency?inverse document frequency weighting technique to vectorize the reviews, supervised machine learning classifiers were used to predict sentiment. The study revealed that the majority of the reviews were positive, indicating that most users found mental health apps to be useful and helpful, emphasizing the importance of ensuring that mental health apps are not only usable and of high quality but also supportive, secure, and noninvasive.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Research by Chikersal et al [22] provided a deeper understanding of how supporter behaviors impact the use of web-based therapy programs. The methodology involved the application of unsupervised machine learning, along with statistical and data mining methods, to analyze complex, large-scale supporter-client interactions. They found that concrete, positive, and supportive feedback from supporters, particularly those referencing social behaviors, were strongly associated with better outcomes. This suggests the importance of identifying effective context-specific support strategies using data for personalized mental health support. This knowledge can contribute to improving the design and implementation of personalized human support in internet-based cognitive behavioral therapy and enhance our understanding of big data in digital health interventions.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Onyeaka et al [23] investigated the use and perceived benefits of digital health tools, identifying the association between the use of digital interventions and the adoption of healthy lifestyle behaviors, and the sociodemographic factors linked to the use of digital tools among individuals with anxiety or depression. Basic descriptive statistics and chi-square tests were used, identifying a notable prevalence of digital interest among individuals with anxiety or depression, with up to 84.7%, 60.6%, and 57.7% of the individuals reporting ownership of smartphones, tablets, and health apps, respectively. These results suggest that digital tools may offer promise for a subset of individuals with mental illness who prefer engaging in technology-based strategies for managing their health.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Vermetten et al [24] investigated the potential use of virtual reality (VR)?based interventions, wearable technology, and text mining to enhance the mental health of military personnel and veterans. Using text mining and the statistical technique of item response theory, they demonstrated that there was a high agreement of 82% with the diagnoses provided by psychiatrists and suggested that the combination of text mining and VR-based interventions holds promise as a valuable tool for psychological and psychiatric assessments in the future.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Van Gemert-Pijnen et al [25] demonstrated how log data could be used to comprehend the adoption of web-based interventions and provide value in improving the incorporation of content in such interventions. By performing a statistical analysis using SPSS, this study showed that pattern recognition could be used to customize the interventions based on use patterns from earlier lessons and act as an aid in supporting the adoption of content essential for therapy. Understanding how participants can derive greater benefits from the intervention and identifying the most effective combination of features can lead to enhancing the effectiveness of web-based interventions.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","There are many ways in which data analysis can be used to support mental well-being; for example, textual data analysis can be used to signal cognitive change, where it has been found that the average word length within text is longer for posts that indicate a cognitive or emotional change [29]. Other analysis results indicate a high prevalence of digital interest among people with anxiety or depression [23], and when NLP and machine learning were used to predict therapeutic alliance, the mean rating showed a typical negative skew found in the assessment of the alliance [15]. VR-based interventions, wearable technology, and text mining are expected to be promising tools in psychiatric assessments in the future [24]. Regarding the use of log data to improve the uptake of a web-based intervention, user pattern recognition from earlier lessons can be applied to tailor the intervention and support the uptake of content essential for therapy [25]. For web-based and non?web-based mental health apps, the majority of the reviews from a study of mental health apps available on Google Play and the App Store were positive, showing that most users found mental health apps useful and helpful [30].",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","When attempting to discover useful insights from text-based digital media in relation to mental health and depression, machine learning and data analysis techniques can be applied in many different ways. They can be used as predictors of personal mental health, for example, to measure how an individual?s socioeconomic status can relate to depression. With the increasing prevalence of mental health issues since the COVID-19 pandemic [31] and the need for effective suicide prevention strategies, using data analysis and machine learning techniques in textual digital media data research has demonstrated that the COVID-19 pandemic and its associated restrictions have resulted in increased depression, anxiety, and feelings of loneliness [32], but this sentiment improved following the news of vaccine rollout to defend against the virus [33]. The pandemic has made a big impact on research in this area, where findings show that students? overall emotional well-being reflected a combination of diverse moods, encompassing feelings of frustration, boredom, anxiety, and being overworked, and experiencing depression during the pandemic. Further themes that emerged from tweets related to the COVID-19 pandemic showed that social media use increased during the onset of the pandemic and that participants of a survey exhibited more pronounced mental health symptoms if their residential communities faced heightened exposure to the spread of SARS-CoV-2.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Machine learning and data analysis techniques can also be used to detect mental ill health and suicidal risk, where neural network models can be used to predict suicide ideation before suicidal thoughts are articulated and to generate models capable of predicting individuals who would be at risk of suicidal thoughts. These tools can also be used to comprehend help seeking for mental health difficulties. Survey data were analyzed to understand help seeking in relation to mental health, identifying that the role of the family is important in encouraging help seeking for war veterans and revealing substantial barriers to help seeking, particularly in relation to the military culture, such as the belief that mental health concerns can be self-managed (if recognized) and a fear of being judged by others.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","When attempting to understand how we communicate personal mental health and suicidal behavior, machine learning techniques can be used in diverse ways, such as to explore digital conversations with regard to suicidality and to identify factors influencing the number of likes in a web-based community for depression. Users were shown to exhibit both benevolent and supportive communication behaviors, with predominantly positive sentiments, on a digital exchange platform. When examining a specific illness, epilepsy, it was revealed that a higher percentage of teenagers expressed a fear of the unknown associated with seizures and concern about the social consequences of seizures, and a higher percentage of adults demonstrated a defeatist attitude compared to teenagers. When Instagram was used to better understand how we can communicate personal mental health, it was disclosed that individuals use various practices and features on the platform to make their experiences with mental health and illness visible to others. Finally, seeking assistance was found to differ across different populations, with significant differences in attitudes, beliefs, and the propensity to seek treatment for depression observed between Hispanic and non-Hispanic populations.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Insights from data analysis and machine learning can be used to assist in the development of digital interventions, and the effectiveness of these interventions can be shown to provide support to people living with depression and improve mental well-being. Through textual data analysis, it was determined, for example, that posts signaling cognitive change exhibit longer word lengths and that support seekers who have not undergone cognitive change tend to express themselves more in web-based replies. Similarly, it was found that there was a heightened prevalence of digital interest among individuals with anxiety or depression. NLP and machine learning can also be used to predict therapeutic alliance between the patient and therapist.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","When exploring the potential of VR-based interventions integrating wearable technology and text mining to enhance mental health, it emerged that text mining coupled with VR-based interventions is anticipated as a promising tool for psychological and psychiatric assessments in the future. The use of mental health apps was analyzed, which showed that attitudes toward them were mainly positive, indicating that a majority of users find these apps useful and helpful. In the context of understanding the uptake of web-based interventions, pattern recognition was used to tailor individual interventions based on use patterns from earlier lessons, thereby supporting the uptake of content essential for therapy.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","This study exhibits limitations in the selection of articles because it used only 4 journal databases (ie, Web of Science, MEDLINE, Embase, and PsycINFO) as well as Google Scholar. Moreover, only articles published in English and related to mental health or suicide, machine learning and data analysis, and digital interventions were included. The search for articles started in March 2023, and the collected articles were published between 2013 and 2023. As some of the researched articles identified some sort of machine learning classification or prediction, we should have considered explainable artificial intelligence to facilitate the understanding of any predictions made by the machine learning models to better understand the models? behavior. Another limitation involves how the inclusion and exclusion of papers were resolved. Even though CS, EE, MDM, and RB assessed the papers and decided what was to be included or excluded based on the applicability criteria, it was CS who made the final decision about what went into this review.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","In conclusion, this review illustrates that the use of data analysis and machine learning techniques to extract useful insights from text-based digital media related to mental health and suicide prevention holds significant promise. Data analysis and machine learning were used to gain valuable insights; for example, findings show that engagement in web-based conversations relating to depression may vary among different ethnic groups and that teenagers engage in web-based conversations about suicide more often than adults. Another finding was that disability acquisition (which is associated with a deterioration in mental health) was shown to be affected by changes to employment but not income.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","The efficacy of digital tools was also analyzed, with machine learning approaches being used to understand users? opinions regarding mental health apps. Using positive and negative sentiments, it was shown that those with mental illness are digitally connected and are incorporating these tools to manage their health. Predictive analytics was also identified to be able to detect cognitive distortions, which are associated with depression and anxiety, from personal blogs with an accuracy of 73%, while other machine learning models were able to predict the risk of suicidal ideation from social media. The use of modern technology has also been investigated, with the application of VR-based interventions showing promising contributions to the field of military and veteran mental health by developing new approaches to delivering preventive or curative care.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","The recent pandemic has also had an influence on this area of research. Analysis was undertaken to try to discover to what extent social media use increased during the onset of the COVID-19 pandemic and to assess how different populations communicated regarding their mental health. It was discovered that virtual communities played an important role in mental health during the pandemic and that social media may be used as a coping mechanism to combat feelings of isolation related to long-term social distancing. Web-based communities also offer great support for people with mental disorders, where the analysis of the number of likes and reposts for posts in web-based mental health communities allowed for these users to gain more support within the community.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Future research could focus on investigating further benefits of textual digital media analysis in mental health and suicide prevention when dealing with depression and, importantly, what makes people happy. Machine learning can be used to predict what are the sources of ?happiness? or even how different activities make different socioeconomic groups ?happy,? and these insights can then be used to assist in the development of a wide range of digital interventions, such as chatbots.",,,,,
"Insights Derived From Text-Based Digital Media, in Relation to Mental Health and Suicide Prevention, Using Data Analysis and Machine Learning: Systematic Review","Ultimately, this systematic review underscores the importance of harnessing advanced analytical methods to derive valuable insights that can lead to improved mental health interventions and enhanced strategies for suicide prevention.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"(1) Background: Artificial intelligence (AI) has flourished in recent years. More specifically, generative AI has had broad applications in many disciplines. While mental illness is on the rise, AI has proven valuable in aiding the diagnosis and treatment of mental disorders. However, there is little to no research about precisely how much interest there is in AI technology. (2) Methods: We performed a Google Trends search for ?AI and mental health? and compared relative search volume (RSV) indices of ?AI?, ?AI and Depression?, and ?AI and anxiety?. This time series study employed Box?Jenkins time series modeling to forecast long-term interest through the end of 2024. (3) Results: Within the United States, AI interest steadily increased throughout 2023, with some anomalies due to media reporting. Through predictive models, we found that this trend is predicted to increase 114% through the end of the year 2024, with public interest in AI applications being on the rise. (4) Conclusions: According to our study, we found that the awareness of AI has drastically increased throughout 2023, especially in mental health. This demonstrates increasing public awareness of mental health and AI, making advocacy and education about AI technology of paramount importance.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"The age of technology colliding with the advances in medicine has resulted in a renaissance of diagnostic and treatment modalities for various disease conditions [1,2]. More specifically, artificial intelligence (AI), especially large language modeling (LLM), is in its heyday, with influences in many medical disciplines including population health, cardiovascular health, neurological health, and mental health [3,4,5,6,7]. The shortage of mental health practitioners has required novel technologies like AI. Due to the shortage of mental health workers, there is increased burden on primary care physicians to treat mental illnesses, although they are not equipped to handle these, which traditionally require a referral to a specialist. This necessitates the innovative use of technology to address shortages in the healthcare profession.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"There are novel generative AI tools, such as Google Bard (LaMDA), ChatSonic API, Microsoft?s GPT-3, and Facebook?s Robustly Optimized BERT Pre-training Approach (RoBERTa), that have the potential to alleviate some of the mental health provider shortages. One of the original generative AI tools, ChatGPT (Chat Generative Pretrained Transformer), represents a revolution in the world of artificial intelligence. OpenAI, debuted in 2020, advanced this conversational AI technology powered by a linguistic model known as GPT, short for Generative Pre-Training Transformer [3]. The ChatGPT-3 model was the latest in a line of large pretrained models designed for understanding and producing natural language [1,2]. In recent times, society has been gripped with awe about the potential that this new technology brings to the area of mental health.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"One area of application that researchers have touted as successful is the improvement of diagnostic accuracy of various disease conditions. The discipline of mental health is no exception. For instance, one study showed how large language modeling or generative AI can be harnessed to make mental health prediction and prevention through retrieving online text data [8]. Additionally, more recently, along with improved treatment, there is a drive to screen and prevent mental illnesses in healthy individuals living in vulnerable populations.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"Many people learn about medical conditions by relying on using Google and other search engines. There are well-researched and efficacious applications in the fields of cardiology, radiology, and surgery, among other areas of medicine. Due to the technical nature of LLM, there is trepidation in applying the novel technology to medicine. Over recent years, as social media has become a source of medical information, researchers found that analyzing user-generated data can improve the effectiveness of AI and increase access to medical information by the public [8]. Even Twitter data have been used for LLM-driven sentiment analysis and can contain vital information to diagnose depression and even suicidal ideation. Many social media users often express their perspectives and thoughts of depression and suicide on these platforms.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"There are other applications of user-generated data in mental health through the applications of AI. LLMs can be useful in predicting mental health disorders for leveraging natural language processing for parsing user-generated information. Some researchers utilized online social media datasets with high-quality human-generated mental health labels. Reddit was their platform of choice because it has nearly half a billion active users who discuss a wide range of topics [9]. The posts and comments are publicly available, and the researchers could collect data going back to 2011. This vast availability of user-generated data can be used to create more precise AI models.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"In many countries and certain areas within the United States, there is fewer than one psychiatrist per every 100,000 population. Tutun et al. found [10] that AI can be used to create decision support systems to accurately predict mental health disorders as indicated in the Diagnostic and Statistical Manual of Mental Disorders (DSM-5) and International Classification of Diseases. Furthermore, there is still room for artificial intelligence applications in mental health. For instance, typically, primary care physicians are not trained in mental health, necessitating further collaboration. AI offers a lot of promise in applying, appreciating, and embracing the application of mental health. More specifically, AI has revolutionized how magnetic resonance imaging (MRI) allows for improved diagnosis through providing higher-resolution images and potential biological changes that are connected to depression [11]. Other instances of AI application include diagnosing sepsis in premature babies from metrics such as vital signs and monitoring devices [12,13]. Even though in medicine there are many examples of AI applications, there is not a thorough understanding of how artificial intelligence has impacted the field of mental health.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"Globally, mental health problems affect one in eight individuals [12]. Mental health is strongly connected to physical health, with large swaths of people becoming aware of the importance. Khubchandani et al. found [14] that depression is strongly intertwined with diabetes as it relates to poor outcomes. Banerjee et al. found [15] that social isolation, a byproduct of mental health, is also a predictor of overall mortality. One distinct way to diagnose mental health disorders is the 90-question Symptom Checklist-90 (SCL-90-R). Tutun et al. [10] found a way to leverage AI to address problems in diagnostic methods. However, the number of questions and the complexity of the SCL-90 questionnaire necessitates alternative AI-driven ways to maintain mental health diagnostic accuracy, even after the reduction in the number of questions, for instance, decreasing a 90-item questionnaire to a 28-item questionnaire (SCL-20-AI) without any human input, to an accuracy level of 89% [10]. Additionally, the researchers emphasized the importance of establishing close cooperation between the creators of AI-based decision support systems and mental health practitioners.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"Many treatments of depression and anxiety have proven to be ineffective against mental health disorders, due to which lack of medical adherence is a concern. Treatment for mental health disorders is only about 30% effective [16]. The lack of efficacy is due to the lack of understanding, requiring the use of more sophisticated algorithms. There are many other reasons for the lack of effectiveness of treatment, including stigma and lack of access. Artificial intelligence can integrate genetic heterogeneity and other considerations to utilize the concept of personalized medicine, to create tailored treatment towards the individual.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"Depression and anxiety remain major mental health and public health problems that are on the rise. In 2023, Canady et al. found [17] that there were approximately 29% of the population that have mental health problems. This increased by 10 percent from the year 2015. Staggering statistics have paved the way for novel technologies such as AI, a more comprehensive treatment modality. Additionally, according to a Gallup Panel [18], the 17.8% who either had a diagnosis or currently have been treated for depression is up from 2015. At the same time, the cost of depression has skyrocketed. In order to stem the tide of increasing mental health disorders, improved diagnostic methods, through generative AI, have proven to be effective.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"According to the Substance Use and Mental Health Service Administration (SAMHSA), mental illness and substance use disorder treatment spending from all public and private sources was USD 280.5 billion in 2020, an increase from USD 171.7 billion in 2009 [19]. Major depressive disorder is now considered the leading cause of disability worldwide. However, in the discipline of mental health, there is a high rate of medication nonadherence. Medication nonadherence is higher among people with mental health disorders than chronic physical conditions. Additionally, chronic diseases may need to be addressed after successfully treating mental health conditions.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"One of the hurdles that mental health professionals have to grapple with is the lack of adherence to medications. There are many reasons for medication nonadherence, such as fear of potential side effects, lack of disease acceptance, and lack of awareness of not taking the medication regularly. Also, polypharmacy due to comorbid chronic diseases can be another deterrent for medication adherence due to lack of understanding or poor patient?physician communication. Additionally, the lack of current efficacious mental disorder treatments leads to higher nonadherence rates. However, the consequences of medication nonadherence can have far-reaching consequences. For instance, there may be an increase in relapse or even exacerbation of mental health symptoms or even suicidal tendencies.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"With the lack of efficacy and adherence to mental health medications, AI technology has become an integral tool to better understand the consequences of mental health and create more targeted therapies [20,21]. While the application of artificial intelligence is not new, the rapid spread of generative AI and large language modeling is recent and has immense potential in diagnosing and treating mental health conditions [22]. In fact, the potential of mental health is seemingly limitless and broad in scope. What is not known is how much interest there is for generative artificial intelligence, particularly around mental health.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"Mental illness continues to be a very serious public health problem. Ivanov et al. found that the traditional methods espouse a very simplistic biological approach to treat mental illness, with the use of psychotropic drugs that are not very effective [23]. However, new approaches are important to develop with the increase in the prevalence of mental health conditions and a shortage of mental health practitioners, importantly in resource-poor settings [24,25]. Large language models can be harnessed to create inexpensive tools that can be used to address these shortages [26,27]. With the aid of generative AI, complex treatment modalities can be used to better address psychiatric conditions. While most studies focus on the medical context of mental illness, what we investigated is how the popularity of AI in mental health is a reflection of AI literacy in the general public, especially in the area of mental health.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"In this study, we used Google Trends, and, through search patterns on the Internet, we analyzed the web queries that were made in the search engines, such as the Google website search engine. All the searches were conducted within the United States. To conduct analyses, we downloaded the data for all searches in the United States.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"After downloading the output, we conducted further analyses. We used the portal to determine the proportion of searches for the terms ?AI?, ?AI and Depression?, ?AI and Anxiety?, and ?AI and Mental Health? over the time series of from 1 January 2023 to 31 December 2023 among all searches performed on Google Search and found a relative search volume (RSV) index. AI was the proxy used for multiple terms (generative AI, artificial intelligence, ChatGPT and large language modeling). Google Trends provides a list of topics?these are a group of search terms that fit into the same general concept. The most important topics were ?ChatGPT?, ?Bard?, and ?Generative artificial intelligence?. The RSV is the query share of a particular term for a given location and time, normalized by the highest query share of that. Sample data are used to display interest in a search term on a global, national, or city level. The search queries are normalized on a scale from 0 to 100 in order to compare search data. Search data are presented using an RSV, where 100 indicates the peak of search volume. Google Trends also normalizes the data based on the time and location of a search query.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"We used the Box?Jenkins time series modeling estimation method to determine what the search volume of ?AI and mental health? will be by the end of 2024. Autoregression (ARIMA) and other statistical analyses were run using SAS v.9.4. Diagnostics for the four models were completed checking for autocorrelation. The adequacy of the model was tested using chi-square test statistics for white-noise residuals. Our autoregressive integrated moving average model is robust to time series biases, such as recurring periodicities. Additionally, a trend line for the time series plot with additional Lowess estimators plot, a nonparametric regression, was generated. Here linear methods do not perform well. Lowess fits a regression line through the moving central tendency of ?AI? along the time gradient. Additionally, using ArcGIS, we geospatially analyzed the County Health Rankings 2023 to assess the distribution of mental health workers per 100,000.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"According toÿTable 1, each of the search terms reached a maximum at varied times in 2023. For instance, the term ?AI? steadily increased from January onward, according toÿFigure 1b. This aligns with the findings inÿFigure 1, showing that the term ?AI? reached its maximum by April. The term ?AI and Mental Health? reached the maximum RSV in October, demonstrating a more gradual increase. The RSV for the terms ?AI and Depression? and ?AI and Anxiety? reached the maximum in November.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"As seen inÿFigure 1, the RSV for the year 2023 varied according to the search volume in mental health and AI. According toÿFigure 1b, the term ?AI? was already popular, and the trend line demonstrates that by the end of 2023, the search for this search term had drastically risen throughout the year. The next terms searched along with AI demonstrated further variations. The term ?AI? was tested with ?mental health? (Figure 1d), ?anxiety? (Figure 1c), and ?depression? (Figure 1a) individually to determine search term volume. InÿFigure 1d, ?AI and mental health? demonstrates an increasing trend; however, the starting RSV was slightly lower than ?AI? alone.ÿFigure 1c,d demonstrate a steady trend with no change in RSV between the beginning of the year and the end of the year.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"InÿFigure 1, the Lowess smoother showed variations present in the trend for each RSV through time that were not quite linear?as was seen in each of the search terms. UnlikeÿFigure 1d ?AI and mental health?, both ?AI and depression? (Figure 1a) and ?AI and anxiety? (Figure 1d) remained steady throughout the year 2023. Also, as seen inÿFigure 1a, the Lowess smoother seemed to have a seasonal variation throughout the year.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"According toÿTable 2ÿandÿFigure 2, the projected RSV through December 2024 is expected to increase from 25.5 to 54.6, indicating a 114% increase throughout the year. This aligns with the findings fromÿFigure 1d, where an increase is already indicated in the year 2023.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"Finally, according toÿFigure 3, we conducted a geospatial analysis and observed that while on a national level there is a shortage, there are variations and severe shortages in the distribution of mental health workers per 100,000. Some of the rural counties in the United States did not have a mental health professional at all, as indicated by white and lighter blue. Darker blue indicates an adequate number of mental health workers in 100,000.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"In recent times, society has been gripped with curiosity about the potential that this new technology of generative AI has for use in the discipline of mental health. In fact, the potential in mental health is seemingly limitless [27]. According to our study, a novel finding was that the search volume and awareness of artificial intelligence increased by 257% from January to April of 2023. As more mental health datapoints will become available, generative AI will be leveraged and harnessed to improve many mental health discoveries and diagnostic methods [28,29,30]. The discipline of mental health is no exception in helping unleash the potential of AI. The increase in Google searches related to AI and mental health between January 2023 and December 2023 may reflect increasing public recognition of the clinical aspects addressing them. More specific terms relating to depression and anxiety as they relate to AI are not as frequently searched but alowly increasing in popularity. Healthcare practitioners should use plain English terms for online discovery of AI-driven mental health resources and be aware of health literacy.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"One way to increase awareness is to educate patients about the techniques and the applications of AI. Medical chart abstraction is a method that has gone through multiple iterations and has gone through a major LLM breakthrough in the discipline of mental health. Through linguistic diversity, ChatGPT-4 has previously exhibited enhanced multilingual abilities to apply linguistic machine learning algorithms to electronic health records to detect ?suicidal thoughts? or ?suicide attempt? [31,32]. Other words that have been used for mental health chart abstraction include ?anti-depression medication? [33,34,35]. Moreover, research also shows that social media, with the help of AI, can predict diagnoses in medical records more accurately than self-report surveys [35,36,37]. However, a combination of multiple AI-driven diagnosis methods can be more accurate than what physicians can achieve alone.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"Another novel finding in our study was that the interest in AI in mental health has been increasing throughout 2023 and is expected to increase by 114% throughout the year 2024. This shows that awareness will increase over time for public health and mental health practitioners alike. In comparison, we found, through geospatial analysis, that there is a shortage in mental health providers across the country, necessitating the importance of AI-guided mental health services. More and more people are relying on ChatGPT and generative AI to receive medical advice in lieu of a physician?s advice [38]. Additionally, AI can unfold the possibilities of applications in mental health treatment.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"AI technology can provide decision-making support that healthcare practitioners can act on. This can aid primary care providers to rely on AI technology to further guide treatment in mental health, alleviating some of the burden experienced by general practitioners. AI can not only improve diagnostic accuracy in many ways, but the technology can also aid in treatment. For diagnosis, researchers found that AI mental health solutions such as wearables can interpret bodily signals using sensors to offer help, instead of waiting for a user to interact. For instance, an individual that is experiencing an anxiety attack can use physiological changes to become aware of these changes to tailor AI-guided treatment for each individual. Utilizing sleeping patterns, physical activity, heart rate, and rhythm variability AI can be used to assess the user?s mood and cognitive state. AI-generated data can be joined with therapy session transcripts to improve treatment quality. Creating specialized AI-generated algorithms can improve treatment quality and efficacy. Additionally, chatbots can provide timely and personalized interventions [39].",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"One caveat of our findings is that due to AI being in the news so frequently, some of the peaks in search volume were attributed to news announcements. For instance, as of the writing of this article, US and China agreed to create an infrastructure to map out a framework for developing AI responsibly, creating an increased level of interest in the topic area [40]. Using the Levels of Emotional Awareness Scale (LEAS), Elyoseph et al. found that ChatGPT-3.5 demonstrated an exceptional ability to differentiate and elucidate emotions from textual cues, outperforming human sample norms [24]. This can lead to the AI-driven administration of cognitive behavioral therapy (CBT) according to the emotions detected in the patient.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"Mental health therapists have mixed opinions about the usage of AI in conducting therapy sessions. In 2024, the American Counseling Association (ACA) has an AI Working Group that they have convened in prioritizing client wellbeing. However, the ACA has warned that AI is not there to replace the therapist, due to the perception that this new technology can start replacing the role of the therapist. In a recent study, researchers found that in 20 scenarios, AI had increased emotional awareness compared to the general population?leading to the fear of replaced jobs [24]. For instance, in comparison to traditional mental health sessions, conversational agents can lead to improved control, choice, and interactivity over session content. While AI can be used for supplementally guide therapy sessions, practitioners cannot be solely relied for delivering therapy [33]. Current use of generative AI for conversational agents in mental health, as used in therapy sessions, has contradictory outcomes. Heston (2023) found that when used on simulated patients, generative AI-based conversational agents are slow to escalate mental health risk scenarios, postponing referral to a human to potentially dangerous levels [40].",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"There are many applications of AI in mental health that are very positive as well. However, other researchers have found a potential improvement by applying conversational agent AI, i.e., chatbots, to capture dynamic human behavior adequately to provide responses tailored to users? personalities [41]. Researchers in the field of human?machine interaction stressed the importance of avoiding ?one-size-fits-all? interactions. Vlkel et al. found approaches to adapt a voice assistant?s personality to the user, improving the interactive experience [42]. This adaptive automated user experience can prove to be a useful application of AI.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"There are several limitations of this study. First of all our study is based on Google Trends data and there is no way to assess how accurately these data represent the general population, potentially affecting the reliability and generalizability of the results. However, predictive models using this method have been applied by other researchers, reflecting the general population. We also did not assess the fears and concerns people have about AI. More specifically, as AI applications in mental health increase, so too does the likelihood of cybersecurity attacks of confidential mental health information. We did not research how people?s fear may be driving some of the research. However, even negative perceptions can equate to some of the trepidation that people feel about the novel technology. Currently, Amazon and Microsoft are in an AI war to create the most optimal platform. However, news and social media can erroneously deflect focusing on mental health and not just news. Patient information must remain ethically confidential, leading to further concerns within the mental health industry about the unbridled growth of generative AI. These areas require further research. To mitigate these risks, Habbal et al. demonstrated the effectiveness of an important framework.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"We did not study the impact of certain systematic approaches to understanding AI. Further innovative approaches should be explored in future studies. One such approach is to conduct AI risk management. Artificial Intelligence Trust [43], Risk and Security Management (AI TRiSM) is a systematic approach to manage risks of AI. Applying the discipline of mental health, future studies should explore the effectiveness of frameworks to mitigate such risks of releasing sensitive information. Furthermore, bias is another serious threat against creating optimal AI models. AI applications will not mitigate mental health disparities if they are built from historical data that reflect underlying social biases and inequities [44]. In mental health applications, AI-related hallucinations, due to biases in the data, inadequate training, or flawed algorithms, can also be a potential negative byproduct of overreliance on this technology.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"Another limitation is that we did not study the context of training data and how this raises major concerns in the spread of AI. Biases can be mitigated through increased use of LLM training data that are more diverse in mental health. According to Kuzlu et al., with the proliferation of Internet of Things (IoT) through wearable devices, AI is becoming more popular [45]. However, cyberattackers are beginning to exploit the weaknesses of AI, known as generative adversarial AI, to carry out cybersecurity attacks [46,47,48,49]. The types of attacks can be categorized as poisoning (AI training data being intentionally tampered), evasion, extraction, and inference?slowing down AI adoption in the area of mental health [50,51]. However, not all adversarial AI is harmful, as this can also be used to train and leverage neural networks in guiding mental health treatment and prevention. Finally, another limitation is that there was no indication whether some of the popularity was due to mistrust or interest, as the two are conflated in using Google Trends. The rapid growth in AI necessitates an improved understanding of how cyberattacks can influence the popular opinion and trepidation of the public about AI.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"There are multiple recommendations that can aid in integrating AI with mental health services. With initial integration of AI in the mental health field, there can be further enrichment of training data, making the application more accurate and less biased. This can help alleviate some of the burden that is experienced by general health practitioners. One application that researchers have used is synthesizing attack trees using LLMs to predict cyberattack scenarios, potentially jeopardizing medical privacy in mental health, thereby fostering mistrust. Most recently, the AI Digital Bill of Rights has been established to ensure safe and effective systems, data privacy, and algorithmic discrimination protections [52,53,54,55]. In the following section, we outline some of the important recommendations in applying AI in mental health.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,Increasing AI awareness among the general public will fuel the transition from traditional therapeutics to AI-assisted therapeutics in the area of mental health that practitioners can act on.,,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"Improve health literacy about the understanding of the mental health condition to know more about what they are experiencing in LLM, and elevating this.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"Increase dynamic interplay between humans and AI rather than replacing healthcare practitioners, leveraging the strengths of each.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"Differentiate between AI detection of physical and mental health problems that are similar, such as atrial fibrillation versus anxiety.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,Increase the use of AI gradually to address gaps created from the mental health profession shortage.,,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"Apply potential advancement and application of AI in mental health sectors, by using AI-based tools to empower patients.",,,,,
Mental Health Applications of Generative AI and Large Language Modeling in the United States,"With the growth of large language modeling, mental health practitioners and patients alike must be well informed about this powerful tool?s vast applications. Our study demonstrates the increasing awareness of mental health and AI among the general public, making advocacy and education about AI technology of paramount importance. Not only is this modality effective for diagnostic purposes, but there are also treatment applications that have mostly been untapped. Some treatment modalities include automated cognitive behavioral therapy and finding medication regimens that are most effective for the mental health condition within the individual. Future popularity trends in the discipline of mental health and topics like depression and anxiety are predicted to increase in popularity. As mental health diagnostic, treatment, and prevention approaches become more accurate, there is a need to apply novel technologies such as AI to increase the diagnostic precision and accuracy. With the rapid growth of AI in mental health, care must be taken to protect confidentiality from cyberattacks and potential bias that may arise from the application of AI. Most importantly, our study shows how AI is perceived by the general public, driving attitudes and uptake of this novel technology, by both mental health providers and patients.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"The use of machine learning (ML) in mental health (MH) research is increasing, especially as new, more complex data types become available to analyze. By examining the published literature, this review aims to explore the current applications of ML in MH research, with a particular focus on its use in studying diverse and vulnerable populations, including immigrants, refugees, migrants, and racial and ethnic minorities.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"From October 2022 to March 2024, Google Scholar, EMBASE, and PubMed were queried. ML-related, MH-related, and population-of-focus search terms were strung together with Boolean operators. Backward reference searching was also conducted. Included peer-reviewed studies reported using a method or application of ML in an MH context and focused on the populations of interest. We did not have date cutoffs. Publications were excluded if they were narrative or did not exclusively focus on a minority population from the respective country. Data including study context, the focus of mental healthcare, sample, data type, type of ML algorithm used, and algorithm performance were extracted from each.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Ultimately, 13 peer-reviewed publications were included. All the articles were published within the last 6 years, and over half of them studied populations within the US. Most reviewed studies used supervised learning to explain or predict MH outcomes. Some publications used up to 16 models to determine the best predictive power. Almost half of the included publications did not discuss their cross-validation method.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"The included studies provide proof-of-concept for the potential use of ML algorithms to address MH concerns in these special populations, few as they may be. Our review finds that the clinical application of these models for classifying and predicting MH disorders is still under development.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,The online version contains supplementary material available at 10.1186/s12911-024-02663-4.,,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Common Mental Disorders (CMDs), including major depressive disorder, mood disorder, anxiety disorder, and alcohol use disorder, affect approximately one in five people worldwide [1,ÿ2]. More specifically, the global prevalence of post-traumatic stress symptoms is 24.1%, anxiety is 26.9%, sleep problems are 27.6%, depression is 28.0%, stress is 36.5%, and psychological distress is 50.0% [3]. Post-COVID, the World Health Organization estimates that there has been further worsening of mental health status with a further 25% increase in depression and anxiety disorders [4].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Mental health (MH) disparities are significantly influenced by stigma, discrimination, and socioeconomic challenges [2,ÿ5]. These disparities are exacerbated for minority populations who often face limited access to MH services due to geographic, economic, and literacy barriers, leading to lower satisfaction with healthcare and higher dropout rates from MH services compared to Whites [6?10]. Black and Latinx individuals, for example, are at higher risk of persistence and disability from CMDs [11?13]. While Asian Americans are considered to have better MH status compared to Whites and other racial and ethnic minorities, this is poorly studied [14]. Immigrants often experience a temporary improvement in MH upon arrival, known as the ?immigration paradox?, but their MH deteriorates over time due to assimilation stresses, racism, discriminatory and exclusionary policies, status loss, and sometimes violence [5,ÿ15?18]. Refugees face significantly higher rates of severe psychiatric disorders, including post-traumatic stress disorder, due to adverse pre-migration conditions [16,ÿ19].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Ultimately, CMDs and other MH conditions may disproportionately affect ethnic and racial minorities overrepresented in homeless, incarcerated, and medically underserved populations [20], and thus there is a need to there is a need to understand and strengthen the MH resiliency of these populations. Clinicians and researchers have increasingly collected ?big data? to aid this mission. This includes structured and unstructured data from electronic health records (EHR), smartphones, wearables, social media, and other large, complex sources. While traditional epidemiological methods have proven highly effective in analyzing complex data in MH research, machine learning (ML) approaches can offer complementary tools that can potentially enhance the ability to identify subtle patterns and relationships, particularly in these large, multidimensional datasets. A combined approach may reveal additional insights into MH disparities across various populations, leveraging the strengths of both traditional and ML-based analytical techniques.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Machine learning encompasses a variety of algorithms and statistical models that enable programs to improve their performance on a task through experience. In the context of MH research, ML techniques can be broadly categorized into supervised learning, where models are trained on labeled data to predict outcomes, and unsupervised learning, which identifies patterns in unlabeled data [21?24]. The application of ML in health sciences, including mental health, has been growing. ML models have been developed to predict risk scores for various mental health conditions, potentially aiding in diagnosis and screening [25?27]. While several reviews have discussed ML applications in mental health research [28,ÿ29], there?s been limited focus on how these models address factors such as race, ethnicity, or immigration status. For example, Maslej et al. [30] conducted a rapid review using a Critical Race Theory perspective to examine how race and racialization are defined in ML applications for Major Depressive Disorder, but their study did not extend to other common mental disorders or broader mental health issues.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"This study encompasses a broad spectrum of mental health conditions, ranging from CMDs to less prevalent but equally critical conditions such as schizophrenia, bipolar disorder, and personality disorders. We also consider related issues like suicidality and juvenile delinquency, which, while not psychiatric disorders themselves, are often associated with mental health challenges. This comprehensive approach allows us to explore how machine learning (ML) can support various aspects of mental health care across diverse conditions and populations. By expanding our focus beyond CMDs, we acknowledge the unique challenges in diagnosis and management presented by different mental health conditions, particularly in vulnerable populations such as immigrants, refugees, and minorities. This broader scope ensures a more inclusive examination of how ML can be applied to improve mental health care across the full range of diagnostic categories and related issues.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Our search terms reflect this comprehensive approach, including both specific psychiatric diagnoses and related mental health conditions. This allows us to capture the full potential of ML applications in mental health, from common disorders to more complex and less frequent conditions, providing a thorough exploration of the field?s current state and future directions.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"This review asks: What is the breadth of existing literature on the application of ML techniques for addressing MH challenges in vulnerable populations of immigrants, refugees, migrants, and racial and ethnic minorities? This study also examines the feasibility of implementing ML solutions in MH, focusing on how ML integration affects the workload of healthcare professionals and analyzing improvements in patient care by ML. Our study aims to build upon existing research by examining ML applications across a wider range of mental health conditions, with a specific focus on how these models account for and perform across diverse populations, including racial, ethnic, and immigrant groups.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Two reviewers (KP and AA) independently conducted searches in Google Scholar, EMBASE, PsycINFO, and PubMed from October 2022 to March 2024. All queries had three components: an ML-related term (e.g., ?machine learning,? ?artificial intelligence?), an MH-related term (e.g., ?mental health,? depression, ?post-traumatic stress disorder?), and a population of a focus search term (e.g., immigrant, refugee, minority*). These terms were combined with the Boolean operators to create final search strings. Queries were conducted on titles, keywords, and abstracts. Backward reference searching was also conducted, reviewing references from the articles that matched our search criteria for more articles that could fit our inclusion criteria. See the Appendix for full query syntax.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Inclusion criteria included: (i) the article reported using a method or application of ML in an MH context; (ii) the primary population studied was immigrants, refugees, migrants, and/or racial and ethnic minorities; (iii) the article was published in a peer-reviewed publication; (iv) the article was available in English. We did not limit articles to just those published in America. Due to the rapid advancements in ML, we limited our search criteria to articles published after 2014. Articles were excluded if they were narrative (e.g., commenting on future applications of ML in MH or were not empirical) or if they did not exclusively focus on a minority population from the respective country (e.g., a study of ethnically Chinese migrants in China would be excluded). Conflicts over inclusion were discussed, and a consensus was sought before the inclusion or exclusion of the publication in question.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Data were extracted from each article, including study context, the focus on mental healthcare, sample, data type, type of ML algorithm used, and algorithm performance. A narrative synthesis approach was applied.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"To summarize the results of this review, we present them in three sections. The first section includes the results of the selection process. The second section details the characteristics of the selected studies, such as their area of focus, publication year and location, and data source. The third section highlights the machine learning models used in the studies for predicting and studying mental health outcomes.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Our search strategies resulted in a total of 22,082 listed articles from Google Scholar, EMBASE, PsycINFO, and PubMed. Figureÿ1ÿshows the flow of our search strategy and results. All records from PsycINFO and PubMed were reviewed, an additional 280 records were reviewed from Google Scholar, and the most relevant 100 were reviewed from EMBASE. Based on titles and abstracts, 79 were selected and further reviewed. Most of these records were excluded because they did not focus on the population of interest. Instead, they focused on majority populations and racially homogenous populations and/or did not include discussions about immigrant/migrant status. We also reviewed five abstracts from citation searching. Ultimately, 13 publications were included in this review.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"In our scoping review, we also identified several gaps that have significant implications for the field of MH research using ML. There is a lack of data availability, especially longitudinal data, which is important for developing predictive models. Most of the studies focus on well-represented groups, leaving the minority population underrepresented, which can lead to biased algorithms and unjust health outcomes. These gaps underscore the need for targeted efforts to broaden the scope of research in this dynamically evolving field.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Surveys [31?34], drawings [35], secondary data sets (including EHR data, surveillance data, and national sample sets) [35?39], internet-based posts [40,ÿ41], and genomic sequencing data [42,ÿ43] were analyzed in the included publications (see Tableÿ1). Various populations were considered, and sample sizes varied widely due to the type of data collected and analyzed. For example, Augsburger and Elbert [31] enrolled 56 resettled refugees in a study to prospectively analyze their risk-taking. Goldstein, Bailey [37] used a retrospective dataset with 22,968 unique Hispanic patients, and Acion et al. [36] included 99,013 Hispanic individuals in their secondary data analysis. Children were also included in the reviewed studies; one examined the depression and PTSD levels of 631 refugee children residing in Turkey [34]. Another study analyzed drawings from 2480 Syrian refugee children to find the predictors of exposure to violence and mental well-being [35]. Other sample sets analyzed 0.15ÿmillion unique tweets from Twitter [40] and 441,000 unique conversations from internet message boards and social media sites [41]. Genomic sequencing data was collected from 4,179 Black individuals [43] and 524 Black individuals [42].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Most reviewed studies used supervised learning intending to explain or predict certain MH outcomes. For example, to classify substance use disorder treatment success in Hispanic patients, Acion et al. compared 16 different ML models to an ensemble method they called ?Super Learning? [36]. Similarly, Huber et al. compared various ML algorithms, including decision trees, support vector machines, nave Bayes, logistic regression, and K-nearest neighbor, to determine the model with the best predictive power for classifying schizophrenia spectrum disorders in migrants [38]. Two studies explored the impact of trauma exposure on MH using ML [31,ÿ35]. Two studies utilized social media data to understand MH at a population-health level through ML algorithms [40,ÿ41]. All study aims are found in Tableÿ1.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Tableÿ2ÿpresents some high-level characteristics of the reviewed publications. All but two of the analyzed articles were published in the last three years, with the two earliest from 2017 [31,ÿ36]. More than half of the papers were from the US or incorporated populations based in the US, four were from Europe, and the rest were from Asia. Among the 13 articles, five focused on refugee populations [31,ÿ33?35,ÿ40], three focused on Hispanic populations in the US [36,ÿ37,ÿ41], two focused on Black individuals [42,ÿ43], one on Native Americans [39], and the last two articles focused on Korean immigrants in the US [32] and immigrant populations in Europe [38]. The areas of mental health focus included stress [40], ADHD [42,ÿ43], trauma [31,ÿ35], depression [33,ÿ41,ÿ43], PTSD [34], psychological distress [32], schizophrenia [38], suicidal ideation [37,ÿ39], and substance abuse [36].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Tableÿ3ÿoutlines a summary of ML characteristics and model performance. This review found that all 13 included publications fell into three categories: classification [32,ÿ36?40,ÿ42,ÿ43], regression [31,ÿ33?35], and unsupervised topic modeling [41].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"The publications used a range of ML models, from one [31?35,ÿ42,ÿ43] to 16 [36]. In studies where multiple ML models were used, the aim was often to compare the models to determine the best predictive power. For example, Acion et al. compared 16 models and evaluated them using the area under the receiver operating characteristic curve (AUC) to classify substance use disorder treatment success in Hispanic patients [36]. Huber et al. compared five different ML algorithms, including decision trees, support vector machines, nave Bayes, logistic regression, and K-nearest neighbor, to determine the model with the best predictive power for classifying schizophrenia spectrum disorders in migrants [38]. Two of the studies used linear regression [33,ÿ34]. All of the studies developed custom models to meet their study aims. The most common programs used in these studies were R [31,ÿ36], SPSS [32,ÿ34], and Python [40,ÿ42,ÿ43].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Predictors that were included in the modeling were sociodemographic characteristics [32,ÿ34,ÿ36?39], and some also included MH variables and experiences [31,ÿ32,ÿ34,ÿ36?39] collected from EHRs or surveys. One study first determined which of the included 653 input variables (including sociodemographic data, childhood/adolescence experiences, psychiatric history, past criminal history, social and sexual functioning, hospitalization details, prison data, and psychopathological symptoms) were the best predictor variables and trained a final ML algorithm using only those [38].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Two studies did not report the best algorithm performance [37,ÿ41]. For the other studies, accuracy and AUC were commonly reported. For example, Acion et al. classified substance use disorder treatment success in Hispanic patients and found that the AUC of studied models ranged from 0.793 to 0.820, with the ensemble method achieving an AUC of 0.820, which was not significantly better than the traditional logistic regression model?s AUC of 0.805 [36]. Huber et al. identified a tree algorithm that differentiated native Europeans and non-European migrants with schizophrenia with an accuracy of 74.5% and a predictive power of AUC?=?0.75 [38]. In Liu et al., the trained ML model had an accuracy of 78% in predicting ADHD in African American patients [42]. In a similar study to classify ADHD, depression, anxiety, autism, intellectual disabilities, speech/language disorder, developmental delays, and oppositional defiant disorder in African Americans, the model had an accuracy of 65% in distinguishing patients with at least one MH diagnosis from controls [43]. A second prediction model aimed at predicting the diagnosis of two or more MH disorders had a low accuracy level, with an exact match rate of 7.2?9.3% [43]. Khatua and Nejdl [40] analyzed tweets acquired from Twitter feeds from self-identified refugees and categorized them into themes of the immigrant struggle with an accuracy of 61.61% and 75.89%.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"The included studies also used p-values to assess their ML algorithms. Goldstein and Bailey utilized multivariable logistical regression to examine the relationship between experienced discrimination and suicidal ideation in Hispanic patients [37]. They found that 19.0% of Hispanic patients who experienced discrimination also experienced suicidal ideation, compared to 11.5% of patients who did not experience discrimination (p?=?0.001). Moreover, Hispanic patients had 1.72 greater odds of having suicidal thoughts if they experienced discrimination compared to those who did not (p?=?0.003). A study by Erol and Seinti used regression analysis to study the relationship between PTSD and depression and various predictors in adolescent refugee minors [34]. They found that moderate and severe changes in family income level and stress in food access predicted depression scores and PTSD symptoms (p?<?0.01). Drydakis [33] used random effects models to estimate the relationship between the number of mobile applications that facilitate immigrants? societal integration and immigrants? integration, health, and mental health [28]. The results showed a negative association between the number of standard m-Integration applications and adverse MH status (p?<?0.01). Accuracy was also measured using importance and normalized importance [32], Root-mean-square error (RMSE) [31], and Least Absolute Shrinkage and Selection Operator (LASSO) coefficients [35].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Six studies used internal cross-validation methods [31,ÿ35,ÿ36,ÿ38,ÿ39,ÿ43]. Only one study used an external data set to validate their ML algorithm [42]. That external validation of the algorithm reduced the accuracy of their algorithm from 78% to 70?75% [42]. Almost half of the included publications did not use or discuss their cross-validation method [32?34,ÿ37,ÿ41].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Our analysis reveals significant gaps in the use of machine learning to address mental health in vulnerable populations such as immigrants, refugees, migrants, and racial and ethnic minorities. Key issues include the underrepresentation of these groups in training datasets, leading to biased algorithms, and the lack of adapted models. Additionally, integration challenges within healthcare systems that serve these populations, combined, significantly hinder the effectiveness and ethical application of ML technologies. Addressing these gaps is crucial for ML to improve MH outcomes equitably.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"This exploratory scoping review explores the application of ML in MH research, focusing on vulnerable populations including immigrants, refugees, and ethnic minorities. Our findings reveal that ML is increasingly used to enhance MH diagnostics, screening, and interventions.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"In recent years, there has been significant interest in the potential of ML to transform the field of MH research [29]. Studies examining ML models in a variety of clinical settings indicate that ML may outperform traditional statistical models, especially as they relate to prognosis or predicting behavior [44?48].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"While ML algorithms can effectively handle large volumes of EHR data for risk prediction, it?s important to note that they still require significant manual input and optimization [47,ÿ49]. Unlike traditional statistical techniques that often involve manual selection and imputation of specific variables, ML models can potentially consider a broader range of data points [44,ÿ48]. However, these models typically require extensive tuning, which involves considerable manual labor and decision-making on the part of developers. Additionally, ML can sometimes capture more intricate, non-linear relationships without the need for explicit specification of interaction terms.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"It?s important to note that ML encompasses a broad range of techniques, including simple linear regression, which is also used in traditional statistical analysis. The advantage of more advanced ML models often lies in their ability to automatically detect and utilize complex interactions and non-linear relationships in high-dimensional data, potentially leading to improved predictive performance in certain scenarios, including the need for careful model selection, hyperparameter tuning, and validation to ensure reliable and generalizable results [50].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Recent advances in computational power and software availability have enabled researchers to reach new audiences and demonstrate the clinical value of ML. In particular, some studies have aimed to inform clinicians about the methods and applications of ML in the context of psychotherapy [51]. However, while many of the reviewed papers provide proof-of-concept for the potential use of ML algorithms to address MH concerns, our review finds that the clinical application of these models for classifying and predicting MH disorders is still under development.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Despite ML?s great interest and potential to transform MH research, few researchers have focused on specific and marginalized populations. In reviewing hundreds of articles on MH and ML, we found only a handful of studies specifically targeting immigrants, migrants, refugees, and/or racial and ethnic minorities. Many researchers simply included race as a variable in their models rather than designing ML algorithms to analyze these specific groups of individuals [52,ÿ53]. Moreover, as noted by Maslej et al. [30], most studies that considered African American and White samples used self-reported race or ethnicity or did not describe how this information was collected and thus were excluded from our analysis.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"There is still a wide gap in health disparities that persist in accessing quality MH services and outcomes. These gaps primarily concern the limited diversity of populations, the lack of research on complex MH outcomes, and the challenges associated with integrating ML tools in healthcare settings. The current lack of ML models tailored to specific populations presents opportunities and challenges. On the one hand, it can help prevent the perpetuation of health disparities that arise when models built on majority populations are used to misclassify minorities [54]. Performance differences in ML exist for different populations, especially with genomic data. For instance, one study externally validated their algorithm [42] on White Americans rather than African Americans and found that their algorithm?s accuracy decreased. On the other hand, this lack of tailored models highlights the opportunity for researchers and clinicians to bridge the gap between what is known about majority populations and what is yet to be uncovered in other populations. Training ML models on other groups could expedite this process without being too resource-intensive. By proposing future research directions aimed at closing these gaps, we highlight the need for more inclusive data collection, enhanced algorithm training that reflects diverse patient experiences, and comprehensive evaluations of ML tools in real-world clinical settings.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"One of the most common challenges in utilizing ML techniques to build classifiers for MH is the use of small sample sizes, which may limit the representation of the entire population and impact the generalizability of the classifier?s accuracy estimate. This can be a practical limitation due to resource constraints in real-world clinical or diagnostic settings. However, researchers need to understand that using ML alone cannot address this issue [26]. Most ML methods rely on supervised learning models, which are successful due to the abundance of training data. However, this training data requires human annotation, which can be time-consuming and costly. In the case of MH, there are insufficient publicly annotated datasets, making the quality of the data a significant concern for developing reliable models [53].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"Another challenge of using ML for behavioral diagnosis is validating the classification algorithms against questionnaires or clinical diagnoses, which are known to have self-report biases and are not completely accurate. This highlights the lack of established best standards in the diagnosis process for mental disorders and other psychiatric conditions [55]. Future directions include the development of more robust and generalizable algorithms that can improve prediction capabilities. ML can be leveraged to understand the prevalence of MH conditions at a population level by using open-source and freely available data, which can be more accurate and less labor-intensive than traditional surveys. Furthermore, ML can enable the study of MH in children and adolescents in innovative ways [35,ÿ43]. The application of these models can be expanded to different sources and sample sizes, potentially leading to a rapid increase in their use in clinical settings.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"The growing application of ML in mental health research presents several key implications. First, there?s a critical need for more focused research on vulnerable populations, including immigrants, refugees, and racial/ethnic minorities, to address potential biases and unique challenges [56]. Second, while promising, the clinical implementation of ML for MH diagnostics and prediction is still in its early stages, necessitating further validation and strategies to overcome integration barriers [28]. Lastly, the lack of appropriate cross-validation techniques in many studies highlights the urgent need for more rigorous methodological approaches to ensure the reliability and real-world applicability of ML models in mental health contexts [57]. Addressing these implications is crucial for realizing the full potential of ML in advancing mental health research and practice.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"ML exhibits varying degrees of effectiveness across MH conditions, largely influenced by the availability of data and the complexity of symptoms. However, results have been mixed. Nemesure et al. [58] used ML to predict depression and anxiety, achieving moderate success but below clinical standards for diagnostics. These findings show both the potential and current limitations of ML in mental health. While ML can process large datasets and potentially uncover subtle patterns, achieving clinically acceptable accuracy remains challenging. Further research is needed to improve ML models before they can be widely applied in mental health diagnosis and treatment planning. Conversely, in complex disorders such as schizophrenia and bipolar disorder, while ML can predict episodes, the variability in symptoms poses challenges for model accuracy [59]. Neurodegenerative diseases, such as Alzheimer?s, also benefit from ML in early detection, though the gradual progression of symptoms limits its immediate utility [60]. In substance use disorders, ML?s ability to track behavioral patterns offers the potential for predicting relapse [61]. Future research should thus focus on enhancing data collection and refining ML models to accommodate the specific needs of each condition while addressing ethical concerns. Also, there is a critical need for addressing algorithmic bias within healthcare to prevent disparities among racial and ethnic minority groups [49]. Chin et al. underline a framework for mitigating bias across an algorithm?s lifecycle, from problem formulation to deployment and monitoring, underscoring the importance of transparency, accountability, and community engagement in ML development [49].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"There is also potential for the future application of ML and natural language processing (NLP) approaches to infer psychological well-being and detect CMDs in marginalized individuals based on social media posts on platforms like Facebook and Twitter. Researchers must implement diagnostic criteria and tools that are precise and suitable for various online populations. Personal information, such as sociodemographic characteristics and behavioral aspects, must be collected by ethical considerations. These inferences can create online platforms that provide health information, support, and tailored interventions. Currently, the computational techniques and evaluations employed for collecting, processing, and utilizing online written data remain scattered throughout academic literature [62]. Moreover, this potential is limited by factors such as class imbalance, noisy labels, and text samples that are either too long or too short, which can lead to performance and stability issues. The diversity of writing styles and semantic heterogeneity in different data sources can also cause a lack of robustness in model performance. Standardizing these measures can allow for the development of scalable approaches for automated monitoring of public psychological health in the future [43].",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"This review had limitations, including the possibility of missing relevant studies due to specificity in search terms. Future studies should consider using broader search terms to address these limitations. Additionally, the ethical and social implications of using ML in MH, including the potential for perpetuating existing biases and social determinants of health, should be carefully considered. Discussing ethical concerns is important when utilizing textual data related to MH, given the significance of privacy and security of personal information, particularly health data.",,,,,
Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review,"In conclusion, ML can potentially transform how we understand mental health, particularly among vulnerable populations. Immigrants and refugees face unique challenges related to migration and resettlement that can negatively impact their MH status, including poverty, discrimination, and exposure to trauma. African Americans and Hispanics in the US also have higher persistence and disability from mental illness. This review has found that, to date, few studies have used ML to predict and classify MH in these populations, despite the wide gap in health disparities that persist in accessing quality MH services and outcomes. The use of big data and ML algorithms in the health sciences is increasing and holds promise, but more study of ML applications in MH is warranted.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"This study examined mental health disparities among African Americans using AI and machine learning for outcome prediction. Analyzing data from African American adults (18?85) in Southeastern Virginia (2016?2020), we found Mood Affective Disorders were most prevalent (41.66%), followed by Schizophrenia Spectrum and Other Psychotic Disorders. Females predominantly experienced mood disorders, with patient ages typically ranging from late thirties to mid-forties. Medicare coverage was notably high among schizophrenia patients, while emergency admissions and comorbidities significantly impacted total healthcare charges. Machine learning models, including gradient boosting, random forest, neural networks, logistic regression, and Naive Bayes, were validated through 100 repeated 5-fold cross-validations. Gradient boosting demonstrated superior predictive performance among all models. Nomograms were developed to visualize risk factors, with gender, age, comorbidities, and insurance type emerging as key predictors. The study revealed higher mental health disorder prevalence compared to national averages, suggesting a potentially greater mental health burden in this population. Despite the limitations of its retrospective design and regional focus, this research provides valuable insights into mental health disparities among African Americans in Southeastern Virginia, particularly regarding demographic and clinical risk factors.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Mental health disorders represent a significant public health concern, affecting approximately 19.86% of adults in the United States (U.S.) annually, which translates to nearly 50ÿmillion Americans. Of these, 4.91% experience severe mental illness1?3. While mental health disorders impact individuals across diverse racial, ethnic, and gender demographics, certain groups face disproportionate burdens in both prevalence and impact4?7.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"African Americans, comprising 13.6% of the U.S. population, experience unique challenges in mental health care. Socioeconomic factors exacerbate these disparities, with 20.1% of African Americans living in povertyÿ8ÿand 10.8% lacking health insurance9. While African Americans experience mental illness at rates similar to the general population, they face significant barriers to accessing quality mental health care. Only one in three African Americans in need receives mental health care, with lower rates of service use compared to non-Hispanic whites10. These disparities stem from various factors, including racial and ethnic biases11, stigma12, limited access to care due to financial and geographic constraints, historical trauma13, distrust of the healthcare system14, poorer quality of care, and lack of culturally competent services15ÿMoreover, African Americans are less likely to receive guideline-consistent care, are underrepresented in research, and are more likely to use emergency rooms or primary care for mental health needs16?19.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Diagnostic disparities further complicate the landscape, with African Americans more frequently diagnosed with schizophrenia and less frequently with mood disorders compared to whites presenting with similar symptoms20. Additionally, African Americans with mental health conditions, particularly schizophrenia, bipolar disorders, and other psychoses, face higher rates of incarceration than individuals of different races21,22. Factors such as gender, age, complications, comorbidities, insurance type, and admission source shape mental health outcomes within this group18,23?25. African Americans exhibit higher rates of mental health disorders due to psychosocial stressors such as marital problems, involvement with the justice system, abuse, and financial crises26?30. Challenges such as inadequate assessment tools and biases in clinical decision-making impede accurate reporting of mental health symptoms among African Americans29,31?35.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Despite the growing body of research on mental health disparities, there remains a significant gap in our understanding of the specific patterns, predictors, and outcomes of mental health disorders among African Americans in regionally defined areas. This study aims to address this gap by leveraging a comprehensive dataset from Southeastern Virginia, employing advanced analytical techniques to identify specific trends that can inform targeted interventions and policy decisions. The primary objective of this study was to employ artificial intelligence (AI) and machine learning (ML) methodologies to analyze patterns and predictors of mental health outcomes among underserved populations in the Southeastern Virginia region, with an emphasis on African American communities. Specifically, the study aimed to (a) Examine the impact of various factors (including gender, age, complications, comorbidities, insurance type, and admission source) on mental health outcomes in the Southeastern Virginia area and (b) Develop comprehensive prediction models for mental health outcomes using advanced machine learning techniques.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"By leveraging a large, comprehensive dataset from the VHI system, this study seeks to address critical gaps in the literature and provide valuable insights into the unique mental health challenges faced by African Americans. The findings aim to inform targeted interventions and health policies to reduce mental health disparities and improve outcomes for this underserved population, contributing to a more equitable and effective mental health care system.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"This study employs a quantitative, cross-sectional design using retrospective data from 2016 to 2020. The analysis incorporates traditional statistical methods and innovative machine-learning techniques to examine patterns and predictors of mental health outcomes for African Americans in Southeastern Virginia.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"The study was approved by the Eastern Virginia Medical School (EVMS) Institutional Review Board and Human Subjects? Protection (IRB #23-07-NH-0174), which determined that it did not involve human subjects research and was therefore exempt from IRB review. Due to the retrospective nature of the study, a waiver of informed consent was granted by the EVMS Institutional Review Board and Human Subjects? Protection, and all patient data were deidentified to maintain confidentiality. Data were received via secure transfer and stored on password-protected devices accessible only to authorized research team members. All research methods followed the guidelines and regulations set forth by the EVMS IRB and Human Subjects? Protection committee. The research team extracted demographic, administrative, clinical, and financial data from the VHI database, including data on comorbidities. To ensure data safety throughout the project, deidentified data were securely transferred via a secure File Transfer Protocol behind the EVMS firewall during the collection phase. After collection, data were stored on password-protected devices with access restricted to authorized team members, and regular backups were performed.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"This study used aggregated hospital discharge data from VHI, a comprehensive healthcare information repository. The dataset provided by the Virginia Department of Health focuses on mental health among underserved populations in Southeastern Virginia. VHI consolidates data from various sources, ensuring accuracy and objectivity. It includes medical and pharmacy claims for around five million Virginia residents covered by commercial, Medicaid, and Medicare plans. The database covers patient demographics, care locations, provider details, diagnoses, and service costs. VHI integrates data from both commercial and public insurance carriers, representing most of Virginia?s insured population, and collaborates with the Department of Medical Assistance Services and nine commercial carriers to ensure data quality and compliance36.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"The target population includes African American adults aged 18 to 85 years residing in the Southeastern Virginia region who sought mental healthcare services between 2016 and 2020. The extracted data comprised demographic information, comorbidities, clinical characteristics, and hospital details. Each discharge record contained one primary diagnosis code, often accompanied by multiple additional codes reflecting the patient?s mental health status. Diagnoses in the VHI system are based on ICD-10 codes assigned by healthcare providers during patient encounters. To ensure diagnostic accuracy and consistency, the study utilized the ICD-10 Classification of Mental and Behavioural Disorders: Clinical Descriptions and Diagnostic Guidelines37ÿas the reference for diagnostic criteria. This standardized classification system ensures consistency in coding across the dataset and aligns with international diagnostic standards. Tableÿ1ÿsummarizes the ICD-10 codes used in this study, categorized by significant mental health disorders:",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"This comprehensive categorization of mental health disorders using standardized ICD-10 codes enables a detailed and reliable analysis of mental health patterns and trends within the study population. By adhering to these international diagnostic standards, the study ensures comparability with other research and enhances the validity of its findings.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"All statistical analyses were conducted in collaboration with Research and Infrastructure Service Enterprise at EVMS. Data analysis was conducted using a combination of R, Python, and SAS to capitalize on the unique strengths of each software. R (tidyverse package) was employed for data cleaning and initial exploratory analyses, enabling efficient data preprocessing and visualization. Python (pandas, numpy, scipy.stats, scikit-learn and statsmodels libraries) was utilized for implementing and evaluating various machine learning models, leveraging its extensive libraries and frameworks for predictive modeling. SAS was used to conduct complex statistical procedures.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Data cleaning involves checking for and addressing missing or inconsistent data. Standardized procedures were applied to handle missing data, including imputation methods where appropriate. The study employed a diverse range of statistical methods encompassing both traditional statistical analysis and machine learning to extract meaningful insights from the patient dataset. Descriptive statistics were conducted for several parameters to identify relevant factors for the research question. Demographic factors such as sex and age, clinical factors including complications or comorbidities, and administrative aspects like admission status and length of stay (LOS) were explored. Frequencies were run for all categorical parameters, while means, standard deviations, and medians were calculated for all numeric parameters. Chi-square testing was conducted for the analysis of categorical variables. Given the nonparametric nature of the data, Kruskal-Wallis and Wilcoxon tests were implemented when analyzing numeric data. These tests evaluated differences in demographic, clinical, and administrative factors across mental and behavioral diseases and disorders (MBDD) groups (e.g., mood affective disorders (MAD), schizophrenia, schizotypal and delusional disorders (SSDD), mental and behavioral disorders due to psychoactive substance use (MBD), and neurotic, stress-related and somatoform disorders (NSRS)). Significant levels were defined as follows: ***: p-value?<?0.0001; **: 0.0001?ó?p-value?<?0.01; *: 0.01?ó?p-value?<?0.05.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"To develop robust mental health outcome prediction models for MBDD, machine learning techniques were implemented using Python?s scikit-learn library38. The ML models included gradient boosting (GB), random forest (RF), artificial neural network (ANN), logistic regression (LR), and Naive Bayes (NB). The selection of ML models was based on their diverse strengths and suitability for the study?s objectives. GB and RF, as ensemble methods, can effectively handle complex interactions and nonlinearities in the data. ANN is powerful in capturing intricate patterns and dependencies. LR, as a probabilistic classifier, provides interpretable results and is widely used in healthcare settings. NB, despite its simplicity, can serve as a robust baseline. This combination of models allows for a comprehensive evaluation of predictive performance and insights into the underlying data structure.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,Hyperparameter tuning was performed using grid search with 5-fold cross-validation. The optimal hyperparameters for each model were:,,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"The performance of these models was assessed using a comprehensive set of evaluation metrics, including area under the curve (AUC), correct classification (CA), F-measure or F-score (F1), Precision (Prec), and Recall: Sensitivity or the true positive rate (Recall). Models were validated through a rigorous approach consisting of 100 repeated 5-fold cross-validations to ensure reliability and accuracy in distinguishing between classes and predicting outcomes.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Predictive nomograms were developed using the Logistic Regression classifier to integrate demographic, clinical, and administrative predictors for MAD, MBD, and SSDD. These nomograms provided a visual representation of the risk factors and their respective contributions to the probability of each disorder. The top ten predictors for each disorder were identified, and their respective weights were calculated to aid in clinical decision-making. The nomograms serve as quantitative tools, enabling clinicians to assess the probability of specific mental disorders based on a comprehensive profile of individual risk factors.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Tableÿ2ÿprovides a breakdown of the prevalence of various MBDD among discharged patients within the Southeastern Virginia area. The total number of readmissions recorded was 22,254. MAD was the most common, constituting approximately 41.66% of the cases, followed closely by SSDD, which represented about 39.57%. MBD accounted for 14.30% of the readmissions, while NSRS comprised 4.46% of the total.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Tableÿ3ÿdetails the demographic, administrative, clinical, and comorbidity characteristics of patients diagnosed with various MBDDs. Females predominantly constitute the patient population for MAD and NSRS, with percentages of 54.54% and 56.50%, respectively. In contrast, SSDD and MBD are less prevalent among females.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"The mean age of patients across disorders hovers around the late thirties to mid-forties. Emergency admissions are the most common across all MBDD, particularly pronounced in the MBD group at 71.28%. When examining insurance types, a significant proportion of SSDD patients are covered by Medicare (34.21%), whereas a higher percentage of MBD patients utilize Medicaid (26.08%). Regarding comorbidity profiles, SSDD patients tend to have fewer comorbidities, with 28.24% having none, while MBD patients show a higher prevalence of multiple comorbidities. Specifically, 10.37% of MBD patients present five or more comorbidities. This table also reveals significant data on the (LOS), with SSDD patients experiencing the most extended stays, averaging 8.54 days. The geographical distribution indicates that Norfolk and Virginia Beach are prominent locations for these patients, suggesting regional variations in the prevalence or treatment availability of mental health conditions.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Tableÿ4ÿpresents a comparative analysis of demographic, clinical, and administrative characteristics across MBDD groups. The analysis highlights statistically significant gender differences, with SSDD showing the most considerable disparity (24.1%,ÿp?<?0.0001) between males and females. Age differences also show significant variances; however, statistically significant differences are noted in MAD (2.9?ñ?0.2,ÿp?<?0.0001) and MBD (4.4?ñ?1,ÿp?<?0.0001). Medicare coverage significantly differs across groups, with notable differences in SSDD (31.6%,ÿp?<?0.0001) and MBD (57.3%,ÿp?<?0.0001), indicating distinct patterns in insurance utilization. The comparison of patients with and without primary procedures reveals significant findings in all groups, particularly MAD (57.5%,ÿp?<?0.0001), SSDD (60.6%,ÿp?<?0.0001), and MBD (7.1%,ÿp?<?0.0001). Complication rates are consistently high across all groups but do not reach statistical significance, suggesting a general trend of high complication rates irrespective of specific disorders. Emergency admission types show significant differences, especially in MBD (42.6%,ÿp?<?0.0001), emphasizing the urgency in admissions for this group. LOS analysis further emphasizes gender differences, particularly in SSDD, where males exhibit a significantly longer LOS compared to females (2.1?ñ?2,ÿp?<?0.0001). This indicates a more complex clinical pathway for males in this group. Post-operative LOS also reflects significant gender differences in NSRS (0.9?ñ?2,ÿp?<?0.05) and SSDD (2.1?ñ?2,ÿp?<?0.0001), suggesting differential recovery times based on gender (tableÿ3).",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Tableÿ5ÿexamines the impact of various factors on total charge differences for patients with MBDD who underwent procedures. In the gender category, a notable increase in charges is observed for SSDD in male patients compared to female patients (5.8%,ÿp?<?0.0001). Medicare recipients generally see higher charges, with significant increases noted in the MAD (7.5%,ÿp?<?0.0001) and SSDD (16.8%,ÿp?<?0.0001) groups. Complication presence corresponds to an increase in total charges, with a substantial effect seen in MBD and SSDD, although it did not reach statistical significance. Different admission types also show significant differences in charges, with emergency admissions generally resulting in higher costs compared to urgent and elective, especially in NSRS (43.0%,ÿp?<?0.0001) and MBD (33.8%,ÿp?<?0.0001). The number of comorbidities correlates with charge differences, where more comorbidities typically lead to higher charges, notably in MBD, with a 25.5% increase when moving from 4 to 5?+?comorbidities (p?<?0.0001) (tableÿ5).",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Tableÿ6ÿexplores total charge differences for patients without procedures across MBDD. Gender differences are particularly stark in NSRS, with females incurring 33.4% higher charges than males (p?<?0.05). For Medicare, all groups show significantly higher recipient charges, especially in SSDD (48.2%,ÿp?<?0.0001). The absence of complications, particularly in NSRS, dramatically lowers charges, highlighting the cost impact of managing complications in mental health care. Differences in admission types are less pronounced here than in tableÿ4ÿbut still significant, with emergency versus elective admissions showing enormous disparities, particularly in MBD (30.0%,ÿp?<?0.0001). As in tableÿ4, an increase in comorbidities consistently correlates with higher charges, especially in NSRS moving from 4 to 5?+?comorbidities with a 77.3% increase (p?<?0.01).",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Tableÿ7ÿpresents the performance metrics for various AI and ML models that predict outcomes for MAD, MBD, and SSDD. The models evaluated include GB, LR, ANN, and RF. These models were rigorously validated using 100 repeated 5-fold cross-validations, and their performance was assessed based on area under the curve (AUC), correct classification (CA), F1 score, Precision (Prec), and recall.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"For MBD, the Gradient Boosting model demonstrated the highest performance with an AUC of 0.955 and a CA of 0.929, along with robust F1 (0.747), precision (0.79), and recall (0.709) scores, indicating its superior predictive capability. LR and ANN also showed strong performance with AUCs of 0.937 and 0.936, respectively, and similar CA and precision metrics. In the MAD category, the GB model again led in performance with an AUC of 0.832 and a balanced F1 score of 0.719, reflecting its reliability in prediction. However, the overall performance metrics for MAD were lower compared to MBD, suggesting potential complexity in modeling MAD outcomes. For SSDD, the GB model achieved the highest AUC at 0.832 and an F1 score of 0.709, highlighting its effectiveness. The LR and ANN models also performed well but exhibited slightly lower metrics across all evaluation criteria. Overall, Gradient Boosting consistently outperformed other models across all disorder categories, particularly excelling in MBD predictions (Tableÿ7).",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"The study developed predictive nomograms for three of the most prevalent MBDDs: MAD, MBD, and SSDD, each depicted in Figs.ÿ1ÿandÿ2, andÿ3, respectively. These nomograms were developed using Logistic Regression classifiers to integrate demographic, clinical, and administrative predictors, estimating the probability of each disorder.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"For MAD (Fig.ÿ1), the most robust predictors include alcohol and drug use, with significant regional differences, notably residents from Poquoson City contributing the highest points. For MBD (Fig.ÿ2), psychological factors and age played pivotal roles, with older individuals showing a higher likelihood of MBD, and clinical factors such as complications and liver function underscored the interplay between physical and mental health.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"The SSDD nomogram (Fig.ÿ3) identified psychiatric symptoms and drug use as the top predictors, along with impactful demographic factors like insurance type and county of residence. Specific insurance types like Medicare and regions like Suffolk City were associated with higher probabilities of SSDD.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Our study provides significant insights into the patterns and predictors of mental health outcomes among underserved African American adults in Southeastern Virginia, contributing to the broader field of mental health disparities research. The findings align with and expand upon existing literature, offering a comprehensive understanding of the complex interplay between demographic, clinical, and socioeconomic factors in shaping mental health outcomes in this population.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Our results indicate that MAD is the most prevalent (41.66%), followed by SSDD) and MBD. This prevalence pattern is consistent with national data39?42, though our higher rates suggest a potentially more significant mental health burden in our study population. This finding underscores the critical need for targeted interventions in this region.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Key predictors of mental health outcomes identified in our study include gender, age, comorbidities, and insurance type. Females predominantly constituted the patient population for MAD and NSRS, aligning with previous research showing higher rates of mood and anxiety disorders among women43?47. The mean age of patients across disorders was in the late thirties to mid-forties, with a trend of decreasing mental disorders with age, consistent with findings by48ÿandÿ49. The significant proportion of SSDD patients covered by Medicare highlights the role of insurance type in mental health outcomes, echoing findings of50?52.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Our study revealed significant differences in total charges based on demographic and clinical factors, particularly for patients with comorbidities and emergency admissions. This finding emphasizes the economic impact of these variables on mental and behavioral disorder care costs, aligning with research by53,54, and55. These insights can guide healthcare policy and clinical practice in optimizing care delivery and managing healthcare costs for underserved populations.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"ML algorithms have revolutionized mental health diagnostics, offering diverse methodological approaches with varying degrees of effectiveness56?60. These computational tools enable personalized prediction of mental health outcomes, facilitating targeted interventions across diverse populations.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Our study?s principal contribution lies in applying sophisticated ML techniques to an extensive regional dataset. The implementation of GB, RF, and LR models, complemented by predictive nomograms, provides a robust empirical framework for understanding mental health trajectories.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"In the broader literature, Support Vector Machines (SVM) and Random Forests have emerged as leading classification methods61, while Convolutional Neural Networks (CNNs) have achieved superior accuracy in bipolar disorder diagnosis62?64. Gradient Boosting algorithms have demonstrated enhanced predictive capabilities through their iterative error-learning mechanisms65,66.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"The field faces persistent methodological challenges, particularly concerning data quality and diagnostic heterogeneity, resulting in variable model performance across research groups62. Model performance varies significantly based on the specific mental health condition, data modality (clinical documentation, patient-reported outcomes, neuroimaging), and algorithmic selection62,65,67?69. Despite these constraints, ML approaches consistently demonstrate improved diagnostic and predictive accuracy compared to conventional methodologies, particularly in analyzing complex, large-scale datasets.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"While our study focused on African Americans in Southeastern Virginia, the findings have broader implications. The higher prevalence of mental health disorders in our study population compared to national averages highlights potential disparities that may exist in other underserved communities. This emphasizes the importance of region-specific research and tailored interventions to address mental health disparities effectively.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Our study lays the groundwork for future research in several key areas. First, validating these findings in broader populations could provide insights into the generalizability of our results. Second, exploring the effectiveness of interventions tailored to the specific needs of underserved communities, as identified by our predictive models, could lead to more effective mental health care strategies. Finally, further investigation into the economic implications of mental health disparities could inform policy decisions and resource allocation.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"In conclusion, our study contributes novel insights to mental health disparities research through its comprehensive analysis of mental health patterns, application of advanced machine learning techniques, and focus on an underserved population. These findings have the potential to inform targeted interventions and personalized care strategies, representing a significant step forward in addressing mental health disparities among African Americans in Southeastern Virginia and potentially in other underserved communities.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,Our findings have several important implications for mental health policy and practice in Southeastern Virginia:,,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"1. Targeted screening and intervention programs should be developed, particularly for Mood Affective Disorders and Schizophrenia, Schizotypal, and Delusional Disorders, which were found to be most prevalent.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"2. Healthcare providers should be trained to recognize and address the unique mental health needs of African American patients, considering the gender and age-related patterns identified in our study.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"3. Efforts should be made to improve insurance coverage and access to mental health services, given the significant impact of insurance type on mental health outcomes and healthcare utilization.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"4. Community-based mental health programs should be strengthened, particularly in areas identified as having higher risk factors.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"5. Future mental health initiatives should adopt data-driven approaches, utilizing predictive models to identify at-risk individuals and tailor interventions accordingly.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Our in-depth examination of 28 comorbid illnesses offers a nuanced view of the complex healthcare needs within this population. This comprehensive approach provides a more holistic understanding of the interplay between mental health and other medical conditions, informing more integrated care strategies. The application of machine learning models, including GB, RF, and LR, represents a methodological advancement in mental health research. These techniques allowed us to identify subtle patterns and predictors that might be overlooked by traditional statistical methods, offering new perspectives on risk factors and potential intervention points.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"By exploring gender and age differences in mental health prevalence and readmission rates, our study highlights subgroups that may require tailored interventions. This granular analysis contributes to a more personalized approach to mental health care and policy development. Our findings have substantial implications for health policy, particularly in addressing healthcare disparities and improving mental health outcomes. The study provides evidence-based recommendations for targeted interventions, potentially influencing policy decisions to enhance healthcare access and equity for African Americans.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"The development of predictive nomograms represents a significant contribution to clinical practice. These tools can assist healthcare providers in identifying high-risk individuals and tailoring interventions, potentially improving patient outcomes and resource allocation. By focusing on Southeastern Virginia, our study provides locally relevant insights that can inform targeted interventions and policy decisions specific to this region while also offering a model for similar region-specific analyses elsewhere.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"While we acknowledge the limitations inherent in our cross-sectional design, the strengths of our study significantly outweigh these constraints. The comprehensive nature of our dataset, coupled with advanced analytical techniques and a focus on an underserved population, positions our research as a valuable contribution to the field of mental health disparities. Our findings not only enhance the current understanding of mental health challenges among African Americans but also pave the way for future longitudinal studies that can build upon this foundation to examine causal relationships and long-term trends.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Our study, while providing valuable insights into mental health disparities among African Americans in Southeastern Virginia, is subject to several limitations that warrant consideration when interpreting the results.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Firstly, The implementation of machine learning algorithms in mental health diagnostics presents distinct methodological challenges and limitations across different model architectures70. GB, while adept at handling complex interactions, requires meticulous tuning of critical hyperparameters, including learning rate, tree depth, and boosting iterations, to mitigate overfitting risks and optimize the bias-variance trade-off71. RF exhibits robustness against overfitting but demonstrates sensitivity to hyperparameters such as tree count and feature split threshold, potentially compromising computational efficiency and model interpretability in high-dimensional datasets72. ANNs present unique challenges in hyperparameter optimization, particularly in architecting optimal layer structures and selecting appropriate activation functions. Their performance significantly depends on training data quality and requires careful tuning of layer composition, neuron count, learning rate, and regularization parameters73. LR, while offering superior interpretability, faces limitations with non-linear relationships and necessitates precise feature selection and regularization parameter optimization to address multicollinearity concerns74,75. Naive Bayes classifiers, despite their computational efficiency, are constrained by their fundamental assumption of feature independence, which rarely holds in clinical settings. While requiring less intensive hyperparameter tuning, these models demand careful consideration of prior selection and zero-frequency handling76.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"These algorithmic limitations are particularly pronounced in mental health applications due to the inherent complexity and heterogeneity of psychiatric data, emphasizing the necessity for robust cross-validation and systematic hyperparameter optimization protocols.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Secondly, our reliance on retrospective, pre-existing hospital discharge data introduces potential biases related to data collection and documentation practices. This approach may lead to misclassification or underreporting of conditions, as we were unable to control the data collection process. Consequently, specific nuances and contextual factors that could influence mental health outcomes may have been overlooked. The retrospective nature of the data also limits our ability to establish causal relationships between the identified factors and mental health outcomes.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Thirdly, while our use of ICD-10 codes for diagnosis enhances the validity and reliability of our findings by providing a standardized framework, it may not capture the full complexity of mental health conditions. Diagnostic accuracy can be influenced by factors such as clinician expertise, cultural competence, and the specific manifestation of symptoms in different populations. Future studies could benefit from incorporating structured diagnostic interviews or additional clinical assessments to further validate these ICD-10-based diagnoses.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Fourthly, the geographic specificity of our dataset to Southeastern Virginia, while providing valuable local insights, limits the generalizability of our findings to other U.S. regions. Mental health disparities and their underlying factors may vary across different geographic and cultural contexts, necessitating caution when extrapolating our results to other populations.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Lastly, our approach to handling missing data by excluding instances with less than 0.001% missing values, while pragmatic, may have overlooked subtle patterns or biases. This could potentially affect the accuracy and completeness of our analysis, mainly if the missing data were not randomly distributed across the dataset.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Despite these limitations, our study makes significant contributions to the understanding of mental health disparities among African Americans. The large, comprehensive dataset and advanced analytical techniques employed provide robust insights into patterns and predictors of mental health outcomes in this underserved population. These findings have important implications for health policy and clinical practice, informing targeted interventions aimed at improving mental health equity and outcomes for African Americans. Furthermore, our study lays a foundation for future research, highlighting areas where more in-depth, longitudinal studies could further elucidate the complex factors influencing mental health disparities.",,,,,
Predicting mental health disparities using machine learning for African Americans in Southeastern Virginia,"Our study provides significant insights into the patterns and predictors of mental health outcomes among African American adults in Southeastern Virginia, leveraging an extensive and comprehensive dataset from the VHI system. Through robust statistical analyses and advanced predictive modeling, we have uncovered critical findings contributing to understanding mental health disparities in this underserved population. The high prevalence of MAD and SSDD within our study population aligns with global mental health patterns, underscoring the urgent need for targeted interventions. Our research has identified key demographic and clinical predictors, including gender, age, comorbidities, and insurance type, which significantly influence mental health outcomes. These findings reaffirm the importance of these factors in addressing mental health disparities and provide a foundation for developing more effective, personalized interventions. A significant strength of our study lies in the application of advanced machine learning techniques, particularly Gradient Boosting, which demonstrated high accuracy and reliability in predicting mental health outcomes. This approach not only enhances the precision of our findings but also showcases the potential of these analytical techniques to revolutionize mental health research and clinical practice. The development of predictive nomograms further translates our research into practical tools for clinicians, enabling more accurate assessment of individual risk profiles for specific mental disorders. Our study?s focus on an underrepresented population, coupled with the use of a comprehensive dataset and detailed comorbidity analysis, provides a nuanced understanding of mental health disparities among African Americans. These insights have significant implications for health policy and the development of targeted interventions. While we acknowledge limitations such as the retrospective design, regional specificity, and potential biases in handling missing data, the value of our contributions to the field of mental health research remains substantial. In conclusion, this study offers a detailed examination of mental health outcomes among African Americans in Southeastern Virginia, identifying key predictors and demonstrating the power of machine learning in predictive modeling for mental health. Our findings support the development of targeted health policies and interventions to reduce mental health disparities and improve outcomes for underserved populations. Moving forward, we recommend validating these findings in broader and more diverse populations to enhance the generalizability and impact of our conclusions. This research not only advances our understanding of mental health disparities but also paves the way for more equitable and effective mental health care strategies for African American communities and potentially other underserved populations.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Camouflaging, the strategies that some autistic people use to hide their differences, has been hypothesized to trigger mental health ramifications. Camouflaging might reflect ubiquitous impression management experiences that are not unique to autistic people and similarly impact the mental health of non-autistic people.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","We first examined whether individuals in the general population camouflage and manage impressions while experiencing mental health repercussions, and how gender and neurodivergent traits modified these associations. We then assessed how camouflaging and impression management arose from internalized stigma, and their inter-relationships in shaping mental health outcomes.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Data were collected from 972 adults from a representative U.S. general population sample, with measures pertaining to camouflaging, impression management, mental health, internalized stigma, and neurodivergent traits. Multivariate hierarchical regression and moderated mediation analyses were used to address the two research aims.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Both camouflaging and self-presentation (a key component of impression management) were associated with mental health presentations in the general population, which overlapped with those previously reported in autistic people. These associations were more pronounced in women compared with men and were of different directions for individuals with higher autistic traits versus higher ADHD traits. Internalized stigma might be a key stressor that could elicit camouflaging and impression management through social anxiety, which in turn might lead to adverse mental health outcomes.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population",These findings advance the conceptual clarity and clinical relevance of camouflaging and impression management across social and neurodiverse groups in the general population. The ramifications of camouflaging and impression management underscore the need to alleviate internalized stigma for better mental health across human groups.,,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Camouflaging involves concealing or adapting neurodivergent (e.g. autistic) characteristics in social situations, such as imitating body language, memorizing social scripts, and maintaining eye contact (Cook et al., 2021;ÿLibsack et al., 2021;ÿZhuang et al., 2023). Social sanctions and prejudice that pervade neurotypical social spaces thwart opportunities for positive social contact and employment in autistic people (Cage & Troxell-Whitman, 2019;ÿHull et al., 2017;ÿMandy, 2019). Hence, some hide their neurodivergence (i.e. deviations in neurocognitive profiles from the general population ?normal?) for safety, belonging, and control over the impressions they form in others (Zhuang et al., 2023). Nevertheless, the mental health repercussions can be substantial. Growing research and lived experiences from autistic people suggest that camouflaging can trigger depression, anxiety, diminished self-esteem, felt inauthenticity, and burnout (Cook et al., 2021;ÿField et al., 2024).",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Many aspects of camouflaging, including its mental health ramifications, are likely not solely present in autistic people (Ai et al., 2024;ÿHull et al., 2019;ÿLivingston et al., 2020;ÿvan der Putten et al., 2024). Camouflaging motivations and strategies in a large U.S. general population sample parallel those reported in autism-enriched samples (Ai et al., 2024), suggesting that camouflaging extends to alterations of behaviors and other social identity aspects that people generally enact in face of belonging needs or stigma (Chapman et al., 2022). Camouflaging outcomes also show continuity across populations. Both autistic and non-autistic individuals who engage in camouflaging experience depression, anxiety, and stress (Cassidy et al., 2020;ÿHull et al., 2019;ÿLorenz & Hull, 2024;ÿMiller et al., 2021;ÿSomerville et al., 2023). These findings echo the impression management (IM) literature, whereby emotional suppression, false self-presentation, and concealment of stigmatized traits are linked to elevated depression, anxiety, stress, and identity difficulties (Jeung et al., 2018;ÿMun & Kim, 2021;ÿPachankis et al., 2020;ÿSedlovskaya et al., 2013). It is thus critical to investigate camouflaging, as a kind of IM, in the general population to expand our understanding of the socio-contextual underpinnings in how camouflaging arises and affects mental health.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","We have proposed the transactional IM framework (Ai et al., 2022) to guide theory-driven research on camouflaging across autistic and general populations (Fombonne, 2020;ÿLai et al., 2021;ÿWilliams, 2021). This framework conceptualizes camouflaging as a component of IM experiences (e.g. self-presentation, self-concealment, self-monitoring) that pervade human social lives (Goffman, 1959;ÿLeary & Kowalski, 1990). This framework also predicts overlapping mental health outcomes of IM across human groups, with unique interactions between social-contextual influences and individual differences (e.g. neurodivergent traits) that determine how IM manifests and affects mental health. Leveraging this framework can address a critical knowledge gap: Are the mental health impacts of camouflaging and their social-contextual underpinnings in the general population parallel to, or different from, recent findings in autism-enriched samples (Field et al., 2024;ÿZhuang et al., 2023)?",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Sociodemographic and neurodivergent trait differences may moderate the psychological impacts of camouflaging/IM. For instance, autistic girls and women tend to experience greater social pressure from gendered expectations to socialize (Kreiser & White, 2014) than autistic boys and men and are thus more compelled to mask their autistic features (Cola et al., 2020;ÿHull et al., 2019;ÿLai et al., 2017,ÿ2023). This might result in more distress, struggle in everyday functioning, and even suicidal ideation, although current findings are mixed (Beck et al., 2020;ÿBernardin, Lewis, et al., 2021;ÿHull et al., 2021). In the general population, however, men reported greater camouflaging than women (Ai et al., 2024). This opposite finding to that of autistic populations might be attributable in part to differences in the purposes and expressions of camouflaging. Existing IM research suggests that self-presentation strategies are more voluntarily employed by men for instrumental gains, and are more agentic, active, and varied in men compared to women (Bolino et al., 2016;ÿGuadagno & Cialdini, 2007). The burdens of camouflaging/IM in gender-diverse or non-binary autistic and non-autistic individuals are just gaining traction (McQuaid et al., 2022).",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Camouflaging/IM could be more pervasive and taxing for autistic than non-autistic people given their neurodevelopmental differences in a world saturated by neurotypical social expectations (Ai et al., 2022;ÿBolis et al., 2017;ÿMilton, 2012). Non-autistic people with elevated autistic traits might also camouflage to mitigate comparable social difficulties as autistic people and face similar mental health impacts (Miller et al., 2021;ÿO?Loghlen & Lang, 2023;ÿSomerville et al., 2023). Emerging findings show that camouflaging in people with attention-deficit/hyperactivity disorder (ADHD) shares similar motivation, strategies, and outcomes with autistic camouflaging, but unique features may emerge from interactions with ADHD traits (Ginapp et al., 2023;ÿLai et al., 2022;ÿMerkt et al., 2015).",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","The transactional IM framework suggests stigma to be a key mechanistic factor linking camouflaging/IM, its social drivers, and mental health outcomes. Stigmatization refers to the discrediting of social-identity attributes that evoke alienation, discrimination, and victimization (Goffman, 1963). When people internalize the stigma, it can lead to shame and self-criticism, cascading to lower quality of life and elevated mental health problems (Drapalski et al., 2013;ÿLivingston & Boyd, 2010). Stigma management in marginalized groups exhausts psychological resources and evokes distress (Frost, 2011). In autistic individuals, internalized stigma is linked to poorer mental health (Botha & Frost, 2020;ÿHan et al., 2021;ÿden Houting et al., 2021), yet mitigating the stigma, a key driver of autistic camouflaging (Cage & Troxell-Whitman, 2019;ÿPearson & Rose, 2021;ÿPerry et al., 2022), is also associated with psychological repercussions, possibly elevating mental health risks in autistic compared with non-autistic people (Lai, 2023).",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Altogether, both social stigma and its mitigation through camouflaging/IM can be psychologically adverse (Field et al., 2024;ÿHan et al., 2021;ÿZhuang et al., 2023). Yet, there are insufficient empirical findings chaining these relationships. One avenue is to examine the indirect effect of stigma on mental health through camouflaging/IM. This indirect pathway was previously investigated in autistic adults and camouflaging did not mediate the relationship between autism-related stigma and mental health (Perry et al., 2022). However, this study used a broad measure of mental well-being (Tennant et al., 2007) without assessing specific mental health domains. Further, this study measured perceived but not internalized stigma, which could compel more pervasive camouflaging/IM and severe mental health repercussions (Botha et al., 2022;ÿHan et al., 2021;ÿHuang et al., 2023). Empirical investigations are needed to determine if this mediating role of camouflaging/IM exists and if it shows continuity across neurodiverse and social groups.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Another key mechanism theoretically linking camouflaging, stigma, and mental health is social anxiety. Camouflaging is associated with increased social anxiety in autistic and non-autistic people (Hull et al., 2021;ÿLorenz & Hull, 2024), but it is unclear if this effect is unidirectional (Chapman et al., 2022). Social anxiety can arise from hostile environments and perpetuate more camouflaging as individuals strive to maintain their social performance (Bargiela et al., 2016;ÿChapman et al., 2022). The transactional IM framework predicts a feedback loop (Ai et al., 2022), whereby heightened social anxiety, initially resulting from camouflaging/IM, sustains camouflaging/IM and exacerbates further psychological distress (Chapman et al., 2022). Hence, it is important to examine social anxiety as a mediator between internalized stigma and camouflaging/IM, and not just as an outcome of camouflaging/IM.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Here, we assessed the theoretical mental health ramifications of camouflaging in the general population, and how these relations were mediated and moderated by key mechanistic factors (Figure 1), as informed by the transactional IM framework (Ai et al., 2022). First, we investigated whether the mental health outcomes of camouflaging and self-presentation overlap in the general population and assessed the moderating roles of gender, autistic, and ADHD traits. Second, to assess theoretical mechanistic relationships, we evaluated whether social anxiety mediates the link between internalized stigma and camouflaging/IM, and whether camouflaging/IM mediates the links between internalized stigma and mental health outcomes. The findings would confer novel, clarifying insights into how camouflaging arises from social pressures and shapes mental well-being across human groups.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","The participants consist of 1,051 adults aged 18?years or older capable of self-reporting and consent. The sample size was the largest we could opt for given study feasibility. It satisfies sample size standards for participant-to-predictor ratio in hierarchical multivariate regression (Tabachnick & Fidell, 2001) and for moderated mediation analysis (Preacher et al., 2007), which are employed in this study. Recruitment occurred over 26?days via Prolific, an online crowdsourcing platform that allows its users to voluntarily participate in web-based studies for monetary compensation.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Participants were compensated at USD $9.50?per hour and were recruited using a U.S. general population representative sampling method, which leveraged U.S. census data (U.S. Census Bureau, 2015) for demographic stratification across age, ethnicity, and sex. Five participants were excluded due to age misreporting (exceeding 400?years) or failed attention checks, and 74 participants with incomplete item-level data were also excluded. The final dataset comprised complete item-level data from 972 participants (Table 1). The psychometric properties of the Camouflaging Autistic Traits Questionnaire (CAT-Q;ÿHull et al., 2019) in the general population have been examined using the current sample (Ai et al., 2024). The study was approved by the Research Ethics Board at the Centre for Addiction and Mental Health, Canada (REB #079/2021).",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Participants completed an online survey hosted on Qualtrics. This survey comprised self-reported measures of demographics information, camouflaging, self-presentation, neurodivergent traits, internalized stigma, and mental health. These scales demonstrate psychometric strengths and are theoretically relevant to the transactional IM framework (Ai et al., 2022). The Cronbach?s alphas for all measures in this sample were all above 0.70, indicating acceptable to excellent internal consistency. For psychometric details seeÿSupplemental Table SM.1.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","The CAT-Q (Hull et al., 2019) measured camouflaging. The Self-Presentation Tactics (SPT) scale (Lee et al., 1999) measured specific self-presentation strategies as a generic IM construct. The Subthreshold Autism Trait Questionnaire (SATQ;ÿKanne et al., 2012) measured dimensional autistic traits, and the Adult ADHD Self-Report Scale Part A (ASRS-A;ÿKessler et al., 2007) measured dimensional ADHD traits. Social anxiety symptoms were measured using the social fear subscale of the Liebowitz Social Anxiety Scale (LSAS;ÿLiebowitz, 1987). Internalized stigma was measured using the Shortened Internalized Stigma of Mental Illness Inventory 10-Item Version (ISMI-10;ÿBoyd et al., 2014); here, the ISMI-10 was adapted for the general population, whereby participants reported the most salient minority group that they belong to (e.g. concerning gender, ethnicity, sexual orientation, religion, atypical hobbies or interests, physical or mental disabilities), and based their reports of internalized stigma-related experiences on this minority identity.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Measurements for the theoretical mental health ramifications of camouflaging/IM included: the Generalized Anxiety Disorder scale (GAD-7;ÿSpitzer et al., 2006) for generalized anxiety symptoms, the Patient Health Questionnaire (PHQ-9;ÿKroenke et al., 2001) for depressive symptoms, the Short Warwick-Edinburgh Mental Wellbeing Scale (SWEMWS;ÿStewart-Brown et al., 2009) for mental wellbeing, the Self-Regulatory Fatigue Scale Short Form (SRF-S;ÿNes et al., 2013) for ego depletion and cognitive exhaustion, and the Kernis-Goldman Authenticity Inventory Short Form (KGAI;ÿBond et al., 2018) for subjective authenticity.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","All analyses were performed with R version 4.2.1(R Core Team, 2018). Two sequential analyses were performed to address the two study aims.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","We used hierarchical multivariate regression to evaluate the mental health correlates of camouflaging and self-presentation, and examined the moderating effects of gender, autistic, and ADHD traits. The multivariate regression method was chosen due to significant correlations among the mental health variables (Supplemental Figure 1). All continuous variables were first standardized toÿz-scores, and no variable showed notable skewness. Assumption of linearity was confirmed via visual inspection of the correlation scatterplots of all variables, and there was no evidence of multicollinearity as the Variance Inflation Factor (VIF) values of all continuous predictors were less than 3. Normality of residuals was confirmed via visual inspection of the density and Q-Q plots. The Goldfeld-Quandt test suggested no heteroscedasticity in the data.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","We performed a three-step hierarchical multivariate regression. At step 1, demographic variables (i.e. age, ethnicity, gender) and neurodivergent traits (i.e. autistic and ADHD traits) were entered as covariates in the nested model predicting anxiety, depression, mental wellbeing, self-regulatory fatigue, and subjective authenticity. At step 2, CAT-Q was additionally entered to assess whether camouflaging tendencies predicted mental health outcomes over and beyond gender and neurodivergent trait differences. At step 3, interaction terms were added to assess whether camouflaging interacted with gender, autistic traits, and ADHD traits, respectively, to influence mental health outcomes. These models were compared via an analysis of variance model comparisons test (Supplemental Table SM.3). After the most optimal model was determined, multiple comparisons were corrected for using the Benjamini-Hochberg procedure (False Discovery Rate, FDR 0.05) to theÿp-values of all predictors included (Benjamini & Hochberg, 1995). Finally, to illustrate whether the mental health outcomes related to camouflaging are comparable to those of self-presentation, the same hierarchical multivariate regression procedures were repeated by replacing CAT-Q with SPT in the modeling process.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","We used mediation modeling to assess the theoretical mechanistic relationships among internalized stigma, social anxiety, camouflaging/IM, and mental health. Given the high internal consistency observed across CAT-Q and SPT items at à?=?0.968 (95% CI [0.965, 0.971]), the standardized total scores from these two scales were averaged as a composite score to parsimoniously represent IM. The two total scores were averaged to ensure that the composite IM variable is equally weighted between the two scales of different item numbers. We used Hayes? PROCESS Model-4 (Hayes, 2013) to estimate the mediation effect of social anxiety between internalized stigma and IM, and then the mediation effects of IM between internalized stigma and mental health outcomes.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","We then used Hayes? PROCESS Model-7 (Hayes, 2013) to assess whether the estimated simple mediation effects are moderated by gender, autistic, and ADHD traits. Gender was dummy-coded, and men was used as the reference group while women and gender-diverse were interchanged as either the moderator or covariate to assess gender-moderation effects. An index of moderated mediation was calculated for each level of the moderators and bootstrapped for 5000 iterations to obtain bootstrapped confidence intervals (bootCI) of coefficients.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","For camouflaging, the analysis of variance model comparisons test deemed the step 3 model as most optimal (Figure 2a,ÿTable 2,ÿSupplemental Table SM.3). Increased camouflaging significantly predicted better mental wellbeing and reduced subjective authenticity. Women who engaged in greater camouflaging reported greater anxiety, reduced mental wellbeing, and greater self-regulatory fatigue than men who engaged in greater camouflaging. With increased levels of autistic traits, increased camouflaging predicted greater generalized anxiety, greater depression, reduced mental wellbeing, and greater self-regulatory fatigue. With increased levels of ADHD traits, increased camouflaging predicted increased mental wellbeing, reduced self-regulatory fatigue, and increased subjective authenticity.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","For self-presentation (Figure 2b,ÿSupplemental Table SM.2), the step 3 model with the interaction terms was also found to be optimal (Supplemental Table SM.3). Increased self-presentation tactics use significantly predicted better mental wellbeing and reduced subjective authenticity. Women who engaged in increased self-presentation reported lower mental wellbeing and greater self-regulatory fatigue than men who engaged in increased self-presentation. Increased self-presentation predicted greater generalized anxiety with increased levels of autistic traits. With increased levels of ADHD traits, increased self-presentation predicted better mental wellbeing and lower self-regulatory fatigue.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","For simple mediation (Figure 3a), social anxiety partially mediated the link between internalized stigma and increased IM. Further, IM partially mediated the links between internalized stigma and increased generalized anxiety, increased depression, increased self-regulatory fatigue, and reduced authenticity.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","For moderated mediation, we found a significant index of moderated mediation (?0.025, 95% bootCI [?0.444, ?0.008]), such that the mediation path from internalized stigma to IM through social anxiety was moderated by autistic trait levels (Figure 3b). Specifically, the mediation effect of social anxiety was significant across all autistic trait levels, but the effect was strongest for lower (-1SD) autistic traits and weakest for higher (+1SD) autistic traits. The mediation path from internalized stigma to IM through social anxiety was consistent across genders and levels of ADHD traits. Lastly, the mediation effects of IM on the associations between internalized stigma and mental health were consistent across genders and levels of autistic and ADHD traits.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","The mental health ramifications of camouflaging and self-presentation in the general population revealed nuanced differences by gender and neurodivergent characteristics (Figure 2). Women, more so than men, who reported greater camouflaging exhibited greater anxiety, lower mental wellbeing, and greater self-regulatory fatigue. Individuals with elevated autistic traits and increased camouflaging reported greater anxiety and depression symptoms, reduced mental wellbeing, and increased self-regulatory fatigue, whereas those with elevated ADHD traits with increased camouflaging particularly reported moreÿpositiveÿoutcomes, including increased mental wellbeing, reduced self-regulatory fatigue, and greater subjective authenticity. When the same analyses were repeated with self-presentation, we found the same directionality of results, also significantly moderated by gender and neurodivergent traits. In sum, increased camouflaging and self-presentation both correlated with poorer mental health more so for women than men and for those with higher than lower autistic traits; yet both were associated with better mental health outcomes in those with higher than lower ADHD traits.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","We then assessed the theoretical mechanistic relationships among internalized stigma, social anxiety, IM, and mental health (Figure 3). Social anxiety partially mediated the link between internalized stigma and IM, an effect uniquely moderated by autistic traits. Compared to individuals with lower autistic traits, those with higher autistic traits were less driven by social anxiety to cope with internalized stigma through IM. Importantly, IM partially mediated the links between internalized stigma and all mental health outcomes, except mental wellbeing, across genders and levels of autistic and ADHD traits.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","The mental health ramifications of camouflaging in autistic individuals have received substantial attention lately (Field et al., 2024;ÿZhuang et al., 2023). However, minimal understanding exists on the extent of these impacts across social-identity and neurodiverse groups. We showed that the mental health correlates of camouflaging and self-presentation in the general population largely overlap (Figure 3) and echoes previous studies and qualitative reports of autism-enriched samples (Zhuang et al., 2023). This continuity provides inferential evidence that camouflaging and self-presentation converge as IM experiences associated with poorer mental health across diverse human groups. Self-presentation was descriptively associated with fewer mental health outcomes when considering gender and neurodivergent-trait moderators (Figure 2). One explanation is that within the same IM umbrella phenomena, camouflaging might capture a specific class of IM that requires a greater extent of behavioral modification (e.g. changing how one behaves overall across social contexts rather than enacting one-off strategies), is more pervasive, and is more socially compelled than voluntary, thus leading to more varied and severe mental health repercussions (Ai et al., 2022).",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Importantly, the camouflaging-mental health links in the general population are dependent on additional factors. Women, on average, reported poorer mental health from camouflaging/IM than men. In many modern societies, women face strong social pressure to conform to gender stereotypes of communality, emotional sensitivity, and submissiveness (Guadagno & Cialdini, 2007;ÿLee et al., 1999). These stereotypically feminine traits are expected of women yet less valued in social situations (e.g. the workplace) pertaining to career progress and self-achievement, whereas stereotypically masculine traits of assertiveness and competitiveness are seen as more desirable (Heilman, 2012;ÿHentschel et al., 2019). This incongruence between expected and valued traits entails that women?s camouflaging/IM are less agentic, more vigilant, and more taxing compared with that of men, and thus might more rapidly deplete self-regulatory resources, increase anxiety, and erode mental wellbeing.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Aligned with predictions of the transactional IM framework, camouflaging/IM is more psychologically adverse for individuals with higher autistic traits. The mechanisms could involve the compounded social stigma and unique cognitive processing demands associated with autistic traits in neurotypical-majority social contexts. Interestingly, we observed the opposite pattern with ADHD traits. Camouflaging and self-presentation in the context of ADHD traits might not involve the extensive re-learning of social skills or forced modifications across levels of behavior and cognition as those in the context of autistic traits; they might instead concern the prompt optimization of fit with particular contexts, and hence serve as efficient social coping strategies that benefit mental wellbeing. These novel contrasting findings highlight the heterogeneity among neurodivergent groups, and, potentially, neurodevelopmental diagnoses. Research is needed to unpack camouflaging/IM efforts and outcomes in relation to ADHD and ADHD features, how they relate to autistic camouflaging findings, and the underlying reasons for the parallels or divergences (Canela et al., 2017;ÿGinapp et al., 2023).",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","The mediation analyses reaffirm that internalized stigma related to each person?s self-reported minoritized identity likely drives IM. Although previous studies regarded social anxiety as an outcome of camouflaging/IM (Hull et al., 2021;ÿLorenz & Hull, 2024;ÿOshima et al., 2024), we showed that social anxiety could also be an explanatory mechanism. In essence, the social anxiety stemming from internalized stigma motivates individuals to engage in camouflaging/IM, and this, in turn, might further increase social anxiety?a reciprocal pathway that needs further empirical validation (Ai et al., 2022). Another new discovery is that this indirect pathway is moderated by autistic traits. The social anxiety in response to internalized stigma seemed to be a more salient IM driver for individuals with lower rather than higher autistic traits. Whereas camouflaging/IM is largely concerned with facilitating positive social perceptions in dominant social groups, it may instead be more of a survival mechanism for marginalized groups, including those diagnosed with autism or who have evident autistic traits, to manage threats of pathologization, harm, and trauma (Ai et al., 2022;ÿBernardin, Mason, et al., 2021;ÿPearson & Rose, 2021). Increased social difficulties and stigma associated with higher autistic traits might have sufficiently compelled IM to a great degree. Another possibility is that high autistic traits are associated with different social needs and processing that elicit unique attunement of social uncertainties (e.g. expectations, protocols). Social anxiety in autistic people is linked with poorer social skills and reduced social motivation (Spain et al., 2018), which might hinder camouflaging/IM frequency and success. Research is needed to understand the variations in which autistic cognitive features and social anxiety interact with camouflaging/IM in context-dependent ways.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Internalized stigma correlated with negative mental health, with IM partially accounting for these associations. The mediation effects of IM were not influenced by gender nor neurodivergent traits. This reaffirms, across social and neurodiverse groups, the ubiquitous function of camouflaging/IM to manage internalized stigma and its associations with poorer mental health. This account is consistent with the minority stress model highlighting stigma as a primary stressor in marginalized groups (including neurodivergent people) that elevates mental health risks (Botha & Frost, 2020;ÿMeyer, 2010), as well as with findings on how IM across social groups and contexts leads to increased anxiety, depression, identity disturbance, and exhaustion (Mun & Kim, 2021;ÿPachankis et al., 2020;ÿSedlovskaya et al., 2013). The overlaps between the current general population findings and the prior IM literature support the conceptualization of camouflaging as part of IM. These new insights, nestled within the interactions among the social environment, IM, and mental health, underscore the need to address mental health ramifications of IM at their common root: alleviating internalized stigma.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Several limitations warrant consideration. First, the cross-sectional data do not permit the validation of definitive causal relations among tested variables. While findings align with predictions from the transactional IM framework (Ai et al., 2022), we are cautious not to overstate the mechanistic relationships. Critically, our data cannot fully elucidate the feedback loop between camouflaging/IM and social anxiety. This kind of reciprocal relation could also apply to other drivers and outcomes of camouflaging/IM that await future research. Longitudinal designs provide a more definitive understanding of the causal relations and their trajectories. These designs could integrate qualitative approaches across developmental stages, particularly during childhood and adolescence, to offer insights into how camouflaging/IM and mental health co-evolve in increasingly complex social environments.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","We did not sufficiently assess positive outcomes of camouflaging/IM. Camouflaging/IM has been reported as a means of securing social benefits, employment, and quality of life by both autistic and neurotypical individuals (Field et al., 2024;ÿLeary & Kowalski, 1990;ÿLivingston et al., 2019;ÿZhuang et al., 2023). Our study might have overlooked these co-existing positive outcomes. Lastly, we only measured self-reported camouflaging/IM engagement and intention but not its effectiveness in daily life. Camouflaging intent, efforts, and effectiveness could differentially predict mental health (Field et al., 2024). Measures that quantify the effectiveness or capacity for camouflaging/IM, such as the self-monitoring scale (Lennox & Wolfe, 1984) or the discrepancy operationalization (Lai et al., 2017), could offer complementary information.",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Future research disambiguating aversive IM strategies from comparatively beneficial ones is necessary. This distinction, with proper consideration of social contextual factors, could support marginalized individuals in leveraging camouflaging/IM to maximize wellbeing while minimizing mental health costs. It also offers clinical implications. For example, social skills interventions for autistic young people might inadvertently instill camouflaging strategies that come with undesired mental health burdens. Therefore, clinicians could consider approaches that are environment-focused, shifting from modifying behavioral presentations to alleviating the internalized stigma and the social anxiety experienced by autistic people. It is necessary to address stigma as a root social determinant of mental health across social and neurodiverse groups, through means such as modifying the social space (e.g. promoting public education, positive social contact, and inter-community connectedness), ultimately enhancing self-acceptance and wellbeing of neurodivergent and other marginalized people (Alegr¡a et al., 2023).",,,,,
"Camouflaging, internalized stigma, and mental health in the general population","Camouflaging/IM is associated with adverse mental health outcomes in the general population that parallel those observed previously in autistic people, providing empirical support for the transactional IM framework (Ai et al., 2022). The impacts of camouflaging/IM on mental health are nuanced; women experience more significant repercussions from camouflaging/IM compared to men, and autistic and ADHD traits differentially moderate the associations between camouflaging/IM and mental health. Camouflaging/IM is likely driven by internalized stigma through social anxiety, yet this form of stigma management likely still leads to poorer mental health. Future research should clarify these individual differences and mechanistic relations using longitudinal and developmental approaches.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"The special collection on Maternal Health Considerations offers a comprehensive exploration of critical issues surrounding maternal well-being across diverse contexts and disciplines. Recognising that maternal health extends beyond the physiological realm, this collection delves into the multifaceted dimensions of maternal well-being, including physical, mental, and socio-ecological factors. The collection comprises a series of interdisciplinary studies that investigate various facets of maternal health, from conception to postpartum stages. It addresses the complex interplay between biological, psychological, and socio-cultural determinants that influence maternal health outcomes. By adopting a holistic approach, the contributors shed light on the interconnectedness of maternal well-being. Key themes explored within this collection include the impact of prenatal care on maternal and neonatal health outcomes, as well as the role of mental health in shaping maternal experiences. In addition, the collection presents innovative recommendations to enhancing maternal well-being, such as community-based interventions, technological advancements, and future policy considerations. Furthermore, the special collection emphasises the significance of culturally sensitive care in promoting maternal health. It highlights the need for tailored interventions that respect the diversity of maternal experiences across different ethnic, racial, and socioeconomic groups. Contributors to this collection employ a range of methodologies, including qualitative and quantitative research case studies, which provide an intricate overview of the current state of maternal health research. The collection also offers valuable insights for policymakers, healthcare practitioners, researchers, and advocates working towards improving maternal health outcomes worldwide. It serves as a vital resource for contributing to our understanding of the complexities surrounding maternal well-being. It offers a platform for critical dialogue and collaborative efforts aimed at promoting holistic maternal health.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"In the wake of the global pandemic, uncertainty has prompted reflections on our priorities. The surge of ?lockdown? babies1,2ÿunderscores the closeness forged during challenging times, juxtaposed against the deliberative decisions to defer or postpone family planning. In light of these circumstances, an intensified focus on maternal health research is certainly warranted. The landscape is evolving rapidly, marked by unprecedented strides in fertility treatments, a growing trend of women choosing to delay pregnancy, and an increasing awareness of holistic health considerations.3ÿ?5ÿIt is imperative that we propel maternal health to the forefront of our collective consciousness, transcending disciplinary boundaries and permeating diverse sectors such as exercise physiology, obstetrics/gynaecology, psychology, nutrition/dietetics, telehealth, and public health interventions.6ÿ?8",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"While existing research has made commendable strides in monitoring foetal health,9ÿ?11ÿa significant gap persists in our understanding of maternal health, particularly throughout the various phases of family planning, conception, and birth.12ÿ?14ÿIn essence, a pressing need exists for researchers and practitioners, from both academia and industry, to unravel the nuances of maternal health and offer pragmatic, translatable recommendations for the future.15ÿ?17ÿThis special collection aspires to be a catalyst for fostering the latest innovative developments in maternal health across the globe, encompassing studies that navigate the complexities of pregnancy and the postpartum period. This initiative strives to elevate the discourse surrounding maternal health, fostering a collaborative environment that transcends boundaries and empowers both research and practice in this domain.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"Postpartum depression is a recognised public health challenge, and in particular for mothers living with human immunodeficiency virus (HIV). As Yeboa et al.ÿ18ÿexplain, the diagnosis impacts upon their engagement in care, HIV disease progression, and elevates the risk of mother-to-child transmission of HIV. A cross-sectional quantitative research design was utilised to evaluate nearly 300 participants in Uganda. Yeboa et al.ÿ18ÿnoted that postpartum depression had a prevalence of 15.9% in their examined cohort. After adjusting for other variables, participants also reported inadequate male partner support which was significantly more likely to indicate the woman experienced postpartum depression compared to those with sufficient support. The findings underscore the importance of routinely assessing mothers living with HIV for depression and the crucial role of male partner support. Healthcare providers for HIV-infected women should devise strategies to promote such support, contributing to enhanced maternal, infant, and HIV treatment outcomes.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"Against the backdrop of the joyous postpartum period, postpartum depression emerges as a significant concern. This mood disorder, characterised by a spectrum of symptoms, poses additional challenges for those concurrently managing HIV. Based on reports from Yeboa et al.,ÿ18ÿthe global prevalence of postpartum depression in the general population of women is estimated at 13%, but the figure rises to 19.8% in developing countries. Varying prevalence rates are reported for women living with HIV in different nations, with this study addressing the knowledge gap specifically in Uganda. The research delves into the prevalence and associated factors of postpartum depression, shedding light on a critical aspect of maternal health in the context of HIV.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"Another article about child feeding practices and malnutrition in rural Malaysia was explored by Chee Din et al.ÿ19ÿin a case-control methodology in a cohort of just over 100 participants. The researchers investigated the association between child feeding practices, maternal depression, and malnutrition among young children in a rural Malaysian community. Structured questionnaires were administered to Malay mothers of malnourished children and mothers of well-nourished children. The findings revealed that depressed mothers ceased exclusive breastfeeding earlier than non-depressed mothers. Binary logistic regression analysis indicated that maternal depression significantly increased the risk of child malnutrition, with each additional child in the family further elevating this risk. The study underscores the importance of early screening for maternal depression, potentially during the first trimester, to mitigate the risk of child malnutrition by addressing associated feeding practices and maternal mental health.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"In a separate study explored by Fleay et al.,ÿ20ÿbreast cancer has a particularly notable occurrence during pregnancy or the postpartum period. This pregnancy-associated breast cancer is on the rise, paralleling the increasing trend of women delaying their first pregnancies. Those undergoing treatment for pregnancy-associated breast cancer face the dual challenge of contending with both the rigours of cancer and its treatment and the unique circumstances of pregnancy or the postpartum period. Often, individuals in this scenario confront symptoms commonly associated with cancer diagnosis and treatment, such as nausea, pain, and fatigue, all while navigating the complexities of pregnancy or early motherhood. Despite exercise being linked to a myriad of benefits for both pregnancy health and breast cancer outcomes, these experiences can pose significant barriers to engaging in physical activity. Fleay et al.ÿ20ÿtherefore evaluated the existing body of literature concerning recommendations and outcomes related to engaging in exercise for individuals grappling with pregnancy-associated breast cancer. While many studies recognise advantages of exercise utility, a consensus regarding appropriate exercise programmes for this specific population remains elusive.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"Aligned with the breast cancer theme was another Australian protocol looking at a comprehensive randomised controlled trial investigating nurse-led Tai Chi aimed at improving a range of mental health and well-being outcomes along with physical functioning in women with breast cancer by Wang et al.ÿ21ÿThis protocol outlines an interventional trial aiming to assess the therapeutic effects of a Tai Chi programme on breast cancer management. The study will involve 40 participants diagnosed with breast cancer, randomised into either a Tai Chi programme or a waiting list control group. The Tai Chi programme will consist of 12 weeks of group sessions held twice a week, focusing on improving mental well-being, physical function, and quality of life. Primary outcomes include potential enhancements in quality of life, while secondary outcomes encompass improvements in mental well-being and physical function, assessed through self-administered online assessments and physical examinations. If successful, this research could highlight Tai Chi as a safe and effective exercise for empowering breast cancer patients in self-management and improving their overall well-being, with findings disseminated through various channels to inform both patients and healthcare professionals. Of note, pregnancy and/or history of pregnancy are not explicitly inclusive or exclusive criteria which would lend itself well to considerations around breast cancer and maternal health more generally.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"A systematic review and meta-analysis by Maleki et al.ÿ22ÿenabled the international team of researchers to examine studies from the last decade which were focused on key features of maternal stress and even nursing strategies for mother empowerment. While targeting neonatal intensive care, the clear take-home messages included the call to action for nursing strategies targeting emotional as well as practical support. The aim of this systematic review and meta-analysis was to compile and analyse global knowledge on nursing strategies for supporting mothers of preterm infants in the neonatal intensive care unit (NICU), focusing on emotional and practical assistance. Twenty studies published from 2010 to 2021 were included and categorised into three main themes: nursing strategies related to mothers? emotions and attachment with their infants, strategies for maternal empowerment, and strategies facilitating mothers? participation in caregiving and support processes. Among the interventions analysed, including educational programmes, spiritual care, and skin-to-skin contact, significantly lower maternal stress was observed in the intervention groups compared to controls. Key nursing strategies identified for supporting mothers of preterm infants encompassed family-centred care, parent education and support programmes, interpersonal psychotherapy, and telenursing, underscoring the importance of holistic support approaches in NICU settings.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"Of timely concern was the work produced by Ross et al.ÿ23ÿin which the psychological impact of COVID-19 testing was evaluated in a Canadian context. Incredible disruption was made throughout the healthcare system to respond to the coronavirus outbreak and subsequent variants of concern internationally. These anecdotal and documented public health measures included routine testing to enable access to hospitals and the admission of birth partners and supports were heavily scrutinised at one of the most vulnerable times in a woman?s life. Ross et al.ÿ23ÿfurther describe the concern of infecting others and how that stress and strain were also among healthcare workers in obstetrics as well. While it was an important step in maintaining health, it may have amplified an already stressful time in the lives of those involved. Obstetric patients expressed concerns about transmitting COVID-19 to their newborns and partners but reported relief and support from the testing programme. They also believed the testing initiative helped reduce anxiety and contributed to research benefitting others. Healthcare workers experienced increased job stress during the pandemic, with the testing programme causing minor additional stress, particularly among nurses. However, the majority of healthcare workers viewed the testing initiative positively and valuable for research purposes. Overall, the study suggests that universal SARS-CoV-2 testing can be beneficial in estimating COVID-19 prevalence without significantly increasing stress levels among patients and healthcare workers.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"Aligned with the impact on healthcare workers, Wissemann et al.ÿ24ÿfocused on midwives and the importance of the availability and impact of mentoring programmes for staff retention and quality of care. This review aimed to analyse the effectiveness of mentoring programmes for midwives with over a year of clinical experience, given the challenges like job dissatisfaction and limited support contributing to midwifery attrition globally. Conducted through a five-step integrative review process, the study identified eight relevant articles. Four main themes emerged, highlighting the impact of mentoring on midwives? work environment, relationships with peers and management, and the overarching organisational support. The findings suggest that organisational backing is crucial for effective mentoring programmes to enhance midwifery staff retention. Understanding midwives? perspectives on mentoring can guide the development of tailored mentoring programmes, potentially addressing workforce retention issues in midwifery practice.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"Cardiometabolic markers and placenta status were the feature from the Spanish research team investigating foetal sex in a sample of over 100 women.ÿ25ÿThis cross-sectional study aimed to investigate variances in maternal-neonatal metabolic markers and placental status based on foetal sex among Caucasian pregnant women and their newborns. Analysis of serum cardiometabolic markers revealed that mothers carrying male foetuses exhibited higher triglyceride levels during late pregnancy, while male newborns had greater levels of total and low-density lipoprotein cholesterol compared to females. Furthermore, mothers of male infants and male newborns had higher uric acid levels at birth. Placentas from female infants showed higher placental-newborn weight ratios, manganese content, and fibroblast growth factor-2, with slightly longer telomeres. Despite these subtle differences, the study suggests the potential for a more personalised approach to prenatal care based on foetal sex, considering the observed variations in cardiometabolic markers and placental status.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"Another addition to this special collection was from Wallace et al.ÿ26ÿin which antenatal and parenting education in an online mode of delivery was scrutinised from an Australian sample. This study aimed to explore the experiences and perceptions of new parents engaging in online antenatal education classes, given the evolving landscape of prenatal education. Conducted with 294 participants from various online antenatal and early parenting education programmes in Australia, the study employed a mixed-methods approach. Through qualitative analysis of responses, three main themes emerged: control and content of videos, accessibility, and support throughout the programme. Participants expressed a desire for trustworthy and accurate information delivered in a framework aligned with adult-learning principles, emphasising the importance of the diversity of families and learning styles among expectant parents. These findings offer valuable insights for the development of online antenatal education programmes, catering to the preferences and needs of millennial parents and informing maternity care policy and practice.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"In a separate Australian cohort, research by Beetham et al.ÿ27ÿused a longitudinal study design and evaluated physical activity and maternal and infant outcomes. Conducted with 1657 pregnant women aged 28?39 years, participants reported their physical activity levels in each trimester and completed surveys regarding pregnancy and childbirth outcomes within 3 years post-birth. Physical activity levels were classified by frequency and described by categories of ?Nil?, ?Low?, ?Moderate?, and ?High?. The study found no significant association between physical activity during pregnancy and infant birthweight, prematurity, gestational diabetes, hypertension, or antenatal depression. However, there was a lower prevalence of antenatal anxiety among women with low or moderate physical activity levels compared to those with no activity. These findings suggest that while different volumes of physical activity during pregnancy did not impact measured adverse health outcomes, engaging in low to moderate physical activity may contribute to reducing antenatal anxiety.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"Aligned with the exercise theme was research from a team in Norway investigating an Italian sample of pregnant women and their engagement in regular physical activity and exercise during the antenatal period.ÿ28ÿThe objective of this study was to investigate the facilitators and barriers to regular exercise among Italian pregnant women and to assess their social support regarding maternal exercise. Conducted with 513 healthy pregnant women in their third trimester, the study utilised a self-administered questionnaire regarding regular exercisers (?150 min/week) or not regular exercisers (<150 min/week). Only 4.6% of participants met exercise guidelines, with ?insufficient time? being the predominant barrier. Facilitators included relaxation, prevention of health issues, enjoyment, and weight management. Exercising with others significantly predicted regular exercise, while receiving advice on exercise from healthcare professionals correlated with higher exercise rates. The study highlights internal motivations for exercise among Italian pregnant women and underscores the importance of social support and healthcare guidance in promoting regular exercise during pregnancy.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"Physical inactivity and other risk factors were investigated by Fondjo et al.ÿ29ÿin the pursuit of understanding postpartum preeclampsia. Postpartum preeclampsia poses significant risks globally, including hospital readmissions and maternal complications. Understanding its risk factors is crucial for prevention and management strategies. This case-control study, conducted in Ghana, aimed to identify such factors. Among 65 postpartum preeclamptic women and 65 normotensive mothers, physical inactivity, infrequent antenatal visits, analgesic use, and caesarean delivery were significantly associated with both new-onset and persistent postpartum preeclampsia. Contraceptive use was linked to new-onset cases, while low-birthweight babies increased the risk of persistent preeclampsia. The findings underscore the importance of screening, close monitoring, and follow-up care post-delivery to manage postpartum preeclampsia effectively.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"The special collection of articles serves to illuminate the nuances and disparities that persist in maternal health. In an era of heightened global connectivity, there has been a commendable surge in awareness regarding the unique challenges faced by women in the realm of maternal health. No longer confined to the boundaries of specific regions, this awareness transcends borders and cultures. It is a rallying call, urging societies around the world to recognise and address the multifaceted needs of women during their maternal journey.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"Nestled within these articles are revelations that have pragmatic applications and recommendations included. They delve into the intricacies of maternal health, not just at a superficial level but by peeling back the layers to expose the profound implications on mental and physical well-being. These articles are a testament to the evolving nature of healthcare, urging us to reevaluate and recalibrate our approach to women?s health. While strides have indeed been made in the field of women?s health, there remain expanses of uncharted territory. These articles, collectively, serve as a compass, directing our attention to the areas around the globe and the topics where knowledge is sparse and where further quality research is needed. It is a call to action for the scientific community, urging them to contribute to a deeper understanding of women?s health.",,,,,
Maternal Health Considerations: Highlighting and advancing opportunities for improved maternal health,"Within this opportunity for inclusivity lies an imperative to amplify the voices that have been historically marginalised. The experiences of women who have been on the fringes of society, whether due to socioeconomic factors, cultural differences, or other determinants, must be brought to the forefront. These articles emphasise the importance of creating spaces where every voice is not only heard but also valued, contributing to a richer and more holistic understanding of women?s health.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"Oxidative stress (OS) is strongly implicated in the pathophysiology of major depressive disorder (MDD) but the molecular mechanisms remain largely unknown. The purpose of this study is to identify genes related to both OS and MDD, and further to evaluate the utility of these genes as diagnostic markers and potential treatment targets. We searched datasets related to MDD from the Gene Expression Omnibus (GEO) database for differentially expressed genes (DEGs) also related to OS according to GeneCards. Bioinformatics analyses and machine learning algorithms were used to identify hub genes mediating OS?MDD interactions. A summary data-based Mendelian randomization (SMR) approach was employed to identify possible causal genes for MDD from blood tissue eQLT data. These investigations identified 32 genes mediating OS?MDD interactions, while SMR analysis identifiedÿKCNE1ÿ(OR?=?1.057, 95%CI?=?1.013?1.102,ÿPÿvalue?=?0.010),ÿMAPK3ÿ(OR?=?1.023, 95%CI?=?1.004?1.043,ÿPÿvalue?=?0.020), andÿSTIP1ÿ(OR?=?0.792, 95%CI?=?0.641?0.979,ÿPÿvalue?=?0.031) as OS-related causal genes for MDD. These genes may thus serve as useful diagnostic markers and potential therapeutic targets.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"Major depressive disorder (MDD) is a common psychiatric illness characterized by persistent depressed mood accompanied by heterogenous cognitive, behavioral, and physical symptoms [1]. The World Health Organization estimates that 280 million people globally suffer from MDD [2]. The China Mental Health Survey reports a lifetime prevalence of 3.4% and a 12-month prevalence of 2.1% [3], with higher rates in females (8.0% and 4.2%) than males (5.7% and 3.0%) [4]. It is generally accepted that genetic, biological, psychosocial, and personality traits all contribute to MDD risk, termed the diversified disease hypothesis of MDD [5]. Pathological processes implicated in MDD include glutamatergic excitotoxicity, brain-derived neurotrophic factor/ tyrosine receptor kinase B signaling insufficiency, neuroinflammation, and gut microbiota?brain axis disturbance [6,ÿ7]. However, there are no effective treatments based on these mechanisms, implying complex multidimensional pathogenesis.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"Cellular metabolism and various signaling mechanisms result in the formation of highly reactive free radicals, including reactive oxygen species (OS) and reactive nitrogen species (RNS). Under normal physiological conditions, these species are neutralized by endogenous antioxidants; however, an imbalance between ROS or RNS production and scavenging will result in oxidative stress (OS), which leads to the oxidative damage of cellular lipids, proteins, and genomic DNA [8], while severe OS can trigger necrotic or apoptotic cell death. Oxidative stress and ensuing cell death is strongly implicated in neurodegenerative diseases such as the Alzheimer?s disease and Parkinson?s disease [9,ÿ10], and recent studies have suggested that OS also contributes to the pathophysiology and treatment response of MDD [11,ÿ12]. For instance, a positive correlation was found between and the amplitude of low-frequency fluctuations in key MDD-associated brain regions, such as the thalamus, anterior cingulate gyrus, and superior frontal gyrus, and plasma concentrations of the antioxidant enzymes superoxide dismutase (SOD) and glutathione reductase [13]. Furthermore, depression severity and working memory impairment were associated with higher plasma concentrations of malondialdehyde (MDA), an indicator of lipid peroxidation from oxidative stress, among recurrent MDD patients both before and after antidepressant treatment [14]. Reduced SOD activity, lower levels of the non-enzyme antioxidant glutathione (GSH), and elevated lipid peroxidation products have been proposed as reliable biomarkers for MDD [15,ÿ16]. In experiment animals as well, chronic unpredictable mild stress can induce depression-like symptoms and concomitant abnormalities in redox balance across brain subregions, including decreased GSH and SOD activities and higher levels of ROS, MDA, and carbonyl in prefrontal cortex and hippocampus [17]. Despite a growing number of studies implicating OS in MDD, there are still discrepancies [11,ÿ18]. An early meta-analysis of 23 studies with 4980 individuals found increased OS among MDD patients compared to matched individuals without depression, but some included studies found lower antioxidant biomarker concentrations (MDA and 8-oxo-2?-deoxyguanosine) in MDD [19]. A recent meta-analysis also concluded that OS status was more severe in MDD, but found no significant differences in catalase, SOD, glutathione peroxidase, and uric acid between MDD patients and healthy controls [20].",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"Current research utilizing Mendelian randomization (MR) studies, a research approach that uses genetic variants associated with target biological intermediates to assess disease causality, has begun to explore the causal relationship between oxidative stress-related biomarkers and MDD, among other psychiatric disorders. One notable study conducted a bidirectional MR analysis to investigate the causal links between oxidative stress injury biomarkers and several psychiatric disorders, including MDD. The study found that while most oxidative stress-related biomarkers did not show a significant causal relationship with psychiatric disorders, there were some interesting associations. Specifically, the study observed that lower levels of bilirubin were significantly associated with an increased risk of MDD, suggesting a potential protective role of bilirubin against depression. Furthermore, MDD was also found to have suggestive causal effects on certain oxidative stress biomarkers, including increased levels of uric acid and decreased ascorbate [21]. The recent two-sample MR analyses exploring causal relationships between antioxidant targets and psychiatric disorders showed that lower levels of Prolyl 4-Hydroxylase, Transmembrane gene expression in the cerebellum could decrease the incidence of MDD [22]. These findings suggested that while OS may play a role in the development of psychiatric disorders like MDD, however the exact mechanisms and the strength of these relationships are not yet fully understood.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"To address this issue, we conducted a comprehensive multi-omics analysis of the association between OS and MDD and identified multiple differentially expressed genes (DEGs) linking the two conditions. Machine learning models trained using these DEGs reliably distinguished patients from controls in an independent dataset. Thus, these genes may serve as feasible biomarkers or treatment targets. Furthermore, we utilized a multi-omics summary data-based Mendelian randomization (SMR) approach to identify putative causal OS-related genes for MDD.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"No ethics committee approval was required for this summary-level study. The gene array data of three study cohorts were extracted from the Gene Expression Omnibus (GEO) database:ÿGSE32280ÿ(platform:ÿGPL570) [23],ÿGSE39653ÿ(platform:ÿGPL10558) [24] andÿGSE98793ÿ(platform:ÿGPL570) [25]. In total these datasets included gene expression profiles for 165 MDD patients and 96 health controls. Diagnostic criteria for the disorder had been previously described in detail. Genes related to OS were identified from the GeneCards database (https://www.genecards.org) using the keyword ?oxidative stress?. Those with a relevance score?ò7 were included according to previous methods [26].",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"We identified genes common among the disease datasetsÿGSE32280,ÿGSE39653,ÿGSE98793, and GeneCards using the ?cbind ()? function of R, and then removed batch bias and performed log2(X?+?1) normalization using the R sva function. These standardized gene expression data formed the basis for all further analysis. To analyze the effect of OS-related gene expression level on MDD risk, the R limma package was used to identify DEGs between disease and normal control samples, with the absolution value of log2-fold change (log2FC)?>?1 andÿPÿvalue?<?0.05 set as thresholds. These DEGs were visualized by volcano plot and a heat map was constructed using the R packages heatmaps (version 1.0.12) and ggplot2 (version 3.3.2).",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,Univariate logistic regression and multivariate logistic regression analyses of theÿGSE39653ÿdataset were used to identify hub genes within the MDD- and OS-related gene set (Hub MDD-OS DEGs) withÿPÿvalues?<?0.05 considered statistically significant. This was followed by dimensionality reduction analysis.,,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"To reveal biological relationships among key genes and gene clusters related to OS and MDD, Gene Ontology (GO) enrichment analysis was conducted using the R package clusterProfiler. Genes were assessed for molecular function (MF), cell component (CC), and biological process (BP) annotations with a False Discovery Rate (FDR)-correctedÿPÿvalues?<?0.05 considered statistically significant. The R package cowplot was then used to conduct Spearman correlation analyses between key OS- and MDD-related genes as well as to draw heat maps, scatter plots, and correlation curves. Again,ÿPÿvalue?<?0.05 was considered statistically significant. Key genes were then mapped to chromosomal locations using the R package RCircos based on data from the R package and downloaded from the ENSEMBL database. The open-source STRING database was then used to build a protein-protein interaction (PPI) network [27], which was subsequently visualized using Cytoscape.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"Key genes mediating MDD?OS interactions were further screened and evaluated using 6 machine learning algorithms, Bagged Trees, Bayesian, Random Forest, Wrapper (Bpruta), Learning Vector Quantification (LQV), and 1000 iterations 10-fold cross-validation Least Absolute Shrinkage and Selection Operator (LASSO). A DEG identified as a feature gene by at least 5 algorithms based on classification performance was considered an important Hub DEG for MDD?OS interactions. The interactions among these key intersecting genes were then visualized using the R package ?Upset? application. To explore the associations of individual hub gene pairs in theÿGSE39653ÿandÿGSE9873ÿdatasets, we conducted Spearman?s correlation analyses and plotting of heat maps, scatter plots, and correlation curves using cowplot. Finally, RCircos was used to draw the chromosome localization map for display.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"Based on these analyses, we constructed a nomogram based on theÿGSE39653ÿdataset using the R package rms. A nomogram model was then constructed based on the hub genes to predict the prevalence of OS-associated MDD. Calibration curve analysis was performed to evaluate the accuracy and resolution of the nomogram. Finally, receiver operating characteristic (ROC) curves were constructed to evaluate the accuracy of the diagnostic model for the onset of OS-associated MDD using the R package pROC. Thorough composition validation techniques were employed to confirm model performance for distinguishing MDD from control samples.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"We also developed a classification prediction model based on expression analysis of blood utilizing a combination of the aforementioned 6 machine learning algorithms. The performance of each model was evaluated by calculating the area under the ROC curve (AUC), followed by visual representation of the results (predictive genes) using heat maps. Optimal model performance was assessed using calibration curve and decision curve analysis (DCA).",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"The R ConsensusClusterPlus package was used to identify subpopulations with distinct molecular phenotypes based on hub genes for MDD?OS interactions [28]. Principal co-ordinates analysis (PCoA) was then conducted to verify consistency of clustering. The R package ggpubr was used to draw box plots with sample cluster labels as groups, and the differences between groups were evaluated for statistical significance by the Wilcoxon rank sum test.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"The relative abundances of specific infiltrating immune cells were estimated using CIBERSORT (https://cibersort.stanford.edu/) [29], an analytical tool designed to reveal the distribution levels of LM22 immune cells based on gene expression profiles. Distinct enrichment fractions of immune cells were then compared using the Wilcox test. We further performed quantitative Single Sample Gene Set Enrichment Analysis (ssGSEA) to calculate the abundance of immune cells associated with MDD?OS interactions. Finally, differences in immune cell infiltration were visualized using ggplot2 withÿPÿvalue?<?0.05 set as the threshold for significance.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"We gathered genome-wide association study (GWAS) summary statistics of 170,756 MDD cases and 329,443 controls (8,483,301 genetic variants in total) from the Psychiatric Genomics Consortium (https://www.med.unc.edu/pgc), one of the largest, most innovative, and productive platforms in psychiatry [30]. The diagnostic criteria for MDD were described in detail in the source data. Single nucleotide polymorphisms (SNPs) associated with expression quantitative trait loci (eQTLs) were selected as instrumental variables (IVs) to infer direct causal effects of gene expression or protein levels on MDD. Whole-blood eQTL summary statistics for 15,882 genes were obtained from 31,684 individuals in the eQTLGen database [31]. The current study focused only on cis-eQTLs within 1-Mb from the start or end of the gene.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,All statistical analyses were performed using R 4.2.0. Continuous variables were compared between two groups using the Wilcoxon rank sum test and among three or more groups using the Kruskal?Wallis test. Categorical variables were compared by the chi-square test or Fisher?s exact test. Associations between immune cell abundance and gene expression levels were evaluated using Spearman?s correlation tests.ÿPÿvalue?<?0.05 was considered statistically significant for all tests.,,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"Causal inferences between GWAS and cis-eQTLs were evaluated using the SMR multi-tool. The top associated cis-QTLs were selected by considering a window centered around the corresponding gene (?ñ?1000?kb) and surpassing aÿPÿvalue threshold of 5.0???10?8. All SNPs with allele frequency differences larger than the specified threshold (0.2 in the current study) between datasets, including the linkage disequilibrium (LD) reference sample, the QTL summary data, and the outcome summary data, were excluded. All SMR analysis were implemented using SMR v1.3.1 and included SNPs as instruments, key genes for MDD?OS interactions as exposures, and MDD as the outcome (SMRÿPÿvalues?<?0.05, cis-eQTLs, and GWASÿPÿvalues?<?1???10-5). The MR method was based on the following crucial assumptions: (1) instrumental variables had to be strongly associated with exposure (e.g., key genes for MDD?OS interactions); (2) instrumental variables influence the risk of outcome (e.g., MDD) only through their effects on exposure (e.g., key genes for MDD?OS interactions) risk, and (3) instrumental variables are independent of confounders. To ensure independency, the PLINK clumping method was used for clumping and was based on the European 1000 Genomes, as a LD reference panel. We then calculated F-statistics, which were used to assess for weak instrumental variable bias. F?<?10 indicated that instrumental variables subjected to weaker instrumental variable bias were poor. We then removed them to avoid affecting the results. Causality was deemed significant based on theÿPÿvalue <?0.05.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"The strengths of SNPs used as instruments were assessed using the F-statistic, and we included only SNPs with an F-statistic >10 to minimize weak instrument bias [32]. The heterogeneity in the dependent instrument (HEIDI) test was applied using SMR v1.3.1 to distinguish pleiotropy from linkage. All instruments withÿPÿvalue?<?0.01 (indicating significant heterogeneity) were omitted from the analysis.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"The GEO datasetsÿGSE32280,ÿGSE39653, andÿGSE98793ÿwere combined using the R ?cbind ()? function and the batch bias mitigated using the R ?sva? package (see Fig.ÿ2ÿand Supplementary Tableÿ1). In total, 596 DEGs were identified between MDD patients and healthy controls (HCs) using Limma, including 294 upregulated genes and 302 downregulated genes in MDD. The magnitudes of differential expression for significant DEGs (Pÿvalue?<?0.05) are shown as a volcano map in Fig.ÿ3Aÿand as a heatmap in Fig.ÿ3Bÿand details in Supplementary Tableÿ2. These DEGs were enriched in GO CC terms ?specific granule?, ?specific granule membrane?, ?secretory granule membrane?, ?specific granule lumen?, and ?tertiary granule?, BP terms ?receptor signaling pathway via JAK-STAT and STAT?, ?placenta development?, and ?carbohydrate catabolic process?, and MF terms ?identical protein binding?, ?immune receptor activity?, ?cytokine receptor activity?, ?phospholipase activity?, and ?1-phosphatidylinositol-3-kinase regulator activity? (Fig.ÿ3C, Dÿand Supplementary Tableÿ3).",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"To identify MDD-associated genes also related to OS, these DEGs were searched against the 817 genes in GeneCards with relevance scoreò7 for OS, yielding 38 potential MDD?OS interaction or crosstalk genes (Supplementary Tableÿ4). The Venn diagram of these overlapping DEGs is shown in Fig.ÿ4Aÿand the chromosomal positions in Fig.ÿ4B. Among these 38 DEGs,ÿAMD,ÿALPP,ÿCAMK2G,ÿDDAH1,ÿKCNE1,ÿLEP,ÿMAPK3,ÿIL10,ÿPINK1, andÿSLC2A1ÿwere significantly upregulated in the MDD?OS samples (Fig.ÿ4C). More details were shown in Supplementary Tableÿ5.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"Machine learning algorithms were trained to deduce the associations between the 38 MDD?OS DEGs and MDD pathogenesis using theÿGSE39653ÿdataset, and model performance was validated using theÿGSE98793ÿdataset. Intersection of results yielded by the Bagged Trees algorithm (Fig.ÿ5A), Bayesian algorithm (Fig.ÿ5B), Random Forest algorithm (Fig.ÿ5C), Wrapper algorithm (Fig.ÿ5D), LQV (Fig.ÿ5E) and 1000 times 10-fold cross-validation LASSO Logistic model (Fig.ÿ5F) identified 32 of these genes as closely related to the pathogenesis of MDD and OS (Fig.ÿ5G):ÿADM, AKR1C3, ALPP, CAMK2G, CREBBP, DDAH1, DNM1L, F5, FKBP5,ÿGADD45A,ÿGATB,ÿGDF15,ÿHSP90AA1,ÿHSP90AB1,ÿHSP90B1,ÿIL10,ÿINSR,ÿKCNE1ÿ(encoding Potassium Voltage-Gated Channel Subfamily E Regulatory Subunit 1),ÿKLF2,ÿLEP,ÿMAP2K1,ÿMAPK3ÿ(encoding mitogen-activated protein kinase 3),ÿMGST1,ÿPLA2G7,ÿPLAU,ÿPTK2B,ÿRETN,ÿSLC2A1,ÿSTIP1ÿ(encoding stress-induced phosphoprotein 1),ÿTNF,ÿUGT1A1, andÿVDR. Subsequently, we constructed a PPI network with these 32 genes as hubs using the STRING database. Based on the criteria |Logfc?|?< 0.05 andÿPÿvalue?<?0.05, this 32-node PPI network included 341 edges, indicating complex multilevel interactions between OS and MDD pathogenesis.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"A diagnostic model was then constructed based on theÿGSE39653ÿdataset (Fig.ÿ6A), and discrimination was verified on both the training setÿGSE39653ÿand validation setÿGSE98793. The recall curve and Hosmer?Lemoeshow goodness-of-fit test results were equal to 1 for the training set (GSE39653), indicating a low probability of type I error, that prediction results were close to the real data, and that the calibration degree of the model was high (Fig.ÿ6B). The AUC of the diagnostic model was also 1.00 for the training setÿGSE39653ÿ(Fig.ÿ6C). The C-index of the diagnostic model was 0.99 for the training set (GSE39653) and 1 for the validation set (GSE98793) (Fig.ÿ6D), and the recall curve and Hosmer?Lemeshow test result P values were equal to 1.00 (Fig.ÿ6E). Finally, the AUC of the diagnostic model was 0.876 for the validation set (GSE98793) (Fig.ÿ6F).",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"The physical, behavioral, and cognitive symptoms of MDD can vary substantially among patients, so we examined the potential functions of these 32 key genes in distinct MDD phenotypes by cluster analysis using ConsensusClusterPlus. This analysis yielded two patient clusters in theÿGSE39653ÿdataset, Cluster A and Cluster B, based on DEG profiles (Fig.ÿ8A). The slope of consistency index for different classifications (Fig.ÿ7B) further confirmed that two was the optimal cluster number for this cohort, while the scree plot in Fig.ÿ8Cÿrevealed the inflection point for best classification. We further validated the stability of this MDD patient subtyping inÿGSE39653ÿby PCoA (Fig.ÿ7D).",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"To explore differences in pathogenesis between the two subtypes, the total DEGs for Cluster A and Cluster B were first identified. In total, 3560 DEGs were found, including 1367 expressed at higher levels in Cluster A and 1223 expressed at higher levels in Cluster B (Fig.ÿ7E). Then, GO enrichment analysis was conducted to reveal differential enrichment of biological functions. Enriched BP terms in Cluster A included ?leukocyte degranulation?, ?aerobic electron transport chain?, and ?ATP synthesis coupled electron transport?, while enriched CC terms included ?respiratory chain complex? and ?ficolin-1-rich granule lumen?, and enriched MF terms included ?antioxidant activity? and ?oxidoreduction-driven active transmembrane transporter activity? (Fig.ÿ7Fÿand Supplementary Tableÿ6).",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"Immune cell infiltration is a major driver of OS in the brain, suggesting an important contribution to OS-related MDD pathogenesis. We employed Cibersort analysis to calculate the infiltration status of 22 immune cells in theÿGSE39653ÿdataset, and the relative abundance of each immune cell type was then compared by the Wilcoxon sign rank test (Fig.ÿ8A). The CIBERSORT algorithm was also used to compare immune cell infiltration profiles between Cluster A and Cluster B. The results revealed that dendritic cells and activated mast cells were highly abundant in Cluster B (Fig.ÿ8B), and that the relative abundances of most immune cell subsets differed between clusters (Fig.ÿ8C). Moreover, the ssGSEA algorithm indicated greater infiltration of activated CD8?+?T cells, effector memory CD8?+?T cells, regulatory T cells, Type 1?T helper cell, eosinophils, macrophages, and monocytes in MDD samples of Cluster A (Fig.ÿ9A) (Pÿvalues?<?0.05). Furthermore, abundances were correlated with the expression levels of the 32 most important DEGs (allÿPÿvalues?<?0.05) (Fig.ÿ9B).",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"We also performed SMR analysis to evaluate the association strengths of these 32 key genes with MDD (withÿPÿvalues?<?0.05 set as the threshold for statistical significance). Results revealed an association between elevated expression ofÿKCNE1ÿand MDD odds (OR?=?1.057, 95% CI?=?1.013?1.102,ÿPÿvalue?=?0.010) (Fig.ÿ10A, B, G). Similarly, elevatedÿMAPK3ÿexpression was associated with greater MDD odds (OR?=?1.023, 95% CI?=?1.004?1.043,ÿPÿvalue?=?0.020) (Fig.ÿ10C, D, G), while upregulation ofÿSTIP1ÿwas associated with reduced MDD odds (OR?=?0.792, 95% CI?=?0.641?0.979,ÿPÿvalue?=?0.031) (Fig.ÿ10E, F, G). Supplementary Tableÿ7ÿshowed the SMR association between expression of geneÿMAPK3,ÿKCNE1,ÿSTIP1ÿand MDD.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"The F-statistic of all SNPs included in the analysis ranged from 29.855 to 3394.048, indicating a powerful instrumental variable?exposure association (threshold set at 10) (Supplementary Tableÿ7). Results of the HEIDI test further suggested that all observed associations were not due to linkage (Pÿvalue?>?0.01).",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"To our best knowledge, this is the first study on the contributions of oxidative stress-related genes to MDD pathogenesis using integrated multi-omics, machine learning, infiltrated immune cell profiling, genome-wide association, and summary data-based Mendelian randomization analysis. We identified 38 genes differentially expressed between MDD patients and controls that were also associated with OS, of which 32 were deemed important to the influence of OS on MDD pathogenesis (MDD?OS interaction genes) in training and validation cohorts by 6 separate machine learning algorithms. Further screening of blood tissue expression profiles by SMR analysis identifiedÿKCNE1, MAPK3, andÿSTIP1ÿas key linkage genes between OS and MDD. These DEGs may thus be convenient biomarkers for MDD as well as potential treatment targets.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"Neuroinflammation in strongly implicated in MDD as evidenced by elevated inflammatory marker concentrations, infiltrating immune cell numbers, and antibody titers [33]. These inflammatory processes both generate and are promoted by ROS and RNS (hence the OS?inflammation interaction is also known as ?evil twins of aging?), further implicating OS in MDD pathogenesis [34]. Elevated ROS production leads to GSH depletion, oxidative damage, and ultimately enhanced inflammation [35]. Excessive ROS can promote the expression of proinflammatory cytokines through several pathways, including activation of promoting protein-1 and nuclear factor kappa-B (NF?B), increased histone acetylation, and activation of caspase-1 and NOD-like receptor thermal protein domain associated protein 3 [36?38]. Inflammatory reactions induce expression and release of peroxiredoxin 2, which in turn stimulates macrophages to release pro-inflammatory tumor necrosis factor-à (TNF-à) [39]. Elevated TNF-à had been detected in serum and in multiple brain subregions (including the anterior cingulate cortex, prefrontal cortex, and hippocampus) of MDD patients [40,ÿ41]. Neuroinflammation also promotes the kynurenine pathway and ensuing quinolinic acid generation by activating indoleamine 2,3-dioxygenase (IDO), tryptophan-2,3-dioxygenase (TDO), and kynurenine 3-mono-oxygenase, which induces mitochondrial damage and results in further ROS production, glutamate release, N-methyl-D-aspartic acid (NMDA) receptor activation, Ca2+ÿinflux, and mitochondrial calcium overload, the end result of which is loss of mitochondrial membrane potential, reduced ATP generation, and accelerated ROS generation [36,ÿ42,ÿ43]. In addition, IDO and TDO activation may reduce 5-HT biosynthesis, and 5-HT insufficiency is widely believed to result in low mood [44]. These relationships also appear to be bidirectional, such that OS can promote neuroinflammation and vice versa in MDD. In accord with previous studies, we found that multiple immune-inflammatory gene pathways were activated in MDD compared to controls. These genes may in turn mediate the reciprocal exacerbation of OS generation and neuroinflammation leading to MDD. The OS?MDD crosstalk genes identified in this study are primarily involved in immune cell function, including activated CD8?+?T cells, effector memory CD8?+?T cells, regulatory T cells, type 1?T helper cells, eosinophils, macrophages, and monocytes, further supporting shared immune-inflammatory mechanisms in OS and MDD.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"We also conducted SMR analysis to identify new causal genes for MDD as such genes may be prime drug targets. Upregulation ofÿKCNE1ÿandÿMAPK3ÿwere found to increase MDD risk, potentially by promoting pathogenic mechanisms involving OS. TheÿMAPK3ÿproduct extracellular signal-regulated kinase 1 (ERK1) regulates cell proliferation, differentiation, and cell cycle progression among other vital processes [45]. It has been reported that ERK signaling is significantly downregulated in the prefrontal cortex and hippocampus of both human patients and animal models of chronic depression [46?48]. The ERK1/2 isoforms are the most thoroughly investigated and well characterized isoforms in the central nervous system [44,ÿ49,ÿ50], and both have been found to promote OS via ROS production and to amplify the inflammatory response through activation of the stress-responsive transcription factor NF?B [51,ÿ52]. At present, most studies on the role ofÿMAPK3ÿin MDD have focused on the brain, while few studies have investigated expression changes in more accessible blood samples. Moreover, most studies have focused on ERK1/2, but few specifically on ERK1. We found higherÿMAPK3ÿexpression in the blood tissue of MDD patients compared to controls, consistent with previous findings. One prospective case-control study reported that aÿMAPK3ÿSNP enhanced interferon-à-induced depression, possibly by increasing the propensity for glutamate dysregulation [53]. A bioinformatics analysis identified 5 genes includingÿMAPK3ÿas key modulators of post-stroke depression risk, disease biomarkers, and therapeutic targets of acupuncture [54]. Others have found significant associations ofÿMAPK3ÿwith schizophrenia, and a recent genome-wide Mendelian randomization analysis identifiedÿMAPK3ÿas a potential drug target for schizophrenia treatment [55], in line with previous studiess [56,ÿ57]. Based on these and our own findings, we speculate thatÿMAPK3ÿmay be a critical mediator of OS effects on MDD pathogenesis and thus a promising therapeutic target. However, in our present study,ÿMAPK3ÿappeared to make only a limited contribution (OR?=?1.023, 95% CI?=?1.004?1.043). Nonetheless, the contributions ofÿMAPK3ÿto OS and MDD warrant further exploration.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"In contrast to MAPKs, few studies have examined the genetic association ofÿKCNE1ÿwith MDD, although McCaffery and colleagues proposed thatÿKCNE1ÿwas associated with longer-term changes in depressive symptoms [58]. The KCNE family proteins are regulatory subunits of voltage-gated K(+) channels [59], and are implicated in multiple arrhythmogenic cardiac myocardium diseases [60]. TheÿKCNE1ÿsubunit regulates the neuronal membrane potential through modulation of K(+) channels, including KCNQ channels [61]. Further, the KCNQ channel modulator retigabine has been shown to improve depressive symptoms, suggesting therapeutic potential for MDD [62]. Another study also includedÿKCNE1ÿexpression in a diagnostic model for MDD [63], although no causal association was suggested. In the current study, preliminary genomic analysis indicated thatÿKCNE1ÿwas upregulated in MDD and positioned as a linker gene between MDD and OS, while according to SMR analysis,ÿKCNE1ÿupregulation increases the risk of MDD. We speculate that drugs targetingÿKCNE1ÿcould show therapeutic efficacy against MDD.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"These same genomics analyses also revealed downregulation ofÿSTIP1, which encodes a co-chaperone that interacts with heat-shock proteins 70 and 90, in the blood tissue of MDD patients, in accord with previous reports [64,ÿ65]. Further, SMR identifiedÿSTIP1ÿas a protective target against MDD (OR?=?0.792, 95% CI?=?0.641?0.979). Thus, activation ofÿSTIP1ÿexpression may be a useful therapeutic strategy against MDD. In addition to acting as a chaperone, extracellularÿSTIP1ÿacts as a trophic factor to engage PrPC, thereby enhancing neuritogenesis and neuronal survival [66,ÿ67]. Studies have also implicatedÿSTIP1ÿin functional recovery after stroke and regulation of A? peptide toxicity in Alzheimer?s disease models. Moreover, a GWAS analysis identified aÿSTIP1ÿpolymorphism as a potential risk factor for attention-deficit disorder [68]. Mice with elevatedÿSTIP1ÿlevels (up to nearly fivefold) showed no neuropathology, anxiety-like behaviors, depression-like behaviors, spatial memory deficits, or attention deficits [69], suggesting thatÿSTIP1ÿaugmentation may be a feasible strategy for antidepressant treatment; however, the detailed underlying mechanisms remain unclarified.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"This study has several limitations. First, it is possible that differences in gene expression between MDD patients and controls reflect the influences of factors such as age, sex, smoking, medications, and other health conditions, which without consider in the subsequent MR analysis. Second, we only focused on the cis-regions of OS and MDD genes, despite the possibility that trans-eQTL SNPs (SNPs >5?Mb from the gene) may have a widespread impact on regulatory networks. In addition, the data we used in the MR analysis were based on a European population, so whether these findings equally apply to other racial or ethnic groups remains to be further validate. Finally, functional experiments are still needed to confirm the importance of these DEGs in MDD pathogenesis through OS-dependent or OS-independent pathways.",,,,,
Novel therapeutic targets for major depressive disorder related to oxidative stress identified by integrative multi-omics and multi-trait study,"This integrative multi-omics and multi-trait study identified numerous genes linking OS to MDD pathogenesis, including three genes,ÿKCNE1, MAPK3, andÿSTIP1, causally associated with MDD. These gene in particular could serve as diagnostic markers and drug targets for MDD treatment. In addition, the dozens of other genes identify may provide clues to novel pathological mechanisms for MDD.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Electronic health records (EHRs) contain patients? health information over time, including possible early indicators of disease. However, the increasing amount of data hinders clinicians from using them. There is accumulating evidence suggesting that machine learning (ML) and deep learning (DL) can assist clinicians in analyzing these large-scale EHRs, as algorithms thrive on high volumes of data. Although ML has become well developed, studies mainly focus on engineering but lack medical outcomes.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,This study aims for a scoping review of the evidence on how the use of ML on longitudinal EHRs can support the early detection and prevention of disease. The medical insights and clinical benefits that have been generated were investigated by reviewing applications in a variety of diseases.,,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"This study was conducted according to the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. A literature search was performed in 2022 in collaboration with a medical information specialist in the following databases: PubMed, Embase, Web of Science Core Collection (Clarivate Analytics), and IEEE Xplore Digital Library and computer science bibliography. Studies were eligible when longitudinal EHRs were used that aimed for the early detection of disease via ML in a prevention context. Studies with a technical focus or using imaging or hospital admission data were beyond the scope of this review. Study screening and selection and data extraction were performed independently by 2 researchers.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"In total, 20 studies were included, mainly published between 2018 and 2022. They showed that a variety of diseases could be detected or predicted, particularly diabetes; kidney diseases; diseases of the circulatory system; and mental, behavioral, and neurodevelopmental disorders. Demographics, symptoms, procedures, laboratory test results, diagnoses, medications, and BMI were frequently used EHR data in basic recurrent neural network or long short-term memory techniques. By developing and comparing ML and DL models, medical insights such as a high diagnostic performance, an earlier detection, the most important predictors, and additional health indicators were obtained. A clinical benefit that has been evaluated positively was preliminary screening. If these models are applied in practice, patients might also benefit from personalized health care and prevention, with practical benefits such as workload reduction and policy insights.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Longitudinal EHRs proved to be helpful for support in health care. Current ML models on EHRs can support the detection of diseases in terms of accuracy and offer preliminary screening benefits. Regarding the prevention of diseases, ML and specifically DL models can accurately predict or detect diseases earlier than current clinical diagnoses. Adding personally responsible factors allows targeted prevention interventions. While ML models based on textual EHRs are still in the developmental stage, they have high potential to support clinicians and the health care system and improve patient outcomes.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Digitizing meaningful health information has been proven to contribute to diagnostics. Electronic health records (EHRs) are a digital repository of patient data and contain retrospective, current, and prospective information supporting health care [1]. EHRs contain a wealth of clinical information about early symptoms of a disease and registries of medical treatments [2]. These can be textual or imaging data and include both unstructured clinical notes and structured, coded data. One important aspect of textual EHRs is that they may include risk and preventive factors and early signs before a disease manifests. Especially for patients with multiple visits, many possible indicators are gathered in EHRs, resulting in possible early indications of disease. Therefore, for a good risk assessment, clinicians need the patient?s health information, physical examinations, laboratory test results, and history [3] available in EHRs.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"In the past 15 years, an explosion in the volume of data registered in EHR systems has occurred [4]. In 2012, the yearly increase in the volume of stored data was up to 150% for hospitals [5]. Not only the number of records continues to increase over time, but EHRs are also quite extensive because of large free texts [6]. Even though the completeness and correctness of EHRs have been found to be at a high level [7], the usability during medical visits lags behind due to this rising volume and variety of EHR data [8]. Consequently, it has even become an experienced usability issue for clinicians to review clinical results and health information from the past [9]. This is quite problematic as some clinicians spend, on average, 32.1% of their time on EHRs reviewing medical care and notes from the past [10]. The increasing EHR workload causes exhaustion and burnout among clinicians [11], negatively affecting the health care quality. This can result in diagnostic errors (missed, delayed, or incorrect diagnoses) because of missed signs [12] registered in the past. In 67.4% of the cases, missing the chief presenting symptoms in EHRs was the reason for missed diagnoses. Overall, meaningful health records have the potential to support risk assessment and early diagnosis, but the increasing amount of data hinder clinicians from using them to their full potential.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"It is currently known that supportive tools can simplify complex diagnostic tasks and reduce potential diagnostic errors [13]. There is accumulating evidence suggesting that machine learning (ML) can assist clinicians in analyzing large-scale EHRs as they thrive on high volumes of data. ML is able to fit models specifically adapted to patterns in the data and, compared to traditional statistics, is able to handle multidimensional data [14]. Deep learning (DL) is a subdomain of ML that uses neural networks with multiple (hidden) layers, incorporating complex interactions between variables [15]. Examples of well-developed ML models are based on imaging data for disease detection [16,17] and textual EHRs of hospitalization or intensive care data for predicting disease progression or therapy success [18]. One of the most promising aspects of DL in the context of EHRs containing historical and present clinical data is the ability to incorporate temporality into the model, that is, to base possible risk assessments on hidden patterns over time in clinical parameters. Indeed, DL models have also proved to be more effective by incorporating temporal information (ie, longitudinally processed) rather than cross-sectional information only [19]. Although the techniques of many ML (including DL) models have proved to be effective on EHRs, their focus is often on the engineering of architectures and frameworks [20], but they lack medical outcomes.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"It is a loss of information if ML developments remain unknown in health care because of the technical perspective of most authors. Especially given that artificial intelligence (AI) is a black box, it is important to clarify the clinical benefits and additional medical insights that can be achieved through these techniques. Therefore, the aim of this review was to perform a scoping review of the evidence on how the use of ML on longitudinal EHRs can support the early detection and prevention of diseases. A preliminary search was conducted, and no current or underway systematic or scoping reviews on the topic were identified. Only 1 review on longitudinal EHRs has been conducted [2], but it focused on methodologies. This study will contribute to what is already known by scoping the substantive medical insights that ML models yield. Given the aim of this study, the following research questions were addressed:",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,1. Which diseases have been detected in longitudinal EHRs using ML techniques?,,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,2. What EHR data have been used by ML methods for the early detection and prevention of diseases?,,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,3. What medical insights are generated by developing and using ML models on longitudinal EHRs?,,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,4. What clinical benefits may be reached through the application of ML models on longitudinal EHRs?,,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,The conduct and reporting of this scoping review adhere to the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) statement [21]. A protocol has been registered in the Open Science Framework (DOI: NY2TE).,,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Articles were included if they reported on early detection for timely prevention of diseases by using ML on longitudinal EHRs; the full description of eligible participants, concept, context, and types of sources can be found in the protocol. Overall, studies were screened according to several criteria.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Studies must have a clear focus on health care instead of a technical focus (eg, the article must include disease-specific information and interpretation, preferably executed and written from a health care perspective, and reflect on health or related care outcomes). Studies with a dominant technical focus or an engineering challenge or those using non?real-world data were assumed to be ineligible for this review.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"ML (including DL) should be aimed at predicting, detecting, or contributing to the risk assessment of diseases. Models aiming for data extraction, clustering, or patient selection for trials did not fit this concept. The purpose also affects the technique used.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"The prediction target of ML must be (the onset of) a disease or a medical event. By using theÿInternational Classification of Diseases, 11th Revisionÿ[22], we ensured that the primary outcomes were a disease or related medical event (ie, the cause of morbidity or mortality). Thus, studies that predicted disease severity once diagnosed, success of treatment, adverse drug reactions, phenotypes, or events that were not the cause of morbidity or mortality and did not focus on timely prevention were beyond the scope of this research. If the outcome was mortality, these articles were excluded because it is always a consequence of a disease or medical event.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Studies must incorporate the essential elements of ML, such as training, testing, or validation steps. DL was assumed as a subdomain within ML and, therefore, was included as well.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"According to the broadest definition of an EHR [1], data were assumed as EHR data if these contained information supporting continuing, efficient, and quality integrated health care or describing the health status of a patient regardless of the collecting database. Studies must use manually entered EHR data, including textual and numeric values. Both structured (numeric or coded) and unstructured (clinical notes) data were accepted as eligible EHR data. EHRs with solely imaging data (such as x-rays or electrocardiograms) were beyond the scope of this review. EHRs from animals were excluded.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,Studies must use EHRs over time registered at multiple visits (before registering a disease or medical event).,,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Studies were included if they were conducted in the context of disease prevention. Optimal prevention in health care settings can be reached when participants at risk or signs of a disease are detected as early as possible, and therefore, these studies were eligible in the context of secondary prevention. Secondary prevention emphasizes early disease detection in subclinical forms and seeks to prevent the onset of illness [23]. Studies conducted using data gathered in intensive care settings during a hospital admission or data gathered at the emergency department cannot be viewed in the context of disease prevention because only tertiary preventive measures can be taken to reduce the effects or severity of the established disease as it is too late to influence the onset of disease.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Because ML is data driven (instead of conventional models that are hypothesis driven), only predictions based on >1000 participants in total were considered eligible. This threshold is based on theory (eg, calculations for multivariable predictions of binary outcomes [24]) and practice (eg, the range of sample sizes for disease prediction models on EHRs seen in the literature).",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Only study designs with clinical, real-world data were considered. If secondary research, such as other reviews, met the aforementioned criteria, the reference list was considered depending on the research question. Conference papers were also considered because of the high quality of evidence in computer science.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"After several preliminary searches, 5 bibliographic databases (PubMed, Embase, Web of Science Core Collection [Clarivate Analytics], IEEE Xplore Digital Library, and computer science bibliography) were searched for relevant literature from inception to April 28, 2022. Searches were devised in collaboration with a medical information specialist (KAZ). The following search terms, including synonyms, closely related words, and keywords, were used as index terms or free-text words: ?neural network,? ?electronic medical record,? and ?prediction.? We used only search terms capturing specific ML techniques that are able to predict or classify. The search strategy was adapted for each included database or information source. The searches contained no methodological search filter or date or language restrictions that would limit results to specific study designs, dates, or languages. We searched computer science bibliography for conference proceedings and hand searched meeting abstracts. Duplicate articles were excluded using the R packageÿASYSDÿ(R Foundation for Statistical Computing), an automated deduplication tool [25], followed by manual deduplication in EndNote (version X20.0.3; Clarivate Analytics) by the medical information specialist (KAZ). The full search strategy used for each database is detailed inÿMultimedia Appendix 1.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Following the search, all identified citations were collated and uploaded into Rayyan (Rayyan Systems Inc) [26] and EndNote (version X7.8). In total, 2 reviewers (LS and FCB) independently screened all potentially relevant titles and abstracts for eligibility. If necessary, the full-text article was checked against the eligibility criteria. Differences in judgment were resolved through a consensus procedure. The full texts of the selected articles were obtained for further review. As the aim was not to search for ?the best available? evidence but to identify and perform a scoping review of all evidence, a critical appraisal was not systematically carried out.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Data were extracted from the papers included in the scoping review by 2 independent reviewers (LS and FCB) using a data extraction form developed in Microsoft Excel (Microsoft Corp). This form was composed based on full-text findings relevant to the research question and was discussed by the research team. The data extraction sheet captured details about study characteristics, health care discipline, generated medical insights, and clinical benefits for health care and the way EHRs were processed temporally.ÿMultimedia Appendix 2ÿprovides the list and definitions of all data items. This form was piloted using the first 5 articles and was revised and slightly adjusted during the process of extracting data. The extraction of ML techniques was modified to include the extraction of all techniques that were internally compared by appointing the central model and the comparison. Any disagreements between the reviewers were resolved through discussion with additional reviewers. Authors were contacted to request missing or additional data where required.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Extracted data were synthesized into results by frequency counts of concepts and qualitative narratives. Study characteristics, detected diseases, and EHR variables were listed in tabular form. The content of these tables was sorted by disease outcomes according to theÿInternational Classification of Diseases, 11th Revisionÿdisease categories from the World Health Organization. For data concerning medical insights and clinical benefits, a qualitative content analysis was carried out according to the guidance for scoping review knowledge syntheses [27,28]. After each study?s key findings were extracted, these were classified into concepts (1-6) and described using a narrative summary. We decided to describe both similarities and exceptions of the generated results and potential impact.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"The literature search generated a total of 895 references. After removing duplicates of references that were selected from >1 database, 483 (54%) of the references remained. By screening titles and abstracts, 426 (88.2%) of the articles were excluded. Of the remaining 57 articles, 2 (4%) could not be retrieved because they contained unpublished work. In the second phase, 55 full texts were reviewed for eligibility, and ultimately, 20 (36%) articles were included. Reports were mostly excluded due to wrong data, a technical focus, the absence of a longitudinal aspect, or models based on N<1000. No additional studies were found by checking reference lists. After the final screening, most included articles (18/20, 90%) were found in PubMed. The flowchart of the search and selection process is presented inÿFigure 1.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Of the 20 included articles [29-48], 19 (95%) were published between 2018 and 2022, and 1 (5%) was published in 2016. The aim of these studies to develop an ML or DL model and examine whether it was able to detect the disease of interest in longitudinal EHRs. Detected diseases or related medical events were hepatocellular carcinoma [29], type 2 diabetes or prediabetes mellitus [30,31], mental health conditions [32], dementia [33,36], cognitive impairment [34], psychosis [35], heart failure [37], cardiac dysrhythmia [38], cardiovascular and cerebrovascular events [39], cardiovascular disease [40], knee osteoarthritis [41], kidney function decline [42,43], extreme preterm birth [44], opioid overdose [45], and suicide attempts [46]. One study proposed a health index [47] based on the prediction of 3 important health events, and another study predicted future disease in the next hospital visit [48]. Sample sizes ranged from thousands to millions. In total, 10% (2/20) of the studies used an external validation data set [35,39].ÿTable 1ÿshows the included studies and the detected diseases.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"The EHRs of patients used in the included studies were originally recorded in hospitals or primary care centers. Especially for the detection of mental and behavioral disorders, EHRs were often extracted from military health records [32,36], and for neurodevelopmental and cardiovascular disorders, EHRs were mostly extracted from general practices [33,37]. Most studies (16/20, 80%) used structured EHRs [29-33,35,38-43,45-48], sometimes combined with unstructured data [34,36,37,44], to estimate the risk of a disease or medical event. Demographic information (statically used), symptoms, laboratory (blood) test results, diagnoses, medications, BMI, and clinical notes were commonly used data from EHRs. In addition, the EHR length and hospital admission and visit history were frequently added to the model. Lifestyle data were included for cardiovascular diseases. Clinical and social signs were more frequently used for self-harm and mental, behavioral, and neurodevelopmental disorders. For the prediction of kidney and diabetes outcomes, laboratory test results were frequently extracted. If EHRs were unstructured, natural language processing methods were conducted as a precursor to analyze clinical notes. The central techniques were a basic recurrent neural network (RNN) or long short-term memory (LSTM) [29,31,34,35,39,44,45,49], often compared with logistic regression, support vector machine, or random forest. When techniques were used that could not handle temporal data, a temporal aspect was created in the data. Although not extensively specified, a slope and intercept of variables [31,36]; a mean [30]; minimum, maximum, median, and SD measures [42]; the addition of a time-weight (eg, 0.9 ? days from reference point+decay) [43]; different time stamps [42]; or dividing the data into time blocks [33,46] were used.ÿMultimedia Appendix 3ÿ[29-48] provides an overview of the EHR data used and the techniques applied.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Disease detection and prevention can be supported by using ML or DL on longitudinal EHRs. First, the development and training of such models on EHRs can generate new medical insights (1-4). Second, when those models are applied (eg, for additional analyses or to ?new? data in clinical practice), the following clinical benefits may be achieved (5 and 6). These insights will be summarized in the following sections.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"The use of ML and DL models on EHRs could support the detection of diseases with a high diagnostic accuracy. Performance metrics such as the area under the receiver operating characteristic curve (AUROC), sensitivity (recall), specificity, accuracy, precision, and the area under the precision-recall curve evaluated the detecting ability of the model. The AUROC was by far the most frequently reported metric because it illustrates the diagnostic ability for a binary classification (disease or nondisease) by using the sensitivity versus the specificity. Although it is not our intention to identify the best-performing model, it was observed that the AUROC of central models varied between 0.73 and 0.97. In 40% (8/20) of the studies, the optimal model had a ?good? detection (AUROC between 0.7 and 0.8), 35% (7/20) of the studies succeeded in having a ?very good? detection (AUROC between 0.8 and 0.9), and 15% (3/20) of the studies reached an ?excellent? detecting performance (AUROC between 0.9 and 1.0) [36,41,46] according to the classification of diagnostic accuracy by Simundic [50]. For the best disease detection, multiple models were compared within the study, or the central model was compared with existing detection tools. The authors of 30% (6/20) of the studies claimed that their model produced a (slightly) higher performance than ?conventional? or ?traditional? models or ML models in the literature [29,34,37,38,44,45]. In 15% (3/20) of the studies, the central model performed better compared with currently used approaches such as a validated clinical model [42], a surveillance tool on which current health indexes are based [47], and a gold standard in routine clinical practice according to the American College of Cardiology and the American Heart Association [40]. In one study, the prediction scores of the model were validated by experts who agreed 100% through manual record reviewing [36]. The diagnostic accuracy of the included models was not dependent on disease categories but relied on the EHR data given to the model. Many studies (7/20, 35%) mentioned that diseases could be detected more accurately (ie, the predictive performance was increased) when the EHRs were closer to the date of diagnosis [32,33,46] and with an increase in the number of predictors [37,40,43,48]. Overall, the ability of the included models to classify nonhealthy and healthy individuals was close to the registered diagnoses in the EHRs.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"In 45% (9/20) of the studies, ML and DL models observed all available EHR data to classify patients as a case or control (ie, ML vs human detection) [30,33,34,36,38,39,42,43,45]. However, in the other studies (10/20, 50%), models were able to detect diseases earlier than the moment they were diagnosed by clinicians in EHRs (ie, prediction) [29,31,32,35,37,40,41,44,46-48]. By dividing the participants? EHRs into 2 pieces, X years were observed (observation period), and based on these data, it was possible to predict the risk of developing a disease or medical event in the future (prediction period). In other words, the prediction was made at an earlier time (x=0) than when it was diagnosed in practice (end of black bars). In some studies (5/20, 25%), it was part of the research to identify what time frame encompasses enough predictive information and, therefore, how much earlier an (accurate) detection was possible [32,33,37,43,46]. For example, Walsh et al [46] used 2 years of EHRs and extended their prediction window more and more to find the earliest moment of an accurate prediction. Raket et al [35] predicted whether a psychosis would occur 1 year before its onset, whereas Zhao et al [40] used 7 years of EHRs to predict the occurrence of cardiovascular events in the following 10 years.ÿFigure 2ÿ[29-48] illustrates the different time frames of longitudinal EHRs and their results according to a possible earlier detection. How much earlier a disease can be detected has a varying clinical meaning and, therefore, needs its own interpretation.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Another way to support disease detection and prevention was by generating insights into factors, topics, predictors, or indicators contributing to disease prediction [30,31,33,35-41,43-46]. In unstructured clinical notes, relevant topics, related words, and medical concepts were found that contributed to disease detection [36,44]. These words concerned daily living, behavior, and medical history. ML and DL models using structured EHRs generated the most contributing factors and their individual contribution to the outcome [30,31,33,35,37-41,43,45,46]. The most contributing predictors reported among all disease categories were (related to) age, blood pressure, BMI, cholesterol, smoking, and specific medication. Concerning mental, behavioral, and neurodevelopmental disorders, additional predictors were related to depression, personal difficulties, and personality changes. Some of these identified predictors were new for their discipline (eg, specific medication) [35,41,44] or not yet incorporated into gold standards for clinical diagnostic guidelines (eg, genetic information) [40]. In addition to this, insights into the importance of (known) predictors were generated. For example, Raket et al [35] identified what factors were responsible for the biggest positive and negative change in risk estimation (eg, differential white blood cells) and, therefore, indicated the most effective targets for preventive interventions. Other models found that the contribution of some predictors was not as high as assumed (eg, stress on diabetes) [31]; factors that seemed individually irrelevant turned out to have cumulative important predictive value [35], and the instability of factors, not the factor itself, was a predictor for one disease [40]. The aforementioned factors were identified during model development, but applying such a model to new EHRs would generate responsible factors for that individual.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"In total, 10% (2/20) of the studies used EHRs not to predict the risk of a disease but to create other health indicators. Hung et al [47] developed a health index based on 3 DL predictions of impactful and costly health indicators (mortality, hospitalization, and cancer). This health index also generated insights into the population?s health and was found to be close to the ?true risk? and, therefore, a better indicator than baseline models. Another study claimed to forecast what disease an individual would have at the next hospital visit [48]. Their results showed that the developed model generated well-performing results in forecasting medical diagnoses aggregated in 3- and 4-digit International Classification of Diseases, 9th and 10thÿRevision codes.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"In 25% (5/20) of the studies, ML models were used to support (preliminary) screening on longitudinal EHRs [29,35,36,42,46]. After developing ML and DL models, risk classes could be generated as a precursor for physical screening. Approximately 90% of the diagnosed cases were concentrated in the highest (10%) risk class. Other studies assessed the utility of ML and DL models by thresholds for the proportion needed to be screened versus the detection possibility [29,42]. For example, to detect 90% of all validated patients with hepatocellular carcinoma, the highest 66% of risk scores (predicted by a DL model) needed to be screened, whereas to detect 80% of all cases, screening from only the highest 51% of risk scores was required [29]. Chauhan et al [42] reasoned the other way around and focused on efficiency. From the 10% highest risk scores for kidney failure, the positive predictive value was 68%. Moreover, the cost benefits for screening options using DL on EHRs were investigated [35]. Disease detection using a DL model was associated with a positive net benefit?to?cost benefit ratio for a single-point risk assessment (1:3) and continuous-time risk assessment (1:16). Reasons for preliminary screening in EHRs were to prioritize those with the highest risk for disciplines with long waiting lists [29,42], before costly or more invasive examinations (eg, image or biomechanical retrieval) [35,41], or to detect cases that might be missed by the current pathway and go undetected [35,36,46].",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Only 10% (2/20) of the included studies were validated using an external data set, but none of the models have been implemented in clinical practice (yet). Consequently, the benefits for health were not evaluated. However, the authors interpreted their findings and suggested opportunities and possible health care benefits for clinical practice. The authors of 35% (7/20) of the studies mentioned that, if their models were applied in clinical practice, this may improve personalized health care [34-36,42,45-47]. Personalized health care was related to a personalized risk prediction, an individual-level index or output, a tailored care plan, and targeted care and screening. The authors of 60% (12/20) of the studies claimed that prevention could be improved by using their ML and DL models [31-38,42,44,45,47]. Early and timely detection and interventions before disease manifestation were often mentioned. In one case, the use of DL on EHRs could not directly prevent the targeted outcome, but by better preparing health care in an appropriate setting, indirect health outcomes could be prevented [44]. Additional suggestions to improve health care were focused on policies. It was suggested to base health policies on risk classes at a nationwide level [39,42]. Moreover, (predicted) future health conditions may be a better base for health care policies than traditional surveillance models reflecting health conditions from years before [47]. In addition to this, DL support can reduce the clinical workload. Even if the positive predictive value to select a screening population is low, a model with an excellent sensitivity can reduce the clinician?s workload by 70% [44]. All studies assumed EHR data to be valuable information to improve health care. The author of one study suggested that even imperfect data can be used as a silver standard to develop risk models [36].",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"The first research question in this study sought to determine which diseases have been detected in longitudinal EHRs using ML techniques. Results showed that a variety of diseases could be detected or predicted, particularly diabetes; kidney diseases; diseases of the circulatory system; and mental, behavioral, and neurodevelopmental disorders [22]. Comparing our findings with those of prior work, only a third of EHR prediction models predict diseases; meanwhile, mortality and hospitalization remain the most prevalent outcomes [51]. Among the studies that have predicted diseases, cancer is the most frequently predicted disease based on EHRs. Another systematic review used clinical notes to identify chronic diseases [52]. It also found diseases of the circulatory system as the most prevalent and explained this by the structure of the data. Not only the structure but also the length of the EHR horizon before diagnosis may explain the diseases that can be detected or predicted. As we determined the scope of diseases that may be prevented, the length of historic data before the diagnosis (in existence of early signs) reflects the ?preventive stage? before the onset of the disease. The literature confirms that the longest EHR time horizon (8-10 years) has been found for diabetes and cardiovascular and kidney diseases [51], which were also prevalent diseases in our scoping review. In the end, the diseases that can be detected rely on available EHR data and, therefore, previous medical visits.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"The second research question determined the scope of what EHR data have been used by ML techniques for the early detection and prevention of diseases. This scoping review found that age, sex, BMI, symptoms, procedures, laboratory test results, diagnoses, medications, and clinical notes are frequently used. Diseases that could be detected earlier than when they are currently diagnosed did not use other EHR variables. In addition, the most important predictors found in multiple studies were age, blood pressure, BMI, cholesterol, smoking, and medication. The consistency in the used and most important EHR variables underlines the importance of establishing generalized regulation and standardization of these variables across electronic health software, especially for variables overlapping in various health disciplines [53]. This would also address well-known challenges and limitations with EHR data, which will be discussed later in this section. According to the literature on the use of EHR data, it seems that a larger variable set improves disease prediction [51]. Their systematic review concluded that studies must leverage the full breadth of EHR data by using longitudinal data. In addition, we found that large longitudinal EHR data can successfully be analyzed via RNN and, derived from it, LSTM. These are both neural network architectures that are able to find patterns while incorporating temporality, making them effective for time-series predictions. Other types of neural networks (eg, convolutional neural networks) are well-known for their performance on images [15]. Similar results for techniques were identified in a review on the same topic from a technical perspective [2]. They concluded that RNN (specifically LSTM) was the most prominent technique to capture complex time-varying EHRs. Another review on AI techniques to facilitate earlier diagnoses of cancer also stated that neural networks were the dominant technique applied to EHRs [54]. Our results showed that there was no consistent way to process EHR variables temporally when techniques other than LSTM and RNN were used. Therefore, we can conclude that a basic RNN and LSTM are the most suitable techniques to analyze multivariable, longitudinal EHRs.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"The third research question of this review was to determine the scope of medical insights that could be generated. Our results showed that, with the development and training of ML and DL models on EHRs, (1) a high diagnostic accuracy was reached, (2) the most responsible predictors could be identified, (3) diseases could be detected earlier than when they are currently diagnosed, and (4) additional health care indicators were created. The most prominent medical insight was the detection performance of the models. However, how good the performance should be is ambiguous. For example, DL models used to facilitate earlier cancer diagnoses had AUROC values ranging from 0.55 to 0.99 [54], indicating performance from almost random guessing to near-perfect detection. Looking into a more mature domain, the diagnostic accuracy of sepsis predictions ranged from between 0.68 and 0.99 in the intensive care unit to between 0.96 and 0.98 in hospital and between 0.87 and 0.97 in the emergency department [55]. This metric is ideally as high as possible because it induces a high sensitivity (true positives) and specificity (true negatives). For comparison, the diagnostic accuracy of a gut feeling (meta-analysis on cancer diagnosis) had a sensitivity of only 0.40 and a specificity of 0.85 [56]. The diagnostic accuracy of physical examination (for the detection of cirrhosis) had a sensitivity between 0.15 and 0.68 and a specificity between 0.75 and 0.98 [57]. If ML can increase both the sensitivity and specificity of disease detection, nonhealthy persons can be found, and delayed diagnoses can be reduced without overtreating healthy persons misdiagnosed as cases [58]. If the developed model is further evaluated in false-negative and false-positive groups, it may be possible that the model detects even more (true) cases than those registered by clinicians. This is already the case for many DL techniques on imaging data [59]. For now, an even more important finding is the ability of some models to detect disease manifestation earlier than the moment of diagnosis registration in EHRs. These examples of earlier detection are aligned with a study on the onset of diseases [60] that concluded that ?slowly progressive diseases are often misperceived as relatively new? (ie, the onset could have been detected earlier). They found that, in 31% of diagnosed cases, the onset of their disease had started >1 year before their diagnosis. When disease predictions are early and accurate enough, it can facilitate disease prevention [23]. Especially with the addition of personally responsible factors and the biggest changers in risk prediction, prevention interventions may be more effective because they are more targeted to the individual. When medical prevention and interventions become based on the unique profile of each individual, personalized health care is delivered [61]. After all, the aforementioned medical insights only show the bright side of ML and DL models.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Our final research question sought the (possible) clinical benefits that could be obtained from using ML on EHRs. We found that preliminary screening was a clinical benefit of applying such models on longitudinal EHRs. Patients were accurately classified into risk classes to prioritize those with the highest risk, and a positive net benefit was found. In addition, the authors of the studies stated that their results (although they were not clinically evaluated) may contribute to a more personalized health care, prevention possibilities, and health care policies and reduce the clinicians? workload. These benefits are perfectly aligned with the near-future vision, strategies, and action foci set by the World Health Organization [62,63]. In particular, the emerging clinical staff shortage makes the future health care system more dependent on technical innovations and the health care system will be forced to be digitally assisted [64]. However, to be adopted in medical practice, ML and DL models require external validation, the absence of bias and drift, and transparency for clinicians. In prior work, benefits have rarely been clinically evaluated either. Even in a more mature health domain regarding ML, the intensive care unit, only 2% of the AI applications are clinically evaluated [65]. In their systematic review, the clinical readiness of AI was explored, but no AI model was found to be integrated into routine clinical practice at the time of writing. The limited amount of publications evaluating the clinical benefits of the application of ML on EHRs indicates the research gap in the literature. Future studies should explore the follow-up of these AI attempts and the reasons for success or failure in practice.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Up until now, we have only discussed possible beneficial results of using ML and DL on EHRs. However, we cannot ignore the possible risks, obstacles, challenges, or issues. Multiple (systematic) reviews have summarized these well-known issues, challenges, and limitations regarding the application of ML and DL on EHRs [2,51,66,67]. Viewed generally across all studies, practical obstacles influence the scientific and clinical implementation process: ethical considerations, privacy guidelines, legal procedures, equity, and data protection and security [68]. Beyond these obstacles, existing predictions face limitations due to their reliance on the data. First, key issues of using EHRs are irregularity, heterogeneity, sparsity (eg, missing data), temporality, the lack of gold-standard labels, and the volume and quality of data [2,51,66,67]. Second, ML and DL models have limited transparency and interpretability, face domain complexity (vs engineering expertise), may include biases, and often lack external validation. It is not possible to assign specific issues to specific studies; they all suffer more or less from the aforementioned issues. Our point is to become aware of the downside as well. Therefore, all our principal findings must be interpreted with this last discussion point in mind. In our opinion, a consistent, reliable, and valid way of EHR registration will improve the (use of) data and could be the first step toward a data-based health care system. This need for movement and improvement is important not only for research but also for practical convenience for clinicians and, consequently, to succeed in improving health outcomes.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"A limitation of this scoping review is the time between the search and the publication. As ML and DL have become a popular topic and the amount of research has grown drastically over the last years, new research could have been published between the literature search and the publishing of this scoping review. Consequently, some of our findings may have been overtaken by the progress in research.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Another limitation was the data synthesis regarding the performance outcomes per technique. Due to a wide variety of internal analyses, outcomes were not directly comparable, and therefore, the data extraction and data synthesis were difficult. Some studies just noted the optimal performance value achieved by the central model, while other studies compared a variety of techniques and noted various performance values for different subgroups, different metrics, and different time windows and with the addition of various technical improvements. A few authors discussed their ultimate results and mentioned that their model was better than literature, that is, ?traditional? or ?conventional,? attempts, which were not always clearly defined. We have attempted to follow the authors? description to avoid incorrect comparisons. However, some comparisons may have become vague or skewed during data synthesis. Nevertheless, we scoped the optimal AUROC for each study at the meta level.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"As we used a broad definition of EHR, we included a greater range of data. This means that the results are not based solely on data directly extracted from clinical record systems but also on data extracted by an intermediate organization, such as insurance companies. Therefore, readers must interpret the results of ML and DL models with this in mind.",,,,,
The Use of Deep Learning and Machine Learning on Longitudinal Electronic Health Records for the Early Detection and Prevention of Diseases: Scoping Review,"Longitudinal EHRs have valuable potential to support the early detection of a variety of diseases. For various diseases, EHR data concerning diagnoses, procedures, vital signs, medication, laboratory tests, BMI, and (early) symptoms have a high predictive value. To analyze multivariable, longitudinal EHRs, a basic RNN and LSTM are the most suitable techniques. For the detection of diseases, using ML (including DL) on EHRs proved to be highly accurate. When the detection occurs at the same moment as the diagnosis of clinicians, it seems not directly relevant for the prevention of diseases. However, the detection of diseases offers the clinical benefits of preliminary screening to prioritize patients from the highest risk class. The prevention of diseases can be supported by ML models that are able to predict or detect diseases earlier than the current clinical practice. The additional information about the most important predictors of the individual and the biggest risk changers allow targeted prevention interventions and, therefore, personalized care. Improved health care policies and workload reduction are frequently cited benefits but have not yet been evaluated in clinical practice. Both ML and DL attempts for disease detection and prevention still remain in the testing and prototyping phase and have a long way to go to be clinically applied.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Transferring and replicating predictive algorithms across healthcare systems constitutes a unique yet crucial challenge that needs to be addressed to enable the widespread adoption of machine learning in healthcare. In this study, we explored the impact of important differences across healthcare systems and the associated Electronic Health Records (EHRs) on machine-learning algorithms to predict mental health crises, up to 28 days in advance. We evaluated both the transferability and replicability of such machine learning models, and for this purpose, we trained six models using features and methods developed on EHR data from the Birmingham and Solihull Mental Health NHS Foundation Trust in the UK. These machine learning models were then used to predict the mental health crises of 2907 patients seen at the Rush University System for Health in the US between 2018 and 2020. The best one was trained on a combination of US-specific structured features and frequency features from anonymized patient notes and achieved an AUROC of 0.837. A model with comparable performance, originally trained using UK structured data, was transferred and then tuned using US data, achieving an AUROC of 0.826. Our findings establish the feasibility of transferring and replicating machine learning models to predict mental health crises across diverse hospital systems.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Recent decades have witnessed a consistent increase in the proportion of mental health-related visits to emergency departments1?3, a trend further accelerated by the COVID-19 pandemic4. These visits stem primarily from individuals who are suffering mental health crises. In general, a mental health crisis, also called a mental health emergency, is a broad term that encompasses any situation in which a person?s actions, feelings, and behaviors put them at risk of hurting themselves or others, and/or prevent them from being able to care for themselves or function effectively in the community in a healthy manner5. Some examples include suicide attempts, psychosis, self-harm, or mental breakdowns. Accurate foresight or prediction of such crises would open new avenues for healthcare providers to not only manage their limited resources but to also proactively intervene. This proactive approach could mitigate the adverse effects on individuals while reducing the burden on healthcare infrastructures6,7.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The evolution of machine learning (ML) techniques, along with research on their applicability across different medical domains, has paved the way for predictive analytics of critical events in areas such as cardiovascular disorders, circulatory failure, and diabetes8?12. In psychiatry, predictive models leveraging electronic health records (EHRs) are emerging as a promising avenue for forecasting mental health crises13,14, thus enabling a long-awaited shift from reactive to proactive healthcare. Moreover, these predictive tools hold the potential to alleviate the global burden of mental disorders, which ranked as the second leading cause of years lived with disability in 201915. However, a notable gap in the current predictive analytics landscape is the robustness of the algorithms across diverse healthcare systems, which limits their adoption and practical use. The predominant focus of research has been placed on developing and evaluating models within single test-bed settings, thereby leaving us ill-informed about the universal applicability and scalability of ML in psychiatry.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"In this regard, the ability to transfer and replicate predictive algorithms across healthcare systems represents one of the key enablers of the widespread adoption of machine learning not only in psychiatry but also in the broader healthcare spectrum. This entails unique and vital challenges, ranging from disparate data collection processes, data architectures, operational protocols, and patient demographics that vary considerably across different systems. These challenges appear both when transferring algorithms - where models trained on one specific dataset are implemented and evaluated in a different setting?, and when replicating them?where the approach and findings should be reproduced under new conditions. Additionally, how well the model performs when transferred or replicated is another critical aspect for the successful implementation. This is typically referred to as the models? generalizability, which describes the extent to which a model?s metrics remain consistent beyond the specific conditions and data used when training the algorithm.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Despite the pivotal role of understanding whether a model can be transferred or replicated and how well it would perform, only a handful of studies touched upon the replication of machine learning models16ÿor their transfer17?24ÿacross different hospitals. Even a smaller fraction of the studies attempted to replicate their findings internationally25?28. Particularly, the successful transferability of algorithms appears to be highly domain-specific. However, within the mental health domain, especially in the context of predicting significant events and crises, these vital aspects of transferability and applicability, in large part, remain uncharted. Moreover, clinical prediction models have been increasingly criticized for their illusory generalizability and for underperforming when applied out-of-sample29.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"In this study, we directly address this gap by exploring whether and how a UK-derived predictive algorithm can be effectively transferred and replicated in a US hospital context. Our prior research13,14, in a single test-bed, has demonstrated the efficacy of ML-based prediction of mental health crises 28 days ahead, utilizing EHRs from the Birmingham and Solihull Mental Health NHS Foundation Trust, a UK-based public healthcare provider. Herein, we investigate the feasibility of applying a UK model within a US healthcare environment, assessing its performance, and exploring potential enhancements through algorithm calibration to new data unique to the US. Given the multitude of approaches when defining a mental health crisis and the lack of global consensus across hospitals30, the target variable needs to be defined locally with each clinical provider. To thoroughly explore the transferability and replicability of our approach, we deploy and evaluate six discrete models, each delving into varying calibration strategies and feature sets?both structured data and language-based features. These models and features were created following standard ML techniques, advancing said techniques remains out of the scope of this study.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"This manuscript targets the challenges and resolutions inherent in replicating and transferring ML models across different healthcare systems, pushing for a shift towards a more global application of ML in psychiatry. Our work aims to bridge the theoretical, often siloed, AI potential and its practical utility in diverse, real-world healthcare settings transcending geographical or operational boundaries.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Machine learning models using features and methods developed on EHR data from the Birmingham and Solihull Mental Health NHS Foundation Trust (UK) were transferred, and their performance was evaluated on EHR data from the Rush University System for Health (US).",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The dataset from the UK healthcare provider included data from both inpatient and outpatient visits, as well as various patient interactions, such as telephone calls. In contrast, the EHR dataset from the US healthcare provider solely comprised inpatient data. These differences significantly impact the level of data granularity available within each setting, posing a considerable challenge to the replicability of features and prediction models. Figureÿ1ÿprovides a visual representation of these disparities, offering an illustrative example of how a patient?s data may differ depending on which healthcare provider collected it.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The process of transferring and replicating Machine Learning models across the two healthcare settings is depicted in Fig.ÿ2. Two machine learning models trained in the UK healthcare system, UK Original, and UK Tuned, were transferred and evaluated for crisis prediction on US data, with the latter being further tuned on US data before evaluation. Another model, UK retrained, was trained on US data using a set of features designed for the UK system, which were then replicated using the US dataset. Finally, three new models were trained using novel feature sets tailored to the US dataset, replicating the methods used in the UK model development. Note that the replicated methods encompass the definition of modeling setup, aimed at predicting mental health crisis in the following 28 days, as well as the feature creation, both in terms of their outer structure (weekly basis) and the aspects of the patient?s journey that they cover (e.g., diagnosis, hospitalization, etc). Supplementary Tableÿ1ÿdetails, for each machine learning model, whether they were transferred or replicated and, if the latter, the level of replication.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The study cohort comprised of patients hospitalized at the Rush University System for Health (USA) during 2018, 2019, and 2020. Patients, aged 16 and older with a history of mental health crises, having had at least one crisis episode, were included in this study. This yielded a study cohort containing records from 2907 unique patients aged between 16 and 100 years, with both genders being well represented (54.5% males, 45.5% females). Patient and crisis episode distribution by age, gender, and race are described in Tableÿ1, for both the US study cohort and the UK cohort originally used for the algorithm?s development. Crisis episodes were defined as a sequence of crisis events preceded by one full week of stability, without any crisis occurring.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Six machine learning models were developed to predict mental health crises up to 4 weeks in advance, either relying on a set of features developed in the UK (UK Original, UK Retrained, UK Tuned models) or on an extended set of features, some of which derived from medical Concept Unique Identifiers (CUIs), developed in the US (US Structured, US CUI tf-idf, US CUI LDA models). The models using UK features were either trained on UK data (UK Original model), on US data (UK Retrained model), or on a combination of both (UK Tuned model). The models using the extended set of features were solely trained on US data using either structured features (US Structured model) or a combination of structured and unstructured features (US CUI tf-idf, US CUI LDA models).",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The set of features developed in the UK consisted of 30 features describing mental health diagnosis, the most recent crisis and hospitalization, contacts, referrals, and demographic information. These were replicated on the US dataset, with 22 of them being computed exactly, 4 of them being approximated, and 4 of them not having the necessary input to be computed and were left as missing values during the modeling phase (Supplementary Tableÿ2).",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"An extended set of features was created from US data, with 87 structured features describing diagnosis, the most recent crisis and hospitalization, interventions and discharge information, and demographics (Supplementary Tableÿ3). Additionally, model-specific unstructured features were used in the predictions by US CUI tf-idf and US CUI LDA.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Mean ranking metrics over the test set weeks for each of the models considered are presented in Tableÿ2. All models were statistically significantly better than the baseline, which determines patients? risk scores based on the number of weeks since the most recent crisis episode, according to the area under the receiver operating characteristic curve (AUROC), with all comparisons yieldingÿp-values <0.001. Moreover, the models that rely on US data for training outperform the UK Original model, trained solely on UK data. The model with the highest AUROC and area under the precision-recall curve (AUPRC) is US CUI tf-idf, showing statistically significant improvements in AUROC against all other models (p-values?<?0.05). All pairwise statistical comparisons between models are in Supplementary Tableÿ4. The receiver operating characteristic (ROC) curves for UK-based models and US-based models can be found in Fig.ÿ3.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"If we only consider those models that were only trained on structured data, UK Tuned is the model that has the highest performance in all ranking metrics, although US Structured?s metrics are comparable. It also tops the metrics that only consider the top 100 patients.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"As the AUPRC can also be interpreted as the average ranking precision, one can use the target prevalence as a useful benchmark. The overall prevalence of the target variable, which indicates a patient will have a crisis in the next 4 weeks, was 1.10%. The prevalence was 1.24%, 1.05%, and 0.91% in the training, validation and test sets, respectively. As the prevalence of the target in the test set is less than 1% then a random ranking of the patients would yield an AUPRC of less than 0.01, which is 5 to 8 times smaller than the AUPRC of the trained models. If we consider the values of Precision@top100, then we expect to flag 7 to 8 patients (except with UK Original) who will have a crisis in the next 4 weeks, in comparison with a single patient if any 100 patients are selected. The precision-recall curves for UK-based models and US-based models can be found in Fig.ÿ4.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Classification metrics are presented in Table 3. The cutoff point was selected in each case to be around 85% specificity in order to maintain a 15% false positive rate across models while comparing their sensitivity, precision, and F1 scores. The US CUI tf-idf model performed the best according to all classification metrics at 85% specificity, achieving almost 70% sensitivity.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"We used SHAP values31ÿto assess the contribution of each feature to the models? output and find the most important features. The features that had the greatest influence on the predictions across all models were ?Weeks since last crisis? and ?Number of crisis episodes?. Moreover, patient?s ?Age? and some diagnosis features were found to be important features in all models, particularly ?F0 organic disorders? and ?F1 substance abuse.?",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Among the top 20 features of the UK Original model, 4 exhibited a constant value on US data: ?Never hospitalized?, ?Weeks since last referral from acute services?, ?Weeks since last discharge category internal? and ?Weeks since last contact not attended?. Regardless, the model is using them for making predictions on the new dataset because it was trained in a different system where the features were useful predictors of mental health crises. By fine-tuning the model with the new data, new trees are learned to correct the bias carried from the previous system that does not apply to the new system?s data. For instance, the second most important feature of the UK Tuned model becomes ?Number of crisis episodes"" (which was the fifth most predictive for UK Original), and some new features show up as highly predictive, such as ?Week sine? and ?Week cosine?, which encode information about the time of the year, while the impact of the less relevant features on US data is diminished. Nevertheless, the model does not ?unlearn"" the trees that were trained on the original dataset, which preserves the generalizability of the model to both datasets.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"When US-specific features were incorporated, ?Weeks since last crisis? and ?Number of crisis episodes? remained at the top 5 most important features, but a large portion of the most predictive features are specific to the US-based models. Concretely, the other structured features that showed up as highly predictive include the patient?s primary and secondary diagnosis and the number of weeks since the last discharge. Importantly, when the CUIs were included, the model took them into account and they replaced most of the diagnosis features in terms of relevance. A potential reason for this is that the CUIs bring information about the treatment and symptoms that are related to a mental health crisis. For instance, ?Hallucinations, Auditory? and ?Aripiprazole? are related to schizophrenia, and ?Depakote? or ?Lithium? are medications given to patients with bipolar disorder. Supplementary Figuresÿ1ÿtoÿ6ÿshow the complete distribution of SHAP values for the top 20 most predictive features for each of the models.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"To our knowledge, this is the first study to demonstrate the transferability and replicability of machine learning models to predict mental health crises from EHRs across two very distinct healthcare systems. Moreover, the trained models demonstrated this transfer or replication could be done in various settings, depending on the availability of a previously trained model, historical data and resources for EHR analysis.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"In a setting where historical EHR data is unavailable for a particular hospital system, then a pretrained model can be transferred (UK Original), while if historical EHR data is available but no pretrained model exists (e.g., due to contractual reasons), then one can replicate the feature set and train a new model (UK Retrained). If both historical EHR data and a pretrained model exists then it is possible to combine both (UK Tuned), for increased performance. This method can potentially yield further performance improvements by leveraging data from more than two hospital systems.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Furthermore, it is possible to replicate the methods used to create new features and models (US Structured, US CUIs tf-idf, US CUIs LDA) for a new hospital system, provided the resources exist for this analysis. Doing the replication at the methodology level led to the best-performing model (US CUIs tf-idf) by leveraging clinical notes, but this approach consumes more resources and requires expert knowledge.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The inclusion of textual features computed from CUIs brought additional predictive power overall (AUROC?=?0.837, AUPRC?=?0.081), and achieved the highest classification metrics at 85% of specificity. This shows that textual features demonstrate potential for predicting mental health crises, and it is plausible that a model incorporating these features if trained on an even larger set of patient data and hospital-specific tuning, could offer clinically relevant improvements. The preprocessing step that converts clinical notes into CUIs simplifies the process of replicating the model from one hospital to another since it standardizes textual data into a set of concepts that are uniquely identified.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Overall, ranking metrics for all models (AUROC 0.799?0.837) replicated the results from previous studies on the prediction of mental health crises13,14,32,33ÿ(AUROC 0.702-0.865). As for the classification metrics, we opted to set the specificity level at 85% and obtained sensitivity values in the range 55.4?67.6%, which are in line with the sensitivity of 58% from our previous work13, and higher than the sensitivity level of 14.0?29.3% reported in the prediction of crisis associated with depression32ÿ(albeit at a higher specificity level). The precision values, and consequently the F1 score values, obtained are lower than those in other studies32,33ÿ(Precision 0.10?0.65, F1 score 0.15?0.65), likely due to the high imbalance in our dataset.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The low precision values should not hinder the clinical use of our models as they are driven by the high number of false positives, in comparison to the number of true positives. Monitoring or contacting a patient that ends up being a false positive (i.e., does not have a crisis in 4 weeks) won?t be harmful for the patient and can, in fact, be beneficial for their mental health condition. The main drawback is the allocation of resources that could have been used toward a higher-risk patient.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The main limitation of this work concerns the definition of a mental health crisis. Depending on the hospital system, this may or may not already exist, and even when it does exist, it can vary from one system to another. If a definition does not yet exist, then it needs to be created based on the EHR data available at that hospital and the inputs from clinical practitioners locally. Another limitation is related to the variability of EHR datasets. EHRs can vary in terms of granularity, level of detail, length of patient history, etc., and the transferability or replicability of a prediction model might be more variable if the two systems differ more significantly. In this study, one significant difference between the EHR systems was their granularity. While the UK dataset included both inpatient and outpatient records, the US dataset only included inpatient records. It is paramount that these sorts of differences are evaluated in practice, both during and after the implementation of a model such as the one described in our work34. Finally, we note that the study period overlapped with the COVID-19 pandemic, in particular for the periods of time used in the validation and test sets. During the COVID-19 pandemic, there was a decrease in acute medical service use that was not directly connected to the pandemic, including the utilization of mental health services.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Importantly, the results achieved by UK Tuned are indicative that a model trained with a carefully selected set of features in a large pool of patients can be brought to a smaller hospital; moreover, with moderate tuning can achieve comparable or even better results than starting the feature extraction process from scratch. This opens the door to scaling the model into multiple hospitals while reducing the time dedicated to feature extraction and modeling. Moreover, the use of various EHR data sets, with different characteristics, for modeling can also help uncover those underlying patterns that are common to mental health crises across hospital systems while minimizing the effect of spurious correlations.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The findings from this paper have significant clinical implications. As we move toward precision medicine approaches for psychiatric spectrum conditions, there is significant potential value and cost savings in crisis prediction and the potential for early intervention in crisis pathways. Imagine a scenario where a patient is getting more depressed and at risk for suicide, and the algorithms alert a care management team to reach out to this patient as the trajectory begins rather than waiting for the event to take place.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"This approach has already been validated via a prospective study in a hospital setting13, with clinically valuable outcomes. In practice, a ranked list of patients is provided to a clinical team, on a regular basis (e.g., weekly and monthly), sorted according to the risk provided by the machine learning model. Benefits of such a tool include better caseload management and clinical decision-making which may lead to better patient outcomes and reduce a health provider?s costs35,36.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"This project also highlights the value of data embedded within EHR systems. The next frontier will move toward the integration of this data with personal and mobile data sources that have shown important potential to track depressive symptoms37?41. The convergence of these approaches has the potential to help us create systemic approaches to population management of high-risk and high-cost conditions like depression. Moreover, on the machine learning aspect, the integration of multiple EHR systems can be leveraged by using privacy-preserving approaches that can train a single model while keeping data decentralized, including federated learning42,43.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The study examined anonymized EHRs collected from patients hospitalized at the Rush University System for Health (USA) between January 2018 and December 2020. The EHRs contained demographic information, hospitalization records, and anonymized patient notes. The model and methods were originally developed on EHRs by the Birmingham and Solihull Mental Health NHS Foundation Trust (UK).",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Unstructured data (i.e., progress notes, reports, consultations) were processed through a data pipeline using Apache Clinical Text Analysis and Knowledge Extraction System (cTAKES)44ÿindexed against the National Library of Medicine?s Metathesaurus. This reduced all of the vocabulary to a set of Concept Unique Identifiers (CUIs) that link to medical terms and thereby removed Protected Health Information (PHI) like patient names. The temporality of these CUIs relative to the notes was retained and maintained for analysis. Structured data elements were extracted, and the date shifted to remove PHI.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The EHR data were processed into features at a weekly level, per patient, resulting in a total of 237,424 patient-weeks. Patient weeks during which a patient was in crisis were excluded since the patient was already being appropriately monitored at the hospital, and deceased patients were excluded once their death was recorded. Moreover, the first six weeks and last 6 weeks of the dataset were also excluded, to account for the date shifts applied as part of PHI removal. As such, the information from those weeks was potentially incomplete.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The processed dataset was split into training, validation and test sets, chronologically, as follows: the training set contains the weeks between week 7 of 2018 and week 48 of 2019; the validation set contains weeks 1 to 18 of 2020; and the test set contains weeks 23 to 40 of 2020. The 4-week gaps between the sets were chosen to avoid data leakage, since the prediction target has information about the following four weeks of a patient.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Crisis events were defined as either an admission (or transfer) to a psychiatric unit, an intervention due to suicide, or a specific psychiatric diagnosis (Supplementary Tableÿ5). Note that these diagnoses were recorded and associated with a hospitalization, where the diagnosis served as a descriptor of a crisis event. Moreover, changes in diagnosis were prompted by additional events that led doctors to establish a new diagnosis, often accompanied by a transfer to another service within the hospital. The list of relevant diagnoses was defined in a comprehensive manner. These are diagnoses events that would either merit inpatient hospitalization or require a one-to-one sitter in the hospital setting due to their acute nature.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Crisis events tend to occur in quick succession, and patients are often closely monitored after one happens. For example, in New York, state guidelines recommend that patients have a psychiatric aftercare appointment scheduled within seven calendar days following discharge45. Therefore, we cluster related crisis events into a single crisis episode, defined as a set of crisis events preceded by one full week of stability, without any such events. Correspondingly, the target of our analysis is to predict whether the onset of a crisis episode, which is the initial event of the episode, will occur during the following 4 weeks.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,The study was approved by Rush University?s Office of Research Affairs?s institutional review board. The need to obtain consent was waived due to the exclusive use of anonymized data that cannot be linked to any individual patient.,,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Two types of features were extracted from the EHRs: structured features, from five data tables (Supplementary Tableÿ6), and unstructured features, from patient notes.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"To build the structured features, a set of 30 features developed in the UK was replicated using US data (UK feature set), and then expanded with the information available in the US dataset. A total of 87 structured features were obtained and, after feature selection during the modeling phase, 57 of them were selected (Supplementary Tableÿ3). This set of features (US structured feature set) can be broadly categorized as follows (with the number of features in the category in parenthesis):",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Primary Diagnosis (17): Describing existing patients? primary diagnosis using the ICD-1046ÿcode system and grouped by the first two characters of the code (e.g., F3 for Mood: mood (affective) disorders), as well as the time elapsed since the most recent diagnosis in each group;",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,Secondary Diagnosis (16): Similar to the ones in the Primary Diagnosis set but calculated with respect to patients? secondary diagnosis;,,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Additional Diagnosis (9): Including features about dual diagnosis as well as statistics on the number of previous diagnoses, both primary and secondary (e.g., the total number of previous primary diagnoses);",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Last Crisis/Hospitalization (6): Describing the most recent crisis/hospitalization (e.g., length of hospitalization during the most recent crisis);",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Intervention (4): Describing interventions done during previous hospitalizations (e.g., number of days with an intervention due to risk of suicide);",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,Demographics (3): Including gender and age features; and,,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,Discharge (2): Comprising features that describe the time elapsed since the most recent hospital discharge and discharge from a psychiatric unit.,,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Patient notes were anonymized before analysis using the Apache cTAKES pipeline, in which Concept Unique Identifiers describing each note were automatically generated. Unstructured features based on CUIs were then extracted using two different statistical methods: term frequency-inverse document frequency (tf-idf) and Latent Dirichlet Allocation (LDA).",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The tf-idf method assigns a weight to each CUI, per document (corresponding to a hospital visit), depending on the frequency of the CUI in the document, as well as the number of documents containing that CUI. In total, 70,259 unique CUI were extracted from patient notes. To select the most important CUI for the study cohort a three-step approach was used: first, select the 3,000 most common CUI and train a tf-idf model using the whole hospital cohort; second, filter the 10 most important CUI per patient in the study cohort, and compute the 100 most common CUI overall, across the study cohort (Supplementary Tableÿ7); finally, the tf-idf algorithm was applied to the patient notes in the study cohort, restricted to the CUI selected in the second step.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Using the LDA method, a list of twenty topics was constructed by grouping the CUI that more commonly appear together in a patient note. A topic contains a series of CUI, and a CUI may be present in more than one topic (Supplementary Tableÿ8). Each patient note is represented by the matching weights between the note and each topic. The number of topics was selected to optimize a coherence metric based on theÿcvÿmeasure47.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"All crisis prediction models are ensemble models trained using the eXtreme Gradient Boosting (XGBoost)48ÿalgorithm, an implementation of Gradient Boosting Machines49. In addition, a baseline model was constructed by scoring the patients on a weekly basis, based on the last time they had a crisis episode. Below are the descriptions of all models analyzed in this study:",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Baseline: Heuristic model that scores patients based on the number of weeks passed since the last crisis episode, the risk score assigned is equal toÿ1?#weekssincelastcrisis??, whereÿMÿis the maximum number of weeks since the last crisis episode, taken over all patients;",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,UK Original: Trained on the UK dataset using the UK feature set;,,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,UK Retrained: Trained on the US data set using the UK feature set. Hyperparameters tuned using the validation set;,,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"UK Tuned: Trained on the UK dataset using the UK feature set, subsequently tuned on the US dataset. Hyperparameters tuned using the validation set;",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,US Structured: Trained on the US dataset using the US structured feature set. Hyperparameters tuned and feature selection performed using the validation set;,,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,US CUI tf-idf: Trained on the US dataset using the US structured feature set combined with tf-idf features. Hyperparameters tuned using the validation set; and,,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,US CUI LDA: Trained on the US dataset using the US structured feature set combined with LDA features. Hyperparameters are tuned using the validation set.,,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"All models except UK Original were trained (or tuned) on the training set, had their hyperparameters tuned on the validation set, and were ultimately trained a final time on both the training set and validation set combined with the best set of hyperparameters. UK Original is a model trained on the UK dataset and tested directly on US data. A particular case is the UK Tuned model, which is an instance of UK Original that was further tuned on US data using the same hyperparameters as UK Retrained. Every model was evaluated on the testing set and their output is a predicted risk score (between 0 and 1) indicating the likelihood of a crisis in the following four weeks.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"The Bayesian optimization algorithm called TreeParzen estimator50, implemented in the Python library Hyperopt51, was used to select the best set of hyperparameters. For each of the models, 50 rounds of hyperparameter search were run, optimizing the AUROC on the validation set. As part of this process, for the US structured model, we performed feature selection by grouping the features in categories and added a binary parameter to select the feature or not in the hyperparameter space provided to Hyperopt. See the hyperparameter space explored in Supplementary Tableÿ9ÿand the final set of hyperparameters selected for each model in Supplementary Tableÿ10.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"Two distinct sets of metrics were used to evaluate the model?s performance on US data, ranking metrics, and classification metrics. The ranking metrics were the primary metrics as the prediction model is meant to provide a ranked list of patients by likelihood of having a crisis in the near future, at a weekly level. These metrics include the AUROC, AUPRC, precision@top100, and recall@top100, where the precision and recall of the model are computed based on the top 100 patients of the ranked list. The AUROC and AUPRC provide an aggregate measure of performance across all possible classification thresholds, based on the tradeoff between sensitivity (how accurately crisis is predicted) and specificity (how accurately non-crisis is detected), and between precision and recall respectively. As secondary metrics, we considered four classification metrics: sensitivity, specificity, precision, and F1 score.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"All metrics were computed on a weekly basis, and the reported results correspond to the average across all weeks within the test set. To compare the models, statistical significance was assessed using the DeLong test52.",,,,,
Transatlantic transferability and replicability of machine-learning algorithms to predict mental health crises,"SHAP values31ÿwere used to measure the contribution of each feature to the models. In particular, we applied the TreeExplainer algorithm, a technique developed to interpret at a local level tree based Machine Learning models through additive feature attribution53. This method was run on each trained model and the feature attributions were computed for each prediction in the test set, assigning a numerical score per feature corresponding to the feature?s influence in the predicted value. The most predictive features for each model were selected based on the average absolute SHAP values across predictions in the test set. The distribution of SHAP values on the test set corresponding to the 20 most predictive features is illustrated in Supplementary Figs.ÿ1?6.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"There are numerous papers focusing on diagnosing mental health disorders using unimodal and multimodal approaches. However, our literature review shows that the majority of these studies either use unimodal approaches to diagnose a variety of mental disorders or employ multimodal approaches to diagnose a single mental disorder instead. In this research we combine these approaches by first identifying and compiling an extensive list of mental health disorder markers for a wide range of mental illnesses which have been used for both unimodal and multimodal methods, which is subsequently used for determining whether the multimodal approach can outperform the unimodal approaches.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"For this study we used the well known and robust multimodal DAIC-WOZ dataset derived from clinical interviews. Here we focus on the modalities text and audio. First, we constructed two unimodal models to analyze text and audio data, respectively, using feature extraction, based on the extensive list of mental disorder markers that has been identified and compiled by us using related and earlier studies. For our unimodal text model, we also propose an initial pragmatic binary label creation process. Then, we employed an early fusion strategy to combine our text and audio features before model processing. Our fused feature set was then given as input to various baseline machine and deep learning algorithms, including Support Vector Machines, Logistic Regressions, Random Forests, and fully connected neural network classifiers (Dense Layers). Ultimately, the performance of our models was evaluated using accuracy, AUC-ROC score, and two F1 metrics: one for the prediction of positive cases and one for the prediction of negative cases.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Overall, the unimodal text models achieved an accuracy ranging from 78% to 87% and an AUC-ROC score between 85% and 93%, while the unimodal audio models attained an accuracy of 64% to 72% and AUC-ROC scores of 53% to 75%. The experimental results indicated that our multimodal models achieved comparable accuracy (ranging from 80% to 87%) and AUC-ROC scores (between 84% and 93%) to those of the unimodal text models. However, the majority of the multimodal models managed to outperform the unimodal models in F1 scores, particularly in the F1 score of the positive class (F1 of 1s), which reflects how well the models perform in identifying the presence of a marker.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"In conclusion, by refining the binary label creation process and by improving the feature engineering process of the unimodal acoustic model, we argue that the multimodal model can outperform both unimodal approaches. This study underscores the importance of multimodal integration in the field of mental health diagnostics and sets the stage for future research to explore more sophisticated fusion techniques and deeper learning models.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"This work expands upon Spruit et al. [1]ÿ?Exploring language markers of mental health in psychiatric stories?ÿas a main source of inspiration for our unimodal text model, both in regards to the methodology and in identifying language markers for various mental health disorders. Furthermore, Cho et al. [2]ÿ?Review of Machine Learning Algorithms for Diagnosing Mental Illness?ÿprovides a thorough review of various machine learning algorithms in the field of diagnosing mental health disorders. According to their review, SVM and RF clearly outperformed simpler models like Na?ve Bayes and KNN during this diagnosis. The authors claim that the SVM model has been employed before for all domains in mental health and it has been revealed that it normally achieves more that 75% accuracy. Other relevant works to support our selection of baseline classifiers were [3?7]. Specifically, the study performed by Assan et al. focused on the detection of depression by exploring a big range of machine learning classifiers. Among the various explored machine learning classifiers, SVM, Random Forest and Logistic Regression were also examined [6].",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Concerning the feature extraction, papers [1,ÿ3,ÿ6,ÿ8?10] demonstrated the strengths of Linguistic Inquiry and Word Count (LIWC) for the text model. LIWC is a toolkit of Natural Language Processing (NLP) techniques to calculate the number of words of certain categories that are used in a text based on a dictionaryÿ[1,ÿ33]. Similarly, other related works (e.g. [11?13]) extracted GloVe embeddings and Mel-Frequency Cepstral Cooefficients (MFCCs), for the text and audio models, respectively. The GloVe model is a well known vector space representation of a global word-word cooccurrences matrix [34], while MFCCs are well known for their ability to detect emotions from acoustic signals [35].",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Another interesting research was performed by Yazdavar et al, who present the positive values of early fusion, where features from different modalities are concatenated into a single feature vector as input for a model. Specifically, they explain how early fusion is less computationally expensive than late fusion and how their model reduces the learning effort and has shown promising results [3]. A recent comparative analysis of early versus late fusion for multimodal prediction models also demonstrates that early fusion is the best option with model knowledge [36].",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"In Tableÿ1, we are presenting our findings with regards to mental health markers that can be identified from textual data. The identified markers are applicable to a wide range of mental disorders, as has been shown in the listed studies. This comprehensive list of language markers were gathered through an extensive research and literature review.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Similarly, Tableÿ2ÿpresents the most prominent speech markers for various mental disorders that have been studied in the respective listed papers (Sources) which we identified through an extensive research and literature review.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"The identified linguistic and acoustic markers were systematically derived from previous empirical studies on the particular field. Each of these studies examined how specific features in these two modalities correlate with underlying mental health illnesses. Based on all of these related works, which are cited in Tablesÿ1ÿandÿ2, the identified markers were selected based on their ability to capture fundamental symptoms and behavioral characteristics associated with each mental health disorder. For instance, schizophrenia-alike disorders are linked to disorganized speech patterns and a lack of coherence, which match with the disorder?s characteristic cognitive disturbances. Similarly, markers such as self-focused language (increased use of first-person singular pronouns) in depression reflect an increased self-focus, which has been proven to be a common depressive symptom. In the case of the speech modality, acoustic features, such as reduced pitch variability in major depressive disorder or heightened jitter and shimmer in anxiety disorders, have been previously identified as indicative of the psychomotor and physiological changes that often accompany these conditions. By identifying these markers, researchers aim to map observable speech and language features with the cognitive, emotional, and neurological dysfunctions that are characteristic of each mental disorder. This connection not only enhances our understanding of the clinical presentation of these conditions but also provides a foundation for the development of objective, speech-based diagnostic tools. Each marker is considered relevant because it taps into key symptomatic domains of the disorders, as demonstrated through robust statistical analyses and cross-study validations in our literature. This is the first comprehensive overview of Linguistic and Speech markers for Mental Health Disorders.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"The main objective of this paper is to study multimodal machine learning in regards to identifying mental health disorder markers, and consequently compare it with the involved unimodal approaches, in order to find out if the multimodal approach can outperform the unimodal ones. The marker identification is performed for a wide range of mental illnesses and to properly assess the performance of all approaches, we employ the four different machine learning models Support Vecor Machine (SVM), Random Forrest (RF), Logistic Regression (LR), and Fully Connected Neural Networks (FCNN, identified by ?Dense Layers?) (as baselines) and we evaluate their performances with four specific evaluation metrics. Moreover, to make the most out of this comparison, we perform an extensive feature extraction, including more than 150 textual and acoustic features (including the aggregated statistics). All source code of our experiments is publicly available on GitHub atÿhttps://github.com/George-Drg/Multimodal-vs.-Unimodal-approaches-for-identifying-mental-disorder-markers/tree/main.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Concerning our dataset, we managed to acquire theÿDAIC-WOZÿdataset, which is a set of clinical interviews designed specifically to help diagnose depression, PTSD and anxiety [32]. The dataset includes interviews taking place between a human-controlled, virtual interviewer called ?Ellie? and a number of real participants. Three modalities are present in this database, namely transcript, audio and video. Although, the list of mental disorders included is limited compared to ours, it is still the most suitable dataset that is publicly available.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"The dataset includes 189 recorded interviews, one corresponding to each participant, with an average length of 16 minutes. Specifically, the minimum and maximum voice recording lengths are 7 minutes long and 33 minutes long, respectively.The dataset included both the audio files and their corresponding transcripts. Pleasantly, the audio files were all standardized already at a sampling rate of 16 kHz. Moreover, the authors used theÿPatient Health Questionnaire 8ÿto assign some binary labels that classified the data with the presence or absence of depression. Another positive attribute of the dataset was that it came along with some extracted formant features.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"A downside ofÿDAIC-WOZÿis its relatively small size. Regarding this, it was unfortunate that we had to exclude one of the 189 samples, as it included a lot of noise to the point that neither noise reduction methods, nor external programs like Audacity could help fix it.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Regarding the DAIC-WOZ dataset, one can acquire it by applying for it through the official website, which falls under the ownership of the University of Southern California (https://dcapswoz.ict.usc.edu/).",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Having identified, through literature research, a variety of mental illnesses? markers and having acquired the dataset, the next step was to create three different models, one unimodal text model, one unimodal acoustic model and one multimodal model that combined both. This setup would enable the comparison between the unimodal and multimodal approaches. For the sake of a fair comparison, we trained the same machine learning models (i.e. SVM, Random Forest, Logistic Regression and a FCNN (Dense Layers)) through each approach and we evaluated their performance using four particular evaluation metrics, namely accuracy, AUC-ROC score and two variances of the F1 score (F1 of positive cases (F1 of 1s) and F1 of negative cases (F1 of 0s)).",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"In Fig.ÿ1, the left flowchart illustrates the methodology that we followed for the text model from this point on.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"The first step was to choose what features would be extracted, in order to preprocess the data accordingly. On that note, the selected features for the text model includedÿLinguistic Inquiry and Word Count (LIWC)ÿcategories,ÿGloVe embeddings, K-means clusteringÿandÿPart of Speech Tags (POS-Tags) counts.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,LIWC is a well known analysis tool within the field of cognitive psychology to analyze texts linguistically.,,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Given the structure of the transcripts available by the DAIC-WOZ dataset, where the speaker is identified in the ?speaker? column (can be either ?Participant? or ?Ellie?, the virtual agent), we modified the script so that it selectively kept only the responses given by the participant. Then, we concatenated all the responses of a single participant in a single string; this way we ended up with 189 strings with an average length of 7306 words. Moving on, to address clustering, we performed the elbow method to determine the optimal number of clusters for our data [30]. Given a range of cluster numbers, this method plots the sum of squared distances of samples to their closest cluster center. Then, by examining the plot, we identified that point in which the decrease acutely changes, similar to looking at an elbow at a ninety degree hold. The particular point is the one that most often represents the optimal number of clusters. The resulting plots indicated that the most suitable number of clusters is either 4 or 5, where the inertia showed the smallest decrease.ÿFurthermore, we confirmed the optimal number of clusters found using the Elbow method with the Silhouette method [31]. Finally, the text preprocesing that was done for the GloVe vectors involved the removal of english stopwords, tokenization and lower-casing.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Once the transcripts were processed, we performed feature extraction. Since the LIWC analysis provides scores for a wide range of categories and not all of them are relevant to our objective, we decided to map the categories with the identified markers and proceed only with the relevant ones. Tableÿ3ÿillustrates this mapping process and the selected categories.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"?<Not mappable>? refers to some language markers that could not be correlated to a specific category and we are including them in the table only for demonstration purposes. Moreover, since this table provides only a sample of the mental illnesses included in our research, some other relevant categories are not present. This refers to theÿanx, we, you, they, bioÿandÿrelativÿcategories.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"The LIWC features, particularly, were present in every study that was related with the combination of text modality and mental health disorders. The overall purpose of these features is analyzing word use on semantic, emotional and syntactic levels. LIWC provides categorical scores based on predefined dictionaries and it offers linguistic and psychological context of words.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"In the case of clustering, each of the created clusters represents a group of texts that have similar LIWC metrics with each other. Using the average values of these metrics as our criterion, we deduced the dominant characteristics of each cluster?s text segments. At this point, the extracted information can be used for both comparative analysis (for instance, noticing that a cluster has significantly higher scores in posemo (positive emotions) can mean that it has a more positive tone compared to others) and for contextual understanding (i.e. drawing hypothesis or identifying patterns based on what the clusters represent). The particular figure (Fig.ÿ2) illustrates the comparison of average scores across different LIWC categories for the four identified clusters (0, 1, 2 and 3). For a certain cluster, each bar shows the normalized average score within a particular LIWC metric. For instance, by observing the scores on the ?sad? category, it is noticeable that clusters 0 and 2 display negative average values, indicating a lower presence of language associated to sad themes. Cluster 1, on the other hand, shows an exceptionally high average score, which suggests that the participants or text samples within this cluster are more involved with sadness-related themes and language. The ?negemo? category displays a similar trend, where cluster 1 shows one of the highest positive averages. This alignment indicates that the contents of cluster 1 are notably more negative compared to the other three clusters. Overall, the figure highlights how the four distinct clusters differ in their emotional and linguistic patterns and it is shown that cluster 1, specifically, consistently scores higher in categories such as ?sad? and ?negemo?, which are associated with negative affect.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"For the GloVe embeddings features, first we downloaded a pre-trained GloVe model, particularly the 100-dimensional (100d) GloVe model, which not only offers a good balance between providing sufficient semantic detail for nuanced text analysis and being computationally efficient (not intensive like the higher-dimensional models), but also provides enough depth in the word embeddings without overfitting. The model we selected isÿWikipedia 2014 + Gigaword 5ÿthat covers a broad range of topics with additional diversity, which is essential in capturing embeddings with terms relevant to mental health contexts. Then the GloVe embeddigns are loaded into python by creating a dictionary, where the keys are words and the values are the corresponding vector representations. GloVe embeddings are especially useful when working with machine learning models, since they can not only improve the model?s performance but also perform dimensionality reduction. Hence, in the context of identifying language markers for mental disorders, GloVe embeddings can be used to perform a more nuanced and morphological analysis of the used words. Their value is also proven by their presence in a big number of related work papers.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"In order to complement our feature set further, we also extracted some information on relevant POS-tags. More specifically, we applied tokenization and part-of-speech (POS) tagging in the cleaned text files, using theÿnltkÿpackage. Through this, we downloaded the necessary components for tokenization and POS tagging. Tableÿ4ÿshows the selected POS-Tags counts that we used in this study.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Furthermore, apart from the relevant tag counts (Tableÿ4), we also extracted counts for first-person singular, third-person singular and third-person plural pronouns, since this categories are particularly relevant to this research (refer to Tableÿ5).",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"The inclusion of POS-Tag counts as features was a novel addition from our side. Unlike the previous linguistic features, the particular features do not have an established clinical basis within the existing literature on mental health disorders. However, based on our review, we observed that certain mental disorders are frequently associated with linguistic markers such as self-focused language or the use of third-person plural/singular pronouns. Therefore, we hypothesized that including a feature that can keep track of and count the pronoun instances could enhance our ability to capture these patterns and provide valuable insights to our research.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"With feature extraction complete, the next step was to normalize our features, in order to ensure a consistent scale and consequently improve the comparability of the data. This entails making the data more homogeneous and possibly revealing new patterns in the data that weren?t evident before. For the normalization task, we applied Z-score normalization, also known as standard scaler or standard normal distribution. This method is a specific type of probability distribution that standardizes the data to have a mean of 0 and a standard deviation of 1 for each feature.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"As part of our research for identifying potential mental disorder markers, we had to create a binary label that would serve as an indicator of our models? performance. Hence, we designed an intuitive and pragmatic labelling process, which emphasizes practicality and common sense to establish a scientific baseline. In order to cover for any lacking points and to fortify its validity, we performed a long series of experiments before creating the final set of binary labels. For this process we used our main dataset (DAIC-WOZ) and we focused on the majority of the mental disorders studied in this paper (i.e. Depression, Bipolar Disorder, Schizophrenia, PTSD and even ASD).",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"The first step was to revisit Tableÿ3ÿand select particular LIWC categories by narrowing down to the most relevant items. The selected categories includeÿanx, bio, cogproc, death, i, negemo, posemo, relig, sad, socialÿandÿthey. The plan was to create a set of thresholds that would help us to classify between the presence or absence of a marker based on whether the value of a threshold is exceeded or not. To discern the optimal values for the LIWC categories? thresholds we extracted the statistical summaries and created the distribution plots for each chosen LIWC category. By observing and comparing those normalized categorical scores, along with studying each category?sÿSkewnessÿandÿKurtosis, we created the first experimental sets of thresholds. For instance, if category ?sad? had a mean value of 1.8 then we created its threshold accordingly. Knowing the skewness (asymmetry of the distribution) and kurtosis (mean outliers) also played a big part in setting thresholds. It helped ensure that the marker identification criteria are not only based on central tendency but also on the distributions? tails. Particularly for categories with high values on these two measures, setting thresholds to capture extreme values ensures that the labeling process is more likely to identify instances that stand out significantly from the norm.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Utilizing all the information obtained up to this point, we created 10 initial threshold sets. Some of the sets were sensitivity focused, meaning that they had lower thresholds that aimed to capture even less obvious cases and other sets were more specificity focused, meaning that they were stricter and aimed to capture the more extreme cases. Tableÿ6ÿillustrates the first experimental sets and the ?Marker Presence? column refers to the percentage of samples that were flagged as including a language marker.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Before refining our thresholds, we examined the previously assigned PHQ-8 binary labels. Although, those labels are particularly focused on depression only, we used them as a baseline. The PHQ-8 labels had flagged approximately 30% of the samples as diagnosed with depression and we considered this percentage a good balance between positive and negative cases. As such, we aimed to created a set of thresholds that not only balanced sensitivity and specificity but also achieved a marker presence label assignment close to 30%. On that regard, seeing how Set 8 (from Tableÿ6) achieved the closest marker presence percentage to the PHQ-8 labels, we used it as our new baseline and created 5 more threshold sets. Tableÿ7ÿpresents the characteristics of the refined sets. With a marker presence of 31.7%, we selected set 15 for our labeling. The refined composite set?s alignment with the known prevalence suggests that it effectively captures a realistic proportion of instances with potential markers, indicating its thresholds are well-calibrated. In Tableÿ8, we present the values of the final threshold set.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Category ?i? has the lowest threshold because of its lower distribution. Categories ?social? and ?cogproc? have a dual threshold. Lower values on ?social? aimed to capture potential social withdrawal and upper values aimed to capture potential excessive social referencing. Similarly, lower thresholds in ?cogproc? aimed to capture disorganized thinking (for instance, for schizophrenia) and upper thresholds aimed to capture higher cognitive processing (for instance, overthinking in the case of OCD). In further research we will further investigate and validate this binary label creation process.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Since our complete textual features set consists of more than 150 features, which is a huge number considering the dataset?s size, we decided to use a wrapper method and select the most optimal features. We proceeded with theÿRecursive Feature Eliminationÿ(RFE) approach, which, as the name implies, works by recursively removing the least important features based on the weights of the model and then re-builds the model until the specified number of features is reached.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"In order to identify the optimal number of features and the most suitable predictive model for the selection of these features, we experimented by tuning various parameters. Tableÿ9ÿdemonstrates the parameters of these experiments.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Attempting to acquire a set of features that would eventually bring better results and that could potentially uncover some underlying patterns and relationships between features, we iterated over this process while tuning each of the parameters with respect to the recommended features subset and the modeling results achieved over each iteration. The first parameter was usingÿRFEÿorÿRFECV. The first one performs the feature selection given a fixed number of features to select (set by us), while the latter performs the selection using cross validation and finally recommends the best number of features (along with the corresponding top features names) as judged by the assigned scores. The selection process of these methods is performed on the training data, in order to avoid any information from the test set being leaked. This ensures an unbiased evaluation of the model?s performance. In both approaches we experimented both withÿLogistic Regressionÿand withÿRandom Forest. RFE (as well as RFECV) is a model-specific feature selection method. This means that the final set of features, proposed by the process, is influenced by the characteristics and requirements of the respective model and emphasizes on maximizing its performance. Then, for each predictive model we iterated five times, setting the number of features to 10, 15, 20, 25 and 30 (in the case of RFE).",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Then, the second parameter we experimented with was the inclusion or exclusion of re-scaling during the feature selection process. As seen at Tableÿ9, all parameter combinations were tested with and without additional scaling. Moreover, it can be observed that Random Forest isn?t? influenced at all by the presence or absence of re-scaling, while Logistic Regression provides completely different results in each case.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Every single features set was then evaluated through all of our machine learning models and we moved on with the set proposed by the best performing selector. In the case of the unimodal text model, this set was the one without cross validation, with re-scaling and that employed Logistic Regression as the classifier. Tableÿ10ÿpresents the top 20 features (unordered) selected by the feature selector with these parameters.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"As the left flowchart of Fig.ÿ1ÿillustrates, the final step of the unimodal text model?s methodology was testing the models? performance. To do that, we used the aforementioned features set as input to our four ML models and we evaluated its performance using the four predefined evaluation metrics.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"The methodology for the unimodal acoustic model follows tightly the unimodal text model?s methodology, which was just discussed.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Once again, the initial step of the methodology involves data preprocessing, and particularly noise reduction and audio file segmentation. First, we performed noise reduction, specifically spectral subtraction, on all our audio files. The particular noise reduction method works well for constant noise like hums or hisses, while still preserving the quality of speech. Then, to verify the method?s successful application, we used theÿAudacityÿsoftware and listened through 15 to 20 samples. Through this testing, we noticed thatÿaudio file #300ÿincluded a particular noise that couldn?t be cleared away, and hence it was removed from our dataset along with the corresponding transcript.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Once all of our audios were properly noise reduced, we segmented those files into smaller chunks, which would be more easily manageable and could potentially offer more nuanced information during the feature extraction process. Smaller segments allow for more precise calculations of features such as pitch, jitter, shimmer, and MFCCs, which can lead to a better understanding of the audio characteristics relevant to mental health markers. The segmentation was done based on volume and with the addition of some buffering. The reason why this segmentation method was selected is due to the fact that throughÿAudacityÿit was noticed that the participant?s speech was considerably louder compared to that of the interviewer. Additionally, the extra buffering was used so that the segmented chunks would include complete sentences and there wouldn?t be any loss of context.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Regarding the feature extraction, we used theÿlibrosaÿandÿpraat-parselmouthÿlibraries in order to extractÿpitch, jitter, shimmer, Harmonics to Noise Ratio (HNR), 13 MFCC coefficientsÿandÿenergy. Specifically, for jitter, we extractedÿjitter local, jitter ppq5ÿandÿjitter absoluteÿand for shimmer we extractedÿshimmer localÿandÿshimmer apq5. All of these features were extracted on the segment level, as feature extraction was applied on every single segment of every interview.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"On the other hand, the authors of the dataset had also provided the first five formant features, which were extracted on the interview level. Hence, at the early stages of this study we worked with two different sets of features; one at the interview level and one at the segment level. Regardless, in both sets we also extracted the mean, median and standard deviation statistics for every feature.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"The feature selection for the audio model was based on the proposed features throughout the literature and the related work. Moreover, as demonstrated by the marker tables in the ?Background? section, most of the extracted acoustic features have been identified as related with one or more mental disorders. Among all those features, pitch was one of the most popular with a presence percentage of about 90%. It has been described as a good indicator in mental health disorder identification, specifically for identifying emotional states or stress. The fundamental frequency F0 mean, which indicates the lowest frequency of the speech signal is perceived as pitch (mean, median). Jitter and shimmer were also very popular features across the literature review. Overall, jitter calculates the voice frequency?s stability and is often chosen as a measure for the detection of voice disorders or vocal pathologies. In short, jitter shows the variations in pitch. In the case of shimmer, it is actually an evaluation measure for the stability of amplitude in the voice. Like jitter, shimmer is critical in diagnosing and researching voice quality. Lower Harmonics to Noise Ratio (HNR) indicates a breathy, hoarse voice, which reflects reduced vocal clarity and is also associated with various mental illnesses. Finally, MFCC coefficients capture spectral features of the voice and have been used to identify disorders such as schizophrenia and PTSD, where vocal tract dynamics and speech patterns are affected.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Moving on, using the same formula as for the text model, we normalized all of our features (including the formants set) and their statistics. This offers consistency on the features? values and makes it easier to analyze and compare.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"In order to be able to compare all of our features and perform feature selection properly, we harmonized all features to the same unit of analysis, i.e. the interview level. To achieve that, we aggregated all of our segmented-level features back to the interview level by extracting the mean, median and standard deviation of all the segments? values per interview.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"To clarify the process, let?s take pitch as an example. So, for pitch we had already extracted mean, median and std on the segment level. Following the above aggregation method we got the mean of theÿpitch_meanÿvalues across all segments (which is actually the average of the averages), the median of thoseÿpitch_meanÿvalues (central tendency of pitch variation across segments) and also the standard deviation (pitch variability) among those values within an interview. Similarly, we got the mean, median and std of theÿpitch_medianÿandÿpitch_stdÿvalues of all segments within each interview.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,Feature aggregation eventually led to a complete features set that merged all the extracted acoustic features and their statistics; with everything expressing a single overall value for each interview.,,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Although the creation of the binary labels was completely based on LIWC features (purely textual), we still assigned the same labels to our audio data. This is because the transcripts on which we implemented the process are directly linked with the corresponding audio files.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,The final acoustic features set exceeded 150 feature columns and as such we proceeded with the same feature selection methodology as we did with the unimodal text model. The exact same experiments are performed and the selector with the best performance in this model is RFE with Random Forest.,,,,,
Multimodal machine learning for language and speech markers identification in mental health,Tableÿ11ÿillustrates the top 20 features (unordered) proposed by the RFE with Random Forest selector.,,,,,
Multimodal machine learning for language and speech markers identification in mental health,"As indicated by the flowchart (see Fig.ÿ1), the features of Tableÿ11ÿwere then used to train our models.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"For the implementation of the multimodal model we proceeded with early fusion (also known as feature level fusion). The particular fusion technique involves the concatenation of features from different modalities into a single feature vector, before feeding them as input into the machine/deep learning models. Although simple, early fusion is a straightforward and less computationally intensive approach that doesn?t require sophisticated synchronization between the two modalities.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"To move on with this modality concatentation, first we created two sets of features from each unimodal model. From the textual model we created a set with 20 features and one with 15 features and from the acoustic model we extracted a set of 15 features and another with 10 features. The difference in the feature sets sizes is due to the preliminary results, which indicated that the acoustic model performed obviously worse than the text model.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Then using this information and the 4 feature sets, we concatenated them into three multimodal features sets; each with a different approach. The three multimodal sets and their details can be found in Tableÿ12.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,The features from each unimodal model were selected based on the top 20 features proposed by the best performing feature selector of the corresponding modality; i.e.ÿRFE with Logistic Regression and rescalingÿfor text andÿRFE with Random Forestÿfor acoustic.,,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Similar to the unimodal methodologies, the three newly created features sets were trained in the same 4 machine/deep learning models and were then evaluated using the same metrics.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"For all three modality approaches we used cross-validation, instead of the typical train-test split. Not only is cross-validation (K-fold) more reliable but it also helps to efficiently assess the models? effectiveness and prevent them from overfitting. To illustrate, Fig.ÿ3ÿvisualizes both the unimodal (Fig.ÿ3a) and multimodal (Fig.ÿ3b) configurations for the neural network-based models.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"In this section we present the performance of the Unimodal Text Model, the Unimodal Acoustic Model, and the Multimodal Model, respectively.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"When the feature elimination and selection process were complete, we observed that certain features stood out across all methods and settings. First of all, we noticed a consistency in the appearance of theÿ?anx?, ?sad?, ?they?ÿandÿ?death?ÿLIWC categories. This indicates that these psychological and thematic aspects of the text are highly relevant to the identification of mental health disorder markers. Their consistent presence underscores the significance of emotional and thematic content in the analysis. Apart from LIWC categories, there were also some GloVe dimensions that were repeatedly selected. This consistency of certain GloVe dimensions suggests that they capture key semantic features relevant to the identification of language markers associated with mental health diseases. Another feature that was prevalent, across the various feature selectors, wasÿPCA2. In the context of Principal Component Analysis (PCA), the second principal component (PCA2) accounts for the next highest variance after the first principal component (PCA1). The fact that PCA2 appears more than PCA1 implies that PCA2 captures significant aspects of the data that are not captured by PCA1. Finally, concerning our last type of textual features, POS Tag counts, we noticed thatÿ?VBG_count?ÿ(verb, gerund or present participle) andÿ?JJR_count?ÿ(comparative adjective) both belonged to the top 15 features selected across all feature selectors. The frequency of the first one points to the syntactic structures of sentences as informative features, while the frequency of the latter suggests that certain grammatical constructs may play a role in distinguishing texts related to mental health. Overall, features that appear consistently tend to be less sensitive to variations in the modeling process or data sampling, making them reliable choices for critical analyses.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,Our analysis indicated that the most selected feature overall (across all of our feature selectors) was the LIWC categoryÿ?death?. This consistency obviously indicates its importance when it comes to the identification of mental health disorder markers.,,,,,
Multimodal machine learning for language and speech markers identification in mental health,"In Tableÿ13ÿwe demonstrate the results achieved by our models, using the features set recommended by the best performing selector approach; i.e. RFE with Logistic Regression and with additional scaling. As discussed earlier, k-fold cross-validation was implemented to our models, and since every fold of the cross validation produced a different accuracy and AUC-ROC score, we modified our script so that it returned the mean cv values of all folds. As such, in Tableÿ13, ?Accuracy? represents theÿmean CV accuracyÿand ?AUC-ROC? represents theÿmean CV AUC-ROC scoreÿacross all folds. Moreover, ?F1 - 0s? and ?F1 - 1s? represent the F1 scores achieved when predicting the absence and the presence of mental disorder markers, respectively. For the three machine learning models we used a random state seed, so regardless of how many times we reran the models the results did not deviate much from the ones presented in the table. On the other hand, in the case of the deep learning model, every run produced different results (with observable variance) and as such we are providing the best scores out of four runs for each set of features.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Based on the presented results, it was indicated that each model works best with a different number of features. SVM with a linear kernel and Logistic Regression both perform best with 20 features and it is also clear that they achieve similar scores in all metrics. On the other hand, when tested with 25 features the performance drops and when tested with 30 features the performance dropped even further. This means that the presence of overfitting became more intense and that the addition of more features was redundant. In the case of Random Forest and Dense Layers, the models performed their best across all metrics (with a small exception at the accuracy of the Dense Layers) when given 25 features. Both Random Forest and Dense Layers benefit from having more features. As an ensemble learning method, Random Forest, can use the larger number of features to create more informative splits across its decision trees, which also explains the considerably better score at the AUC-ROC score. Similarly, neural networks can use larger sets of features to learn more complex patterns because of their capacity to handle and learn from additional features. However, when tested with a set of 30 features (using the same feature selector), every model under-performed in every single metric. This implies that after a specific point the models cannot generalize as well.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Overall, while testing for overfitting by comparing the train and test set metrics, we noticed some mild overfitting (on average about 5% gap between the train and test set performances). However, due to all the mitigation measures taken and the use of cross validation, we deem this modest amount of overfitting acceptable in this case.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"In the case of the unimodal acoustic model?s feature selection, we noticed that across all different methods and settings, certain features (particularly from the MFCCs and formant features) show a consistency in appearing as significant. This suggests that there may be an important relationship between these features and the target variable across both linear (LogReg) and non-linear (RF) model perspectives. Another notable fact that we noticed is that pitch-related features were more prominently selected by the RF model and specifically with the RFE method. This indicates that the relationship between pitch features and the target variable can probably be captured more effectively compared to linear models (at least in some contexts). Further weight was given in the research of pitch-related features, as they were discussed a lot during related projects. This, in association with the lack of pitch-related features selected by the Logistic Regression model, lead us to conclude that the linear nature of the particular model may not always capture the complex ways in which the specific features contribute to the specific classification task. It?s probably why, Random Forest, being a non-linear model, might be better in capturing such complexities and interactions; for instance if pitch interacts with other features in a way that doesn?t lend itself to linear separation.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,The results shown in Tableÿ14ÿrepresent the performance of our models when tested on the features of theÿRFE with Random Forestÿselector. The columns of the table represent the same values as the columns of the corresponding table (Tableÿ13) of the unimodal text model.,,,,,
Multimodal machine learning for language and speech markers identification in mental health,"By observing the results it?s noticeable that the models performed best with the same feature set sizes, as in text. SVM had the best results with the 20 features set, but it did surprisingly bad in the case of predicting marker presence (F1 score of 1s). With 10 and 15 features, SVM actually had a score of 0 on this metric. This can be attributed to various reasons, like overfitting or feature selection impact. It?s possible that SVM might be overfitting to the majority class (ignoring the minority class entirely), or that the feature selection might not be sufficiently informative for the particular model to distinguish between classes. Logistic Regression, although comparable with SVM at the other metrics, managed to achieve approximately double the score of SVM?s ?F1 score - 1s?. Dense Layers did better than SVM and LogReg, especially with 10 features and it actually achieved the best score on ?F1 - 1s?, along with RF. Both LogReg and Dense Layers performed the best with the 10 features set. Finally, the RF model got the best scores with the 15 features, with the single exception of ?F1 - 1s?, which appeared to be higher with less features (10). It was also interesting how RF performed the best across all models and metrics. We hypothesize that this is due to the fact that the feature sets used were picked by the selector that used RF as its classifier. It is noteworthy to mention that the particular results of RF (on 15 features) were the highest results (for every single evaluation metric) achieved by the unimodal audio model across all feature selectors.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"For reference, unlike the unimodal text model, the audio model under-performed with any additional amount of features (tested with 25 and 30 features as well). This indicates that our models cannot handle and learn the same with the acoustic features, as they did with the textual ones.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"The presented results indicate that the ?20t, 10a? features set works great with our models. In all cases, with a couple of exceptions, the particular set pulls off the highest results. The exceptions include the AUC-ROC score achieved by the ?20t, 15a? features set on the SVM model, which is the highest one observed across all cases, and the case of the Dense Layers. Dense Layers appear to work best (overall) with the ?20t, 15a? set, although the score gap with the other two sets isn?t that noteworthy. The ?20t, 15a? features set is the largest one out of the 3, consisting of 35 features, instead of 30. This could possibly mean that Dense Layers can be effectively trained on larger feature sets and even improve their attained results further.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Tableÿ16, presents a comparison between the three modality approaches, for each model, using the best performing features in each case.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Just like with the unimodal approaches, the RF model shows high levels of overfitting here as well. We discovered that the RF model achieves a 100% accuracy and AUC-ROC scores on the train sets, while the results presented on Tableÿ15ÿare the ones of the test set. This gap is a clear indicator of the presence of overfitting. Unlike RF, SVM only indicates minimal overfitting on the ?20t, 15a? and ?20t, 10a? features sets and mild overfitting on the ?15t, 15a? set. Logistic Regression overfits slightly as well, but not to the point that it is negatively affected.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Observing the performances of the two unimodal approaches, it is evident that the unimodal text model is by far outperforming the unimodal audio model. More importantly, this gap is even more intense in some of the classifiers. In the case of SVM and Logistic Regression, the text model achieves anÿ÷18%ÿhigher accuracy andÿ÷32%ÿhigher AUC-ROC score than the audio model, while the F1 score of 1s is higher by more than 60%. Similarly, for Dense Layers the audio model attains an accuracyÿ÷15%ÿlower and an AUC-ROCÿ÷20%ÿlower than the text model. On the other hand, in the case of Random Forest, which shows the best performance for the audio model, the gap in accuracy is onlyÿ÷12%ÿand the gap in AUC-ROC score is barely 10%. Concerning the F1 score of 1s metric however, we can still observe a performance difference of more than 20%.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"However, this huge performance gap between the two unimodal models can most probably be attributed to the way that the binary labels were created. Since that process was based on the LIWC categories, which are a text feature, it makes sense for the text features to be more accurate during predictions and for the audio features to encounter some difficulties.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"It?s not rare for text features to outperform audio features in tasks related to the particular topic. When it comes to identifying mental disorder markers, the text modality has proven to be extremely capable of leading to better predictions, even more so when there is a relevant textual content that offers clear linguistic markers. Although the text model significantly outperforms the audio model, we should still not diminish the value provided by the audio features. Analyzing these features can help discover distinct and complementary insights and this is where multimodal models, that utilize both of these modalities, can shine. By combining the strengths offered by each modality and implementing fusion techniques that bring forth those strengths, it is possible to capture more comprehensive information and details of mental health states.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"As indicated by the results on Tableÿ15, the best scores are attained by theÿ20t, 10aÿset of features, with a few exceptions appearing with theÿ20t, 15aÿset. However, there is not a single instance of theÿ15t, 15aÿfeatures set pulling off the best results over both of the other two sets. It is evident that assigning additional weight over the textual features brings forwards a boost in the models? performance. By emphasising more on the text features our multimodal model learns to generalize better. This was already indicated earlier, through the big gap between the text model?s and the audio model?s results, but the latest comparison even proved this observation. Regardless, experimenting with a modality balanced features set proved helpful in realizing the flaws and the correct steps in the whole modeling approach.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"To prevent overfitting, our initial approach was to use cross-validation instead of the traditional train-test-split approach, which proved to be effective. Not only did we observe a noticeable gap in the overfitting levels between the two approaches, but also cross-validation led to minimal, or at the worst case mild, levels of overfitting. We also noticed that overfitting was more prevalent with a higher number of features, which can be associated to the small size of the dataset compared to the number of features selected. Furthermore, during the mulimodal model?s experiments, we also implemented a regularization technique to our Logistic Regression model and added Dropout layers to our Dense Layers model. Although this had only a slight impact towards the prevention of overfitting, it had a larger impact on the model?s performance. The results of the Logistic Regression model after applying regularization dropped greatly across all metrics and number of features. Additionally, the F1 scores of the positive cases decreased by 60%. This was due to the low recall rate. For each features set the model has a precision rate of 100%, while the recall rate ranges between 7% and 10%. This is why, for the case of Logistic Regression, we moved on with the pre-regularization results. The overfitting level may be slightly higher but the model?s performance was not even comparable.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"The limitations of this study can be easily realized through the future work recommendations. Everything mentioned there includes methods and techniques, whose implementations can improve this research significantly. Yet, one important limitation that isn?t mentioned is the process of creating the binary labels. As elaborated above, this process was intuitive and pragmatic but requires further refinement and improvement. Finding a way to make the process more modality neutral, would make the results less skewed towards one modality and less biased. Moreover, along with some refined feature engineering for the acoustic model, its performance could increase and consequently improve the performance of the multimodal models as well.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Another limitation to this study was the dataset selection. Although DAIC-WOZ was a great asset for our project, it did limit our research because of its size and its specificity towards a couple of particular mental disorders. Moreover, because of the dataset?s interval overlaps in the transcript we had to avoid text-speech alignment; a process that has a fundamental role in multimodality, especially between the particular two modalities. Finally, we believe that implementing models with increased complexity could help to capture more nuanced details that might have been missed by simpler models.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"In this study we focused on two of the three modalities in the DAIC-WOZ dataset. As such this study is a multimodal extension (linguistic and audio markers) in line with [1] which focused on the identification of linguistic markers only. The second modality (audio) was selected based on compatibility. Transcripts and audio data are usually interconnected in most datasets, just like many of their features. Nevertheless, the inclusion of the video modality as a third provider of mental health illness markers, which is expected to capture important non-verbal indicators such as facial expressions and gestures, has great potential to further enhance the accuracy of mental diseases identification. This will be part of future research.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"One of the challenges that we overcame was avoiding the loss of modality-specific insights. When merging features at an early stage, it sometimes becomes challenging to discern which modality is contributing to predictions and this can lead to reduced model interpretability. However, by creating three different sets of combined features (one of which represented the balance between the two modalities), we showed that for the majority of the models the best performing features set was the one with the 66% weight on the textual features. Then, for some of the models, the challenger was the features set that was only slightly skewed towards the textual modality. Yet, in none of the models did the balanced features set perform better than the other two. This clearly indicates that the textual features have more insight to offer in the identification of mental disorder markers, at least on the individual level.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Risk of feature dominance posed another challenge during the early fusion. Although, giving additional weight to the better performing text features (compared to the acoustic features) proved that it increased the performance of our models, this could potentially lead to an imbalance in feature contribution. It?s possible for the text modality to have dominated the feature importance, overshadowing the audio modality and this would have led to partly biased models. To prevent that we performed modality-specific preprocessing. We followed the exact same scale-balancing (normalization) techniques in every single feature during the development of each unimodal model. By doing that we guaranteed that all features (of both modalities) were on the same scale and their impact should be balanced such that any possible feature dominance would be prevented.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"The finding of this study can potentially play a very important role in the development of practical mental health screening or monitoring tools. The study provides not only an extensive list of linguistic and acoustic mental disorder markers, but also some experiments and comparison between unimodal and multimodal approaches. Through the identification of linguistic and acoustic mental disorder markers, this research opens a path towards early, non-invasive screening systems. It should be possible to develop applications, meant for both clinicians and individuals, that utilize these markers in order to monitor mental health states in real-time. These applications could work by receiving as input data of different modalities, like textual content, conversations or voice recordings, and in turn assess mental health conditions. One can consider such tools as an additional diagnostic layer in clinical settings or alternatively as part of remote mental health care, where patients can be monitored over time without requiring frequent clinical visits in person. Moreover, since markers like reduced pitch variability in depression or increased jitter and shimmer in anxiety have clear physiological correlations, they can provide objective, quantifiable data to complement traditional psychiatric assessments. This can lead to improved early detection, personalized treatment plans, and more accurate tracking of patient progress during therapy.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"The most significant recommendation we have to offer, regarding the future work, is the implementation of text-speech alignment, which constitutes a significant aspect of multimodality that facilitates a more comprehensive integration of the two modalities. Implementing this process would also open more opportunities for experimenting with other fusion techniques. Although early fusion provided us with a way around text-speech alignment, it may oversimplify the interaction between the two modalities and it is less flexible in handling their distinct characteristics.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Text-speech alignment would not only enable the extraction of additional important features (speech ratioÿandÿpause duration), but also the option of experimenting with deeper deep learning models, like GRUs and LSTMs. These models excel in processing sequences where the timing and order of inputs are crucial to understanding the data?s context and dynamics. The alignment is particularly important in tasks where the synchronization of spoken words and vocal characteristics adds value to the interpretation. GRUs, for instance, are tailored to handle sequences by capturing dependencies at different time steps. In order for the GRU to effectively analyze the responses of the textual information to the speech variations (e.g. speech rate, pauses, intonation, etc), it is crucial for the two modalities to be properly aligned.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Other than the implementation of text-speech alignment we would also recommend experimenting with theÿ??0.25ÿmetric, which is a variance of theÿ????.ÿ????ÿis a generalization of the F1 score that allows the alteration of the original weights between precision and recall. For completeness, we provide the equation forÿ????ÿbelow:",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"In theÿ??0.25ÿoperationalization,ÿ??ÿis set to 0.25, indicating that precision is considered more important than recall. This alteration of the original F1 metric is recommended in cases where the consequences of false positives are crucial. For instance, in our project, we might prefer falsely marking a few samples as marker-including (higher precision) over missing too many actual markers (lower recall).",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"Furthermore, as mentioned earlier, the implementation of text-speech alignment could also open the path to more sophisticated and complex fusion techniques like hybrid fusion and end-to-end fusion. The first one combines aspects of both early and late fusion. For instance, some features may be combined at an early stage, while others may be merged after some additional individual processing. This way modality-specific processing is preserved (at least at some level) and the model can learn the distinct properties of each modality better. On the other hand, end-to-end fusion involves the integration of modalities at a deep level, with a preference for using deep neural networks, which learn to extract and combine relevant features autonomously. Following this approach, we could for example feed all 300 features into one deep neural network and have it recommend and extract the most optimal combination of features. This is even supported by the fact that this method can dynamically adjust to the modality and feature importance through training. It?s particularly advantageous when there is a more complex and highly non-linear interaction between the modalities.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"It is possible that exploring these two fusion approaches could allow for a more sophisticated handling of modalities, as well as lead to a potential improvement of the accuracy and robustness of identifying mental health disorder markers.",,,,,
Multimodal machine learning for language and speech markers identification in mental health,"In conclusion, in our study we presented, to our knowledge, the first comprehensive overview of Linguistic and Speech markers for Mental Health Disorders. We have found that the text model outperforms by far the acoustic model when identifying mental health markers. However, this may in part be due to bias in the binary label creation process. Furthermore, we observe that the multimodal model comes head to head with the text model and in some cases even outperforms it (i.e. in the F1 scores of all models except Random Forest). Even though this is not the case for every metric, taking into account the performance of the acoustic model, even this modest increase in the F1 scores indicates that the multimodal model is actually affected by the information of both modalities. This is especially so in the case of the F1 scores of the positive cases, which are more important in this study compared to the F1 scores of the negative cases. Therefore, we conclude that a multimodal model for mental health markers identification can indeed outperform unimodal approaches, while providing several research opportunities for further realizing its potential in mental health.",,,,,
"War, emotions, mental health, and artificial intelligence","During the war time dysregulation of negative emotions such as fear, anger, hatred, frustration, sadness, humiliation, and hopelessness can overrule normal societal values, culture, and endanger global peace and security, and mental health in affected societies. Therefore, it is understandable that the range and power of negative emotions may play important roles in consideration of human behavior in any armed conflict. The estimation and assessment of dominant negative emotions during war time are crucial but are challenged by the complexity of emotions? neuro-psycho-physiology. Currently available natural language processing (NLP) tools have comprehensive computational methods to analyze and understand the emotional content of related textual data in war-inflicted societies. Innovative AI-driven technologies incorporating machine learning, neuro-linguistic programming, cloud infrastructure, and novel digital therapeutic tools and applications present an immense potential to enhance mental health care worldwide. This advancement could make mental health services more cost-effective and readily accessible. Due to the inadequate number of psychiatrists and limited psychiatric resources in coping with mental health consequences of war and traumas, new digital therapeutic wearable devices supported by AI tools and means might be promising approach in psychiatry of future. Transformation of negative dominant emotional maps might be undertaken by the simultaneous combination of online cognitive behavioral therapy (CBT) on individual level, as well as usage of emotionally based strategic communications (EBSC) on a public level. The proposed positive emotional transformation by means of CBT and EBSC may provide important leverage in efforts to protect mental health of civil population in war-inflicted societies. AI-based tools that can be applied in design of EBSC stimuli, like Open AI Chat GPT or Google Gemini may have great potential to significantly enhance emotionally based strategic communications by more comprehensive understanding of semantic and linguistic analysis of available text datasets of war-traumatized society. Human in the loop enhanced by Chat GPT and Gemini can aid in design and development of emotionally annotated messages that resonate among targeted population, amplifying the impact of strategic communications in shaping human dominant emotional maps into a more positive by CBT and EBCS.",,,,,
"War, emotions, mental health, and artificial intelligence","The impact of war and trauma on mental health is devastating, particularly for civilians who are living in a state of constant fear, hopelessness, misery, horror, sadness, and humiliation. Individuals in war-inflicted societies are subjected to profoundly traumatic and stressful events that can have detrimental effects on their mental health, leading to anxiety, depression, post-traumatic stress disorder (PTSD), and suicidal tendencies (Kleber, 2019;ÿRozanov et al., 2019;ÿJain et al., 2022). Prevalence rates of mental health disorders are strongly correlated with the number of traumatic events people have experienced during war time, as well as their individual stress resilience and vulnerability (Lim et al., 2022). A continuous flow of armed conflicts, global crises, natural disasters, and pandemics has resulted in an unprecedented number of individuals feeling stressed, anxious, depressed, and emotionally fragile (Jakovljevic et al., 2020;ÿ?osi? et al., 2020a;ÿKopila? et al., 2021;ÿLass-Hennemann et al., 2023;ÿMejia et al., 2023;ÿPrazeres et al., 2023). Globally, yet unrecognized demand for high on-time effective preventive and treatment resources has contributed to a significant mental disease burden. This gap between what is needed and what is available has continued to grow due to the lack of mental health professionals and unmet need for early preventive treatment. Mental health disorders induced by war and trauma may lead to disorganization of key human emotional, cognitive and behavioral functions, like dysregulation of thoughts, emotions, feelings, compromised physiology, immune-inflammatory dysfunction, cognitive distortions and maladaptive coping mechanisms (Rozanov et al., 2019). The impact of war on the overall mental health and well-being might be catastrophic, surpassing the toll inflicted by any major disease in terms of mortality and disability. It can devastate entire nations, communities, families and individuals, frequently disrupting their socio-economic development and prosperity (Betancourt et al., 2018;ÿKleber, 2019;ÿRozanov et al., 2019;ÿTrujillo et al., 2021;ÿLim et al., 2022).",,,,,
"War, emotions, mental health, and artificial intelligence","The war-related death toll represents only the visible wounds of war, while numerous other consequences, such as the invisible wounds of war, like PTSD and suicides, are not yet efficiently and adequately addressed and treated. Potential of new mental health artificial intelligence (AI) tools and means might be effectively used in early recognition and treatment of mental health challenges. Therefore, this paper aims to address the capacity of a more comprehensive approach based on AI state-of-the-art tools and means to provide effective utility in coping with this global health challenge, particularly in societies affected by wars and traumas. Consequences of war, including forced displacement, exposure to violence, supplies? deficiencies, damages to essential infrastructure, and disruption of vital services, can exert significant adverse effects on the psychological well-being and overall health of the Ukrainian population during and after the war (Hamama-Raz et al., 2022;ÿEllis et al., 2024). Measures of standard of living, psychological well-being, depressive symptoms, substance misuse, and consumption of unhealthy foods are commonly linked to the conflict regardless of sex, age, religion, or marital status (Konstantinov et al., 2023a,b). Our research highlights the importance of emotions as a motivating factor for engaging in voluntary service as well, since the majority of volunteers emphasized that feelings of compassion, anger, and a willingness influenced their decision to engage (Domaradzki et al., 2022).",,,,,
"War, emotions, mental health, and artificial intelligence","Global security challenges and wars might be expressed by different negative emotions, particularly those of fear, anger, despair, hatred, resentment, rage, and frustration (Milevski, 2020;ÿCricenti et al., 2022). These emotions may escalate into behavior of aggression, war, resistance, terrorism, insurgent action. Emotions may play a very important role in understanding human behavior and have a significant impact on the politico-security analysis. It is almost impossible to fully understand the complexity of global military tension, insecurity and armed conflicts without trying to understand the range and power of emotions in a theater of war. During the war, unlimited production and distribution of negative emotions makes multidimensional emotional space uncontrollable (?osi? et al., 2012b). Therefore, the emotional dimension of any conflict or problem should not be underestimated. War tragedies and the negative emotion of humiliation generates irrational, harmful, devastating and hateful feelings. If emotions are not integrated and embedded into a global multidisciplinary politico-security analysis, the world will be in danger due to ignoring a fundamental aspect of human emotional behavior. Hence, strength and diversity of negative emotions remain a crucial factor in understanding the complexity of the global political and security landscape (?osi? et al., 2018).",,,,,
"War, emotions, mental health, and artificial intelligence","The explosion of negative emotions and their impact on relationship between nations, cultures, and religions is a crucial important topic which deserves much more attention. Without understanding the pivotal influence of emotions, which have greater control over individuals than they exert on them, it is fundamentally impossible to grasp the political and security realities of war trauma (?osi? et al., 2012b;ÿWebster and Albertson, 2022). For example, fear as absence of confidence can lead to obsessive worries about the present and the future and become more dangerous for overall security and individuals? mental health. At the same time, fear is a force for survival in a dangerous environment and a natural protective response. Anger involves appraisals of relative strength and coping potential, while hatred is the strongest, extreme emotion which is characterized by willingness to harm and even annihilate the hated individual or hated group. However, war traumatic events can challenge and uproot related attachments, making their emotional nature exposed in a very visible manner (Bleiker and Hutchison, 2008).",,,,,
"War, emotions, mental health, and artificial intelligence","In order to understand such complex societal situations, analysis of emotional contexts is extremely important and necessary (?osi? et al., 2012b). Each emotion is related to a specific response tendency and action readiness (Frijda, 1987). This means that negative dominant emotional maps have corresponding action tendencies and behaviors, closely related to group willingness and energy to create some kind of change in the society.",,,,,
"War, emotions, mental health, and artificial intelligence","An approach to use emotions as a mechanism to explain irrational behavior of war actors might be an innovative way to add value in searching for a solution for the most complex, unpredictable and uncertain war conflicts in the modern world. In order to reconcile people with diverse emotional landscapes, it is necessary to understand the main drivers of their behaviors and actions. Behavioral characteristics of people cannot be understood without deeper and complex analysis of their dominant emotional maps and their socio-cultural and security conditions and interactions. Different dominant emotions of the population must reflect in different policy ramifications (Mercer, 2005). This indicates that different societal and cultural values and norms cannot be easily changed by excessive use of military power. Finally, the effects of military dominance, like airstrikes or drone attacks, may produce strong negative emotions and effects in the battle for hearts and minds of a war inflicted population, making the use of military power a less effective (Dixon, 2009). Potential military failure might be a consequence of unrealistic expectations that serious security problems in war-inflicted societies can be resolved by the military while ignoring the fact that the post-conflict developmental and recovery programs are the most crucial (Galula, 1964).",,,,,
"War, emotions, mental health, and artificial intelligence","The estimation and assessment of dominant emotions during and after war is extremely important, but at the same time a very challenging and complex task. In politico-security analyses the aggregation of dominant emotional maps, and their potential transformation into group actionable scenarios, actions, reactions, behavior, and riots, deserves more attention (Lofland, 1985). Participants in the same social situation often share a common awareness and a common emotional reaction to it (Barbalet, 1998;ÿPizarro et al., 2022). Aggregation and unification of these individuals? emotional characteristics may lead to strongly unified emotional groups which may become powerful strategic agents in conflict management. Dominant emotional maps determine the ability of a society to cope with its own social and security challenges. Identifying the dominant emotions within populations in war-affected societies should be considered one of the foundational tasks. This endeavor aims to ameliorate negative emotions wherever they exist and capitalize on positive ones.",,,,,
"War, emotions, mental health, and artificial intelligence","Group dominant emotional maps arise from the aggregation of emotional maps of individual members within a population (?osi? et al., 2012a), and serve as representations of ?dominant emotions,? which are publicly expressed feelings of collective behavior (Lofland, 1985). Additionally, they can be understood as depictions of ?emotional atmospheres,? which encompass collective moods, or as ?emotional climates,? which encompass collections of significant emotions or feelings that contribute to the formation and maintenance of political and social identities, as well as collective behavior (Barbalet, 1998;ÿDe Rivera et al., 2007). The synchronous alteration of dominant emotions among substantial portions of the population can potentially act as a driving force or leverage for broader societal transformations. The nuanced, but simultaneous modification of individuals? feelings at the micro-level could lead to far-reaching transformations at the macro-level. Consequently, changes in dominant emotions entail shifts in the action tendencies of numerous individuals, thereby providing a basis for cohesive collective action on a societal scale.",,,,,
"War, emotions, mental health, and artificial intelligence","Analyses of these dominant emotional maps in combination with other relevant efforts are the basis for a comprehensive approach to conflict resolution, and corresponding peaceful policy. Dominant negative emotions, particularly on the global and strategic political scene, are the main driving force of war and global insecurity (Webster and Albertson, 2022). Therefore, estimation and assessment of dominant negative emotion in times of war and trauma are extremely important.ÿFigure 1ÿillustrates the hypothetical normalized negative emotional map during the war time. From the illustrated contour plots it is easy to notice that centers of gravity of dominant emotional maps are situated in the upper-left quadrant of the valence/arousal space, due to the presence of negative and mostly arousing emotions, like fear, anger, hatred, frustration etc.",,,,,
"War, emotions, mental health, and artificial intelligence","Emotions affect attention, beliefs, and actions, focusing and guiding memory and influencing our cognitive processes (Tyng et al., 2017). They shape and strengthen our beliefs, help us rearrange our priorities and revise our goal hierarchies, influence our preferences, and act as a nexus among our beliefs, value systems and thereby strengthening our commitments (Gonzalez et al., 2020;ÿFurman, 2024;ÿKisley et al., 2024).",,,,,
"War, emotions, mental health, and artificial intelligence","The estimation of dominant emotional states may encompass various elements such as aggregated emotional feelings, beliefs, and a behavioral component characterized by impulsive or expressive gestures. Moreover, it incorporates a cognitive element associated with the evaluation of the scenario, as well as a drive component linked to the preparedness for activity (Scherer, 1984). As a result, when estimating dominant negative emotional maps, one must consider not only the collective emotional experience of a group, but also the corresponding behavioral and cognitive components (?osi? et al., 2012a).",,,,,
"War, emotions, mental health, and artificial intelligence","Dominant emotional maps can display data or signals from different sources, like linguistic textual records related to emotion from social media which are increasingly popular. Individuals experiencing mental health issues frequently express their psychological difficulties through various platforms and forums, such as Facebook, Instagram, Twitter, Reddit, and other online forums, by sharing text messages, comments, photos, videos, and other related information (Naslund et al., 2020;ÿZhang et al., 2022,ÿ2023). A differentiating characteristic of Reddit, when compared to other sources of data, is the classification of posts into distinct subreddits based on specific subjects, such as anxiety, depression, post-traumatic stress disorder (PTSD), and even suicide (Zhang et al., 2022). In addition, electronic health records (EHR) function as a valuable source of secondary healthcare data, providing comprehensive documentation of individuals? historical medical records. Another viable approach involves identifying mental illness by conducting user interviews and subsequently analyzing the linguistic information obtained from transcribed clinical interviews (Morales and Levitan, 2016;ÿSpruit et al., 2022). Finally, the application of standardized questionnaires for individual?s diagnosis and self-assessment is also considered fitting in this circumstance (?osi? et al., 2021).",,,,,
"War, emotions, mental health, and artificial intelligence","Regarding mental health diagnostic analysis of keywords and statistical representations of words dominates, but involvement of state-of-the-art NLP methods, like large language models (LLM) can significantly improve word representations with better and deeper understanding of mental health context and semantics (Bartal et al., 2024). The interpretation of keyword-based features is much easier, while clarification of context and meaning of words is more abstract. Analyses of dominant emotional maps in war-inflicted societies reveal dominant emotions which people express in online posts or forums, such as fear, sadness and anger. Uncovering the overall emotional tone and how people describe their emotions in the war environment is the right approach to prediction and prevention of potential massive mental health diseases in a reliable and accurate way. Available NLP tools have a variety of computational methods to analyze and understand the emotional content of relevant textual data in war-inflicted societies, enabling better and deeper insights into their emotional states. From the utilization of NLP methodologies and illustrative large-scale data collections, we are able to observe intricate patterns of emotions and sentiments that are manifested in language and associated emotional and semantic characteristics that exhibit dynamic changes over time (Sawalha et al., 2022). Through the examination of posts, we can analyze linguistic features such as word frequencies, lexical diversity, narrative coherence, emotional content, and sentiment content to effectively detect and forecast significant mental health disorders (?osi? et al., 2021). The most commonly used features in mental illness detection are linguistic patterns such as Bag-of-Words, Linguistic Inquiry and Word Count (LIWC), sentence and passage length, N-gram language models, emotional thesauri like WordNet-affect, and normative databases like the Affective Norm for English Words. Domain specific ontologies, dictionaries, and social attributes in social networks have the potential to improve accuracy. However, LIWC is the most widely used software tool in mental health research projects which is composed of more than 6,000 words, word stems and selected emotions and calculates approximately 90 output variables (Pennebaker et al., 2015).",,,,,
"War, emotions, mental health, and artificial intelligence","Disruptive AI-based technologies using machine learning (ML), deep learning (DL), neuro linguistic programming (NLP), cloud infrastructure, and new digital therapeutic apps offer a significant promise for enhancing mental health care on a worldwide scale, rendering these approaches more cost-effective and readily implementable, specifically targeting nations and individuals lacking sufficient access to health care (Schwalbe and Wahl, 2020;ÿLekkas and Jacobson, 2021;ÿKoutsouleris et al., 2022;ÿTutun et al., 2023). Due to an inadequate number of psychiatrists and limited psychiatric resources to cope with war-related disasters, traumas and tragedies, new digital therapeutic wearable devices supported by advanced statistical methods and machine learning algorithms might represent a positive shift in the psychiatry of the future (?osi? et al., 2021). The predictive AI-based methods which can recognize potential chronic psychopathology early enough compared to traditional reactive psychiatry is example of more proactive and preventive type of medicine (?osi? et al., 2020a,b,ÿ2021;ÿBertl et al., 2022). The major advantage of predictive AI is its ability to identify specific non-obvious patterns which are beyond human observation capabilities and may be essential for early detection of individuals at high risk of mental health deterioration (?osi? et al., 2021). These AI-based tools and means are leading to a new era of mental health global management offering new opportunities and a more holistic approach to patients by early intervention with novel therapeutic methods (Schwalbe and Wahl, 2020;ÿGarriga et al., 2022;ÿKoutsouleris et al., 2022). These changes can be objectively assessed by state-of-the-art wearable devices which can capture clusters of different multimodal and multidisciplinary features focusing on early prediction and prevention of potential chronic mental health disorders using new AI-based therapeutic strategies, like computerized cognitive behavioral therapy (Wilhelm et al., 2020;ÿGrodniewicz and Hohol, 2023;ÿKhawaja and Blisle-Pipon, 2023). Early prediction and prevention of mental health disorders, particularly for populations in war zones, based on the objective measurement and computation of relevant neuro-psycho-physiological and linguistic features and a machine learning model development of highly heterogeneous data sets, may enhance traditional face-to-face therapy. Such approach is particularly important for all of those who are exposed to high levels of stress during war time and need assistance more quickly and accurately.",,,,,
"War, emotions, mental health, and artificial intelligence","Machine learning (ML) models have been developed to detect mental illness based on a combination of various multimodal physiological sensors (Chen et al., 2022;ÿGarriga et al., 2022;ÿSabry et al., 2022). The computation of corresponding features, selection and labeling training datasets, and selection of validation and verification datasets using a supervised learning model, can be developed for classification or prediction of different mental health issues. Traditional and most common machine learning methods include: support vector machine (SVM), k-Nearest Neighbors (KNN), Adaptive Boosting (AdaBoost), Decision Tree (DT), Random Forest (RF), Naive Bayes (NB), and Logistic Regression (LR;ÿSarker, 2021). To develop a robust ML model, it is crucial to identify the primary multimodal features that serve as key predictors of severe mental health conditions (Zhang et al., 2022). The main advantage of supervised learning lies in the model?s ability to learn patterns from labeled datasets, therefore leading to better model performance. However, labeling the large amount of data with high quality is a time consuming and challenging job, therefore the methods that can help reduce the human annotation burden are of special interest. Methods which do not rely on labeled data or need only a small amount of data to train a classifier, are based on unsupervised learning methods which can discover patterns from unlabeled data, such as clustering data.",,,,,
"War, emotions, mental health, and artificial intelligence","Currently, deep machine learning (DL) methods receive more attention and perform better than traditional machine learning methods, while the interpretable models, like XAI, deserve particular attention. DL methods can capture valuable features automatically without feature engineering and may be preferred for tasks of mental illness detection from text. DL methods consist of multiple layers, including an embedding layer and a classification layer (Zhang et al., 2022). The embedding layer has the ability to retain both semantic and syntactic information, thereby enhancing the training of deep learning models. Various embedding techniques exist, such as ELMo, GloVe word embedding, word2vec, and contextual language encoder representations like bidirectional encoder representations transformers (BERT). Depending on the structure of the classification layer, DL methods might be divided into convolutional neural networks (CNN), recurrent neural networks (RNN), transformer-based methods, and hybrid-based methods (Zhang et al., 2022). DL models have shown high accuracy in predicting mental health disorder diagnosis and severity (Garriga et al., 2022;ÿAlles?e et al., 2023).",,,,,
"War, emotions, mental health, and artificial intelligence","The utilization of NLP and the analysis of free-form online posts can provide significant advantages in accurately predicting potential psychiatric disorders (Le Glaz et al., 2021;ÿArowosegbe and Oyelade, 2023). In particular, distinguishing between individuals who are vulnerable to mental stress and those who are resilient to mental stress can greatly contribute to the reliability of such predictions (?osi? et al., 2021). NLP-based semantic analysis and recognition of specific keywords to track individual emotions and moods illustrates promising improvements to empower mental health management (Zhang et al., 2022). Such linguistic features and information and related unstructured data may be valuable tool in identification of relevant keywords for early detection of various mental health problems (?osi? et al., 2021). Early warning text-based indicators of potential mental illness deserve particular attention since they enable early intervention and prevention of serious mental health diseases, like PTSD. NLP methodologies possess the capability to apprehend irrational or distorted conversations that are related with some psychopathological patterns, such as the patient?s cognitive distortions, biases, core beliefs and negative wording. By employing NLP techniques, medical practitioners can unveil the configurations that exemplify how specific psychopathological conditions are manifested in language, as well as the corresponding semantic and acoustic qualities over a period of time (?osi? et al., 2021). All individual posts, their contents, and comments on related, continuously monitored, social networks may serve as a source of relevant linguistic features such as word frequencies, lexical diversity, narrative coherence, sentiment of speech content and others, using them to classify major mental health disorders. These features might be calculated, for example by Linguistic Inquiry and Word Count (LIWC), Bag-of-Words model, word2vec and BERT.",,,,,
"War, emotions, mental health, and artificial intelligence","Digital therapeutic devices and apps based on cognitive behavioral therapy and explainable artificial intelligence (XAI) might be an additional transformative and powerful approach in psychiatry of the 21st century leading toward highly efficient diagnosis and treatment as complementary assistance to traditional face-to-face therapy (Tong et al., 2022;ÿG¢rriz et al., 2023). A virtual digital therapist might be as good as a human therapist based on the enormous potential of AI-based tools and means. Such applications offer great promise since they only require smart wearables sensors and smartphones. Cognitive behavioral therapy (CBT) is a type of evidence-based psychotherapy that is often recognized by the Institute of Medicine as the first-line approach to provide behavioral, cognitive, and emotional change and adaption to a range of common psychological and psychiatric problems (David et al., 2018). Finally, to the personalization of online CBT and XAI treatments using minimal human resources is an important research topic which deserves much more attention, particularly regarding the issues of optimal adaptive treatments, selection of best treatments, minimization of dropouts etc.",,,,,
"War, emotions, mental health, and artificial intelligence","Explainable AI within the field of psychiatry could potentially serve as a self-explanatory digital aid to psychiatrists, enabling them to meticulously analyze vast amounts of data and identify intricate patterns and concealed indicators that may elude the perception of a psychotherapist. The goal of XAI in mental health diagnostics is to understand explanatory factors of mental illness in order to improve diagnostic performance and empower therapeutic decision-making (Kerz et al., 2023). The interpretability of diagnostics and treatments is extremely important for guiding psychiatrists to understand not only what has been extracted from big multimodal datasets, but also to enhance treatment and prediction (Koppe et al., 2021). Machine and deep learning-based methods achieve good performance by utilizing a large number of features, their extraction and computation, but they still fail to explain some complex decisions (Zhang et al., 2022). As a result, the explainability or interpretability of the machine and deep learning decision making process will become an important research direction in the future. This is an issue when both patients and doctors need to understand why an outcome has been produced for a given specific set of multimodal inputs. This allows physicians to check if the reasoning of the trained model aligns with their own understanding and general medical domain principles. Understanding the mechanisms and rationales behind a particular machine learning algorithm is crucial in establishing confidence and trust among domain experts. These factors can lead human experts to either reject or embrace these diagnostic approaches. Therefore, the need for transparency in psychiatry due to probabilistic variations relating to the complexity of neuro-psycho-physiological factors of mental health disorders is extremely important. As increasingly complex models are developed and their replacements for human expert decision making, it is necessary to ensure that the ?black box? nature of these models have not learned undesirable patterns (Ali et al., 2023).",,,,,
"War, emotions, mental health, and artificial intelligence","Wearable and wireless sensors and sensing technology using a variety of AI algorithms can be applied in the prediction of different mental health disorders by monitoring human physiology, emotion, cognition, and behavior (Lee et al., 2021;ÿKalisperakis et al., 2023;ÿSigcha et al., 2023;ÿZheng et al., 2023). Majority of applications are deployed on smartphones or configured with a chatbot interface via a web application for providing access to a larger population offering a unique opportunity for ubiquitous mental health screening. Connected and embedded into people?s personal lives, smartphones provide considerable insight into individual routines, habits, activities, and human way of living. The convergence of sensor networks, fusion of sensors, processing of signals, and human interaction with these devices result in a vast amount of data, which serves as a valuable source for extracting intricate characteristics utilized by machine learning algorithms (Sabry et al., 2022). These algorithms are then able to identify and acquire meaningful patterns that aid in the prediction of potential mental health disorders. Wearable devices have the capacity to incorporate a range of sensor types, enabling the continuous monitoring of various bodily signals. Consequently, these devices can gather an extensive amount of data, potentially reaching millions of data points per person per day. Such information can be utilized by a range of machine learning techniques, like deep neural networks, for the purposes of training, learning, and predictive modeling (?osi? et al., 2024). Smart wearables supported by AI can be very helpful in digital psychiatry to provide care to millions of potential patients simultaneously and can be used for clinical purposes to track patients with greater care and accuracy (Chen et al., 2022;ÿShajari et al., 2023). A large amount of the biometric data can be analyzed on edge computing devices enabling developers to secure sensitive data and enhance security and privacy. Based on innovation in new sensors technology and sophisticated algorithms, wearables can be used as diagnostic devices using machine learning models built on data streaming from each individual. It might be also very helpful to enhance traditional conventional face-to-face therapies which currently represent a serious barrier to care. These devices can resolve many problems regarding potential massive mental health problems induced by war traumas, natural disasters or pandemics.",,,,,
"War, emotions, mental health, and artificial intelligence","Today, each part of human biology can be captured by more than a thousand sensors collecting a few thousand physiological, emotional, cognitive and behavioral features (Dang et al., 2023). Wearable physiological sensors may include measurements of heart rate variability, body temperature, breathing dynamics, oculometric features, electrodermal activity, respiration rate, blood volume, blood oxygen saturation, blood pressure, acoustic recordings, movement sensors, such as tri-axis accelerometers, tri-axis gyroscopes, inertial platforms, magnetometers, and many others (Ates et al., 2022;ÿScataglini et al., 2023). From all these neuro-psycho-physiological variables, more complex physiological states can be computed (i.e., respiratory sinus arrythmia). Daily tracking of activity and movement by GPS, their mutual interactions, and physiology or even metabolic functions, including variations of glucose, microbiome analysis, genomics sequencing, offers a new dimension in monitoring and tracking human behavior, and offers valuable tools and means in prevention of serious mental health disorders in war-inflicted societies.",,,,,
"War, emotions, mental health, and artificial intelligence","Model development based on extracted features and sophisticated and complex innovative machine learning algorithms can be used for classification of certain mental disorders. For example, activity monitoring and recognition by text messages, location, movement, touch screen typing patterns, and voice recordings can assist in mental health monitoring and diagnostics. However, the interpretation of the impact of certain statistical features on classification or other outcome variables can often be challenging. Furthermore, the precision of a model can be adversely impacted by the incorporation of irrelevant characteristics (Sabry et al., 2022). It is important to note that the notion of ?more is better? does not always hold true, as the inclusion of domain-specific features that possess expressive qualities tends to yield superior performance. For instance, features such as heart rate, breathing rate, changes in acceleration, motion jerk, and transient alterations in skin resistance can be considered as domain-specific features for seizure detection (Sabry et al., 2022). In certain applications, the focus lies on changes occurring over extended periods, while in others, attention is directed toward transient changes resulting from specific events like fall detection and emotion recognition. The growing array of wearable devices can lead to big changes in the prevention of chronic mental health diseases by continuous measurements to identify which patterns are normal and which are abnormal. Continuous measurements make it possible to establish which patterns are normal for a specific individual, such as respiration or heart rate, and can assist in recognizing important deviations before disease develops.",,,,,
"War, emotions, mental health, and artificial intelligence","Acoustic characteristics of speech, like prosody have commonly been utilized as indicators of sentiments, emotions and underlying physiological states (Huang et al., 2021). Slight alterations in physiological and cognitive states can result in perceptible acoustic alterations in speech perception, particularly during distressing incidents (Scherer, 1984). Certain descriptions can be readily elucidated by individual characteristics such as reduced fundamental frequency of speech, decreased number of voiced frames in an utterance, and pauses between words. Additional set of acoustic features that delineate such phenomena contributes to more information in the emotional analysis of speech (?osi? et al., 2021).",,,,,
"War, emotions, mental health, and artificial intelligence","Challenges for machine learning applications on wearable devices are related to the accuracy of machine learning models. Cross-validation techniques increase accuracy by testing the model on unseen data that have not been used in training (Sabry et al., 2022). Model interpretability is crucial, especially in wearable device applications in healthcare, where users need understandable results. Model size also matters for wearable devices due to memory constraints, as does computational complexity for inference and online training. Past obstacles in model development include data collection, feature selection, and model evaluation, highlighting the need for caution in relying on machine learning decisions. Healthcare models must generalize well, handle unseen examples, consider personal attributes, offer interpretable results, and communicate outcomes carefully (Sabry et al., 2022).",,,,,
"War, emotions, mental health, and artificial intelligence","Transformation of dominant emotional maps might be undertaken by simultaneous combination of computerized CBT (CCBT) on an individual level, as well as usage of emotionally based strategic communications (EBSC) on a public level. Strategic communications, aimed at shaping perceptions and behavior, can be enhanced by leveraging emotions, as proposed in EBSC (?osi? et al., 2012a,b). This aligns with J. A. Treadwell?s statement: ?If you want to influence someone, you have to touch their emotions? (Merle, 2005). Emotionally infused strategies, whether in individual therapy like CCBT or in strategic communications like EBSC, are essential for effective intervention. Integrating emotional strategies into strategic communications can be pivotal in conflict and post-conflict management within diverse social and cultural contexts. Hence, the proposed positive emotional transformation by means of CBT and EBSC may provide important leverage in efforts to protect mental health of local populations in war-inflicted societies. The transformation of negative dominant emotional maps into more positive emotions delivered by EBSC messages to targeted audiences is focused on mental health protection and support. This type of psychological operation can be defined as ?planned psychological activities using methods of communications and other means directed to selected audiences in order to shape their perceptions, attitudes and behavior to achieve specific political and military objectives? (Reding et al., 2010). Strategic communication can be defined as ?a systematic series of sustained and coherent activities, conducted across strategic, operational and tactical levels to promote and sustain particular types of ideas, opinions and behavior? (Tatham, 2008).",,,,,
"War, emotions, mental health, and artificial intelligence","The idea of EBSC originates from our research focused on new technologies in digital psychiatry, like Virtual Reality (VR) adaptive stimulation (?osi? et al., 2010). The similarity between individual psychotherapy, such as Virtual Reality Exposure Therapy (VRET) and their generalization to psychological operations on a strategic level, based on EBSC, is based on their common neurobiological background in ?emotional brain? (Wiederhold and Wiederhold, 2008;ÿLeDoux, 2012;ÿ?osi? et al., 2012a). The best information contents, context, and emotional properties delivered by EBSC are related to ideas and emotions that quickly resonate among targeted audiences and cause a small incremental positive emotional step toward desirable dominant emotional maps (?osi? et al., 2018). In other words, EBSC must be delivered as a comprehensive communication strategy through which individual and group emotions are reshaped in a more positive manner, producing and shaping ?soft power? important for reaching the desired emotional end state (?osi? et al., 2012a).ÿFigure 2ÿillustrates the transformation of a negative dominant emotional map of a war-inflicted society to a desirable more positive dominant emotional map, which could be facilitated by EBSC. Redirection of attention of more vulnerable individuals or selected groups from dominant negative emotions to more positive emotions may change how people appraise their current war situation, stimulating incremental emotional transformation toward more positive emotional and mental states.",,,,,
"War, emotions, mental health, and artificial intelligence","AI-based tools that can be applied in the creation of EBSC stimuli, like Chat GPT or Google Gemini (Alford, 2024), may have great potential to significantly enhance EBSC by deeper understanding of the dominant emotional maps in targeted populations by more comprehensive semantic and linguistic analyses of available text datasets (Elyoseph et al., 2023). Chat GPT and Gemini can aid in crafting emotional messages that resonate among the targeted populations, amplifying the impact of strategic communications and reshaping dominant emotional maps over time into more positive ones, simultaneously protecting human mental health in war torn societies. It is important to stress that Gemini has an advantage over Chat GPT in EBSC providing high-quality information extracted in real-time, having been trained from Gmail, Google Docs, Google Maps, and Google Drive accounts instead of books and articles to ensure more up-to-date information. However, before one can fully rely on these AI tools, the applied LLM must provide high accuracy, transparency, and trust. Off-the-shelf models such as ChatGPT 4 or Gemini can produce wrong answers which is unacceptable in any kind of public campaigning, therefore human experts must be permanently embedded in the EBSC closed loop. To be applicable, understandable, and explainable within a specific war zone or region, LLM should be trained on a relevant dataset, for example, using Ukraine or Gaza posts related to current security environment and war disasters.",,,,,
"War, emotions, mental health, and artificial intelligence","Training Chat GPT for such a specific strategic communication issue requires fine-tuning the model on a dataset relevant for the selected use cases. The collection of war domain-specific datasets from different local data sources should reflect the emotional and mental states covering a wide range of scenarios and questions that users might encounter within the selected use case domain. After cleaning and preprocessing the collected data to remove noise and tokenization, the preprocessed dataset is used to fine-tune a pre-trained ChatGPT model. Techniques like transfer learning might be used to leverage the knowledge already encoded in the pre-trained model. Training the fine-tuned model on the selected use case specific dataset is monitored by tracking metrics such as loss and validation performance. Once training is completed, evaluation of the performance of the fine-tuned model using validation data, or by manually testing it with sample inputs from related domain. Once the model has satisfied required performance metrics, it can be deployed in an EBSC campaigning process. Continuous monitoring of its performance in production requires its fine-tuning based on user feedback and real-world usage. Real time monitoring and tracking of emotional dynamics based on different data sources with a variety of NLP tools and methods within specific war zone and consequently mental health states deteriorations is extremely important. Early detection and prevention of serious mental health disorders just in time and online comprehensive state of the art therapy is prerequisite for meaningful success.",,,,,
"War, emotions, mental health, and artificial intelligence","The power of simultaneous usage of CCBT and EBSC supported by tools and means of AI may provide a breakthrough in global mental health recovery in war-inflicted societies after the enormous psychological distress caused by war brutality and tragedies. The synergy between individual psycho-therapeutic techniques, such as Virtual Reality Exposure Therapy (VRET), and psychological operations on a strategic level, based on EBSC can be understood by their common neurobiological underpinnings (Wiederhold and Wiederhold, 2008;ÿ?osi? et al., 2012a,b). The potential of AI-based tools and means, such as machine learning, deep learning, neuro-linguistic programming, cloud infrastructure, and new wearable therapeutic devices and apps offer an immense prospect to enhance mental health care on a global scale, rendering them more economically viable and readily implementable. Specifically, when considering the insufficiency of psychiatrists and the limited availability of psychiatric resources in addressing war traumas, disasters, and tragedies, the suggested approach may prove to be a transformative force in the field of psychiatry in the years to come.",,,,,
"War, emotions, mental health, and artificial intelligence","Emotionally based strategic communications supported by ChatGPT and Gemini have the potential to revolutionize digital psychiatry in combination with previously described tools and means based on multimodal physiological features, wearable and wireless devices, machine learning and edge and cloud computing. Sustainability of any long-term solution in war zones will depend on the proposed approach, bringing the new vision on how to cope with and overcome the invisible wounds of war trauma.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Precisely estimating the probability of mental health challenges among college students is pivotal for facilitating timely intervention and preventative measures. However, to date, no specific artificial intelligence (AI) models have been reported to effectively forecast severe mental distress. This study aimed to develop and validate an advanced AI tool for predicting the likelihood of severe mental distress in college students.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","A total of 2088 college students from five universities were enrolled in this study. Participants were randomly divided into a training group (80%) and a validation group (20%). Various machine learning models, including logistic regression (LR), extreme gradient boosting machine (eXGBM), decision tree (DT), k-nearest neighbor (KNN), random forest (RF), and support vector machine (SVM), were employed and trained in this study. Model performance was evaluated using 11 metrics, and the highest scoring model was selected. In addition, external validation was conducted on 751 participants from three universities. The AI tool was then deployed as a web-based AI application.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Among the models developed, the eXGBM model achieved the highest area under the curve (AUC) value of 0.932 (95% CI: 0.911?0.949), closely followed by RF with an AUC of 0.927 (95% CI: 0.905?0.943). The eXGBM model demonstrated superior performance in accuracy (0.850), precision (0.824), recall (0.890), specificity (0.810), F1 score (0.856), Brier score (0.103), log loss (0.326), and discrimination slope (0.598). The eXGBM model also received the highest score of 60 based on the evaluation scoring system, while RF achieved a score of 49. The scores of LR, DT, and SVM were only 19, 32, and 36, respectively. External validation yielded an impressive AUC value of 0.918.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning",The AI tool demonstrates promising predictive performance for identifying college students at risk of severe mental distress. It has the potential to guide intervention strategies and support early identification and preventive measures.,,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning",The online version contains supplementary material available at 10.1186/s12888-024-06017-2.,,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","The mental well-being of college students has become a growing concern due to the increasing prevalence and negative impact of mental distress [1?3]. The college years are a critical period when young adults face various challenges and transitions that can significantly impact their mental health. Studies have shown that college students experience high rates of mental distress, including anxiety, depression, and other psychological disorders [1], and there was a notable rise in self-reported psychological distress. Severe mental distress, including severe anxiety or depression [4], has been linked to several negative outcomes such as poor academic performance, decreased social engagement, and an increased risk of substance abuse [5,ÿ6].",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Accurately predicting the likelihood of mental issues among college students is crucial for early intervention and prevention [7?9]. Recent advancements in artificial intelligence (AI) and machine learning techniques have shown great promise in the field of mental health [7?9]. These technologies have the potential to revolutionize the prediction and prevention of mental health among college students. AI algorithms can process large amounts of data [10], including demographic information, lifestyle factors, and psychological parameters, to develop predictive models with high accuracy and reliability. Additionally, AI tools can provide personalized risk assessments and recommendations, facilitating targeted interventions and support [10?13]. Several studies have explored the use of AI in predicting mental health problems among college students [14?16]. These studies have shown favorable results, with AI algorithms achieving relatively high levels of accuracy in identifying individuals at high risk for mental issues, such as negative mental well-being traits, mental health problems, severe depressive symptoms, suicidal ideation, and perceived stress [7?9,ÿ14?16]. However, there have been no specific AI models reported for predicting severe mental distress currently.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Therefore, the main objective of this study was to establish an advanced AI tool specifically for predicting the risk of severe mental distress among university students, and internally and externally assess the performance of the AI tool. The findings of this study would have important implications for early intervention and preventive measures in college mental health.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","This study analyzed 2088 college students from five universities between September, 2021 and May, 2023. We recruited college students who volunteered to participate in a survey. The survey included questions about participants? basic demographics, exercise and eating habits, lifestyle, sleep quality, and mental health status [17]. The questionnaire was presented in Chinese, and the same language versions questionnaires applied uniformly on all participants. The questionnaire was distributed online at these various universities. Participants were excluded if they had a previous diagnosis of anxiety or depression, or were unwilling to participate. All participants were randomly divided into a training group and a validation group in an 8:2 ratio. The training group was used to develop models, while the validation group was used to test the models internally. External validation was conducted on 751 participants from three universities between May and June 2023. The survey distributed was identical to the one used for model development, ensuring consistency in the data collection process. Notably, the online survey was anonymous and did not collect any personal information. See Fig.ÿ1ÿfor a visual representation of the study design. The study was approved by the Academic Committee and Ethics Board of the Xiamen University of Technology, and all participants provided informed consent. This study was conducted in accordance with the Declaration of Helsinki and reported following the TRIPOD Checklist [18].",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","In this study, data on participants? age, gender, grade, marital status, drinking and smoking habits, dietary preferences (such as low salt and oil, fatty foods, red meat, barbecued foods, vegetables, and fruits. In addition, a dietary questionnaire is presented as Supplementary Fileÿ1), monthly expenses, daily sedentary time, frequency of exercise per week, presence of chronic diseases, and sleep quality were collected, after reviewing literature and counseling experts. An explanation of why the selected variables were chosen in this study is summarized in Supplementary Tableÿ1. Chronic diseases considered in the study included hypertension, diabetes, congenital heart disease, chronic kidney disease, chronic lung disease, chronic liver disease, previous cerebral infarction, rheumatoid arthritis, multiple sclerosis, Parkinson?s disease, thyroid disorders, inflammatory bowel disease. The sleep quality of college students was assessed using the Pittsburgh Sleep Quality Index (PSQI), a widely-used questionnaire that measures various aspects of sleep quality [19]. The PSQI consists of 19 items that evaluate factors such as sleep duration, disturbances, latency, efficiency, medication usage, and daytime dysfunction. Each item is scored on a scale from 0 to 3, with a total score ranging from 0 to 21. Higher scores indicate poorer overall sleep quality. The Chinese version of PSQI has been pre-validated in Chinese university students [20].",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","The severity of anxiety was evaluated with the general anxiety disorder-7 (GAD-7), and the severity of depression was evaluated with the patient health questionnaire-9 (PHQ-9). The GAD-7 and PHQ-9 are widely used self-report questionnaires [21,ÿ22]. Both scales consist of several items that are scored on a scale from 0 to 3, with higher scores indicating greater symptom severity. A score of 15 or above was regarded as severe anxiety or depression in both scales. They were valuable tools for screening, diagnosing, and monitoring anxiety and depression in individuals. The reliability of GAD-7 and PHQ-9 was pre-validated in Chinese populations [23,ÿ24]. In this study, severe mental distress in this study was defined as participants with severe anxiety or depression [4].",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","In order to ensure the smooth development and validation of machine learning-based models, a comprehensive data preprocessing pipeline was employed in this study. The pipeline utilized the scikit-learn library (version 1.1.3) to achieve data standardization. Additionally, to address the challenge of imbalanced data distribution and improve the robustness of our models, we employed the Synthetic Minority Oversampling Technique in conjunction with Tomek Links Undersampling Techniques [11?13,ÿ25,ÿ26]. This resampling technique, known as SMOTETomek, effectively balanced the proportions of outcome classes within the training and validation groups. The SMOTETomek was selected to address data imbalance because it combines SMOTE, which generates synthetic minority class samples, and Tomek Links, which remove borderline or noisy instances, resulting in a balanced and cleaner dataset. This approach reduces overfitting by eliminating overlapping instances, enhances class separability, and is particularly effective in complex datasets where the minority class is dispersed. In addition, by implementing a stratified strategy, we ensured consistency in these proportions.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","In this study, a wide range of machine learning techniques were employed for modeling purposes. These techniques included logistic regression (LR), extreme gradient boosting machine (eXGBM), decision tree (DT), k-nearest neighbor (KNN), random forest (RF), and support vector machine (SVM). All models were trained and optimized using the same input features identified through subgroup analysis of university students with and without severe mental distress. The process of hyperparameter tuning for our machine learning models was meticulously designed to ensure optimal performance while maintaining a balance between complexity and generalization. Initially, we established wide ranges for each hyperparameter, informed by extensive literature reviews and empirical evidence [27]. This approach enabled a thorough exploration of potential values. For instance, we set the depth of decision trees to range from 2 to 100. To navigate these ranges, we employed a combination of grid search and random search techniques; grid search was used for smaller, discrete hyperparameter sets, while random search covered larger, continuous ranges. The performance of each model configuration was rigorously evaluated using k-fold cross-validation, typically with k set to 5 or 10, depending on the dataset?s size. By employing this approach, we ensured the selection of well-performing models while avoiding both underfitting and overfitting. The machine learning algorithms were implemented using Python (version 3.9.7), and hyperparameter tuning was conducted using scikit-learn (version 1.2.2).",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","To assess the prediction performance of our models, we employed highly recognized and commonly used metrics. These metrics included the AUC, accuracy, precision, recall, specificity, F1 score, Brier score, log loss, discrimination slope, calibration slope, and intercept [28,ÿ29]. The AUC was calculated by applying 100 bootstraps and represents the overall performance of a model, as it measures the area under the receiver operating characteristic (ROC) curve. A higher AUC indicates a better discrimination ability of the model, and a value above 0.90 is typically indicative of excellent prediction performance. Accuracy, precision, recall, and specificity were evaluated using confusion matrix [29]. Accuracy is a fundamental metric that quantifies the ability of a classification model to correctly classify instances. It was calculated by dividing the number of correctly classified instances (true positives and true negatives) by the total number of instances. Precision, on the other hand, focuses on the proportion of instances that were accurately predicted as positive out of all instances predicted as positive. It was calculated by dividing the number of true positive predictions by the sum of true positive and false positive predictions. Recall, also known as sensitivity or the true positive rate, measures the proportion of correctly predicted positive instances out of all actual positive instances. It was calculated by dividing the number of true positive predictions by the sum of true positive and false negative predictions.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning",The Brier score is a commonly used metric for assessing the accuracy and calibration of probabilistic predictions [28]. It calculates the mean squared difference between predicted probabilities and the actual outcomes. A lower Brier score suggests that the probabilistic predictions are more accurate and well-calibrated. The Brier score can be calculated using the following formula [28]:,,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Where, N represents the total sample, p_i represents the predicted probability of severe mental distress for the i-th instance, and 0_i represents the actual probability of severe mental ditress for the i-th instance.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Log loss, commonly referred to as cross-entropy loss, is a widely employed metric in classification tasks [30]. It computes the average negative logarithm of the predicted probabilities for the correct class. This metric assesses the disparity between predicted probabilities and the actual class labels. A lower log loss signifies superior performance of the classification model. The log loss is determined by the following equation [11]:",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Where, N represents the number of samples, M represents the number of classes, y_ij represents the true label of sample i for clas j (0 or 1), and p_ij represents the predicted probability of sample I belonging to class j.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","In addition to log loss, we utilized the discrimination slope to assess the model?s ability to rank individuals based on their predicted probabilities. The discrimination slope measures how well the model distinguishes between high-risk and low-risk individuals [11,ÿ28]. The calibration slope, on the other hand, evaluates the alignment between the model?s predicted probabilities and the observed probabilities. A calibration slope value of 1 indicates perfect calibration. Both the calibration slope and the intercept-in-large were obtained from the calibration curve, which provides insights into the model?s calibration performance.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Furthermore, we conducted a decision curve analysis to evaluate the clinical net benefit of each model. This analysis assesses the net benefit of using the model?s predictions compared to other strategies, considering the potential risks and benefits. To provide a comprehensive assessment of the predictive performance, we developed a scoring system based on previous studies [10?13]. This scoring system incorporates the 11 metrics mentioned above, assigning each metric a rating from one to six. Higher scores indicate better predictive performance, and the scoring system encompasses a range from 0 to 66.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning",This study employed the Shapley Additive Explanation (SHAP) method to assess the significance of each feature in order to enhance interpretability in clinical settings [31]. This method assigns a numerical value to each feature reflecting its influence on the model?s output. Higher SHAP values indicate a stronger feature impact. We derived individual outcome predictions using the SHAP method. The feature importance can be elucidated through the following formula [26]:,,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Where, the output of the interpretation model is denoted by g, the total number of input parameters is represented by M, phi_0 stands for a constant term, phi_j signifies the attribution value (Shapley value) assigned to each model parameter, and Z'_j corresponds to the value of the j-th feature for the specific under examination.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Within the coalition vectors, a value of ?1? denotes the presence of respective feature that aligns with the features of the case being analyzed. Conversely, a value of ?0? indicates the absence of that feature in the current case. By setting all simplified features to ?1? in a hypothetical scenario, the SHAP expression can be streamlined for a more concise depiction of feature importance based on SHAP values, and the equation is shown as follows.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","The web-based AI tool created with the best model in our study was launched to offer a user-friendly platform for researchers, clinicians, and healthcare professionals. GitHub was utilized as the code hosting platform for effective storage and version control of the codebase. Streamlit, a cloud infrastructure platform, was employed to host the online calculator, ensuring consistent and scalable performance. The tool?s user interface was crafted to allow users to effortlessly input university student?s information and promptly receive the predicted likelihood of the severe mental distress. It featured user-friendly panels for selecting model parameters, conducting probability calculations, and accessing details about the model. The interface aimed to deliver a smooth and engaging user experience, empowering users to interpret and evaluate the probabilities of severe mental distress in college students.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","In our analysis, we summarized continuous variables by calculating the average and standard deviation (SD) of the data. Categorical variables were expressed as percentages. To assess the distribution of categorical variables, we utilized the Chi-square test. When comparing continuous variables, either the student t-test or Wilcoxon rank test was applied depending on the characteristics of the data. All statistical analyses were performed using the R programming language (version 4.1.2). Statistical significance was considered present when the two-tailed P value was below 0.05.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","A total of 2088 participants were included in the study. The mean age of the participants was 19.84 years (SD: 2.12 years), with a majority of 55.9% being female. Among the participants, 46.4% were in their sophomore year. The majority of participants were single, accounting for 76.4% of the sample. Notably, a significant proportion of participants reported not drinking (80.8%) or smoking (91.7%). Details of eating and physical activity habits are summarized in Tableÿ1. Results revealed that 26.1% of participants had a preference for consuming fatty foods, whereas 29.8% preferred barbecue. Only 48.9% and 58.1% of participants reported a preference for consuming vegetables and fruits, respectively. Sedentary behavior was prevalent among the participants, with 42.4% reporting a daily sedentary time of 6ÿh or more. In terms of comorbidity burden, participants had relatively low rates of chronic diseases, with only 4.4% reporting a chronic condition. The participants had an average PSQI score of 5.57 (SD: 2.88), and the prevalence of severe mental distress was 4.07% (85/2088) among these participants.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Subgroup analysis revealed that participants with severe mental distress exhibited certain distinct characteristics. They tended to be older (P?=?0.008) and in higher grades (P?=?0.016) compared to those without severe mental distress. Additionally, they had a higher rate of smoking (P?=?0.044), a higher preference for consuming fat food (P?=?0.037), a higher monthly expense (P?<?0.001), a higher rate of chronic disease (P?=?0.043), and a higher PSQI score (P?<?0.001) (Tableÿ1). In the study, we did not find a preference for eating vegetables (P?=?0.648) to be a protective factor against severe mental distress. Additionally, while participants without severe mental distress showed a relatively higher rate of fruit consumption, this difference did not reach statistical significance (P?=?0.077).",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Furthermore, participants who engaged in physical activities frequently were found to have a lower likelihood of experiencing severe mental distress, although this association did not reach statistical significance (P?=?0.057).",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Among the developed models, the eXGBM model exhibited the highest AUC value of 0.932 (95% CI: 0.911?0.949), closely followed by the RF model with an AUC of 0.927 (95% CI: 0.905?0.943) (Fig.ÿ2). The calibration curve demonstrated that most models, particularly eXGBM, RF, and KNN, displayed favorable calibration ability (Fig.ÿ3). Further assessment of the calibration slope and intercept-in-large confirmed the good calibration of these models, with calibration slopes close to 1 and intercept-in-large values close to 0 (Supplementary Fig.ÿ1). The probability density curve revealed the ability of the eXGBM, RF, and KNN models to effectively distinguish participants with and without severe mental distress. This was indicated by the leftward shift of the peak of the blue curve (participants without severe mental distress) and the rightward shift of the peak of the red curve (participants with severe mental distress) (Fig.ÿ4). Violin plots supported this trend, with the eXGBM model exhibiting the highest discrimination slope (0.598), followed by the KNN model (0.594) and the RF model (0.553) (Fig.ÿ5). In terms of performance measures, the eXGBM model demonstrated superior accuracy (0.850), precision (0.824), recall (0.890), specificity (0.810), F1 score (0.856), Brier score (0.103), and log loss (0.326) (Fig.ÿ6; Tableÿ2). The decision curve analysis for each model (Supplementary Fig.ÿ2) indicated that the eXGBM model provided favorable clinical net benefit compared to the other models (Fig.ÿ7). Based on the comprehensive evaluation scoring system, the eXGBM model received the highest score of 60, while RF achieved a score of 49 (Fig.ÿ8). The scores for LR, DT, and SVM were only 19, 32, and 36, respectively. These results suggested that the eXGBM model was the optimal one.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","External validation of the eXGBM model was conducted using a separate cohort of 751 participants. The baseline characteristics of these participants are summarized in Supplementary Tableÿ2. The external validation yielded an AUC value of 0.918 (95% CI: 0.904?0.933) (Supplementary Fig.ÿ3). In terms of performance measures, the eXGBM model demonstrated an accuracy of 0.849, precision of 0.886, recall of 0.801, F1 score of 0.841, Brier score of 0.115, and log loss of 0.408. The probability density curve showed that the eXGBM model had favorable discrimination (Supplementary Fig.ÿ4), supported by a discrimination slope of 0.594 (Supplementary Fig.ÿ5). The calibration slope was found to be 0.739, and the intercept-in-large value was 0.637 (Supplementary Fig.ÿ6). Decision curve analysis further demonstrated that the eXGBM model provided favorable clinical net benefits (Supplementary Fig.ÿ7). Additionally, it was observed that the PSQI was positively associated with the SHAP value for PSQI. Overall, the external validation results confirmed the robustness and generalizability of the eXGBM model in predicting the outcome in an independent cohort.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","The SHAP analysis revealed that the three most important features for predicting the outcome were PSQI, age, and grade, as evidenced in both the training (Fig.ÿ9A) and validation (Fig.ÿ9B) groups. The relationship between continuous features, such as age and PSQI, and their corresponding SHAP values is depicted in Supplementary Fig.ÿ8. The absolute value of the SHAP value for PSQI indicates its contribution to the outcome. A larger absolute SHAP value suggests a greater contribution, while a negative value represents a protective factor, and a positive value represents a promoting factor. Supplementary Fig.ÿ9ÿillustrates a true positive case, where features such as PSQI, grade, monthly expense, age, smoking, and fat food were identified as risk factors, while chronic disease acted as a protective factor. Each feature had a corresponding SHAP value, with larger values indicating a greater contribution to the outcome. The sum of the SHAP values in this case was 1.737, significantly larger than the base value of -0.010, indicating a positive prediction. On the other hand, Supplementary Fig.ÿ10ÿdepicts a true negative case.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","The web-based AI tool has been successfully developed by uploading the highly optimized eXGBM model and its code to a GitHub repository. This model has been integrated into the Streamlit platform, ensuring easy and user-friendly access to the AI tool. The code of the model can be available at:ÿhttps://github.com/Starxueshu/predictionofmentaldistress. Once accessed, users can generate highly personalized risk assessments for severe mental distress among college students (Fig.ÿ10). By selecting their desired model parameters and simply clicking the ?submit? button, the tool will provide individual risk assessments based on the powerful eXGBM model. Additionally, the tool provides a stratification of university students into high-risk and low-risk groups, enabling tailored recommendations for early prevention of mental distress. To ensure uninterrupted access and a smooth user experience, the platform includes a reactivation feature. In the event of platform inactivity or shutdown, users can reactivate it effortlessly by clicking on the ?Yes, get this app back up!? option. Within a short span of approximately 30ÿs, the platform will be up and running again, allowing users to continue utilizing the online application without any inconvenience.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","The main finding of this study is that the developed AI tool demonstrates promising predictive performance for identifying college students at risk of severe mental distress. Among the various machine learning models evaluated, the eXGBM model achieved the highest performance with an AUC value of 0.932. This indicates the model?s ability to accurately discriminate between individuals with and without severe mental distress. In addition, external validation of the AI tool further supported its effectiveness, yielding an impressive AUC value of 0.918. This validates the generalizability and robustness of the tool?s predictive capabilities across different university populations. Thus, the AI tool could effectively stratify college students into high-risk and low-risk groups, enabling personalized recommendations for preventive interventions. By stratifying students into risk groups, the tool could facilitate targeted interventions and preventive measures, ultimately improving mental health outcomes and overall well-being in the college population.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","Machine learning and artificial intelligence techniques have been utilized for early detection, prognostication, and prediction of negative psychological well-being states [7?9]. For instance, Rahman et al. [7] discovered that machine learning algorithms can effectively assess mental well-being, with random forest and adaptive boosting algorithms achieving the highest accuracy in identifying negative mental well-being traits. The key predictors of poor mental well-being included the frequency of sports activities per week, body mass index, grade point average, sedentary hours, and age. The study proposes that these findings could be utilized to offer cost-effective support and enhance mental well-being assessment and monitoring at both the individual and university levels. Baba et al. [8] developed a machine learning model to predict students? mental health problems using health survey data and response time metrics. The LightGBM model was found to be the most effective, with high predictive performance (AUC?=?0.857). Responses to questions about campus life were key predictors of mental health issues based on the SHAP analysis. While the inclusion of response time-related variables did not significantly improve predictions, certain derived variables based on response times enhanced prediction accuracy. The findings suggest the potential of using machine learning to predict mental health issues over time and highlight the importance of incorporating behavioral data in mental health assessments. Meda et al. [9] focused on the mental health of university students, revealing high levels of severe depressive symptoms and suicidal ideation. Economic worry was associated with depression, and demographic factors were found to be poor predictors of mental health outcomes. The random forest algorithm showed high accuracy in predicting students maintaining well-being (Accuracy: 0.85) but had limitations in predicting symptom worsening (Accuracy: 0.49). Anbarasi et al. [14] used the RF to established a model to assess quality of life, and the study found a positive correlation between sleep quality and anxiety levels. Students were identified as being highly susceptible to mental health disturbances during the COVID-19 pandemic, particularly due to factors such as online learning challenges, parental involvement, and workload stress. In the present study, we also found that quality of sleep was an important contributor to severe mental distress, as it ranked first based on feature importance analysis. Ratul et al. [15] developed a reliable machine learning-based prediction model using the multilayer perceptron algorithm for perceived stress and achieved high accuracy (Accuracy: 0.805), precision, F1 score, and recall values. However, the convenience sampling technique used in the study may have biased results and lack generalizability. In addition, Rois et al. [16] used advanced machine learning approaches to predict the prevalence of stress among Bangladeshi university students (n?=?355), and identified important risk factors for stress, including pulse rate, blood pressure, sleep and smoking status, and academic background. The RF model showed the highest performance in predicting stress (AUC: 0.897), outperforming logistic regression and support vector machine models. The outcome indicator of our study was severe mental distress, while the outcome indicators in the above other studies included negative mental well-being traits, mental health problems, severe depressive symptoms, suicidal ideation, and perceived stress. Although the model variables differ, they generally cover similar aspects such as exercise habits and sleep habits. In addition, by comparing, it can be seen that although these studies all utilize machine learning and artificial intelligence techniques to predict and assess the mental health status of college students, their research content and focus are different, exploring and studying different aspects of mental health issues.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","For university students identified as high-risk individuals with severe mental distress, a comprehensive management approach is imperative to address their specific needs. Firstly, a multidisciplinary team comprising mental health professionals, counselors, and medical practitioners should be involved in their care. This team can collaborate to develop personalized treatment plans tailored to the individual?s condition. Intensive therapy sessions, such as cognitive-behavioral therapy [32] or dialectical behavior therapy [33], can be implemented to help these students develop coping mechanisms and improve their emotional well-being. Additionally, pharmacological interventions, under the guidance of a psychiatrist [34], may be considered to alleviate symptoms and stabilize their mental health. Regular follow-up appointments and close monitoring of their progress are crucial to ensure the effectiveness of the management plan. It is crucial to acknowledge that although the AI application offers risk estimates and recommendations, clinical decision-making should encompass the expertise of healthcare providers and take into account the unique context of each student.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","University students identified as low-risk individuals in terms of severe anxiety and depression require a different approach to management. While their mental health concerns may be less severe, proactive measures should still be taken to promote their overall well-being and prevent the development of more significant issues. One key aspect is the provision of mental health education and exercise or mindfulness-based programs on campus [35,ÿ36]. These initiatives can help students recognize the signs of mental distress and equip them with self-help strategies to manage mental distress and maintain good mental health. Additionally, establishing a supportive environment through peer support groups or mentoring programs can foster a sense of belonging and provide a platform for students to share their experiences and seek guidance [37]. By implementing these preventive measures, the university can create a nurturing environment that supports the mental well-being of all students, including those at low risk for severe mental distress. It is crucial to acknowledge that although the AI application offers risk estimates and recommendations, clinical decision-making should encompass the expertise of healthcare providers and take into account the unique context of each student. Notably, a comprehensive support mechanism was implemented during the study. This included providing participants with access to mental health professionals, offering counseling services, and ensuring that participants were informed about these resources prior to their involvement. Besides, this study established a clear protocol for managing distress during and after participation, ensuring participants had immediate support if needed.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","There are several limitations in this study. Firstly, the sample size was limited to 2088 college students from five universities, which may constrain the generalizability of the model. The results may not be applicable to populations with different culture in other nations. Secondly, although a favorable AUC value was achieved in external validation, further extensive external validation is needed to ensure the robustness and reliability of the model. Additionally, while the machine learning models used in the study performed well on the training set, they may be influenced by data quality and feature selection in real-world applications, necessitating further optimization and improvement. What?s more, some of the important confounding variables, such as social support, academic stress, financial stress, interpersonal relationships and exposure to digital media, were not included for analysis. Incorporating these factors into the prediction model might further improve the prediction performance and impact of the model. Lastly, while the AI tool showed promising performance in predicting severe mental distress in college students, mental health issues are complex and diverse, and a simple prediction may not comprehensively assess an individual?s mental health status. Therefore, a comprehensive evaluation and intervention combining other factors are still required. Further in-depth research and improvement are needed before applying the AI tool in practical clinical practice.",,,,,
"An artificial intelligence tool to assess the risk of severe mental distress among college students in terms of demographics, eating habits, lifestyles, and sport habits: an externally validated study using machine learning","In conclusion, the developed AI tool demonstrates promising predictive performance for identifying college students at risk of severe mental distress. Its high accuracy and reliability highlight its potential to guide intervention strategies and support early identification and preventive measures. The tool?s accessibility and ability to provide personalized recommendations make it a valuable resource for improving mental health outcomes among college students.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Brain disorders are one of the major global mortality issues, and their early detection is crucial for healing. Machine learning, specifically deep learning, is a technology that is increasingly being used to detect and diagnose brain disorders. Our objective is to provide a quantitative bibliometric analysis of the field to inform researchers about trends that can inform their Research directions in the future.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,We carried out a bibliometric analysis to create an overview of brain disorder detection and diagnosis using machine learning and deep learning. Our bibliometric analysis includes 1550 articles gathered from the Scopus database on automated brain disorder detection and diagnosis using machine learning and deep learning published from 2015 to May 2023. A thorough bibliometric an lisis is carried out with the help of Biblioshiny and the VOSviewer platform. Citation analysis and various measures of collaboration are analyzed in the study.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"According to a study, maximum research is reported in 2022, with a consistent rise from preceding years. The majority of the authors referenced have concentrated on multiclass classification and innovative convolutional neural network models that are effective in this field. A keyword analysis revealed that among the several brain disorder types, Alzheimer's, autism, and Parkinson's disease had received the greatest attention. In terms of both authors and institutes, the USA, China, and India are among the most collaborating countries. We built a future research agenda based on our findings to help progress research on machine learning and deep learning for brain disorder detection and diagnosis.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"In summary, our quantitative bibliometric analysis provides useful insights about trends in the field and points them to potential directions in applying machine learning and deep learning for brain disorder detection and diagnosis.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The evolution and development of healthcare systems have become an important aspect of the medical field. Detecting diseases has also grown more reliant on biomedical technology such as ultrasonography, X-rays, particle beams, and MRI, among others [1]. The excessive accumulation of biological data is a challenge for healthcare providers as technology is used more. Nonetheless, high-performance computer technologies have accelerated the analysis of biological data and lowered the workload on healthcare workers. Adoption of technology has helped us understand various human diseases including cardiovascular, genetic, psychological, brain, skin, trauma, infectious, tissue, and digestive issues, to name a few [2].",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Despite advances in medical technology and care, diagnoses of brain disorders (especially psychiatric disorders) remain a challenge due to our limited understanding of brain function. The brain is often regarded as the most essential organ in the human body, governing ideas, memories, emotions, motor abilities, vision, and respiration. The human brain is made up of 100 billion neurons that are linked together by more than 100 trillion synapses [3]. These connections are organized at different spatial scales anatomically, and interact with one another at different temporal scales functionally. Because of this complexity, understanding the neurological underpinnings of brain functions remains a challenge.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Since the brain is such an essential organ, brain disorders have a large burden on one?s life. People's memory, senses, and even the personality can all be negatively impacted by the brain disorder [4]. Although increased awareness of these diseases and technological/scientific progress has reduced mortality, some chronic brain disorders can cause permanent or partial impairment or pain. The global prevalence of these diseases was 15% of all cases [5]. Furthermore, these disorders have a high annual causation rate of 16.8%.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Brain disorder diagnosis is a growing and challenging issue due to the large volumes of brain disorder data generated by current diagnostic tools. Manual analysis of this data is often subjective, leading to the development of automated computer-aided diagnosis systems using machine learning (ML) and deep learning (DL) technology [6-8]. These systems have become an important research topic in recent years, as medical data collection techniques and ML approaches may vary depending on the diagnostic method and disorder type. The field has seen explosive growth in recent years, making it difficult to understand the path charted due to the large and diverse literature. A systematic bibliometric study of the field is needed to assess trends, future research subjects, state-of-the-art, and breakthroughs in brain disorder detection and diagnosis using ML and DL techniques.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The motivation of this study is to enhance past evaluations with a bibliometric review of ML and DL-based brain disorder detection and diagnosis. Bibliometric research is a quantitative and statistical examination of literature that allows for the investigation of far bigger bibliographic datasets than qualitative systematic literature studies. Bibliometric studies have grown in popularity in recent years as a result of their benefits. In recent years, bibliometric methodologies have been employed in a wide range of fields and subjects [9-11] assist in to progress of a topic by gathering and analyzing earlier research and methodically summariz- ing existing results and can also assist in defining possible future research topics, providing a forum for interested re- searchers. The second objective of this research is to identify the most significant entities in this sector, such as influential countries, institutions, sources, and publications as well as to identify research gaps in the field of ML and DL-based brain disorder detection and diagnosis which can lead to indicate future research priorities.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The purpose of this bibliometric research is to address the following questions to expand earlier research on ML and DL in brain disorder detection, and diagnosis:",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"1. What are the most reputable sources, materials, and most often referenced papers in this field?",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,2. How many average and year-by-year citations for each research document receive?,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"3. What is the yearly research growth rate and the link between countries, authors, and research papers?",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,4. Which journals are the most successful and frequently cited as well as which countries have made the biggest contributions in the aforementioned field?,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,5. Who are the field's most influential and most often mentioned authors and which are the most influential institutions?,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,6. What is the link between the number of papers published and the number of authors in the most trending topic in this field?,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,7. Which keywords are often used?,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,8. What are some prospective future research directions that might aid in the advancement of research on ML and DL-based brain disorder detection and diagnosis?,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The above research questions reveal changes in research output over time, influencing funding decisions and future research orientations. By analyzing citation effects of publications, and journals, scholars can identify significant research on a subject [12-14]. Understanding collaboration patterns can the researchers identify successful research partnerships, reveal new research areas, and provide insights into productivity and impact across different areas and nations, driving research policy and funding decisions.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"This research contributes to the field of ML and DL-based brain disorder detection and diagnosis by identifying research trends, creating a bibliometric framework for analysis, and identifying networks of collaboration among authors, institutions, and countries [15-17]. It helps identify gaps in the literature and guides future research strategies. Practical contributions include identifying essential study areas for other researchers to prioritize and identifying important researchers and institutions for collaboration. This data can help researchers identify gaps in the literature and encourage knowledge sharing among researchers.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"In our investigation, we combined two tools: Bibliometrix/Bilioshiny [18] and VOSviewer [19]. To begin, Bibliometrix is a free and open-source R program created by Massimo Aria and Corrado Cuccurullo. It enables a wide range of different types of analysis on bibliometric data. Bibliometrics was also supplemented by Biblioshiny. Biblioshiny improves the generation of bibliometric data visualizations. VOSviewer was used alongside Biblioshiny and Bibliometrix. VOSviewer is a bibliometric data visualization tool developed by the Centre for Science and Technology Studies at Leiden University in the Netherlands. VOSviewer has been used in several bibliometric studies and allows for the creation of bibliometric networks that demonstrate associations between, for example, publications, keywords, or researchers. VOSviewer also allows for the establishment of co-citation, bibliographic coupling, and co-authorship analysis. Although Biblioshiny excels in statistical features, we found VOSviewer to be an excellent tool for visualizing keyword co-occurrences.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The organization of the manuscript is as follows: section 2 provides the overview of materials and methods, results of the analysis are reported in section 3, the discussion and the details of the future research agenda related to the analysis are reported in section 4, and at last the conclusion section concludes the manuscript.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"This section describes our bibliometric methodology [20-22]. The process of conducting bibliometric research may be separated into three parts. First, the data to be analyzed must be gathered. The first subsection describes this phase. The data-collecting process is followed by the data analysis step. The second subsection describes this procedure. The third subsection describes the bibliometric analysis methodology.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The initial step was to gather bibliometric information for our investigation. Several databases exist now for the collection of bibliometric data, with Scopus and Web of Science being among the most popular. The characteristics and functionality of these databases differ and thus we collected the bibliometric data from only the Scopus [23] database. The main motivation for selecting the Scopus database is as follows. This database includes more journals than Web of Science and was thus deemed to be appropriate for identifying as many research articles as feasible. Although additional databases such as Google Scholar and PubMed are available, we choose not to use them [24]. First, unlike Google Scholar, Scopus allows researchers to create a comprehensive search phrase and instantly obtain all bibliometric metadata. Second, Scopus covers far more multidisciplinary research than PubMed. Thus, we identified Scopus to be the best database for conducting a bibliometric study since ML and DL-based brain disorder detection and diagnosis is a multidisciplinary research field.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"We conducted a subject data search that comprised the title, abstract, and keywords on 1stÿJune 2023. We discovered that many titles did not fit our desired keywords even when the corresponding papers investigated topics relevant to the scope of our search. For example, instead of referring to ?deep learning? and ?machine learning,? authors would refer to a specific deep learning technique, such as the convolutional neural network (CNN). Some researchers didn't even include ?brain disorder? in the title, rather they have used the name of the disorder such as Alzheimer?s, Parkinson's,ÿetc. This led to the following search string that was applied: ((?machine learn*? OR ?deep learn*? OR ?neural network?) AND (?brain disord*?) AND (?detection? OR ?diagnosis? OR ?classification?). The search results were narrowed down to 8.5 years (2015-May 2023) to find the most recent trends and state of the art. The justification for taking into consideration the articles from 2015 is as follows: before 2015 there was no significant number of articles published in the considered domain. Because of Scopus' syntax, the * sign is used to search for all potential word ends of the search query. An additional filter was used, which restricted the document type to the article, conference paper, review, book chapter, and book. Finally, a total of 1550 Scopus document entries with all associated metadata were exported. Fig. (1) shows the pictorial depiction of the bibliometric data collection method.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Bibliometric analysis techniques are emerging techniques nowadays as it provides the trend and importance of a particular research field. In thus study two tools Bibliometrix/Bilioshiny [18] and VOSviewer [19] are used for the analysis as discussed in the introduction section.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Bibliometric analysis is an academic literature evaluation approach that depends on the quantitative examination of publications.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"We begin by providing a summary of the dataset, which includes the following items:",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Main information and general matrices: A table displaying the key characteristics of our dataset.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Scientific production: a diagram representing the investigated field's yearly scientific productivity.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Average citations per year: An illustration depicting the increase of average citations over time.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Three-field plot: Relationship between authors, countries, and titles.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The second section of the findings is regarding sources. This is based on a domain analysis and visualization approach. The source in bibliometric analysis typically includes several components These components can call attention to potentially relevant trends and patterns, as well as scientific transformation concepts that can influence conceptual frameworks. We concentrated on the following concerns in this step:",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,The most productive and top cited sources: A visualization displaying the top ten most active journals in terms of the number of papers published and the top cited journals in terms of the number of citations received.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Sources based on Bradford?s law: A pictorial depiction of sources which is based on Bradford?s law [25].,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Sources production over time: A graphic that represents the sources' publication amount over time.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,The third part is related to the detail visualization of the information related to the authors. In this section we have covered the following:,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,The Most Relevant Authors: a graphic displaying the top ten writers in terms of article volume.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,The Most Relevant Institutions: A graph depicting the top ten most productive organizations based on the number of papers generated.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The most relevant countries: A diagram displaying the top ten most relevant nations based on the number of articles generated, either in single-country or multiple-country publications.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,The Most Cited Authors: A diagram of the top ten most cited authors from the Scopus database.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Author productivity through Lotka's Law: A diagram and table displaying the frequency analysis of research publications based on Lotka's law [26].,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Most cited countries: A graph depicting the most cited countries.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,The fourth subsection is based on the detail representation related to documents. In this part we have covered the following:,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,The Most Cited documents: A graph of the top ten most cited publications from the Scopus database.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The Most Frequent Words: A visualization and a word cloud of the most frequently used words in the documents' abstract, title, and keywords.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Word?s frequency over time: A graph that represents the most frequently used words over time.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Trend topics: A representation of the hot topics in the field.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Most local cited references: A visualization of the most cited references collected from the selected publications.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,The fifth part presents details of the conceptual structure. In this part we have focused on the following:,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Keyword co-occurrence network: A graph that shows the association between important terms and separates them into smaller groupings.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Thematic Map: A thematic map is a network graph that is generated by the keywords and how they are related. The labels of each thematic map are recognized by the name of the keyword that appears most frequently in the associated topic [27].,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Factorial analysis: The factorial analysis is done based on Correspondence Analysis (CA) and Multiple Correspondence Analysis (MCA). CA [28] is a visual approach to understanding the relationship between elements in a frequency table is correspondence analysis. It is a derivative of principal component analysis and is meant to analyze links between qualitative factors. MCA [29] is used for analyzing the data visually, multidimensionally, and mathematically.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The final section is network analysis. Network analysis, according to graph theory or network theory, is the study of network characteristics and the interactions between their vertices and arcs. The betweenness centrality indices and proximity are the most important measurements for network analysis [30]. We concentrated on the following items in this section of the research:",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Collaboration globe Map and Network: data visualization and a globe map depicting the collaborative relationships between countries.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Authors co-citation network: a representation of the connection network between authors based on co-citations.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"In this first paragraph, we will provide a summary of our sample as well as some of its characteristics such as yearly output, document kinds, and author information. Tableÿ1ÿprovides an overview of our final sample's basic metrics. The sample has 1550 distinct papers in total. These publications were authored and co-authored by 3801 distinct researchers, for a total of 0.4 documents per author. 403,380 references were mentioned in all, with 1834 author keywords and 5010 keywords plus (additional keywords). The 1550 documents were published in 388 different sources and garnered an average of 15.87 citations. Around 31.43% of the 1550 multi-authored publications were created in collaboration with an international team. The vast bulk of research has been published in the previous 8.5 years.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Fig. (3) depicts the annual scientific output in the field of ML and DL-based brain disorder detection and diagnosis. With 4 relevant publications released in 2015, the number of documents published in 2022 has reached 433 articles. Till May 2023 the number of relevant publications is 100.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Fig. (4) depicts the annual average number of publication citations. The average number of citations per publication published in 2015 is 2.14 with 9 citable years whereas the average number of citations per publication published in 2022 is 1.43 with 2 citable years. The publications of the year 2017 have gained 12.14 average citations with 7 citable years. Up to May 2023, the average number of citations per publication published is 0.42.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The three-field figure depicts the link between the countries (left column in Fig.ÿ5), authors (middle column in Fig.ÿ5), and keywords (right column in Fig.ÿ5) of the relevant publications. Rectangles in various colors were used to depict the diagram's relevant components. The total of the associations forming between the elements that the rectangle represented determined the height of the rectangles. The thickness of the linkages indicates that a significant quantity of information is traveling between a group of values. The most significant study themes on ML and DL-based brain disorder detection and diagnosis have been authored by authors from China, and USA, as illustrated in Fig. (5). The total number of items considered is 20.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Fig. (6) shows the top 10 most productive sources for ML and DL-based brain disorder detection and diagnosis publications. Lecture notes in computer science are the most prolific source with 37 documents, Frontiers in neuroscience journal has published 23 documents, and Biomedical signal processing and control journal has 18 documents, according to the research.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The top ten most-cited sources for works in ML and DL-based brain disorder detection and diagnosis are shown in Fig. (7). The Neuroimage journal was the most cited source, with 1112 citations, followed by Frontiers in neuroscience journal with 504 citations, and Neuroimage: Clinical journal came in third with 498 citations.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Fig. (8) represents the spread of sources in the field of ML and DL-based brain disorder detection and diagnosis based on Bradford's law.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Fig. (9) shows the five most productive sources over time in the field of ML and DL-based brain disorder detection and diagnosis. From the illustration, we can see that Lecture notes in computer science are publishing more papers in this field over time followed by Frontiers in neuroscience journal, NeuroImage, and IEEE journal of biomedical and health informatics.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Fig. (10) depicts the ten most relevant authors. In the topic of ML and DL-based brain disorder detection and diagnosis, 3801 authors published 1550 publications. The most productive authors were Acharya, U.R. with 16 publications, with a fractionalized value of 2.63 and 457 total citations since 2018, respectively, followed by Zhang and Li with 14 publications but 530 total citations and 13 publications with 167 total citations and fractionalized values of 1.94 and 1.71 correspondingly since 2017. Calhoun V.D. is in the fourth position with 11 publications but with 858 total citations since 2016.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Fig. (11) depicts the evaluation of the publishing output of organizations or author affiliations that contributed to the field of ML and DL-based brain disorder detection and diagnosis. Stanford University earned the top place with 67 articles.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"As demonstrated in Tableÿ2ÿand Fig. (12), this study also considered the countries where the authors published their contributions to the field of ML and DL-based brain disorder detection and diagnosis. The USA took first place with 94 single-country publications, 34 multi-country publications, and a frequency of 0.149. The USA, China, and India are the top three scientific productivity countries in the world in this field.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Local citations indicate how often a researcher in this selection has been cited in other articles in the selection. Local citation score and global citation score measures were utilized to conduct a more in-depth evaluation of the source publications. The local citation score measured the frequency with which other publications in the collection acknowledged the authors' works in the Scopus database. Total citations reflect the number of times the articles in this collection have been referenced, according to the global citation score. However, the articles cited did not necessarily deal with ML and DL-based brain disorder detection and diagnosis. The higher the score for local citations, the more relevant the item was to the domain. The research also used bibliometrics to examine the publication output of the subject's most widely read authors. Duncan, J.S., Dvornek, N.C., Li, X., Papademetris, X., Staib, L.H., Ventola, P., and Zhuang, J. have ranked first, as shown in Fig. (13), with 7 citations.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Taking into account the authors? local impact, we identified the 10 most globally cited authors in terms of total publications (TP), total citations (TC), and publication year start (PY_start), as shown in Tableÿ3.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"This bibliometric study computes Lotka's law coefficients for ML and DL-based brain disorder detection and diagnosis articles. Lotka?s law describes the productivity of authors in a certain subject area. Lotka?s law states that ?as the frequency of publications increases, the approximate number of authors with that frequency of publications may be predicted?, and in particular, ?at a higher level of productivity, there are fewer authors?. This law enables the identification of the most significant authors in a certain area [31]. Lotka's Law's frequency distribution of scientific output is seen in Fig. (14). It can be noticed how the percentage of authors with a lower number of articles produced is very high concerning the percentage of authors with more than three documents published. Tableÿ4ÿdemonstrates how the number of publications and the frequency of authors in the area under examination significantly follow Lotka's law.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Fig. (15) shows the most cited countries in the field of ML and DL-based brain disorder detection and diagnosis. As per the representation, the USA has gained the maximum citation with 5595 citations followed by China with 2700 and Brazil with 1330 citations.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,The amount of citations a given document has received from any other publication in the whole Scopus Core Collection is referred to as its global citation count. Fig. (16) depicts the most widely referenced documents worldwide.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Arbabshiraniÿet als research ?Single subject prediction of brain disorders in neuroimaging: Promises and pitfalls? [32] was published in Neuroimage Journal in 2017, rated #1 with 522 citations. This paper summarises and discusses detailed information about schizophrenia, mild cognitive impairment, Alzheimer's disease, depressive disorders, autism spectrum disorder, and attention deficit hyperactivity disorder, such as sample size, type and number of extracted features, and reported accuracy. The authors describe key weaknesses of existing research from the perspective of ML and DL. Common prejudices are explored, and recommendations are made. There is also a discussion of upcoming themes such as decentralized data sharing, multimodal brain imaging, differential diagnosis, disease subtype categorization, and deep learning.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The second most cited article, ?Identification of autism spectrum disorder using deep learning and the ABIDE dataset? [33] was published in 2018 by Heinsfeld, A.S. et al in Neuroimage: Clinical journal and has been cited 462 times in the Scopus database, with an annual citation rate of 77. Using ABIDE data, the authors used DL to classify autism spectrum disorder (ASD) from controls. The authors looked at functional connection patterns that objectively identify ASD individuals in functional brain imaging data, and they sought to uncover the neural patterns that came from the classification. rs-fMRI was used to extract brain function patterns, which revealed anterior-posterior underconnectivity in the autistic brain.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Vieiraÿet al. published the third most cited article ?Using deep learning to investigate the neuroimaging correlates of psychiatric and neurological disorders: Methods and applications? [34] in the journal Neuroscience & Biobehavioral Reviews in 2017. This article has been referenced 365 times. The authors explained the fundamental ideas of DL and reviewed research that employed this technique to categorize brain-based disorders in this paper. This article discusses future research and the issues of DL in neuroimaging.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Habesÿet al.ÿpublished ?White matter hyperintensities and imaging patterns of brain aging in the general population? [35] in Brain journal in 2016 which is the fourth most cited article. This study looks at the association between the burden of white matter hyperintensities and patterns of brain shrinkage associated with brain aging and Alzheimer's disease in a large population-based sample (n = 2367) with a wide age range (20-90 years) from the Pomerania Health Study.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Another work of the year 2016 was the fifth most cited document, ?Deep neural network with weight sparsity control and pre-training extracts hierarchical features and enhances classification performance: Evidence from whole-brain resting-state functional connectivity patterns of schizophrenia? [36] published by Kimÿet al. in NeuroImage journal. The goal of this study was to use a deep neural network (DNN) to classify whole-brain resting-state Functional connectivity (FC) patterns in schizophrenia (SZ) patientsÿvs.ÿhealthy controls (HCs) and to identify aberrant FC patterns associated with SZ.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The sixth most cited (211) article is entitled ?Brain MRI Analysis for Alzheimer?s disease diagnosis using an ensemble system of deep convolutional neural networks? [37] and was published by Islamÿet al. in Brain Informatics journal in 2018. Using brain MRI data analysis, the authors proposed a deep convolutional neural network for Alzheimer's disease diagnosis and identifying distinct phases of Alzheimer's disease.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Likewise, ?A Review on a Deep Learning Perspective in Brain Cancer Classification? [38] was the seventh most cited (198) document. Tandelÿet al.ÿpublished this study in the Cancers journal in 2019. The authors summarize the pathophysiology of brain cancer, imaging modalities for brain cancer, and automatic computer-aided approaches for brain cancer characterization in an ML and DL paradigm in this study. Another goal of this article was to identify present problems with existing engineering approaches and to forecast a future paradigm. Furthermore, in the context of machine learning and the deep learning paradigm, the authors have emphasized the association between brain cancer and other brain disorders such as stroke, Alzheimer's, Parkinson's, Wilson's disease, leukoaraiosis,ÿetc.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"?Hierarchical Fully Convolutional Network for Joint Atrophy Localization and Alzheimer's Disease Diagnosis Using Structural MRI? [39], the eighth paper, was published in 2020 and has been referenced 190 times in the Scopus database, with a citation rate of 47.5 each year. Lianÿet al.ÿpublished this paper in IEEE Transactions on Pattern Analysis and Machine Intelligence journal. The authors propose a hierarchical fully convolutional network (H-FCN) to automatically identify discriminative local patches and regions in whole brain structural magnetic resonance imaging, which is then used to jointly learn and fuse multi-scale feature representations to construct hierarchical classification models for Alzheimer's disease diagnosis.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,The ninth most-cited paper (183 citations) is titled ?3D CNN Based Automatic Diagnosis of Attention Deficit Hyperactivity Disorder Using Functional and Structural MRI? [40] and was published in IEEE Access magazine in 2017 by Zouÿet al.ÿThe authors provide a DL-based attention deficit hyperactivity disorder classification approach using 3-D convolutional neural networks (CNNs) applied to magnetic resonance imaging data in this research.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Finally, Grahamÿet al. published ?Artificial Intelligence for Mental Health and Mental Illnesses: an Overview? [41] (158 citations) in Current Psychiatry Reports in 2019 with 31.6 citations each year. This article provides an overview of artificial intelligence (AI) and its current applications in healthcare, a review of recent original research on AI specific to mental health, and a discussion of how AI can supplement clinical practice while taking into account its current limitations, areas for further research, and ethical implications regarding AI technology.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The number of citations a certain document has received from any other article in the researched dataset is known as its local citation count, in our instance, the area of ML and DL-based brain disorder detection and diagnosis. Fig. (17) depicts the most frequently mentioned documents on a local level.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,LIÿet al.ÿpaper ?2-Channel convolutional 3D deep neural network (2CC3D) for fMRI analysis: ASD classification and feature learning? [42] was ranked #1 with 7 local and 49 global citations. This article was published in the IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018) in 2018. The authors suggest a new whole-brain fMRI-analysis technique to diagnose autism spectrum disorder (ASD) and investigate biological markers in ASD classification in this research.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The second most locally cited article, ?Synthetic structural magnetic resonance image generator improves deep learning prediction of schizophrenia? [43] was published in 2015 by Ulloaÿet al. in the IEEE 25thÿInternational Workshop on Machine Learning for Signal Processing (MLSP) and has been locally cited twice with 21 global citation times in the Scopus database. The authors of this article employed a feed-forward neural network to classify schizophrenia patients and healthy controls using structural magnetic resonance data.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Khanÿet al.ÿpublished the third most locally cited article ?A deep learning based scoring system for prioritizing susceptibility variants for mental disorders? [44] in the IEEE International Conference on Bioinformatics and Biomedicine (BIBM) in 2017, with 2 and 4 local and global citations in the Scopus database. The authors created a computational tool, a deep learning-based scoring system (ncDeepBrain), to analyze whole genome/exome sequencing data on personal genomes by incorporating contributions from coding, non-coding, structural variants, known brain expression quantitative trait loci (eQTLs), and PsychENCODE enhancer/promoter peaks.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"In 2018, Yaoÿet al.ÿpublished ?Resting Tremor Detection in Parkinson's Disease with Machine Learning and Kalman Filtering? [45] at the IEEE Biomedical Circuits and Systems Conference (BioCAS), which is the fourth most locally cited (2) paper with 28 global citations. The authors suggest using an ML technique to detect resting-state tremors using local field potentials (LFPs) collected from the subthalamic nucleus (STN) in 12 Parkinson's patients.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Yangÿet al.ÿpublished ?Functional connectivity magnetic resonance imaging classification of autism spectrum disorder using the multisite ABIDE dataset? [46] in the IEEE EMBS International Conference on Biomedical & Health Informatics (BHI) in 2019 which is the fifth most locally cited document with 24 global citations. The goal of this paper is to use ML algorithms to classify ASD patients and typically developing (TD) participants using resting-state functional MRI (rs-fMRI) data from the ABIDE (Autism Brain Imaging Data Exchange) large multisite data repository and identify important brain connectivity features.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The sixth locally cited (2) article entitled ?A CNN Model: Earlier Diagnosis and Classification of Alzheimer Disease using MRI? [47] was published by Salehi, A.W. et al in the International Conference on Smart Electronics and Communication (ICOSEC) in 2020 with 38 global citations. In this article, the authors employed MRI pictures, the ADNI 3 class of images, and a total of 1512 mild, 2633 normal, and 2480 AD to develop a Convolutional Neural Network (CNN) for the early identification and categorization of AD.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"In contrast, ?Implementation of a smartphone wireless accelerometer platform for establishing deep brain stimulation treatment efficacy of essential tremor with machine learning? [48] was the seventh most locally cited (1) document with 32 global citations. LeMoyneÿet al.ÿpublished this study at the 37thÿAnnual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) in 2015. In this study, authors used deep brain stimulation for the diagnosis of essential tremors.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"?Brain MRI analysis for Alzheimer?s disease diagnosis using an ensemble system of deep convolutional neural networks? [37], the eighth paper, was published in 2018 and has been globally referenced (sixth position) 211 times in the Scopus database, with a local citation 1. Islamÿet al.ÿpublished this paper in Brain Informatics journal.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The ninth most locally cited paper (1 citation) with 4 global citations is titled ?On the need for adaptive learning in on-demand Deep Brain Stimulation for Movement Disorders? [49] and was published in the 40thÿAnnual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) in 2018 by Khobragadeÿet al.ÿIn this study, two ML algorithms-Decision Tree and Large Memory STorage And Retrieval (LAMSTAR) neural networks-with surface Electromyography and accelerometry as control signals--are used to predict the onset of tremor after Deep Brain Stimulation (DBS) turned off in two patients, one with Parkinson's disease and the other with essential tremor.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Finally, Choiÿet al. published ?Deep learning only by normal brain PET identify unheralded brain anomalies? [50] (1 local and 34 global citations) in eBioMedicine journal in 2019. In this article, the Abnormality Score was defined as how much a particular brain picture deviates from normal data using variational autoencoder which is a sort of unsupervised learning.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The words ?deep learning? and ?machine learning? were the most frequently used by authors, with a total of 300 and 213 occurrences, followed by ?eeg? and ?classification? with 53 and 51 occurrences. Fig. (18) depicts the most frequently used terms in the field of ML and DL-based brain disorder detection and diagnosis. Fig. (19) depicts a word cloud of the most commonly used terms in the study on the subject under consideration. From the depiction, we can say that magnetic resonance imaging is the most popular modality for ML and DL-based brain disorder detection and diagnosis.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Fig. (20) shows the word?s frequency over time as per keyword plus in the field of ML and DL-based brain disorder detection and diagnosis for the period January 2015 - May 2023. From the representation, we can see that the frequency of using the terms ?deep learning?, ?human?, ?female?, ?brain?, ?electroencephalography?ÿetc. increasing over time.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Fig. (21) depicts the trend topics in the field of ML and DL-based brain disorder detection and diagnosis. Till May?23 the topic ?biomarkers?, ?t1 weighted imaging? and ?tinnitus? were the hot topics with frequencies 24, 10, and 9 respectively. In 2022, the topics ?electroencephalography?, ?convolutional neural network? and ?procedures? were the hot topics with frequencies 296, 235, and 141 respectively. In 2021 the topics ?deep learning?, ?brain? and ?human? were the hot topics with frequency 688, 475, and 471 respectively.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The number of citations a certain reference has received from any other article in the researched dataset is known as its local cited reference, in our instance, the area of ML and DL-based brain disorder detection and diagnosis. Tableÿ5ÿdepicts top ten the most cited references on a local level. Lecunÿet al?sÿpublication ?Deep learning? [51] published in 2015 in Nature Journal placed first with 49 citations. In this article, the authors have discussed different DL-based techniques available that can be applied in the medical field. The second most referenced (25) citation is Heÿet al'sÿwork ?Deep Residual Learning for Image Recognition? [52] published in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) in 2016. The authors give extensive empirical data in this study demonstrating that residual networks are easy to optimize and can gain accuracy from much greater depth. The book ?Deep Learning? [53] was published by Goodfellowÿet al. in MIT Press in 2016 and gained the third position (23 citations) in terms of the most cited reference. In this book, authors have covered linear algebra, probability, and information theory, different numerical computations, ML basics, deep feedforward networks, regularization for deep learning, optimization for training deep models, convolutional networks, recurrent networks, recursive networks, different applications, autoencoders, linear factor models, monte carlo method, deep generative models,ÿetc.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Fig. (22) depicts the keyword co-occurrence network. Each node in the network represents a keyword. The size of the node indicates the frequency of the keyword (how frequently the term appears). The link between the nodes represents the co-occurrence of terms (terms that appear together or co-occur), and the thickness of the association shows the frequency with which two or more terms appear together. Each color represents a topic grouping. There are 6 clusters. Cluster 1 (red) includes 31 terms such as ?deep learning?, ?machine learning?, ?Alzheimer?s disease?, ?neuroimaging?, ?epilepsy?, ?MRI?, ?schizophrenia?ÿetc. Cluster 2 (blue) consists of only two keywords such as ?electroencephalogram (EEG)? and convolutional neural network (CNN). Cluster 3 (green) includes 11 keywords like ?autism spectrum disorder?, ?fMRI?, ?deep neural network?, ?functional connectivity?ÿetc. Cluster 4 (violet) consists of only 4 keywords such as ?deep brain stimulation?, ?Parkinson's disease?, ?Parkinson?s disease? and ?essential tremor?. Cluster 5 (orange) and cluster 6 (brown) include only one keyword ?machine learning (ml)? and ?magnetic resonance imaging (MRI)? respectively.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Thematic maps are keyword clusters that may be grouped into only one circle and mapped as a two-dimensional representation utilizing the density and centrality of their keywords [59-61]. As shown in Fig. (23), a thematic map is split into quadrants based on their location. Niche topics appear in the upper-left quadrant; they are keywords with a high degree of development but may not be extremely important. In our sample, ?deep brain stimulation?, ?major depressive disorder?, and ?machine learning? fall into this category. The lower-left quadrant contains emerging or diminishing subjects, which are keywords of low to medium significance and development degrees. In this category ?convolutional neural network?, ?magnetic resonance imaging? and ?functional connectivity? are there as per our data. There are motor themes in the upper-right quadrant with the highest level of development and importance. In this category ?deep learning?, ?machine learning?, ?EEG?, ?essential tremor?, ?neuroimaging?, ?autism spectral disorder?ÿetcÿare there. The lower-right quadrant contains basic themes, which are terms with a high relevance degree and a low to medium development degree. In this category ?epilepsy?, ?deep neural network?, ?Parkinson?s disease?, ?transfer learning?, ?dementia?, ?support vector machine?ÿetcÿare there. We generated the thematic map using the ?author keyword? and ?walktrap? clustering algorithms.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Figs. (23ÿandÿ24) represent the factorial analysis using multiple correspondence analysis (MCA) and correspondence analysis (CA). MCA [62-64] is used to visually and statistically analyze multivariate categorical data. It explores the interplay of a group of categorical data to find new latent variables or components. The relative placements and distribution of the dots along the dimensions are used to interpret the results; the closer the words are put, the more similar the distribution is. Fig. (24) shows how the ML and DL-based brain disorder detection and diagnosis publications were analyzed using 30 author keywords and then ranked based on their overall citation count. There are two groups of keywords: Cluster 1 (28 keywords) and Cluster 2 (2 keywords). The densest cluster is represented in red color in Fig. (23). This category contains the vast majority of accepted and published new research. This cluster is quite powerful. The bulk of publications in this field contains study subjects including ?convolutional neural network?, ?transfer learning?, ?Parkinson's disease?, ?magnetic resonance imaging?, ?depression?, ?neuroimaging?, ?machine learning?, ?epilepsy?, ?deep learning?ÿetc. Cluster 2 (represented in blue) indicates the learning algorithms and systems for forecasting. This cluster includes two terms: ?Parkinson's disease? and ?deep brain simulation?.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"CA [65-67] is a visual way of studying how the variables in a contingency table relate to one another. It provides a way to reduce and describe data sets using two-dimensional graphs. The goal, as seen in Fig. (24) is to produce a full data picture that may be utilized for interpretation. Fig. (24) was created by using 30 author keywords and then ranking them based on their overall citation count. We discovered two keyword clusters: Cluster 1 (36 keywords) and Cluster 2 (4 keywords) and two publication clusters: Cluster 1 (593 publications) and cluster 2 (12 publications). The red area in Fig. (25) indicates that most of the research has been done on these topics including ?autism spectral disorder?, ?Parkinson's disease?, ?schizophrenia?, ?electroencephalogram?, ?electroencephalography?ÿetc.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"As seen in Figs. (26ÿandÿ27), the USA is at the heart of the largest cluster of cooperation, followed by China, the United Kingdom, Brazil, and Canada. Another cluster is visible between Germany, Australia, India, Netherlands, Italy, and Egypt. There will also be a third between Saudi Arabia, Spain, Iran, Korea, Singapore, and France.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Fig. (28) depicts a network of author co-citations. The network is organized into four clusters that reflect author co-citations. The most referenced author in Cluster 1 (red) is Acharya, U.R. Calhoun, V.D. the author with the most citations in Cluster 2 (blue). In Cluster 3 (green), Shen, D. is the most referenced author. In Cluster 4 (yellow), Dvornek, N.C. and Craddock, R.C. is the most mentioned author.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The findings of this bibliometric study and content research have led to several views and implications that have stirred much controversy. This study included 1550 publications on ML and DL-based brain disorder detection and diagnosis authored by 3801 authors between 2015 and May 2023. The annual growth rate is 36.78% and the average citation rate is 15.87. According to the numbers, the majority of documents were co-written, with just 22 being single-authored, indicating a very high degree of collaboration in this area.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The three-field plots, which use three essential metadata fields, provide useful insights into the relationship between domains, such as relating authors' work to particular keywords and nations participating in the study area. The most significant contributions to the research of ML and DL-based brain disorder detection and diagnosis were made by Acharya, U.R. from Singapore, Zhang, J. from China, as well as Calhoun VD from the USA in terms of citation impact. Our data indicate a tight relationship between topic studies in the USA, China, and India.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Fig. (6) revealed that the conference proceedings series Lecture Notes in Computer Science (LNCS) [68] provides the most recent academic breakthroughs in all fields of computer science. LNCS volumes, along with its subseries Lecture Notes in Artificial Intelligence (LNAI) [69] and Lecture Notes in Bioinformatics (LNBI) [70], are submitted for indexing in the Conference Proceedings Citation Index (CPCI), which is part of Clarivate Analytics' Web of Science; Scopus; EI Engineering Index; Google Scholar; DBLP; and other databases.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Frontiers in Neuroscience journal [71] is a peer-reviewed publication that publishes thoroughly peer-reviewed material from a wide range of professions and fields. This open-access publication is at the forefront of distributing and communicating scientific information and groundbreaking discoveries to researchers, universities, doctors, and the general public throughout the world.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The goal of the Biomedical Signal Processing and Control journal [72] is to create an international cross-disciplinary platform for the exchange of information on research in the measurement and analysis of signals and pictures in clinical medicine and the biological sciences. Contributions dealing with practical, applications-led research on the utilization of methodologies and technology in clinical diagnosis, patient monitoring, and management are prioritized. This publication highlights the primary areas in which these technologies are applied and developed at the intersection of engineering and clinical science.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Fig. (7) reveals that NeuroImage [73], a Journal of Brain Function, serves as a platform for conveying significant breakthroughs in the use of neuroimaging to investigate structure-function and brain-behavior links. Though the emphasis is on the macroscopic level of human brain organization, breakthroughs in meso-and microscopic neuroimaging across all species are published in this journal if they contribute to a systems-level knowledge of the human brain. The key criterion used to evaluate publications for NeuroImage is the extent to which the scientific contribution advances our understanding of brain function, organization, and structure.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Bradford's Law investigates the aggregation of papers in a certain field inside a specific set or zone of academic publishing journals and deals with journal efficiency in terms of quantitative publications as seen in Fig. (8). Bradford's Law of Spread Publications argues that a large number of publications are spread among a small number of journals, while a large number of journals have a correspondingly smaller number of articles. Articles scattered throughout many periodicals can be separated into an approximated percentage. Bradford's law of scattering states that writings on a specific subject are distributed in roughly a set mathematical ratio.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Fig. (9) shows original papers highlighting contemporary breakthroughs in the field of biomedical and health informatics where information and communication technologies interface with health, healthcare, life sciences, and biomedicine and are published in the IEEE Journal of Biomedical and Health Informatics [74]. This includes, but is not limited to, the acquisition, transmission, storage, retrieval, management, processing, and analysis of biomedical and health information; applications of information and communication technologies in healthcare, public health, patient monitoring, preventive care, early disease diagnosis, the discovery of new therapies, and patient-specific treatment protocols leading to improved outcomes.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The analyses also revealed four clusters of keywords, each with one or more terms. Cluster 1 (red) includes 31 terms such as ?deep learning?, ?machine learning?, ?Alzheimer?s disease?, ?neuroimaging?, ?epilepsy?, ?MRI?, ?schizophrenia?ÿetc. Cluster 2 (blue) consists of only two keywords such as ?electroencephalogram (EEG)? and convolutional neural network (CNN). Cluster 3 (green) includes 11 keywords like ?autism spectrum disorder?, ?fMRI?, ?deep neural network?, ?functional connectivity?ÿetc. Cluster 4 (violet) consists of only 4 keywords such as ?deep brain stimulation?, ?Parkinson's disease?, ?Parkinson?s disease? and ?essential tremor?. Cluster 5 (orange) and cluster 6 (brown) include only one keyword ?machine learning (ml)? and ?magnetic resonance imaging (MRI)? respectively. These findings reflect the extensive usage of ML and DL for brain disorder detection and diagnosis and their application to psychiatry using MRI (cluster 1), specific application to Autism (cluster 3) possibly driven by the early availability of a large public database of fMRI data from Autistic subjects in the form of ABIDE database, the application of Parkinson?s and the widespread clinical use of deep brain stimulation for Parkinson?s (cluster 4) and the generic use of EEG and MRI data to drive ML and DL algorithms for brain diagnosis (rest of the clusters). This also indicates that EEG and MRI modalities dominate the field despite the clinical use of other modalities (such as PET/SPECT, CT, fNIRS,ÿetc).",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Using knowledge frameworks, thematic maps represent the structural and dynamic components of a study domain. They were utilized to develop conceptual structures that identified major topics, subjects, and intellectual frameworks that classified how an author's work affected this scientific community. These conceptual structures served to offer a comprehensive overview of the major developments and discoveries in ML and DL-based brain disorder detection and diagnostic research. Another application may be the study of how ideas or conditions evolve throughout time. This method provides academics with a list of the most well-known articles for each subject cluster, which may be used to focus research on a certain theme. The scientific map can provide statistics on the relevance of topics based on centrality and density, allowing for projections of possible future growth. From the thematic map discussed in this study, it can be shown that ?machine learning?, ?deep brain stimulation?ÿetcÿhave a high degree of development. Medium significance is on ?convolutional neural network?, ?MRI?ÿetc. The highest level of development in this field is on ?deep learning?, ?EEG?ÿetcÿwhereas the high relevance degree is on ?deep neural network?, ?transfer learning?ÿetc.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The results of our bibliometric research demonstrate that the most renowned publications are from a small number of authors. Because the bulk of publications are open access, contributions are promptly shared with the public, and a huge number of authors develop as the field advances. It is also worth noting that papers in the field are being increasingly referenced (with 522 citations for the most cited work), demonstrating how relevant it is right now. The USA, India, and China are the top three countries in terms of research production in this sector. These findings are not surprising considering that these countries' top Nation Rank's rankings for global scientific production across all categories. The findings reveal that even the most prolific researchers employ a diversity of methodologies and skills, confirming the field?s interdisciplinarity. Journals must be both functional and thorough to successfully communicate knowledge to all players. Our research found that ?Neuroimage? and ?Frontiers in neuroscience? journals have the most citations on the subject.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"This study focused on papers about ML and DL-based brain disorder detection and diagnosis that were indexed in the Scopus database. While comparing datasets from many databases is beyond the scope of this study, searching them may provide distinct groups of things, and the results of this analysis may differ.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"We reported the findings of our bibliometric investigation in the preceding sections. In this part, we will provide possible directions for further study based on our findings. These are intended to serve as a starting point for interested academics. It is critical to examine how the interplay of ML, DL, and humans may or should appear in the context of brain disorder detection and diagnosis. Future studies should look at which type of collaboration between ML, DL, and humans [75] is most suited for brain disorder detection and diagnosis. This raises the question of whether an ML and DL-based system in place of a physician for brain tumor detection and diagnosis is even possible or not. ML and DL have the potential to help with the case of brain disorder detection and diagnosis, improve brain MRI scanning and segmentation, support decision-making, and anticipate disease risk. As a result, ML and DL in brain disorder detection and diagnosis are utilized to aid medical scientists, lab personnel, and researchers in the health care business. ML and DL in brain disorder detection and diagnosis assist doctors in providing disease analysis and guiding them in treating a specific ailment more effectively. As a result, doctors' medical judgments may be made more prudently, and standards are increasing. Furthermore, trust between the ML and DL-based brain disorder detection and diagnostic model and the humans involved is critical. Although ML and DL algorithms frequently outperform human experts in terms of accuracy [76], there is a lack of trust in the predictions provided by these systems. It should thus be examined why there is a lack of confidence and how trust in ML and DL-based systems may be increased. This is also true for patients who may be subjected to therapies based mostly on the outcomes of these systems.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The security and robustness of the ML and DL-based models are also crucial considerations [77-79]. Many ML and DL models published in the literature have only been tested on a single dataset. As a result, it's unknown if the ML and DL models can be applied to input data from multiple scanning devices. As a result, it would be useful to examine how the ML and DL models should be developed to ensure portability. It may also make sense in this context to assess ML and DL models using several datasets supplied by various sensors or manufacturers. As previously said, ML and DL systems need a significant quantity of data to learn and construct solid models. When it comes to data, it is also critical to ensure the credibility, dependability, and security of the sources or platforms from which the data is derived. If malicious actors are successful in altering or modifying the data used as input for the ML and DL system, the outcome of the ML and DL system may be affected. As a result, these results are no longer dependable and may harm the patient's health due to the risk of incorrect outcomes. Data storage is particularly crucial since medical data is subject to strict data-protection requirements [80-82]. As a result, whether storage options have complied with legislation and how to ensure that data is not traceable should be investigated. Future studies should investigate if data masking is adequate or whether total anonymization is necessary in this circumstance. Various academics are also investigating whether emerging technologies for distributed data storage and administration, such as blockchain, are suitable for medical data. A future study might thus examine whether a blockchain makes sense for the goal of organizing and preserving medical data, or whether alternative technologies and databases are more appropriate. Furthermore, it is worth noting that there are currently a few research available that look into the security and resilience of ML and DL models for brain disorder detection and diagnosis. External validation of ML and DL algorithms and robustness testing against adversarial pictures, as well as rigorous data pre-treatment, are potential approaches for achieving robustness and security goals and should thus be researched further. In this context, design science research might be used to iteratively address specific security issues to identify an efficient solution.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"Only Scopus was employed in this work to derive bibliometric datasets. Future research might compile data from numerous digital libraries, such as PubMed, and Web of Science, into a single dataset. As a result, the target dataset for the study would be significantly bigger, allowing for a far broader examination. When collecting datasets from Scopus, we used 8.5 years as a constraint in the search circumstances. A considerably greater range of study findings might be discovered by looking over 10 years of publishing. Finally, non-English materials were not removed or chosen, which aided the automatic bibliometric analysis. However, a linguistic bias might have occurred. Non-English publications might be translated by language translators, allowing them to be included in the dataset as well.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,Tableÿ6ÿbelow summarizes our future research plan and highlights some future research issues that might assist in developing the area of ML and DL for brain disorder detection and diagnosis.,,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"This bibliometric analysis article assessed 1550 publications from January 2015 to May 2023 in light of 16 research topics. This work examined and assessed global research productivity linked to ML and DL-based brain disorder detection and diagnosis using data from the Scopus database. We used VOSviewer and the Biblioshiny program from the Bibliometrix package for R to analyze the data and create a wonderful visualization. Scientific publishing statistics reveal an annual growth rate of 36.78%, with an average citation rate of 15.87.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The United States, China, and India were among the most influential and productive countries, with the most publications. These were also the most visible countries in the collaboration network. Institutional collaborations seemed to be the most prevalent in the United States, with China, the United Kingdom, Brazil, and Canada also ranking among the most productive countries. In terms of the number of publications, Stanford University fared the best. The United States was among the best-performing countries in terms of both collaboration and yearly publication performance. The most popular ML and DL models were support vector machines and CNNs, respectively, with transfer learning emerging as a population technique to address limited data availability in certain applications of DL.",,,,,
Brain Disorder Detection and Diagnosis using Machine Learning and Deep Learning - A Bibliometric Analysis,"The most common brain disorder data modalities are MRI and EEG. Some researchers also highlighted the application of fMRI for the automated identification of brain diseases. Also, ML and DL applications mostly targeted Parkinson's, Alzheimer's, autism, epilepsy, and schizophrenia. Our study also points towards potential directions for future research including explainability of models, data privacy issues, and human-AI interactions in the clinic for diagnostic decision-making. In conclusion, our study documents growing interested and productivity in this field, which may continue to grow exponentially until many limitations are sorted out and ML/DL-based diagnosis of brain disorders becomes robust enough for adoption in clinical practice.",,,,,
Ethical trade-offs in AI for mental health,"It is expected that machine learning algorithms will enable better diagnosis, prognosis, and treatment in psychiatry. A central argument for deploying algorithmic methods in clinical decision-making in psychiatry is that they may enable not only faster and more accurate clinical judgments but also that they may provide a more objective foundation for clinical decisions. This article argues that the outputs of algorithms are never objective in the sense of being unaffected by human values and possibly biased choices. And it suggests that the best way to approach this is to ensure awareness of and transparency about the ethical trade-offs that must be made when developing an algorithm for mental health.",,,,,
Ethical trade-offs in AI for mental health,"AI is coming to psychiatry. The expectation is that machine learning (ML) algorithms will help improve diagnosis, prognosis, and treatment (1). Such algorithms have already shown expert-level accuracy in detecting medical conditions such as eye diseases (2), kinds of cancer (3), and pulmonary conditions (4) to mention a few. ML algorithms can also provide accurate estimates of the probability that a patient has an outcome of interest for mental health, e.g. of whether the patient will transition to psychosis (5). The average accuracy of ML algorithms in psychiatry has been estimated to be around 80 percent and improving (6). This level of accuracy would seem to be a boon to psychiatry which struggles with low predictive accuracy (7). Moreover, the development of algorithms focusing on mental health and psychiatric disorders is accelerating. For example, the yearly number of publications of algorithms for predicting depression more than doubled from 2013?2017 (6).",,,,,
Ethical trade-offs in AI for mental health,"The comparatively high predictive accuracy of algorithms has been recognized for more than half a century. In 1954 Meehl (8) argued that statistical reasoning should play a more dominant role in clinical decision-making. In 1970 Sines (9) reviewed studies comparing statistical/actuarial and clinical methods for making predictions in psychopathology and concluded that ?the actuarial predictions were found to exceed or at least equal the accuracy of clinical predictions? (9, 142). Dawes etÿal. (10) reconfirms this conclusion. Current studies of ML algorithms in medicine and psychiatry yet again shows that statistics-based methods can achieve expert-level accuracy.",,,,,
Ethical trade-offs in AI for mental health,"A central argument for deploying algorithmic methods in clinical decision-making in psychiatry is that they may ?enhance the speed, accuracy and objectivity? of clinical decisions (7, 172). Thus, using ?objective and automated methods? for clinical decisions in psychiatry (11, 2) is expected to improve the highly subjective nature of decision-making in psychiatry, which in large part relies on the clinician-patient communication.",,,,,
Ethical trade-offs in AI for mental health,"However, one must be careful when describing ML algorithms as objective. An algorithm may be said to be more objective than a clinician in the sense that training and test datasets, algorithm type, performance, and other factors can be made public for all to see. Still, characterizing an algorithm as objective signals that the algorithm?s output is not influenced by human values and biases. Being data-driven, the algorithm may be thought to simply look at the facts, derive a predictive pattern, and produce a prediction with no room for human bias to creep into the process. In fact, studies show that 40 percent of Americans consider it possible to produce algorithms which are objective in the sense of being free from human biases (12). In other words, there is a strong association between algorithmic predictions and value-neutrality. Algorithmic outputs are not influenced by human values. They just consider the facts and produce their predictions.",,,,,
Ethical trade-offs in AI for mental health,"This article aims to highlight several ways in which algorithms incorporate choices and assumptions that reflect ethical trade-offs - notions of what is good and bad, right and wrong, fair and unfair. That is not to say that using algorithms might not improve on current methods of clinical psychiatry. There are aspects of algorithmic predictions which may indeed be thought to make predictions more accurate, uniform, reliable, and less prone to human biases. However, it is important also to explicate how predictive algorithms for psychiatry will be shaped by judgments that, perhaps unreflectively, invoke ethical values and trade-offs.",,,,,
Ethical trade-offs in AI for mental health,In this article I characterize these tradeoffs so that patients and psychiatrists are not lured into thinking that ML algorithms simply reflect the facts independently of any value-laden decisions. Hopefully the framework outlined may facilitate clarification and discussion of the value assumptions informing predictive algorithms which are candidates for being used in psychiatry.,,,,,
Ethical trade-offs in AI for mental health,"There is a plethora of AI tools which may enter clinical practice. However, for the purpose of this analysis, I will focus on the prediction and diagnosis of mental disorders. I illustrate the considerations in relation to a hypothetical case of the development and use of an algorithm for predicting major depressive disorder (MDD) in primary care. Such use does not seem wholly unrealistic. Depression is a frequent and costly condition, and in most cases the initial diagnosis is made by general practitioners. However, as with other psychiatric disorders, you cannot just take a blood test and get a reliable determination of whether the condition is present. MDD comes in many guises and degrees making its diagnosis a complex and challenging affair, in particular in primary care, where physicians? diagnostic accuracy tends to be low with general practitioners failing to make correct diagnosis in about 50 percent of cases (13).",,,,,
Ethical trade-offs in AI for mental health,In this section I present and discuss five decision points in the development of a ML algorithm for MDD prediction which reflect ethical values.,,,,,
Ethical trade-offs in AI for mental health,"Generally, the traditional methods of diagnosis rely heavily on interviews and questionnaires. There are several reasons why it might be attractive for patients and practitioners alike to welcome algorithmic diagnostic support. First, the traditional methods are time-consuming and labor-intensive. Moreover, their accuracy is highly dependent on the practitioner?s personal experience including not only years of experience but also the variety of patients to which the practitioner has been exposed in the past. Obviously younger practitioners must rely on less experience than more seasoned ones. In addition, practitioners will likely be influenced by some form of bias regardless of their experience and genuine attempt to rely only on relevant information. Finally, patients will also display personal differences when it comes to their ability and willingness to reveal information, e.g., due to fears of stigmatization. An algorithm applied, e.g., across the country may improve on this situation by providing more uniform assessments of patients based on empirically established patterns in much larger and more varied dataset than any individual practitioner can acquire and analyze on their own. In turn this may not only improve accuracy but also prevent the practitioner from missing out on relevant symptoms.",,,,,
Ethical trade-offs in AI for mental health,"While these are some of the ways in which algorithmic support may improve on current methods, the choice to deploy an algorithm to classify patients with respect to some outcome does not take place in a vacuum. Opting for deploying a predictive algorithm will be guided by some goal that is assumed to be best achieved by better prediction. Thus, the first decision point concerns the identification and characterization of the goal of using the algorithm. What sort of problem is the algorithm supposed to help solve?",,,,,
Ethical trade-offs in AI for mental health,"In our case of MDD prediction, there are many different goals that one might seek to achieve by introducing algorithmic MDD prediction in primary care. One might have as a goal to improve diagnostic accuracy. Or to achieve the same level of accuracy for less money. Other aims could be to address problems of over- and underdiagnosis or to address biases against certain patient groups among diagnosticians.",,,,,
Ethical trade-offs in AI for mental health,"A decision to look to a predictive algorithm will rely on some goal or other, which provides the initial justification for investing in algorithmic prediction. The way the goal is stated determines the alternative courses of action and investment that will be competing with the algorithmic solution. Goal setting is clearly a value-laden activity. The goal one chooses to pursue expresses a notion about what one takes to be valuable states of affairs. Moreover, there might well be disagreement about whether a goal is indeed worth pursuing, and even if there is agreement about the goal, there might be disagreement about whether investing in an algorithmic approach is the best way to achieve the goal.",,,,,
Ethical trade-offs in AI for mental health,"To illustrate, there might be agreement that it is important to improve diagnostic accuracy of MDD in primary care. One way to do so is to develop and implement algorithmic prediction tools. However, there are other ways in which this goal could be achieved. One alternative could be to invest in better education and training of general practitioners, or in providing them with better feedback on the diagnoses they make enabling them to learn from their past diagnoses. And if the problem to be solved is that men are underdiagnosed with MDD, an alternative way of handling the problem could be to improve physicians? awareness of possible biases in diagnostic reasoning about male patients. In either case, the decision to invest in development and implementation of algorithmic MDD prediction is in effect to suggest that it is a better solution to a problem than alternatives. And as such the choice can be described as reflecting an ethical tradeoff: Assuming one cannot do both, it is better to invest in developing and implementing an algorithm than in better and targeted education of general practitioners.",,,,,
Ethical trade-offs in AI for mental health,"The quality of an algorithm for predicting MDD is dependent on the data available for training. This is because the training dataset provides the algorithm with a representation of the world in which it is going to be used ? the world according to the data (14). Thus, the choice of training data is a choice about what representation of reality the algorithm is going to learn from. Notably, the way a training dataset is compiled will reflect value judgments, judgments about what makes the dataset good (enough) for the purpose of training the algorithm to predict the outcome of interest. Thus, ?the data,? do not provide a representation of reality which is independent of human values and interests. When it comes to determining what to include in a training dataset several value-laden considerations will come into play.",,,,,
Ethical trade-offs in AI for mental health,"To illustrate this, consider a team of algorithm developers with a fixed budget who must decide on how to construct their training dataset (15). How should they spend the data budget? Assuming that the real-world population consists of 50 percent men and 50 percent women, should they aim for a dataset that has equal representation of men and women? Perhaps it is more expensive for them to acquire depression diagnosis data about men. Thus, ensuring equal representation will result in a smaller dataset than allowing for a larger proportion of women.",,,,,
Ethical trade-offs in AI for mental health,"And what sort of considerations would support one or the other decision? Perhaps the overall accuracy of the algorithm will be higher by allowing for an imbalance with respect to men and women. However, the comparative improvement of accuracy would be due to improvement for women. Prioritizing acquiring more data about men would on the other hand not achieve as high overall accuracy. However, it would ensure that the algorithm achieved almost equal accuracy rates for men and women.",,,,,
Ethical trade-offs in AI for mental health,"In addition to considerations about representativeness such as those just described, another important decision concerns whether the data to be used are structured. In case they are, there is a question about which categories should be included. For example, there has been some debate about whether protected categories such as race and gender should be made available for the algorithm during training, as well as whether gender should be given a binary categorization. Again, I do not claim that there is a single correct way to construct a dataset. My point is that a dataset, the way the world is represented to the algorithm, is a construction based on several value-laden decisions concerning what in the present context makes for a good dataset.",,,,,
Ethical trade-offs in AI for mental health,"Problems of bias and fairness may arise for several reasons. Some important ones include skewed datasets used for training and testing (16), choice of proxy variable (17), and the use context of the algorithm, e.g., on a population that differs from the population represented in the training and testing data.",,,,,
Ethical trade-offs in AI for mental health,"In relation to our focus on the prediction and diagnosis of mental disorders a key issue concerns how to fairly distribute prediction errors across salient groups such as protected groups referred to in relation to discrimination legislation. The issue became top of the agenda when an algorithm for predicting recidivism widely used in the criminal justice system in the United States was criticized for being biased against Black defendants (18). The problem identified by Angwin etÿal. (18) was that COMPAS, as the algorithm is called, seemed to have very different error rates for Black and White defendants. Thus, it was twice as likely to falsely flag a Black defendant as high risk of re-offending if released before trial as compared to a white defendant. And it was twice as likely to falsely flag a White defendant as low risk of re-offending if released before trial as compared to a Black defendant.",,,,,
Ethical trade-offs in AI for mental health,"A wide range of algorithmic fairness definitions has been explored in detail since Angwin etÿal. (18). A key upshot of this literature is that there are several plausible candidates for algorithmic fairness and that, as a matter of mathematics, not all plausible candidate definitions of algorithmic fairness can be met simultaneously in ordinary circumstances (e.g.,ÿ19,ÿ20). Tradeoffs must be made. To see this consider a situation in which one wants the MDD algorithm to have the same sensitivity and specificity (or true positive and true negative rate) for men and women. The ratio of true positive predictions to the total number of predictions about patients who in fact have MDD should be the same for male and female patients. And the ratio of true negative predictions about patients who are in fact negative for MDD should be the same for men and women. In ordinary circumstances, the frequency of MDD will differ for the male and female population. However, if this is the case, then achieving equal sensitivity and specificity can only be achieved if some men and women, who are estimated to have the same probability of suffering MDD, do not receive the same prediction. This is because to achieve equal sensitivity and specificity, the algorithm will have to apply different classification thresholds to men and women.",,,,,
Ethical trade-offs in AI for mental health,"What transpires is that when designing an algorithm for MDD prediction, its performance will tend to differ with respect to protected groups such as groups defined by gender or race. However, how it differs is a design choice. If one decides to set up the algorithm to produce equal error rates for men and women one also accepts that there will be men and women who will not receive the same prediction despite the fact that they are estimated to be equally likely to suffer MDD. Alternatively, one can decide to apply the same threshold for when the algorithm should make a positive prediction of MDD for all individuals. However, in that case one also accepts that error rates might be very different for protected groups. The disparity in error rates will in turn affect the burdens imposed on these groups from erroneous predictions. Thus, the design of an algorithm will reflect a decision about the appropriate distribution of prediction errors across groups.ÿ1",,,,,
Ethical trade-offs in AI for mental health,"The main selling point of predictive ML algorithms is their comparatively high accuracy. The most accurate types of algorithms are often described as ?black boxes.? This characterization aims to convey the fact that deep neural networks and other types of highly accurate ML algorithms are too complex for humans to be able to explain how they arrive at an output from an input. In response to the black box nature of algorithms, research on ?Explainable AI? or XAI has surfaced with researchers trying to develop tools that may help users understand why an individual prediction was produced based on an input from a patient.",,,,,
Ethical trade-offs in AI for mental health,"The black box nature of ML algorithms reflects their central strength. The complexity of the algorithm is not limited by human capacities for finding predictive patterns in a dataset and manually transforming the pattern into a mathematical model. The flipside is that ML models go beyond what humans can comprehend and explain. An alternative to ML algorithms is algorithms which are interpretable. Such models are simpler and perhaps less accurate. However, they have the advantage of being such that humans can understand and explain how they arrive at a prediction based on an input. A linear function with one or two predictive variables may not be as accurate as a complex deep neural network but it is easy for humans to grasp how the values of the input variables produce the prediction.",,,,,
Ethical trade-offs in AI for mental health,The development of an algorithm for predicting MDD thus involves an important tradeoff between the improvement of accuracy that may be achieved by a highly complex algorithm versus the possibility that humans can understand why the algorithm generated a particular output from an input. In the context of decision-making in psychiatry explainability would seem to be of great importance to ensure that algorithmic outputs can be trusted and acted upon.ÿ2,,,,,
Ethical trade-offs in AI for mental health,"An algorithm to be used in clinical practice must convey information to its user. Focusing on cases of prediction and diagnosis, the assumption has been that an MDD prediction algorithm would provide the user with a binary output: positive or negative for MDD. However, it is by no means obvious that this is the proper way to present the output of the algorithm to the user. To begin with, a binary classification of patients will be based on a predetermined threshold such that patients whose risk score is at or above the threshold will be classified as positive for MDD and those scoring below the threshold are classified as negative. However, the information provided by the algorithm could also be the risk score of the patient. This would leave more room for the user to decide whether to classify the patient as MDD.",,,,,
Ethical trade-offs in AI for mental health,At this point it also becomes important to keep in mind that algorithms rely on statistical reasoning when they assign a risk score to an individual patient. The sort of inference that the algorithm in effect makes when it assigns a risk score to a patient is the following:,,,,,
Ethical trade-offs in AI for mental health,1. The proportion of patients with features X who suffer MDDÿ= n.,,,,,
Ethical trade-offs in AI for mental health,2. This patient has features X.,,,,,
Ethical trade-offs in AI for mental health,3. Hence the probability that this patient suffers MDD = n.,,,,,
Ethical trade-offs in AI for mental health,"There is a fundamental issue about the validity of this kind of inference from the frequency of, say, MDD in a reference group to the risk that an individual member of the reference group has MDD (24). There can easily be features of the individual member which make her much more or much less likely to have MDD than the probability that a randomly drawn member of the reference group suffers MDD. To bring this out, one could require that this was made explicit in the way the algorithm presented its finding: Patient A belongs to a group of patients of which n/100 are positive for MDD.",,,,,
Ethical trade-offs in AI for mental health,ML algorithms are showing promising results for prediction of psychiatric conditions. In this article I have argued that psychiatrists should be wary of claims that ML algorithms are objective in the sense of not being influenced by human values and biases. At several stages in the development of a predictive algorithm decisions must be made which will reflect value judgments.,,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,This study aims to investigate the potential of machine learning in predicting mental health conditions among college students by analyzing existing literature on mental health diagnoses using various machine learning algorithms.,,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"The research employed a systematic literature review methodology to investigate the application of deep learning techniques in predicting mental health diagnoses among students from 2011 to 2024. The search strategy involved key terms, such as ?deep learning,? ?mental health,? and related terms, conducted on reputable repositories like IEEE, Xplore, ScienceDirect, SpringerLink, PLOS, and Elsevier. Papers published between January, 2011, and May, 2024, specifically focusing on deep learning models for mental health diagnoses, were considered. The selection process adhered to PRISMA guidelines and resulted in 30 relevant studies.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"The study highlights Convolutional Neural Networks (CNN), Random Forest (RF), Support Vector Machine (SVM), Deep Neural Networks, and Extreme Learning Machine (ELM) as prominent models for predicting mental health conditions. Among these, CNN demonstrated exceptional accuracy compared to other models in diagnosing bipolar disorder. However, challenges persist, including the need for more extensive and diverse datasets, consideration of heterogeneity in mental health condition, and inclusion of longitudinal data to capture temporal dynamics.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"This study offers valuable insights into the potential and challenges of machine learning in predicting mental health conditions among college students. While deep learning models like CNN show promise, addressing data limitations and incorporating temporal dynamics are crucial for further advancements.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"In recent times, the utilization of Machine Learning (ML) techniques for predicting mental health diagnoses among students has gained significant traction. The rise in mental health issues among student populations has prompted a pressing concern for educators, healthcare professionals, and policymakers. Mental health profoundly impacts emotions, reasoning, and social interactions, necessitating innovative prevention and intervention strategies, especially for college students. Early detection is crucial, and medical predictive analytics could revolutionize healthcare, particularly with the profound impact of mental health on individuals.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Machine learning techniques, which fulfill the purposes of data analysis, prediction, and deriving meaning from data, have become invaluable for predicting mental health. Two main types of ML, namely supervised learning and unsupervised learning, are commonly employed in mental health research [1]. Supervised learning, utilizing structured training data, is extensively used in medical research, while the application of unsupervised learning in clinical settings is limited [2]. Reinforcement Learning (RL) is not covered in this paper due to its limited relevance to mental health data, as it focuses on agents learning optimal behaviors in interactive environments.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Over time, collected information undergoes processing and analysis using various machine learning techniques to enhance platform usability and develop interactive tools. Machine learning, a part of Artificial Intelligence (AI), aims to impart knowledge to computers by leveraging data, observations, and real-world interactions [3]. The availability of abundant data, cost-effective storage, and powerful computational systems has propelled machine learning, elevating it from a mere pattern recognition algorithm to encompass Deep Learning (DL) approaches. Liuÿet al. examined depression among college students, highlighting its detrimental effects on health, academics, and social life.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"The study reviews factors contributing to depression, predictive methods, and non-pharmaceutical interventions [4]. Another significant study by Johnsonÿet al. applied unsupervised learning to identify patterns linked to anxiety and stress among university students, analyzing physiological and behavioral data collected from wearable devices [5].",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Kirlicÿet al. explored machine learning algorithms, including logistic regression, decision trees, random forests, and deep learning techniques for early detection of suicidal tendencies in college students, using data from student counseling centers and campus resources [6]. Integrated machine learning techniques with electronic health records to predict the likelihood of mental health issues among college students showcase the potential for identifying risk factors and tailoring personalized interventions [7,ÿ8].",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Sofianita Mutalibÿet al. specifically employed Decision Tree, Neural Network, Support Vector Machine, Naive Bayes, and logistic regression algorithms to categorize students based on different mental health problems, revealing distinct optimal models for specific concerns [9]. Ashley E. Tate carried out a comparative analysis of various machine learning techniques, indicating the superior performance of the random forest model in mental health prediction [10].",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Machine Learning (ML) has emerged as a valuable tool in understanding and addressing mental health issues [11]. Its application in mental health diagnosis demonstrates the potential for ML algorithms to analyze vast amounts of data, identify patterns, and provide valuable insights into various disorders. Friedÿet al. introduced the possibility of using Deep Learning (DL) methods not only to predict and diagnose specific mental health disorders but also to simultaneously identify comorbidities and interconnected conditions [12]. The intricate neural network architectures of deep learning models enable them to capture complex relationships within the data, offering a more comprehensive understanding of the multifaceted nature of mental health.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Despite the success of machine learning algorithms, there is a lack of explicit justification by many researchers for their chosen ML methods, raising concerns about potential oversights in leveraging algorithmic strengths for specific mental health analysis tasks [1]. Additionally, a worrisome trend of applying ML algorithms without a thorough understanding of the underlying data characteristics has been noted, compromising the reliability and generalizability of study findings. This emphasizes the critical need for researchers to consider the compatibility between the selected ML algorithm and the nuances of the mental health data under investigation.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Despite the promising potential of machine learning in predicting mental health diagnoses in college students, several limitations and challenges persist. One primary concern is the lack of standardized, high-quality datasets that adequately represent the diversity and complexity of mental health conditions. Ethical considerations, such as data privacy and potential biases in the training data, are critical problems that must be addressed to ensure the fair use of machine learning models. Another challenge lies in the interpretability of complex models like deep neural networks, which can hinder understanding of how decisions are made. Furthermore, mental health stigma can affect data collection and introduce biases in self-reported information, leading to skewed results. Consequently, this comprehensive review contributes to this emerging research area and aims to:",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"This study identified high-quality datasets for developing robust and generalizable predictive models, enhancing the accuracy and applicability of the results in real-world scenarios.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"This research contributes to understanding methodologies, key findings, and trends in using machine learning to predict mental health diagnoses. Through an extensive literature review, it identifies the latest advancements and emerging patterns in the field. Identifying popular techniques will help researchers select appropriate models for their specific research objectives.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"This research evaluates machine learning model performance in predicting mental health diagnoses. Examining previous research outcomes establishes the effectiveness and accuracy of these models in various contexts. It also reveals the strengths and weaknesses of different approaches, guiding researchers in making informed decisions about selecting and optimizing predictive models.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Reports by the World Health Organization (WHO) emphasize the critical role of mental health in overall well-being, recognizing it as a fundamental human right existing on a continuum from optimal well-being to severe suffering [13].",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"The COVID-19 pandemic has significantly impacted global mental health, increased rates of anxiety and depression, and widened the treatment gap. Anxiety and depression are prevalent worldwide, with suicide being a leading cause of mortality, particularly among young individuals. Moreover, severe mental health conditions often lead to premature mortality due to preventable physical illnesses. Despite these challenges, global mental health systems face substantial gaps and disparities in information, research, governance, resources, and services. To address these issues, this research conducted a literature review following a structured eight-step approach proposed by Okoli [14], ensuring scientific rigor throughout the process.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Fig. (1) explains the systematic review of machine learning techniques for predicting mental health diagnoses following a rigorous eight-step methodology. Firstly, a clear research question was defined. A comprehensive search strategy was then developed, including database selection and search term formulation. Studies retrieved were screened based on predefined criteria. Selected studies underwent effectiveness assessment, considering methodological aspects. Pertinent data were systematically extracted using a standardized form. A comprehensive analysis followed, identifying patterns and themes across studies. Depending on the research question, either quantitative (meta-analysis) or qualitative (thematic analysis) synthesis was conducted. Finally, findings were summarized, including re findings were summarized, including results, conclusions, and implications, in a systematic review report or academic publication. By adhering to these steps, this research ensured a systematic, rigorous, and comprehensive approach to collecting and analyzing relevant evidence.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Fig. (2) categorizes mental illness diagnoses, including bipolar disorder, schizophrenia, PTSD, depression, anxiety, and ADHD. It also organizes machine learning approaches into supervised learning, unsupervised learning, neural networks, and deep learning based on their respective learning methods. Furthermore, this study assesses the performance of these models to illustrate their effectiveness in mental health applications.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Bipolar disorders are a group of serious and long-lasting mental health conditions [15-17]. There are two main types: bipolar I disorder, which involves experiencing manic episodes, and bipolar II disorder, which involves hypomanic episodes and major depressive episodes. These disorders have a significant impact on how well a person can do everyday tasks and are associated with a reduced lifespan of about 10 to 20 years.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Schizophrenia, a multidimensional mental health illness, presents long-term issues for both people and families. It usually appears early in childhood and causes symptoms, such as skewed beliefs, sensory experiences disconnected from reality, and issues with cognitive functioning [18-20]. These symptoms remain over time, limiting the affected person's capacity to participate in everyday activities and maintain social interactions.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Negative symptoms of Schizophrenia, which include difficulties in emotional expression and motivation, as well as cognitive impairments, such as attention deficits and reduced executive function, exacerbate the handicap experienced by persons suffering from the disorder [21]. Schizophrenia is a common mental condition that affects around 1% of the world's population, with diagnostic criteria established in the Diagnostic and Statistical Manual of Mental Disorders (DSM-5) [21]. This systematic guide supports physicians in diagnosing and treating persons, showing the hallmark signs of schizophrenia, allowing for appropriate interventions and support for those afflicted by this difficult disorder.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"The DSM-5 [21] delineates diagnostic criteria for PTSD, requiring exposure to potentially life-threatening events accompanied by specific symptoms persisting for at least a month, causing distress or impairment. Risk-taking behaviors encompass actions with uncertain outcomes, such as substance abuse, delinquency, poor health, unhealthy eating, and unprotected sex [22-24]. Studies highlight a correlation between exposure to trauma, the development of PTSD, and subsequent engagement in risk-taking behaviors [25-28]. Childhood maltreatment predicts higher levels of risky behavior in adolescence and adulthood, with sexual abuse being a significant factor [29]. These findings underscore the interplay between traumatic experiences, mental health, and behavioral outcomes.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Depression, clinically known as major depressive disorder, is assessed using the Patient Health Questionnaire (PHQ) [30]. It is characterized by profound sadness and loss of interest, significantly affecting daily life. Shoreyÿet al. found that 34% of adolescents aged 10-19 are at risk of clinical depression, exceeding estimates for those aged 18-25 [31].",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Depression prevalence is highest in the Middle East, Africa, and Asia, with females more affected than males. Untreated depression can lead to suicidal thoughts [32]. Anxiety, defined by the APA, involves tension, worry, and physical symptoms like increased heart rate and muscle tension [33]. It arises from perceived threats or stressors, real or imagined.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"ADHD is a neurodevelopmental illness characterized by symptoms, such as inattention, hyperactivity, and impulsivity [34]. These symptoms frequently emerge in numerous facets of everyday living, providing difficulty for those with the illness. ADHD is not just a childhood disorder; it may last into adolescence and age, impacting people all their lives. Its ubiquity makes it one of the most widely diagnosed mental health problems, impairing people's ability to focus, manage their impulses, and engage successfully in daily activities.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"The systematic review followed the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) method, recognized as the gold standard for structured, systematic reviews and meta-analyses. This method offers authors a comprehensive framework, facilitating a thorough examination of concepts discussed in scholarly articles across diverse research fields. A pivotal aspect of this methodology involves precisely defining eligibility criteria, which is crucial for formulating the research hypothesis. In line with PRISMA guidelines, the review included sections on search methodology, inclusion and exclusion criteria, and data extraction. Employing a PRISMA checklist, the review aimed to enhance the quality and precision of the evaluation process for all analyzed articles [14].",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"The systematic review focused on assessing machine learning techniques for predicting mental health diagnoses. The search strategy encompassed keywords like ?deep learning,? ?mental health prediction,? and ?mental health diagnoses? conducted across reputable repositories, such as IEEE Xplore, ScienceDirect, Pubmeb, and Elsevier, among others [8]. Only published papers specifically addressing machine learning and deep learning models for mental health diagnoses were considered, with duplicate papers eliminated.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"The study focused on reviewing papers published between 2011 and 2024, emphasizing deep learning models for mental health diagnoses. Initially, 101 articles were identified, with 12 more found through alternative methods. After screening, 30 relevant studies were included for evaluation (Fig.ÿ3). There were no restrictions on machine learning algorithms, study country, language (English), or population demographics. Mental health conditions of interest included bipolar disorder, ADHD, schizophrenia, PTSD, depression, and anxiety. Duplicate publications were rigorously removed following the PRISMA flowchart for transparency. Studies failing to meet at least two performance criteria, as well as newspapers, magazines, proposals, and posters, were excluded.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"The chosen articles underwent comprehensive evaluation covering content, references, machine learning methodologies, performance metrics, and dataset origins, and identified limitations or areas for future investigation. Fig. (4) presents a graphical representation illustrating the distribution of articles included in the review spanning from 2011 to 2024. Notably, 2021 and 2022 exhibited the highest count, each featuring seven papers. In contrast, 2023 contributed four papers, while 2017 and 2020 each accounted for three. The years 2013, 2014, 2016, and 2018 had the lowest contribution, with one paper each. Interestingly, several two-year periods displayed identical numbers of papers, underscoring a consistent trend in research output throughout the years [8].",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"This research article presents a comprehensive review of machine learning methods for predicting mental health diagnoses. Spanning the last 14 years, the study evaluates recent advancements in the field, employing a transparent methodology and search strategy to bolster reliability and replicability. Key findings are highlighted, with particular emphasis placed on the outcomes of interest, including Bipolar Disorders (6 papers), Schizophrenia Prediction (4 papers), PTSD (6 papers), Depression and Anxiety (10 papers), and ADHD (4 papers), totaling 30 selected papers detailed in Tableÿ1. Although the review lacks official registration, it benefits from non-financial support from academic institutions, peer reviewers, and research collaborators. No external funding is acquired, ensuring transparency and unbiased reporting.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"The summary of datasets in Tableÿ1ÿutilized in 30 studies included in this review spans a diverse array of sources, including data on male and female students covering grades 5 to 9, IBM?ÿMarketScan?ÿCommercial Subset, clinical data, resting-state functional magnetic resonance imaging (rsfMRI) data, Twitter data, and more. Dataset sizes ranged from 50 to 2,500,000 records, reflecting the variability and scale of the data sources utilized. The studies targeted a wide range of outcome variables, including near-term suicidal behaviors, diagnosis of Post-Traumatic Stress Disorder (PTSD), presence of Childbirth-related PTSD (CB-PTSD), suicide attempts, Bipolar Disorder (BD), Attention-Deficit/Hyperactivity Disorder (ADHD), depression, and anxiety. Prediction nature varied across studies, with aims such as predicting the likelihood of individuals engaging in suicidal behaviors, identifying PTSD patients from structured and unstructured medical records, and predicting PTSD diagnosis probability in firefighters exposed to trauma. Variable sources included surveys, experiments, observations, and existing databases, while variable types encompassed categorical, continuous, ordinal, and binary variables, highlighting the complexity and heterogeneity of mental health data.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"The systematic review aimed to evaluate the performance of thirty classification algorithms in predicting five different diseases, particularly focusing on mental health. It encompassed advancements in machine learning algorithms from 2011 to 2024. Inclusion criteria involved scrutinizing research papers and employing a comprehensive search across databases. Measures, such as eliminating duplicates and adhering to the PRISMA flowchart, were implemented for reliability. The major evaluated classifiers included Random Forest, Logistic Regression, Support Vector Machine (SVM), Multi-layer Perceptron (MLP), Decision Tree, Naive Bayes, K-nearest neighbors, Gradient Boosting Machine (GBM), and Convolutional Neural Network (CNN).",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Machine learning techniques have emerged as valuable tools for identifying and detecting bipolar disorder, a complex mental illness characterized by extreme mood swings. Timely diagnosis is crucial for effective management. Birnerÿet al. examined how LR can aid in diagnosing bipolar disorder, aiming to decrease misdiagnosis rates and shorten diagnosis time [55]. Sonkurtÿet al. developed a prediction algorithm utilizing CANTAB neurocognitive battery and a novel machine-learning approach to differentiate bipolar disorder patients from healthy controls, achieving a 78% accuracy rate [56]. Passosÿet al. identified a suicidality signature among mood disorder patients, including bipolar disorder, using machine learning [57]. Chenÿet al. presented a support vector machine (SVM) for detecting brain structural changes as biomarkers from magnetic resonance images. The SVM demonstrates superior performance in bipolar disorder datasets, achieving an AUC of 80.6%. It offers the potential for automatic diagnosis and mechanism studies in neurological and psychiatric diseases [58]. These studies underscore the potential of machine learning to enhance early detection, diagnostic precision, and personalized treatment strategies for bipolar disorder.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Several studies have showcased the effectiveness of machine learning (ML) techniques in predicting schizophrenia. While Bohaterewiczÿet al. concentrated on leveraging machine learning and advanced neuroimaging to improve prediction of suicide risk in schizophrenic patients [38], Kirchebnerÿet al. employed Boosted Classification Trees to explore the factors influencing violent behavior in the same population [39]. This dual approach highlights the potential of machine learning for both improving risk prediction of suicide and identifying factors associated with violence in schizophrenia, paving the way for better patient outcomes and targeted interventions. Hahnÿet al. achieved an impressive 84% accuracy using Support Vector Machine (SVM) and diffusion tensor imaging data [59]. Building on prior research, Hettigeÿet al. and Birnbaumÿet al. explored machine learning for mental health diagnosis using different algorithms, like SVM, LR, RF,ÿetcÿ[60,ÿ61]. Notably, Birnbaumÿet al. performed better in identifying schizophreniaÿviaÿsocial media analysis [61]. Similarly, Hettigeÿet al. focused on developing models to predict suicide attempts among individuals already diagnosed with schizophrenia spectrum disorders [60].",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"In summary, ML shows promise in schizophrenia prediction, especially when utilizing neuroimaging and genetic data in multimodal approaches. Overcoming challenges like sample sizes and embracing longitudinal research could advance the early detection and management of schizophrenia.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Various machine learning techniques have been explored for detecting Post-Traumatic Stress Disorder (PTSD), leveraging diverse datasets and methodologies. Costaÿet al. proposed Support Vector Machines (SVM) using physiological signals [64], while Banerjeeÿet al. focused on Long Short-Term Memory (LSTM) neural networks with textual features [65]. Heÿet al. combined Random Forest, AdaBoost, and SVM with demographic and behavioral features [66]. Lekkasÿet al. explored the use of GPS data from smartphones to detect PTSD diagnostic status among previously traumatized women, achieving high predictive performance with an AUC of 0.816, balanced sensitivity of 0.743, balanced specificity of 0.8, and balanced accuracy of 0.771, suggesting the potential utility of GPS information as a digital biomarker for PTSD [67], Beymohammadiÿet al. used Convolutional Neural Networks (CNN) with EEG signals [68], and Miottoÿet al. utilized Deep Learning models with electronic health records [69]. Jeffreyÿet al. employed machine learning on social media data for PTSD signs [70]. These studies collectively illustrate diverse methodologies and data sources, contributing to a comprehensive understanding of PTSD detection. Despite limitations, this body of research highlights the potential of machine learning in aiding PTSD detection and advancing treatment strategies.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Recent studies have leveraged machine learning (ML) techniques to predict mental health conditions, such as depression and anxiety. Chenÿet al. [71] developed a diagnostic model for adult ADHD. They demonstrated promising statistical accuracy, suggesting the potential of machine learning models, such as (SVM) and KNN, to inform clinical practice in diagnosing ADHD. Ojoÿet al. [72] employed Natural Language Processing (NLP) and sentiment analysis on social media data for depression detection. Alghowinemÿet al. [73] differentiated depressed individuals from controls using Gaussian Mixture Models (GMM) and Mel Frequency Cepstral Coefficients (MFCC) from speech data.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Wattsÿet al. [74] utilized algorithms like Random Forests and SVM on EEG data to predict major depressive disorder (MDD) diagnosis. Deep learning methods, including Long Short-Term Memory (LSTM) networks and Convolutional Neural Networks (CNN), were applied by Chiongÿet al. [75] for anxiety and depression detection from social media texts. Yoonÿet al. and Xezonakiÿet al. [76,ÿ77] contributed to depression detection using Multimodal Vlog Dataset and Hierarchical Attention Networks. These studies underscore the potential of ML in mental health screening and intervention.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"ADHD, a neurodevelopmental disorder characterized by symptoms like inattentiveness, hyperactivity, and impulsivity, necessitates early and accurate detection for effective management. Sinanÿet al. [78] proposed a method employing Convolutional Neural Networks (CNN) with multimodal feature fusion using resting-state functional MRI (rs-fMRI) and EEG data for precise ADHD classification. Shoeibiÿet al. [79] introduced a 3D CNN-based framework for rs-fMRI analysis, showing promising results in automatic ADHD diagnosis. Gurcanÿet al. [80] utilized Deep CNNs on functional near-infrared spectroscopy (fNIRS) data, achieving high accuracy in distinguishing ADHD patients. Arbabshiraniÿet al. [81] integrated machine learning algorithms with structural and functional brain scans for individualized ADHD prediction. As mentioned in Tableÿ1, results demonstrated that DT [71] outperformed other algorithms in predicting ADHD from images with an accuracy of 86.6%. This suggests that DT has slightly superior performance in ADHD prediction using provided images compared to other classification models.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"The increasing prevalence of mental health disorders, coupled with the advancement of technology, has led to a growing interest in utilizing machine learning techniques for early detection and diagnosis. In recent years, the potential of machine learning in detecting a range of mental health disorders, including bipolar disorder, schizophrenia, PTSD, depression, and anxiety, has gained significant attention. These disorders pose a substantial challenge to mental healthcare due to their complex nature and the limitations of traditional diagnostic methods.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"This review delves into a collection of studies that have explored the application of machine learning in detecting mental health disorders. These studies showcase the promise of machine learning approaches in improving the accuracy and efficiency of diagnosis. However, it is crucial to critically evaluate both the strengths and limitations of these studies to gain a comprehensive understanding of their implications.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Liuÿet al. and Johnsonÿet al. [4,ÿ5] employed natural language processing to anticipate bipolar disorder using textual data and demonstrated the potential of neuroimaging data in differentiating bipolar disorder patients from healthy controls. For instance, in the context of mental health disorders, studies conducted by L¢pez Steinmetzÿet al. and Joshiÿet al. [45,ÿ46] highlight the extensive assessment of the COVID-19 mental health implications among Argentine college students, as well as the creative application of Artificial Intelligence and Machine Learning algorithms for diagnosing depression and emotional states. Birnerÿet al. [55] proposed that because of the variety of symptoms associated with bipolar disorder, correctly diagnosing bipolar disorder can take over nine years. Individuals with bipolar illness may benefit from early detection and care, which might dramatically enhance their quality of life and lifespan. The hypothesis is that machine learning approaches can help with the diagnostic process, potentially lowering misdiagnosis rates.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Transitioning to schizophrenia, Hahnÿet al. [59] showcased the power of neuroimaging data and support vector machines in achieving high accuracy in predicting schizophrenia. Hettigeÿet al. [60] highlighted the serious problem of suicide among those suffering from schizophrenia, as well as the difficulty in recognizing those who are most likely to attempt suicide in the future. It emphasizes the ability of machine learning algorithms to include various risk variables and predict suicide attempts. However, it highlights the present ambiguity about how to effectively combine previously established risk variables into a useful prediction tool for evaluating the likelihood of suicide attempts in schizophrenia patients. Birnbaumÿet al. [61] reported that previous research demonstrated that language analysis of publicly available Twitter feeds may be used to discriminate persons who self-identify as having schizophrenia from healthy individuals. However, there have been few initiatives, including professional involvement, to examine the legitimacy of these diagnostic self-disclosures. The integration of multiple modalities, including clinical assessments, neuroimaging, and genetic information, demonstrated improved prediction accuracy and a better understanding of the heterogeneous nature of schizophrenia in studies by Bartalÿet al. [62] and Kim [63]. These articles explore innovative approaches to address mental health challenges; the first investigates using computational methods to screen for childbirth-related posttraumatic stress disorder, while the second focuses on developing an analysis model, leveraging AI algorithms and big data, to understand the prevalence of post-traumatic stress disorder among firefighters. However, sample size limitations and the dynamic nature of schizophrenia's progression pose challenges that need addressing.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"In the case of PTSD, diverse approaches using physiological signals, textual features, EEG signals, and social media data have shown the potential of machine learning in detection. Costaÿet al. [30] utilized physiological signals, Banerjeeÿet al. [65] focused on textual features, and Coppersmithÿet al., Beymohammadiÿet al.,ÿand Miottoÿet al. [67-69] analyzed EEG signals by employing natural language processing and deep learning models, respectively, on various data sources, revealing the versatility of machine learning in assisting with PTSD detection.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"In the realm of depression and anxiety, studies explored audio/visual features, social media data, speech data, and EEG data to detect these conditions [72-74]. The application of deep learning models trained on social media texts by Chiongÿet al. [75] further underlines the potential of machine learning in this domain. However, the limitations encompassing small sample sizes and the necessity for validation hinder the full realization of their potential.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"In summary, this review sheds light on the potential of machine learning in detecting mental health disorders, such as bipolar disorder, schizophrenia, PTSD, depression, and anxiety. The use of machine learning models presents avenues for early detection and personalized interventions, promising to enhance patient outcomes. Nevertheless, researchers must acknowledge the limitations within these studies, including small sample sizes, diverse datasets, and ethical considerations. Addressing these challenges is crucial for further validation and the eventual implementation of machine-learning approaches in mental health diagnostics (TableÿS1ÿ(194.2KB, pdf)ÿ).",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"This comprehensive study delves into the existing literature on the application of deep learning and machine learning techniques for predicting mental health outcomes, specifically among college students. The research demonstrates that these approaches exhibit promising potential in accurately diagnosing mental health conditions. Various algorithms and methods have been employed to analyze a range of data sources, including demographic data, clinical assessments, social media content, and neuroimaging data, effectively identifying individuals at risk of mental health disorders. Supervised learning methods, including Random Forest, Support Vector Machines (SVM), Extreme Learning Machine (ELM), as well as deep learning algorithms, such as Neural Network (NN) and Convolutional Neural Networks (CNN), have demonstrated effectiveness in forecasting mental health disorders.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"Supervised learning methods, including Random Forest, Support Vector Machines (SVM), Extreme Learning Machine (ELM), as well as deep learning algorithms such as Neural Network (NN) and Convolutional Neural Networks (CNN), have demonstrated effectiveness in forecasting mental health disorders. Certain algorithms stood out using the author's dataset for each specific disease. Convolutional Neural Networks (CNNs) in bipolar disorder demonstrated outstanding performance, achieving an impressive accuracy rate and f-measure of 99.75%, surpassing other models. In the case of schizophrenia, SVM attained 90% for f-measure and 95% for AUC. For PTSD, both CNN and RF achieved a notable accuracy rate of 99%. In ADHD, ELM outperformed other algorithms with an AUC of 0.8757%. Lastly, neural networks showed the highest accuracy and AUC metrics of 99.03% for depression and anxiety.",,,,,
Machine Learning Techniques to Predict Mental Health Diagnoses: A Systematic Literature Review,"However, challenges remain, including needing more extensive and diverse datasets, accounting for the diversity of mental health conditions, and integrating longitudinal data for temporal insight. Furthermore, improving the interpretability and transparency of machine learning models is crucial to fostering trust and acceptance in clinical settings. Despite these challenges, the application of machine learning in mental health prediction offers the potential for early detection, personalized interventions, and enhanced mental health outcomes among college students. Continuous research collaboration among researchers, clinicians, and policymakers is vital to fully harness the benefits of machine learning in mental health care.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"The application of artificial intelligence (AI) to health and health care is rapidly increasing. Several studies have assessed the attitudes of health professionals, but far fewer studies have explored the perspectives of patients or the general public. Studies investigating patient perspectives have focused on somatic issues, including those related to radiology, perinatal health, and general applications. Patient feedback has been elicited in the development of specific mental health care solutions, but broader perspectives toward AI for mental health care have been underexplored.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"This study aims to understand public perceptions regarding potential benefits of AI, concerns about AI, comfort with AI accomplishing various tasks, and values related to AI, all pertaining to mental health care.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"We conducted a 1-time cross-sectional survey with a nationally representative sample of 500 US-based adults. Participants provided structured responses on their perceived benefits, concerns, comfort, and values regarding AI for mental health care. They could also add free-text responses to elaborate on their concerns and values.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"A plurality of participants (245/497, 49.3%) believed AI may be beneficial for mental health care, but this perspective differed based on sociodemographic variables (allÿP<.05). Specifically, Black participants (odds ratio [OR] 1.76, 95% CI 1.03-3.05) and those with lower health literacy (OR 2.16, 95% CI 1.29-3.78) perceived AI to be more beneficial, and women (OR 0.68, 95% CI 0.46-0.99) perceived AI to be less beneficial. Participants endorsed concerns about accuracy, possible unintended consequences such as misdiagnosis, the confidentiality of their information, and the loss of connection with their health professional when AI is used for mental health care. A majority of participants (80.4%, 402/500) valued being able to understand individual factors driving their risk, confidentiality, and autonomy as it pertained to the use of AI for their mental health. When asked who was responsible for the misdiagnosis of mental health conditions using AI, 81.6% (408/500) of participants found the health professional to be responsible. Qualitative results revealed similar concerns related to the accuracy of AI and how its use may impact the confidentiality of patients? information.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Future work involving the use of AI for mental health care should investigate strategies for conveying the level of AI?s accuracy, factors that drive patients? mental health risks, and how data are used confidentially so that patients can determine with their health professionals when AI may be beneficial. It will also be important in a mental health care context to ensure the patient?health professional relationship is preserved when AI is used.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"The potential of artificial intelligence (AI) to transform health care has been touted since the early 2010s [1-4]. In health care applications, practitioners commonly operationalize AI by training machine learning algorithms using large retrospective data sets to perform human reasoning tasks, such as identifying issues (eg, anomalies in medical images), predicting events (eg, disease incidence), recommending treatments (eg, pharmacogenomics), detecting patterns (eg, finding symptom clusters), and generating text (eg, for clinical decision support rules).",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"AI has already made significant strides in the field of medical imaging, aiding health professionals at various stages, including improving image quality [5], guiding image acquisition [6], risk-stratifying images to be reviewed by a specialist (ie, a radiologist) [7,8], and interpreting images [9,10]. More recently, predictive AI has been leveraged to detect mental health?related issues, including major depressive disorders [11,12], stress, anxiety [13], bipolar disorder [14], and even suicide [15,16]. AI has also commonly been used for treatment selection in fields such as oncology and mental health [17,18]. Despite the demonstrated predictive accuracy of AI, relatively few of the predictive AI tools created are implemented in everyday clinical care [19], and even fewer tools have demonstrated a positive clinical impact compared to current standards of care [20-22]. Furthermore, of the 89 unique articles in 2 systematic reviews of clinical trials evaluating predictive AI, none focused on mental health?related conditions [20,21].",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Due to the gap between the predictive AI?s accuracy and its lack of observed impact on health outcomes, many researchers in many countries have studied health professionals? perceptions of AI-based tools and related implementation challenges [16,23-28]. However, patients? perspectives of AI have been understudied [29-31]. While some predictive AI developers may not intend for patients to view the AI?s output on their own, it has become more likely that patients have access to predictive AI output due to recent advances in patient data ownership and access. The US 21st Century Cures Act, for example, prevents blocking information from patients, requiring health organizations and insurance providers to give patients access to their eHealth information without delay or expense [32]. This may result in a patient seeing a predictive AI risk score before a discussion with their health care team. In a 2020 predictive AI preimplementation study, health professionals stressed the importance of keeping the patient in the information loop when the AI predicts a risk or recommends a treatment to justify to the patient why they may require further support [24]. In addition to practical considerations, there is an ethical imperative to ensure patients understand how their data are being used, what predictive AI may reveal, and what the insight means, especially for sensitive issues, such as mental health care concerns [33]. Before we design solutions for communicating AI information to patients, it is important to understand the public?s perceived benefits, comfort, concerns, and values related to AI use, particularly for mental health care [34].",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"To address the deficit in knowledge regarding patient perspectives on AI, Khullar et al [35] conducted a survey of a nationally representative panel of the US-based population. While most respondents reported a perceived benefit of using AI in health care, comfort with AI unsurprisingly varied based on the accuracy, transparency, and clinical application of AI (eg, reading a chest x-ray vs making a cancer diagnosis) [35]. The survey conducted by Khullar et al [35] focused on somatic applications of AI, leaving questions regarding public perceptions of AI for mental health care applications unanswered. However, others have explored narrower issues related to feedback on specific mental health care apps and specific prediction tasks (eg, the prediction of suicide) [36,37].",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"AI applications for mental health are rapidly increasing as patients gain greater access and ownership of their data. Given the ethical concerns regarding the creation and use of AI and the stigmas surrounding mental health care, understanding patients? perceptions of whether and how AI may be appropriately used for mental health care is critical [38,39]. This study adapts and extends the survey conducted by Khullar et al [35] to evaluate patient perspectives on the use of AI for mental health care applications. We specifically surveyed members of the public to gain patient perspectives on AI applications for mental health. Khulllar et al [35] did not explore values regarding AI use, that is, what patients? priorities for effective, appropriate AI use for mental health care are. We also explored these values in this study using a bioethics-informed framework. The specific research questions (RQs) guiding our work were as follows:",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,RQ 1: Do the public perceive AI to be beneficial for mental health care? RQ 1 Equity: Do perceived benefits differ by sociodemographic factors?,,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,RQ 2: How concerned is the public about common issues related to AI use in mental health care?,,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,RQ 3: What types of predictive tasks are the public comfortable with AI executing in mental health care applications?,,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,RQ 4: What are the public?s values related to AI use for mental health care?,,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,We also elicited open-ended responses from participants to add to their quantitative feedback.,,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"In our study, we conducted a 1-time, cross-sectional survey of US-based adults in September 2022. We sampled a general US adult population to elicit the public?s perspectives on AI for mental health. We partnered with Prolific (Prolific Academic Ltd), a web-based survey sampling platform, to recruit participants. Prolific provides access to an international sample of verified users (>100,000 users residing in the United States) who are willing to be involved in survey research studies. Prolific matches eligible participants with research studies, streamlining the recruitment, data collection, and compensation processes. Prospective participants had to be verified Prolific users aged ò18 years who were fluent in written and spoken English to be eligible.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"This study was approved by the BRANY Institutional Review Board (protocol 22-01024358). Before answering the questionnaire, participants read an information sheet and consented to participate in this specific study. Participants who completed the full questionnaire were compensated at an hourly rate of US $13.60 based on Prolific?s policies.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"We designed our questionnaire such that it mimicked items asked in a previous study by Khullar et al [35] but applied to perspectives specifically related to AI for mental health, instead of AI for health care broadly. Question categories related to AI for mental health care were as follows: (1) perceived benefits of AI, (2) concerns about AI, and (3) comfort with using AI for specific predictive tasks. Adapting questions related to perceived benefits and concerns predominantly involved updating the terms ?health? or ?health care? to ?mental health? or ?mental health care,? respectively. In the questionnaire developed by Khullar et al [35], questions regarding predictive tasks included those on reading a screening tool (ie, a chest x-ray); making a diagnosis for 2 different conditions, with 1 being more severe (pneumonia and cancer); and telling a patient they had either of the 2 aforementioned conditions and making a treatment recommendation. Our team worked with a trained psychiatrist to construct tasks following similar patterns but pertaining to mental health care, adding 2 more tasks (resulting in a total of 7 tasks) to explore more sensitive concepts relating to mental health.ÿMultimedia Appendix 1ÿpresents the questions in each of the aforementioned categories along with the question from which they were adapted as applicable.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"We also extended the questionnaire to understand participant?s values pertaining to AI design and implementation for mental health care to facilitate a more patient-centered design of future AI applications for mental health. This section asked patients to rate their level of importance regarding various statements pertaining to AI for mental health care, as informed by the constructs of MITRE?s bioethical framework.ÿMultimedia Appendix 1ÿdisplays the value statements presented to participants based on the relevant bioethics constructs.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"In addition to the questions on perspectives and values, participants also answered questions on sociodemographic characteristics, including personal characteristics, health literacy, subjective numeracy, previous mental health care experience, and pregnancy history (results reported in a separate manuscript). The full battery of sociodemographic questions is presented inÿMultimedia Appendix 1.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Finally, following the sections regarding concerns and values, the survey contained open-ended questions to allow people to provide free-text responses with additional concerns or values.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"We designed the battery of questions with input from experts in AI, human-centered design, and psychiatry and the author of the original survey from which the questions were adapted. The survey questions underwent 2 rounds of pilot testing to improve their comprehensibility and understand the amount of time needed to complete the questionnaire. The question-and-answer design was optimized and pilot tested for completion on both desktops and mobiles (ie, smartphones) to ensure those with different devices or preferences could participate in the study.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"All participants were recruited from Prolific?s survey sampling panel and were verified users who agreed to participate in research studies via the Prolific website. Our sample included those aged ò18 years, residing in the United States, and with the ability to speak and read English. We recruited a sample representative of the adult US population in terms of age, race, and gender, according to the US Census. We initially recruited 530 survey respondents, of whom 30 (5.7%) did not begin the survey after reading the informed consent document, resulting in a total of 500 (94.3%) respondents. All 500 respondents finished the survey (0 incomplete responses) over a median time of 15 minutes and 24 seconds.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Our team designed and programmed the questionnaire using the Qualtrics XM (Qualtrics) platform. Participants received an invitation to complete the questionnaire through Prolific and then proceeded by clicking on a secure, anonymous link to Qualtrics. Participants could complete the survey using any smartphone, tablet, or computer, provided they had an internet connection. Participants then completed the questionnaire. There was no time limit for completing the questionnaire, and participants had the option to pause and resume completing the questionnaire at a later time. Participants also had the option to discontinue the survey at any time.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"The first level of analysis involved assessing descriptive statistics to understand trends in participant perceptions and values. We also selected an outcome of interest (perceived benefit of AI for mental health) and created a logistic regression model to better understand whether perceived benefits may differ by sociodemographic factors, specifically age, gender, race, education, financial resources, mental health history, and self-rated health literacy [40]. The à value for all analyses was set at .05, and the R software (version 4.2.1; The R Foundation) was used. An analysis of a subset of this data (only those of participants reporting female sex at birth) related to differences in perspectives based on pregnancy history has been reported in a separate manuscript [41].",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"We analyzed free-text responses through an inductive thematic analysis and a constant comparative process. One analyst initially reviewed the codes and created a draft codebook. Free-text responses to the 2 open-ended questions were analyzed using a singular coding scheme. A second analyst then used the coding scheme to independently dual code each free-text response. The analysts met with a third team member to resolve discrepancies, coding via consensus and updating the codebook throughout the discussion. Once detailed codes had been developed and 50% of the initial coding was completed, the team completed axial coding, coming up with higher-level summary themes to describe patterns in the detailed codes.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Participants were first asked, ?Overall, in the next 5 years, do you think AI will make mental health care in the United States...? Answer options included ?much better,? ?somewhat better,? ?minimal change,? ?somewhat worse,? ?much worse,? and ?don?t know.? We computed a logistic regression model such that ?much better? and ?somewhat better? were classified as 1, and the other responses were classified as 0, excluding the 3 (0.6) participants, among the total 500 participants, answering, ?don?t know.? Among 497 included respondents, 245 (49.3%) respondents believed that AI would make mental health care better or much better.ÿTable 2ÿreveals that participants of Black or African American race (P=.04; odds ratio [OR] 1.76, 95% CI 1.03-3.05) and those with lower health literacy (P=.004; OR 2.19, 95% CI 1.29-3.78) were significantly more likely to endorse that AI would make mental health care somewhat or much better. Women, by contrast, were significantly less likely to endorse this statement (P=.046; OR 0.68, 95% CI 0.46-0.99).",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"On the basis of the survey conducted by Khullar et al [35], we asked participants their level of concern (very concerned, somewhat concerned, not concerned, and don?t know) related to 6 potential challenges of using AI for mental health care (Figure 1). Participants reported being somewhat or very concerned about AI making the wrong diagnosis (402/500, 80.4%), leading to inappropriate treatment (435/500, 87%), or leading to them not knowing their mental health care provider well (409/500, 81.8%). Participants reported being very or somewhat concerned regarding spending less time with their mental health care professional (346/500, 69.2%) and their confidentiality (302/500, 60.4%) but expressed relatively less concern regarding increased costs (217/500, 43.4%).",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Next, we asked patients their level of comfort with AI performing various tasks instead of their mental health care professional. We assessed a range of tasks (ie, assessment, diagnosis, diagnosis delivery, and treatment recommendation) and mental health issues of varied levels of perceived severity (ie, depression, bipolar disorder, and suicide), as shown inÿFigure 2. Participants were the most comfortable (reporting being very or somewhat comfortable) with recommendations of nonpharmacological interventions, including general wellness management strategies (357/500, 71.4%) and talk therapy (328/500, 65.6%). Participants expressed moderate comfort with AI performing a mental health care assessment but were less comfortable (with only 20% to 32% selecting very or somewhat comfortable) with various prediction, diagnosis, and diagnosis delivery tasks, as well as a medication recommendation task. Participants were the least comfortable with diagnosis delivery tasks (ie, telling someone directly they have a mental health condition), including for clinical depression (123/500, 24.6%) and bipolar disorder (103/500, 20.6%).",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"We also asked participants their level of comfort sharing mental health information with a (human) mental health care professional, an AI chatbot, or an AI program that treats disease to improve it. We chose these categories to understand perspectives of common uses of patient data for AI, such as the use of patient data to build models that make predictions or help treat diseases as compared to the use of patient information directly for patient support (eg, an AI chatbot). Patients were the most comfortable (very or somewhat) sharing information with a mental health care professional (389/500, 77.8%), followed by sharing with an AI program that treats disease (300/500, 60%) and then sharing with an AI chatbot (238/500, 47.6%).",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"We replicated a series of questions from Khullar et al [35] assessing patient values of various aspects of AI, including transparency, explainability and performance, responsibility, and the effect of AI on trust in health professionals (Table 3).",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Participants were first asked how important it was to know when AI played a (1) small or (2) big role in their mental health treatment or diagnosis. Most participants found it somewhat or very important to know whether AI played a small (450/500, 90%) or big (474/500, 94.8%) role in their mental health treatment or diagnosis, although participants tended to report it was very important based on whether AI played a big (365/500, 73%) versus small (253/500, 50.6%) role. This pattern remained consistent with a specific scenario regarding the use of an AI program in prescribing antidepressants, with many participants stating it was very important (355/500, 71%) or somewhat important (114/500, 22.8%) that their mental health care professional informed them regarding the AI?s involvement in this prescribing decision.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"In comparing AI that was not explainable (ie, it could not describe why it made a given diagnosis), participants were generally uncomfortable even with stated AI performance accuracies of 90% (383/500, 76.6% somewhat or very uncomfortable) and 98% (289/500, 57.8% somewhat or very uncomfortable).",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Participants answered a series of questions regarding who was responsible in the event of a medical error when AI was used in conjunction with their mental health treatment; answer options included the following: the mental health professional who made the decision, the company that made the computer program, the hospital or clinic that bought the computer program, the government agency that approved the computer program, someone else, no one, and don?t know. In the case where AI was used in collaboration with a single mental health professional, most participants (>80%) reported that the mental health professional would be the one responsible if a medical error (eg, wrong diagnosis or unnecessary treatment) occurred for both a specific (ie, sleep disorder) and a general scenario.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Participants were more divided on who had responsibility for ensuring an AI program for mental health care was safe, with the plurality stating the company that created the program was responsible (229/500, 45.8%), followed by the mental health professional (135/500, 27%) and then the health system (73/500, 14.6%), with fewer than 10% of the participants selecting each of the remaining answer options.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Most participants (265/500, 53%) said that if an AI program that was accurate 80% of the time in detecting health issues related to sleeping, eating, and concentrating disagreed with their mental health professional, it would make them question the health professional?s assessment. Notably, nearly 30% (137/500) of participants said they ?did not know? how such information would change their view of their mental health professional?s assessment, with the remaining 17% (85/500) stating it would not change.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"To better understand what participants valued the most related to AI for their mental health, we asked the importance of various ethical constructs, based on MITRE?s ethical framework for consumer-generated health information [43], as they pertained to an example AI program used to support treatment for depression (Figure 3). Over 80% (range 80.2%-96%) of participants found each of the constructs somewhat or very important. Notably, the highest proportion of participants (402/500, 80.3%) viewed explainability and transparency, ?explainability,? to be very important. Participants tended to perceive decreasing the risk of negative outcomes as slightly more important than improving symptoms. Participants found AIÿnotÿreducing trust in their mental health professional as the least important trait by comparison, although 37.2% (186/500) and 43% (215/500) rated this trait as very and somewhat important, respectively.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Participants provided free-text responses describing themes related to nuanced aspects of AI?s performance, human-AI dynamics, and further values or concerns pertaining to AI. Free-text responses were mandatory, but some participants simply stated they had no additional concerns (165/500, 33%), or they did not provide sufficient detail for their responses to be categorized (7/500, 1.4%). Of the 1000 responses (2 per participant), 97 involved >1 code, so percentages listed subsequently reflect the proportion of total codes observed. On the basis of the results listed inÿTable 1ÿ(sociodemographic differences in the perceived benefits of AI for mental health care), quotes shown also provide the patients? gender, race, and self-rated literacy for context.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Table 4ÿprovides the detailed codes, proportion of occurrence, and examples related to AI performance. Participants described issues related to AI?s accuracy, biases in AI data or biases that may occur in the use of AI, potential errors AI may commit, and how these errors may affect the quality of care. Participants expressed mixed opinions regarding whether AI would improve or degrade the quality of mental health care.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Table 5ÿpresents participant feedback related to human-AI dynamics. Participants described worry that AI may not be able to replicate things done by humans (AI capabilities, human reasoning and communication, and the importance of human connection). By contrast, some pointed out ways in which AI may offer advantages to human cognition (AI capabilities). They also provided feedback on how AI and humans may (or may not) work together (human-AI collaboration and overreliance on AI), with many noting that AI should be overseen by humans and not work autonomously in mental health care applications. Finally, a few participants expressed concerns regarding how AI may take away jobs from humans.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Respondents expressed further values and concerns beyond performance and human-AI dynamics, many of which were also covered in the closed-ended survey responses, including trust, transparency, privacy, responsibility, and cost (Table 6).",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"This is one of the first studies to explore public perspectives of the use of AI for mental health?related applications. Our results expand upon other works studying public perceptions of AI for non?mental health care applications and raise important considerations regarding patient involvement in AI use for their mental health [31,44]. We also focused on various applications of AI to mental health care, differentiating our results from previous user-centered design studies that have elicited participant perceptions of a single, specific AI tool under development. Our study highlights the nuances of patients? perspectives regarding AI for mental health care, revealing that their comfort with AI use depends on the purpose of the AI (tasks it performs), use process (when it is used and what factors drive predictions), and performance of the AI (how well it works and what happens when it is wrong) [45].",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Just under half (245/497, 49.3%) of the respondents in our study reported that they thought AI would make mental health care better or somewhat better. This is similar to a study conducted in Germany where 53% of patients reported positive or very positive attitudes toward AI, but not specifically for mental health [46]. Participants in other studies asking perceptions regarding more specific applications of AI (eg, a radiology image interpretation study in Saudi Arabia and a pregnancy and postpartum exploration in Spain) had stronger positive attitudes toward AI [47,48]. This is consistent with qualitative studies that have found patients with specific health challenges more readily connected with AI?s potential benefits. Our study also found that women were associated with lower perceived benefits of AI for mental health, while lower self-rated health literacy and Black or African American race were each associated with more positive perceptions. The previously cited study conducted in Germany had similar findings related to lower perceived benefit among women [46]. However, it is interesting that this result remained consistent for mental health care applications, in light of the fact that women have reported lower levels of stigma regarding mental health care than men [49,50]. Our study also detected an interesting paradox that those having lower self-reported health literacy had more positive perceptions toward AI for mental health, although this finding warrants further replication and investigation. Regardless of patient perceptions, the inclusivity of patient-facing information regarding AI, ensuring those of various levels of literacy and numeracy may equitably comprehend its functions, remains critically important. Those of African American and Black race in the United States consistently report greater stigma and lower levels of trust toward mental (and other) health institutions due to biases, discrimination, and systemic racism [51,52]. The greater perceived benefit of AI for mental health care may represent a view that AI can be more just and without the biases of humans. This notion also requires further exploration, particularly given that the biases of human can often be embedded into the AI because training data embody previous human behavior.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Participants in our study cited concerns consistent with previous work related to AI accuracy, risk of harm (eg, wrong diagnosis and inappropriate treatment) [44,53,54], decreased human communication and connection [35,44,48,53], and issues pertaining to confidentiality [35,44,48,54-57]. Issues related to privacy were also the most commonly mentioned concern in the qualitative feedback. Participants also qualitatively described concerns about the performance of AI and doubts in AI?s ability to truly replicate human reasoning. In our study, participants expressed some concern related to rising costs, although, as found in other studies, this worry was less pronounced [35,58]. These results continue to stress the importance of contextualization for patients in terms of the following: the accuracy of AI, harms and how they are mitigated, and data use and protections. As described in previous studies, continuing to support human connection is particularly needed in mental health care applications given the importance of the patient?mental health care professional therapeutic relationship.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Our study provided further evidence that patients? comfort with AI varies based on what the AI does. People were the least comfortable with diagnosis delivery tasks, which lends further support to the importance of continuing to keep health professionals in the loop related to AI [35]. Similar to a previous study of pregnant people in Spain [47], patients were most comfortable with tasks that recommended general wellness strategies or talk therapy. These results also suggest that AI for tasks patients are less comfortable with may require greater care to explain and also emphasize how the AI works with the health professional.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Despite the rapid proliferation of chatbots [37,59], less than half of the participants (237/500, 47.4%) were comfortable sharing mental health information with a chatbot, which may simply signify that these types of tools should be used on an opt-in basis. Previous studies have suggested that it may be easier for someone to share these sensitive feelings with a computer or AI [60], and this may be true for certain people, but our findings did not universally support this assertion. It was also notable that approximately a quarter of the sample was not comfortable sharing mental health information with a mental health care professional. We acknowledge this may have been impacted by the types of mental health information listed in our survey, but it may also represent a continued stigma related to sharing mental health concerns.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Findings in our study related to patients? values for AI for mental health care revealed challenges that AI integration may present to the patient?health professional relationship. In individual scenarios, patients overwhelmingly found mental health care professionals responsible for AI-related errors. While this does reflect similarity to the current standard of practice (ie, that health professionals are held responsible for medical errors even when computer systems are involved), future work should consider how this affects health professional well-being given the challenges related to burnout and shortages in trained mental health care workers. It also supports programs, such as AI programs falling under the US Food and Drug Administration?s purview and the European Union?s AI Act of 2023, where algorithms may be reviewed before use and subject to regulations [61]. Participants also noted that their trust in their mental health care professional would decrease if their assessment disagreed with AI. However, this was somewhat at odds with relatively fewer patients viewing issues with AI decreasing trust in their mental health care professional as ?very important.? It was also notable that approximately one-third (137/500, 27.4%) of participants said they ?did not know? how this scenario would affect their trust in their mental health care professional, which seems to highlight that patients may still be wrapping their heads around feelings regarding emerging technologies, such as AI.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Patients desired a high degree of transparency related to AI use, with >90% of participants considering it important that they be told when AI played even a small role in their care. Participants also valued explainability, as most participants (289/500, 57.8%) were not comfortable with highly accurate AI that could not explain how it made its predictions and as ?understanding individual risk factors? was rated as the most important value related to AI for mental health care applications. It is at best unclear what patients are typically told regarding when AI is used for their care; how explainable it is; and to what extent, if at all, they are informed what factors drive predictions regarding their care. These results suggest that patient values may be at odds with the current standard of practice for patient communication. Similar to the concerns previously described, participants also highly rated the importance of AI not leading to errors and helping with their mental health symptoms.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Implications regarding our findings are organized topically and include concrete recommendations, which have been italicized for emphasis.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"The therapeutic relationship between a patient and their health professional is crucial in mental health care settings. Our study revealed issues that will need to be reconciled if AI is to be safely, transparently, and acceptably used for mental health care. From our results, it is clear that patients want mental health care professionals to be the ultimate decision makers, using AI to support (but not make) decisions when it is deemed safe and effective [36]. Participants also overwhelmingly viewed mental health care professionals as the people responsible if an error occurred related to treatment where AI had been used.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Future work should investigate shared regulations for AI responsibility, health professional competencies for AI use (Russell et al [62]), and interfaces that support shared decision-making when using AI.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Specifically, designs should support collaborative patient?health professional decision-making in a way that fosters trust instead of degrading it while also not creating undue burden for the health professional. Previous studies have described how clinicians should be able to contest AI, such as ignoring it (when it is not relevant or appropriate), trusting it when it is appropriate, or being able to uncover explanations to negotiate in borderline cases [63]. Such systems should be able to track health professional decisions in relation to the AI, possibly allowing health professionals to provide brief rationale that they may use in conversations with patients. In creating such systems, usability and model explainability will be critical. While these systems may be difficult to study in situ given the sensitivity of mental health conversations,ÿsolutions may first be evaluated in realistic clinical simulation environments to ensure safety and usability prior to larger scale deployment.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Participants in this study desired various information regarding the use of AI for their mental health care; that is, they wished to know when, for what, and why it was used; how accurate it was; and the risk factors that drove a decision. Even with highly predictive AI, patients were still not comfortable with AI that could not explain how it arrived at a result, and they qualitatively expressed concerns related to misdiagnosis and improper treatment that could result from AI use. They also reported ?understanding individual risk factors? as the most important value. It is unclear as to how much if any ?information? patient receive, and there seems to be a mismatch between the current deployment of AI for mental health care and patients? desires.ÿAt minimum, we recommend promoting transparency in AI?s use, the communication of its accuracy, and including individual risk factors to help patients and clinicians decide when AI may be appropriate for use in health-related applications. Communications should also address how potential biases (eg, in the training data) have been evaluated and mitigated in the resultantÿAIÿtool.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Communicating the desired information to patients, however, is not straightforward, as concepts such as AI performance and process involve complex mathematical concepts. Furthermore, this desire for additional information regarding AI is also at odds with how patient communication has traditionally been practiced. When we consider other non?AI-based diagnostic or decision support tools (eg, magnetic resonance imaging, blood tests, and screening assessments), communicating information regarding how they work (ie, their process) or their performance is far from standard practice. AI seems to be held to a higher standard than other diagnostic tools related to transparency in performance.ÿFuture work should consider not only communicating the process and performance of AI but also providing this information in the context with the performance of the existing approach to a given task.ÿThis would allow health professionals and patients to determine whether the potential benefits of AI outweigh their concerns.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Providing patients with explanations of AI performance and factors driving prediction will require extensive study involving experts in human-centered, inclusive design working alongside AI developers, mental health care professionals, and patients.ÿThere is a need for laboratory-based studies to understand what information regarding AI balances recognizing patient values, but also supports comprehension of important concepts and fostering appropriate trust.ÿThese issues raise many questions for numeracy and data visualization experts regarding how information may be conveyed inclusively to patients with different needs so that the benefits of AI may be equitably realized.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,Our study detected differences in who may find AI beneficial and for what tasks they may be comfortable using it.ÿFuture work should explore how we may respect individual autonomy with regard to the use of AI applications so that patients and health professionals may collaboratively make decisions about the appropriate application of AI to mental health care issues.,,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Our study was limited in that the sample was recruited using a web-based platform, which may not generalize to those with technology, literacy, and other barriers to web-based survey completion. The sample was representative of the adult US population in terms of age, gender, and race distributions (Prolific/academic researchers), leading to most of the survey respondents being White due to >70% due to the US demographic makeup (US Census Bureau [64]). Therefore, important perspectives from other racial and ethnic groups may be limited. Our results may also be subject to response bias, as those who had strong feelings regarding topics pertaining to AI, mental health, or their intersection may have been more likely to respond. For example, a higher-than-anticipated proportion of respondents (215/500, 43%) reported having a history of mental illness. We did attempt to control for this in RQ 1, and the history of mental illness was not found to significantly affect responses regarding participants? perceived benefits of AI for mental health care. We, however, did not have a mechanism for evaluating how preexisting attitudes of AI may have affected responses, and this may be addressed with validated measures of AI attitudes in future surveys (Schepman and Rodway [65]). Given the scope of this paper, we were unable to assess sociodemographic differences (eg, based on race and literacy) across all outcomes. Future work may use this or other data sets to provide a more nuanced picture of differing views related to specific questions regarding AI for mental health.",,,,,
Patient Perspectives on AI for Mental Health Care: Cross-Sectional Survey Study,"Our study found that approximately half (245/497, 49.3%) of the US adults surveyed perceived some benefit for the use of AI in mental health care applications. These perceived benefits were lower among women but higher among Black or African American participants and those with lower self-rated health literacy. Participants also expressed nuanced differences in the types of tasks they would be comfortable with AI completing, showing the greatest discomfort with AI handling clinical diagnosis, diagnosis delivery, and the recommendation of medication. Those surveyed valued high-performing AI that could explain individual risk factors driving predictions. In general, participants were concerned that AI may mean a loss of human connection, and they perceived humans as the ultimate decision makers, with AI serving as an additional data point when appropriate. Qualitative feedback also revealed participants? deep-seated fears regarding the use of AI for their mental health care. These findings stress the importance of working with patients and mental health care professionals to understand whether and how AI may be safely, ethically, and acceptably implemented for mental health care applications.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"Mental illnesses represent a significant global health challenge, affecting millions with far-reaching social and economic impacts. Traditional exercise prescriptions for mental health often adopt a one-size-fits-all approach, which overlooks individual variations in mental and physical health. Recent advancements in artificial intelligence (AI) offer an opportunity to tailor these interventions more effectively.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"This study aims to develop and evaluate a multimodal data-driven AI system for personalized exercise prescriptions, targeting individuals with mental illnesses. By leveraging AI, the study seeks to overcome the limitations of conventional exercise regimens and improve adherence and mental health outcomes.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"The study is conducted in two phases. Initially, 1,000 participants will be recruited for AI model training and testing, with 800 forming the training set, augmented by 9,200 simulated samples generated by ChatGPT, and 200 as the testing set. Data annotation will be performed by experienced physicians from the Department of Mental Health at Guangdong Second Provincial General Hospital. Subsequently, a randomized controlled trial (RCT) with 40 participants will be conducted to compare the AI-driven exercise prescriptions against standard care. Assessments will be scheduled at 6, 12, and 18?months to evaluate cognitive, physical, and psychological outcomes.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"The AI-driven system is expected to demonstrate greater effectiveness in improving mental health outcomes compared to standard exercise prescriptions. Personalized exercise regimens, informed by comprehensive data analysis, are anticipated to enhance participant adherence and overall mental well-being. These outcomes could signify a paradigm shift in exercise prescription for mental health, paving the way for more personalized and effective treatment modalities.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"This is approved by Human Experimental Ethics Inspection of Guangzhou Sport University, and the registration is under review by ChiCTR.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"Mental illnesses, a significant global health concern, encompass a wide spectrum of psychological disorders affecting millions worldwide (1,ÿ2). The ramifications of these disorders extend beyond the individual, affecting families, communities, and economies. For instance, depression alone is a leading cause of disability worldwide, and mental disorders are among the major contributors to the overall global burden of disease (3,ÿ4). The societal impact of mental illness is profound, encompassing economic costs due to lost productivity, healthcare expenses, and the intangible yet substantial cost of reduced quality of life (5,ÿ6). Additionally, mental health disorders can exacerbate social issues such as homelessness and unemployment, creating a vicious cycle of poverty and illness (7).",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"The field of exercise prescription for mental illness has garnered increasing attention in recent years, as evidenced by a growing body of research. Studies have consistently demonstrated the efficacy of regular physical activity in alleviating symptoms of various mental disorders, including depression, anxiety, and schizophrenia (8?11). For example, a meta-analysis by Rosenbaum et al. indicated that moderate to vigorous physical activity could significantly reduce depressive symptoms in adults (12). Despite these advancements, several challenges and gaps remain in the application of exercise prescription for mental health. A primary concern is the lack of individualization in exercise regimes. Most existing studies and protocols adopt a one-size-fits-all approach, neglecting the unique needs, preferences, and limitations of individual patients (13). This generalized approach may lead to suboptimal outcomes and lower adherence rates, as patients may find the prescribed exercises either too challenging or not engaging enough. Another significant limitation is the scarcity of data-driven methods in tailoring exercise prescriptions. While some studies have begun to explore the use of data in optimizing exercise interventions (14,ÿ15), there is still a considerable gap in integrating comprehensive, multimodal data ? such as genetic, physiological, and behavioral information ? to inform exercise prescriptions. This lack of integration results in missed opportunities to enhance the precision and effectiveness of exercise as a therapeutic tool for mental health.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"The integration of Artificial Intelligence (AI) in healthcare and medicine has marked a transformative era, particularly with the advancements in deep learning algorithms and the enhanced capabilities in processing large volumes of data (16,ÿ17). These technological leaps have enabled the deployment of AI across various medical fields, including mental health, internal medicine, infectious disease control, heart failure management, and diabetes care, among others. Specifically in the domain of mental health (18), AI-driven tools are being used to predict patient outcomes, personalize treatment plans, and even assist in early diagnosis through pattern recognition in patient data. In internal medicine (19), AI algorithms contribute to diagnostic accuracy and patient management, while in the field of infectious diseases control (20), AI plays a pivotal role in outbreak prediction, tracking, and formulating response strategies. The application of AI is equally significant in managing chronic diseases. For instance, in heart failure (21,ÿ22), AI assists in patient monitoring, risk assessment, and tailoring treatment regimes. Similarly, in diabetes management (23), AI technologies are employed for continuous glucose monitoring and predicting episodes of hypoglycemia or hyperglycemia, thereby enhancing patient care. In the context of China?s medical resource constraints, the development of AI-based prescription recommendation systems is particularly promising (24). These systems have the potential to mitigate the gap in healthcare delivery, offering efficient, accurate, and accessible medical advice. A notable example of such innovation is the reinforcement learning-based dynamic prescription recommendation system proposed by Wang and colleagues (25). This system exemplifies the application of AI in optimizing treatment plans, adapting to patient-specific needs and changes over time (26).",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"In the burgeoning field of exercise prescription, the application of AI and machine learning has begun to show promising results. Tuka and Linhart have explored the potential of these technologies for creating personalized exercise prescriptions, tailoring recommendations to the unique needs and conditions of patients (27). Additionally, this research underscores the superiority of current AI technology over traditional methods in exercise prescription. AI systems offer a higher degree of personalization and adaptability, leveraging real-time data to tailor exercise plans more effectively to individual needs and conditions. This approach signifies a significant shift from traditional, generalized exercise guidelines to more individualized, data-driven strategies.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"In a more targeted study, Chen and colleagues have devised a hierarchical learning framework specifically designed for crafting physical exercise prescriptions for Chinese children (28). This innovative framework takes into account various factors such as age, physical development, and individual health conditions, demonstrating the effectiveness of AI in addressing the diverse needs of specific populations. However, despite these advancements, there remains a notable gap in the literature regarding the application of machine learning in the context of exercise prescription for mental health. Mental illness presents unique challenges and necessitates tailored approaches in exercise prescription, considering factors like psychological state, medication side effects, and the fluctuating nature of symptoms. To bridge this gap, our research aims to develop an interpretable, machine learning-based intelligent system dedicated to exercise prescription for the prevention and management of mental illness. This system will not only adapt to the individual needs of patients but also provide insights into the rationale behind each prescription, ensuring transparency and trust in AI-driven recommendations.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"In the first phase, we focus on developing a multimodal data-driven intelligent system for exercise prescription. To achieve this, we will initially recruit 1,000 participants for AI model training and testing. Of these, 80% (800 participants) form the training set. To enhance the robustness and generalizability of the AI model, we will use ChatGPT to simulate an additional 9,200 cases based on the initial 800, resulting in a comprehensive training set of 10,000 instances. The remaining 20% (200 participants) will be reserved as a testing set. This diverse dataset will then be annotated by a team of 10 experienced doctors from the Department of Mental Health at Guangdong Second Provincial General Hospital. Their expertise will ensures the accuracy and clinical relevance of the data labeling, which is critical for the development of a reliable and effective AI system.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"In our analysis, we will set the effect size at 0.5 to assess the intervention?s effectiveness. This value represents a medium effect size, which is considered substantial in the context of our study. Following the development and preliminary testing of the AI model, the second phase of the study will involves an RCT with 50 participants. These participants are randomly divided into two groups: 25 in the experimental group and 25 in the control group. The experimental group will receives personalized exercise prescriptions generated by the newly developed AI system, while the control group will receives standard exercise recommendations. This phase aims to evaluate the efficacy of the AI-driven exercise prescription system in a real-world clinical setting. The RCT?s design ensures that the results are robust and can be attributed specifically to the intervention, thereby providing strong evidence of the system?s potential benefits for individuals with mental illnesses.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"The effectiveness of the AI-driven exercise prescriptions is evaluated at multiple time points: initially at the end of the 6?months trial period (Trial Completion Assessment), followed by a 6?months follow-up assessment and a 12?months follow-up assessment. These assessments are designed to track and compare the short-term and long-term impacts of the AI-driven exercise prescriptions on the mental health outcomes of the participants (shown inÿFigure 1).",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"Participants for the study will be recruited from the general community and the Department of Mental Health at Guangdong Second Provincial General Hospital, utilizing platforms like WeChat or other social media to effectively reach and engage potential participants. To reach a diverse pool of potential participants, advertisements will be placed in community centers and local newspapers in Guangzhou. At the Department of Mental Health, individuals receiving care will have the opportunity to consent to the use of their medical records for research purposes and express their interest in participating in research studies. Prospective participants will initially undergo a telephone screening process to determine their eligibility. This screening will include an evaluation based on predefined inclusion and exclusion criteria, alongside the Physical Activity Readiness Questionnaire for Everyone (PAR-Q Plus) (29), a widely recognized tool for assessing an individual?s readiness for physical exercise. Upon passing the initial screening, eligible participants will be invited to a detailed consent and screening session. This session, which can be conducted either over the phone or in person, will provide comprehensive information about the study, including its objectives, methodology, potential risks, and benefits. During this session, research staff will ensure that participants fully understand the study and are comfortable with their involvement, thereby upholding the highest standards of ethical research practice. For participants involved in the AI part of data collection, we are offering a subsidy of 100 RMB per person. This incentive is designed to encourage their active participation and consistent engagement with the data collection process. Additionally, for participants in the RCT, we are providing a more substantial subsidy of 300 RMB per person.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"The enrollment of participants for this study will commenced on January 1, 2024. This will mark the beginning of a crucial phase in our research, where we started gathering data from a diverse group of individuals, crucial for the development and testing of our AI model. The final assessment of the study is anticipated to be completed by January 1, 2027. This assessment will mark the conclusion of the two-year follow-up period post the trial completion.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"In this study, participants are selected based on specific inclusion criteria to ensure both relevance and safety. Individuals aged 18 to 65, diagnosed with a mental illness such as depression, anxiety disorders, bipolar disorder, or schizophrenia, are eligible. They must be in a stable medical condition, with no acute mental health crises in the past 6?months, and have the cognitive ability to understand and consent to the study procedures. Physical capability for exercise, assessed by the PAR-Q Plus, is required, alongside a willingness to adhere to the study?s protocol. Participants should not be engaged in any other structured exercise program, have access to communication tools for remote monitoring, and reside within a distance from the study site in the Guangzhou area. These criteria are designed to ensure that participants are representative of the target population and can safely and effectively engage in the study.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"Certain exclusion criteria are established to maintain the integrity and safety of the research. Individuals are excluded if they are under 18 or over 65?years of age, to focus the study on a specific adult demographic. Those without a clinically confirmed diagnosis of mental illness, or those experiencing acute mental health crises or hospitalizations within the last 6?months, are also excluded. Participants with severe cognitive impairments that prevent understanding of the study or informed consent, as well as those with physical conditions or disabilities that contraindicate exercise, based on the PAR-Q Plus assessment, are not eligible. Additionally, individuals already engaged in a structured exercise program or unable to commit to the study?s schedule and protocols are excluded. Further, lack of access to necessary communication tools for remote monitoring or residing outside the practical geographical scope of the study (beyond the Guangzhou area) also leads to exclusion. These criteria ensure that participants are well-suited to the study?s aims and methods while safeguarding their well-being.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"Throughout the data collection process, no personal identifiers will be gathered to ensure participant confidentiality. All data collected on paper will be securely stored in locked cabinets, accessible only to authorized study personnel. Trained staff will be responsible for entering alphanumeric data, implementing range checks to verify the accuracy of data values. Both alphanumeric data and neuroimaging files will be stored on a secure server managed by UBC, adhering to strict data protection protocols. To further safeguard participant privacy, all collected data will undergo a de-identification process, removing any potential links to individual identities.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"In our study, a range of comprehensive assessment tools have been meticulously chosen to serve as inputs for the machine learning model (shown inÿTable 1). These include the State and Trait Anxiety Inventory (STAI), Center for Epidemiologic Studies Depression Scale (CES-D), Pittsburgh Sleep Quality Index (PSQI), and several others, each uniquely contributing to a multi-dimensional understanding of participant well-being. The collected data from these tools encompass various aspects of mental health, physical activity, social engagement, and general well-being. For instance, the STAI provides insights into anxiety levels, the CES-D focuses on symptoms of depression, while the PSQI assesses sleep quality. Other questionnaires like the CHAMPS Physical Activity Questionnaire and the Lubben Social Network Scale offer valuable data on physical activity habits and social network strengths, respectively. This diverse dataset is fed into the machine learning model to analyze patterns, correlations, and potential predictors of mental health outcomes.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"In the crucial phase of data annotation, our study collaborates with the Department of Mental Health at Guangdong Second Provincial General Hospital, enlisting the expertise of five experienced physicians. The data annotation process involved five doctors, each with over 10?years of experience. The dataset was divided equally among them, with each doctor responsible for annotating a specific portion. This approach ensured that the entire dataset was annotated efficiently and effectively, with all doctors completing their assigned tasks until the full dataset was annotated.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"The physicians, utilizing their medical expertise and understanding of mental health, carefully review the responses from the various questionnaires, including the STAI, CES-D, and others. The doctors consider several critical aspects of exercise prescription: (1) Type of Exercise: determining the most suitable form of physical activity, whether it?s aerobic, strength training, flexibility exercises, or a combination, based on the participant?s health status and preferences; (2) Frequency: establishing how often the participant should engage in the prescribed exercises, balancing effectiveness with practicality. (3) Intensity: setting the appropriate level of exertion for each exercise, tailored to the individual?s physical capabilities and mental health needs. (4) Duration: recommending the length of each exercise session to maximize benefits while ensuring safety and adherence.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"The initial dataset comprised 800 cases, designated as the training set, and a smaller set of 200 cases, set aside as the test dataset. To augment the robustness and diversity of our training dataset, we employed theÿChatGPTÿto generate an additional 9,200 simulated samples. This step was based on the patterns and characteristics observed in the initial 800 cases. By doing so, we significantly expanded our dataset, enriching the training process and enhancing the model?s ability to generalize across a broader range of scenarios. This extensive data annotation and augmentation process is crucial for developing an accurate and effective AI-driven exercise prescription system. It ensures that the model is not only trained on a substantial and varied dataset but also fine-tuned to reflect real-world complexities and nuances in mental health and physical fitness.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"In the model selection phase of our study, we employed a multi-model approach to identify the most effective machine learning algorithm for our data. We will rigorously trained and tested various models, including Linear Regression, Decision Trees, Random Forests, Support Vector Machines (SVMs), Neural Networks, Recurrent Neural Network (RNN), and Gradient Boosting Machines (GBMs), each evaluated on accuracy, precision, recall, and F1 score. The process involved using our annotated dataset for training and a separate testing set for validation. Ultimately, the model demonstrating the highest predictive accuracy and robustness on the testing set will be selected. This model, excelling in processing complex mental health data, forms the cornerstone of our AI-driven exercise prescription system, ensuring personalized and effective recommendations for individuals with mental health conditions. In our study, we anticipate that the AI model will achieve an AUC of over 0.9, demonstrating its high accuracy in tailoring exercise prescriptions for mental health improvements.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"Our predictive models were constructed using Python 3.7.13, leveraging libraries such as Pandas for data manipulation, scikit-learn for machine learning algorithms, and NumPy for numerical computations.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"Our study employs a parallel-group RCT to evaluate the effectiveness of an AI-based exercise prescription system in mental health management. Participants are divided into two groups: an intervention group and a control group, each consisting of 25 individuals. This balanced design allows for a robust comparison of outcomes between the groups, thereby providing reliable evidence on the impact of the AI-driven intervention. The randomization process involves a computer-generated sequence, ensuring an unbiased assignment of participants into the intervention group (n?=?25) and the control group (n?=?25). Stratification is conducted based on key variables such as age, gender, and specific mental health diagnoses to maintain comparable groups. This methodology is critical for mitigating potential confounding factors and ensuring the validity of the study results. In the intervention group, each participant receives a personalized exercise prescription tailored by the AI system, based on their unique health profile. This approach aims to maximize the efficacy of the exercise regimen in improving mental health outcomes. The control group, on the other hand, receives standard care practices, which may include general health advice or standard exercise recommendations. The distinction in treatment between the groups is central to evaluating the added value of the AI-driven exercise prescriptions.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"The 25 participants in the intervention group receive personalized exercise prescriptions generated by our AI model. These prescriptions are meticulously tailored based on each participant?s health profile and mental health status. The AI model determines the most suitable Type of Exercise for each individual, ranging from aerobic activities to strength training, depending on their physical and mental health needs. The Frequency of exercise is set, aiming for a balance that maximizes benefit while considering each individual?s lifestyle and capacity. Intensity levels are also customized, ensuring that exercises are challenging yet safe and achievable for each participant. Lastly, the Duration of each exercise session is specified by the AI model, optimizing the time spent on each activity for maximum efficacy. For example, for a participant with moderate depression and a sedentary lifestyle, the AI model might prescribe light aerobic activities like brisk walking or cycling for 30?min, three times a week. The intensity would be set at a moderate level, ensuring the participant can comfortably sustain the activity while gaining mental health benefits. The model may also suggest gentle yoga twice a week to improve flexibility and reduce stress, tailoring the duration to 20?min per session to match the participant?s initial physical fitness level. The intervention lasts for a period of 4?weeks, during which participants adhere to their personalized exercise regimen. The control group, comprising another set of 25 participants, receives standard care practices. This generally includes generic health advice and non-tailored exercise recommendations, reflecting the conventional approach to mental health management. The control group?s treatment does not involve the AI-driven customization of exercise parameters, serving as a baseline to evaluate the effectiveness of the personalized exercise prescriptions provided to the intervention group.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"This study employs a rigorous and comprehensive assessment schedule, as outlined inÿTable 2, to evaluate a broad spectrum of outcomes across different time intervals: at 6?months (Trial Completion), 12?months (First Follow-up), and 18?months (Second Follow-up) (detail shown inÿTable 2).",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,Cognitive assessments: the MoCA (Montreal Cognitive Assessment) and MMSE (Mini-Mental State Examination) are conducted at the trial completion (6?months) and again at the 18?months follow-up. These tools are essential for measuring cognitive function and detecting any changes over time.,,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"Functional and physical assessments: the study includes the Instrumental Activities of Daily Living (IADL) assessment at the 6?months mark to evaluate functional abilities. Physical performance is measured at 6?months using tests such as the Short Physical Performance Battery, the 400?m Walk Test, and the 30?s sit-to-stand test. These assessments are repeated at the 18?months follow-up to track physical endurance and mobility changes.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"Memory and psychological assessments: subjective memory complaints are evaluated at the 12?months follow-up, while other detailed memory tests like the Rey-O Complex Figure and Judgement of Line Orientation are conducted at 6?months. The State and Trait Anxiety Inventory is administered at both the 6?months and 18?months follow-ups to assess changes in anxiety levels.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"Lifestyle and quality of life questionnaires: the study also incorporates the Reproductive, Florida Cognitive Activity Lifetime Stimulation, and Epic-Norfolk Physical Activity Questionnaire at the 6?months mark. In addition, the FCI (Frailty Criteria Index), PSQI (Pittsburgh Sleep Quality Index), and Life Space Questionnaire are administered at all three assessment points (6, 12, and 18?months) to monitor lifestyle changes and quality of life.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,Health-related assessments: health-related quality of life and sedentary behavior are evaluated at all three time points to provide a comprehensive view of the participants? overall health status and lifestyle habits.,,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"In the initial phase of our statistical analysis, we will employ descriptive statistics to summarize the participant characteristics, including demographics, baseline health measures, and other relevant variables. This step will involve calculating means, standard deviations, and proportions to provide a clear overview of the study population. Following this, comparative analyses between the intervention and control groups will be conducted using independentÿt-tests (or Mann?Whitney U tests for non-normally distributed data) for continuous variables, and Chi-square tests (or Fisher?s exact tests) for categorical variables. This will enable us to detect any significant differences arising from the intervention.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"Considering the multiple assessment points in our study, longitudinal data analysis techniques will be crucial. These methods, including repeated measures ANOVA or mixed-model ANOVAs, will allow us to track and analyze changes over time both within and between participant groups. This approach is essential for understanding the dynamics of the intervention?s impact, accounting for both individual variations and time-dependent factors.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"To quantify the intervention?s effectiveness, we will calculate effect sizes, providing a measure of the practical significance of our findings. The handling of missing data, a common challenge in longitudinal studies, will be addressed through methods like multiple imputation or last observation carried forward, ensuring the robustness of our results. All statistical tests will be two-tailed, with a significance level set atÿp?<?0.05. We plan to use sophisticated statistical software such as SPSS or R for these analyses, enabling us to apply the most appropriate and advanced statistical techniques for our data.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"This study represents a significant step forward in the field of exercise prescription for mental health, leveraging the power of AI and machine learning to tailor interventions to individual needs. Our findings contribute to a growing body of evidence underscoring the importance of personalized healthcare approaches, particularly in managing mental illnesses.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"The application of a multimodal data-driven AI system in developing exercise prescriptions has demonstrated significant promise in enhancing mental health outcomes. This innovative approach effectively counters the limitations inherent in traditional exercise regimes, which often adopt a generalized approach, potentially overlooking individual nuances. Our AI-driven system, by incorporating a diverse array of data points including mental health status, physical capabilities, and personal lifestyle preferences, offers interventions that are far more customized and aligned with each participant?s unique needs.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"This level of individualization in exercise prescription is pivotal (49). It recognizes the complex interplay between mental health and physical activity, allowing for adjustments based on factors such as an individual?s specific mental health condition, their physical fitness levels, and their daily routines and preferences. For instance, someone with mild depression might benefit from a different type and intensity of exercise compared to someone with severe anxiety. Likewise, a physically active individual might be prescribed a more vigorous regimen than someone who is less active. By tailoring exercise recommendations in this way, our AI system not only caters to the distinct needs of each participant but also maximizes the potential for adherence. Adherence is often a significant challenge in traditional exercise regimes, but by offering personalized and therefore more relevant and engaging exercise plans, our system could significantly improve compliance rates (50).",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"Moreover, the enhanced efficacy of these personalized exercise regimes could lead to better mental health outcomes. Regular, tailored physical activity can positively impact various aspects of mental health, including mood elevation, reduction in anxiety symptoms, and overall improvement in mental well-being. This suggests that personalized exercise prescriptions, as adjuncts to conventional mental health treatments like psychotherapy and medication, could offer a comprehensive approach to mental health care.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"While our research has yielded encouraging outcomes, it is not without limitations. The complexity of mental health disorders and the variability in individual responses to exercise highlight the challenges in developing universally effective AI-driven interventions. Additionally, the reliance on self-reported data in some of our assessments could introduce bias or inaccuracies. Future research should aim to incorporate more objective measures and explore the long-term sustainability of AI-prescribed exercise regimes.",,,,,
Evaluating machine learning-enabled and multimodal data-driven exercise prescriptions for mental health: a randomized controlled trial protocol,"In conclusion, this study marks a significant stride in the realm of mental health care, demonstrating the potential of a multimodal data-driven AI system to revolutionize exercise prescription for individuals with mental illnesses. While acknowledging the complexities inherent in mental health disorders and the limitations of our current approach, our findings underscore the promise of personalized, AI-enabled exercise regimens in enhancing mental well-being. The integration of sophisticated AI with individualized exercise prescriptions paves the way for more effective, patient-tailored therapeutic strategies, offering a glimpse into the future of mental health treatment. Moving forward, it is imperative to address the identified limitations through more extensive research, aiming to refine the AI algorithms further and explore the long-term impact of these personalized interventions, ultimately contributing to more comprehensive and effective mental health care.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Suicide-related media content has preventive or harmful effects depending on the specific content. Proactive media screening for suicide prevention is hampered by the scarcity of machine learning approaches to detect specific characteristics in news reports. This study applied machine learning to label large quantities of broadcast (TV and radio) media data according to media recommendations reporting suicide. We manually labeled 2519 English transcripts from 44 broadcast sources in Oregon and Washington, USA, published between April 2019 and March 2020. We conducted a content analysis of media reports regarding content characteristics. We trained a benchmark of machine learning models including a majority classifier, approaches based on word frequency (TF-IDF with a linear SVM) and a deep learning model (BERT). We applied these models to a selection of more simple (e.g., focus on a suicide death), and subsequently to putatively more complex tasks (e.g., determining the main focus of a text from 14 categories). Tf-idf with SVM and BERT were clearly better than the naive majority classifier for all characteristics. In a test dataset not used during model training, F1-scores (i.e., the harmonic mean of precision and recall) ranged from 0.90 for celebrity suicide down to 0.58 for the identification of the main focus of the media item. Model performance depended strongly on the number of training samples available, and much less on assumed difficulty of the classification task. This study demonstrates that machine learning models can achieve very satisfactory results for classifying suicide-related broadcast media content, including multi-class characteristics, as long as enough training samples are available. The developed models enable future large-scale screening and investigations of broadcast media.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Current estimates suggest that approximately 700,000 individuals die by suicide each year, making suicide a priority in mental health research and prevention [1]. There are a variety of prevention approaches that have been widely used and recommended, with media reporting about suicide being one of the focal areas in most suicide prevention programmes and strategies [2,ÿ3]. Research suggests that media can influence suicidal thoughts and feelings and potentially, suicidal behaviours in vulnerable individuals, in both a harmful and beneficial direction. For example, a recent-meta-analysis shows evidence for increases of suicides after news about celebrity deaths by suicide within two months after the death, making the reporting of celebrity suicide a core characteristic considered to carry some risk of harmful effects [4]. Specifically, after the reporting of celebrity suicides, suicide rates tend to increase by 13% in one to two subsequent months [4]. Imitation of suicidal behavior such as after celebrity suicide news is commonly referred to as the Werther effect [5]. Studies suggest that other types of media content may have a protective effect. With regard to positive media effects, the strongest evidence exists for stories of hope and recovery from psychosocial crises and suicidal thoughts [6?9]. A recent meta-analysis of randomized controlled trials suggests that media stories that feature individuals who managed to cope with their adversity and suicidal thoughts lead to a small-sized reduction in suicidal thoughts [8]. This beneficial media effect has been coined the Papageno effect and has received increasing attention in prevention and research over the last decade [6].",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"In order to mitigate the risks associated with suicide-related reporting in broadcast and online media, media recommendations for the reporting on suicide have been developed by national and international public health organizations [3]. These recommendations list content characteristics that have been deemed as potentially harmful and protective. On the one hand, recommendations include suggestions such as not focusing on suicide death; but rather on suicidal ideation in prevention-reporting. Further, they discourage extensive reporting on celebrity death from suicide, and recommend not to perpetuate common public misconceptions and myths about suicide. On the other hand, media recommendations also encourage reporting characteristics that might be helpful to vulnerable audiences. Specifically, they encourage the reporting of alternatives to suicidal behaviour, reporting of healing stories (i.e., stories of individuals who managed to recover from suicidal thoughts), and the reporting of positive outcome of crisis. Although not all of the specific recommendations have solid empirical evidence (many of them are based on expert consensus), current media recommendations are considered to be the most available and practical tool to help prevent suicide from suicide-related media reporting [3].",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"In order to prevent harm from media reporting on suicide, screening for proactive identification of media reporting has been identified as a priority in suicide prevention [2,ÿ3]. In case of reporting that might do harm, media screening can speed up the process of identifying media reports and potentially distributing media reaching out to media professionals. Such screening, however, has been hampered by the considerable resources needed for content analytic work. Machine learning approaches to automatically detect specific media reporting characteristics might be helpful in this regard. Further, automatic detection of reporting characteristics across a large body of media items would also help with building the evidence base for specific media recommendations, as this would increase the feasibility of testing of how specific media reporting characteristics are associated with suicide and other important outcomes, such as help-seeking.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"With regard to broadcast media content, machine learning approaches to categorize content are largely missing. This is in spite of the fact that particularly news media reporting has frequently been found to be associated with suicide [5], and although global efforts to reduce imitation suicide using media recommendations for safe portrayals have largely focused on news media [3]. In contrast, some research has been done on social media content. Specifically, there are now three machine learning studies that categorized Twitter posts into frequent content types, including celebrity suicide posts, posts signaling suicidal ident, awareness campaigns, prevention information, condolences and flippant remarks [10,ÿ11]. These studies have typically used word frequency statistics as predefined features for model training. However, the meaning of words also depends on their context, and more novel deep learning models [see e.g.,ÿ11,ÿ12] are needed to take context better into account.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"For the present research, we build on previous studies by using a comprehensive human annotation scheme that systematically identifies selected putatively harmful and protective characteristics in broadcast reports about suicide. We selected a number of reporting characteristics from media recommendations for suicide, starting with a difficulty level that we assumed to be more simple (e.g., identifying a report on a celebrity suicide), to increasingly difficult classification tasks (e.g., identifying stories of healing) and ultimately, highly complex tasks such as the identification of the main focus of a news item. Using this selection of content characteristics with different difficulty levels for classification, we want to assess the feasibility of current machine learning approaches for the detection of suicide-related media reporting characteristics.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"We retrieved a total of 2519 transcripts of media items for Oregon and Washington for April 1 2019 to March 30 2020 from the media screening company Infomart/Brandwatch. Only items with a ""major focus"" on suicide / suicidal ideation / suicide prevention, defined as more than just a short paragraph about the topic, were included. Other items were excluded by Infomart, similar to the approach used in previous related research [13]. The focus on the geographical regions of Oregon and Washington was taken because this study built up on a media evaluation project that included specifically media items from these two states [14]. We reused the transcripts from this previous project to develop the machine learning approach in this study. The dataset was derived from 44 broadcast sources across both states (see [14] andÿS1 Tableÿfor details about sources covered). We received full transcripts of broadcast media items in pdf format.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"We developed a coding system to assess the quality of media items. The content analysis built on previous analytic approaches for print and online media conducted by members of the study team and was based on the most current versions of media recommendations for the reporting of suicide [3,ÿ6,ÿ13].",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"The characteristics included reporting elements that are considered to be harmful, as well as characteristics deemed to be relevant for suicide prevention. The process is decribed in detail in Niederkrotenthaler et al., 2022 [14].",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Authors ZL, and BT independently coded a random selection of items for each characteristic. Their intercoder-reliability for each characteristic was assessed in terms of percent agreement and Cohen Kappa coefficients. By the end of the process, all codes had substantial agreement (minimum percent agreement: 85%; minimum Kappa: 0.62) with most codes clearly outperforming these minimums. Mean percent agreement was 92.4%; mean Kappa: 0.87. The code book with code definitions and coding examples is provided inÿS2 Tableÿ[14].",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"We developed different machine learning models with the goal of automatically classifying transcripts according to selected reporting characteristics. We selected a pre-defined number of characteristics for the machine learning exercise based on considerations about the difficulty of tasks, starting with characteristics that we assumed to be relatively straight-forward to classify, and proceeding to more complex characteristics. To be selected, characteristics further had to",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,1. reach sufficient intercoder-reliability in human coding (all characteristics satisfied this criterion; seeÿS2 Table);,,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,2. include characteristics deemed harmful as well as characteristics deemed preventive;,,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"3. ideally, be supported by some evidence for an association with suicides in previous studies.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Level 1. We assumed simple binary classification tasks that distinguish between two classes to be easiest, because they likely only depend on detection of specific keywords. A characteristic is either present (positive instances) or not (negative instances). We hypothesized that predicting such characteristics would be simple. We included the following characteristics:",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,Suicide death:ÿThe text includes information on one or several suicide death(s) as one of its focus areas. Stories about suicide death have sometimes been found to be positively associated with suicides [5].,,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,Celebrity suicide:ÿThe text reports on suicidal behaviour of a celebrity. The strongest evidence for harmful media effects on suicide comes from studies on the reporting of celebrity suicides [4].,,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Level 2. We assumed this to be binary classification tasks that distinguish between two classes that most likely depend on a rather diverse set of keywords, because different types of keywords may qualify an observation as a positive instance. This often applies for meta-categorical items, which code if one specific example for a type of content is mentioned, e.g., if the text mentions one of multiple possible prevention actions or warning signs. The class depends on what is present, but multiple different contents qualify as a positive instance. We selected the following characteristics for this category:",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Alternatives to suicide:ÿThe text reports on alternatives to suicidal behaviour. This might include a specific action taken by an individual instead of suicidal behaviour, or a suggestion or advice to seek help [9].",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Monocausality:ÿThe text gives a monocausal explanation for suicidal behaviour, that is, an explanation relying on exactly one possible motive, cause, or trigger.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Positive outcome:ÿThe item reports on a person experiencing a suicide attempt or suicidal ideation, and mastering his/her crisis, or showing or accepting life-affirming or -saving behaviour. The ending is positive [6?9].",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"There has not been any conclusive evidence about how these reporting characteristics are associated with suicide. Not all of them have been found to be associated with suicides in previous analyses investigating associations of specific media content characteristics and suicide.[6,ÿ13?15]. Nevertheless, such as the suggestion to highlight alternatives for readers and viewers who might be suicidal and to avoid portraying oversimplified reasons for suicide frequently receive specific consideration in media training and have therefore been included in this analysis [3].",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Level 3. Recent research has increasingly focused on the narrative of specific media stories rather than specific content characteristics. It has been hypothesized that the overall narrative might be more relevant to media effects than specific individual reporting characteristics [16,ÿ17]. Binary characteristics that require the detection of a narrative or the emotional connotation and meaning of a text may be more difficult than level 2 tasks, because the classification depends on how a topic is described in a text. We assumed the following characteristics to require this type of classification:",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Suicidal ideation:ÿThe text includes information about suicidal ideation as one of its focus areas. Suicidal ideation is the most serious type of suicidal experience mentioned, it is not accompanied by suicide or suicide attempts. Previous studies have found that stories about suicidal ideation in the absence of suicidal behaviours were associated with small decreases in suicides subsequently [6].",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Healing story:ÿThe narrative is about a healing story, i.e., the process of coping with adversity, hope, and recovery from suicidal thoughts and feelings [8,ÿ9].",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,There are several randomized controlled trials that indicate that healing stories and positive outcomes of suicidal crises have been found to be associated with reductions in suicidal ideation among vulnerable individuals [9].,,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Myths:ÿThe text enhances a common public myth about suicide (explicitly mentions or implicitly hints at one of nine defined myths). Enhancing means confirming/mentioning without denying it, if a myth is mentioned but debunked, this does not qualify [6].",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,One study has identified a positive association of portraying public misconceptions related to suicide with subsequent suicides [6].,,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Level 4. Classifying which of multiple classes a text focuses on requires distinguishing between multiple classes, and additionally depends on the extent to which a certain topic is discussed within a text in comparison to other topics (as opposed to the simple presence or absence of a topic). We assumed that two characteristics would be among the most difficult:",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Problem vs. solution narrative (4 classes):ÿIf the text focuses mainly on suicidal behavior or ideation as a problem, or shows how to find solutions and tackle the problem. If both aspects are described, we compared the emphasis on each in terms of the quantity of devoted text, but also investigated the prominence/framing of both. If they were balanced, we coded both; if neither was mentioned, neither.18",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,Main focus of the text (14 classes):ÿeither assisted suicide; suicide prevention advocacy; attempted suicide; suicide cluster; suicide death; healing story; suicidal ideation; legal issues related to suicide; mass murder suicide; murder suicide; policy; prevention; research; other [14].,,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"One study suggests that the framing of suicide as a problem versus solution might have a different effect on the audience. Although this study did not reveal any significant findings for suicide-related outcomes, it identified that individuals reading problem-focused items were more likely to think about concepts related to death and dying as compared to individuals reading prevention-focused media items.18ÿRegarding the main focus of the media item, some focus areas, most importantly healing stories, have been found to be associated with decreases in suicides subsequently [6]. Stories with a main focus on suicide death might be associated with increases in suicides [5]. The detection of the overarching main focus is of high relevance to suicide prevention research and is a complex task based on the sheer number of frequent main content categories. Note that the detection of the main focus is different from other aspects listed above in that the main focus is about the most relevant focal areas of all areas tackled in the text. For example, presence of a healing story is one of the twelve categories but also listed above as a separate characteristic under level 3. In the ?main focus? section, only healing stores that make the most important overall focus of the entire item would qualify. Any inclusion of a healing story, no matter which prominence it has within the specific media item, would qualify for ?healing story? in the level 3 task.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"We used Python 3.6 for our analysis, including the packages ktrain wrapper [18] for the deep learning library Tensor Flow Keras [19], and the sklearn library [20] for TF-IDF & SVM (see below). For links to the model, the code and data, see the data and code availability statement.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"We apply standard preprocessing strategies. see e.g., [21]. We converted the PDF files into text files using the Linux package pdftotext (https://pdftotext.com/). The original transcripts contained metadata about the radio/TV channel, the time of broadcast, a unique identifier (ID), and the transcribed broadcast. We first separated these metadata from the text using Python, and focused on analysis of the broadcasted text only for all following analyses. Input for BERT (one of the models we trained) is limited to a sequence length of 512 tokens, with remaining tokens being cut off, resulting in information loss. We compensated for this loss by training the word-frequency based models (see below) on the full sequences and comparing their performances to BERT. The majority of the 2519 transcripts in the final sample (83.2%) were shorter than 512 tokens, with a mean length of 316, the 95thÿpercentile at 944, and the 99thÿpercentile at 1411 tokens.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"The primary objective of machine learning is to make correct predictions on previously unseen data. To achieve this goal, the dataset is split into three distinct subsets: the training set, the validation set, and the test set. The training set is used for fitting the parameters of the model, the validation set to tune its hyperparameters and for evaluation of the model throughout development. The test set, finally, consists of data that the model has no access to during training, and is used to evaluate the model?s ability to generalize to new data. We divided the dataset of 2519 transcripts into a random training (64%), validation (16%), and test set (20%). Sklearn?s train_test_split was used for this purpose.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,We used different text representations and models to classify transcripts:,,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,This is a naive classifier that always predicts the most frequent class.,,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,Term-frequency-inverse document frequency (TF-IDF) represents text by assigning a weight to each word in a document (transcript) based on how often it appears in this document and how uncommon it is across all documents in a corpus. We used a small modification to the standard formula for TF-IDF by adding 1 in both the numerator and denominator. This change guarantees that every word appears at least once and prevents division by zero [22]:,,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Regarding the main focus of transcripts (Fig 1C), items focusing on suicide deaths were clearly the most frequent (25%). Advocacy (11%), murder-suicide (9.6%), and policy (11.9%) were also among the more frequent focus areas, while healing stories (3%), or suicidal thoughts (0.5%), were rarely the major focus. Given these low percentages, considering the absolute number of examples that models were trained on is crucial before interpreting performance scores. The median number and range of broadcast items for a particular main focus was 89 (min 8, max 381) in the training set, and 27.5 (min 2, max 121) in the test set. The most rarely mentioned main focus areas definitely have too few transcripts in the test set to allow a conclusion about their performance scores. These include assisted suicide (n = 10), suicide clusters (n = 7), healing stories (n = 14), and suicidal ideation (n = 2). Another group of main foci (attempted suicide, mass murder, prevention, research) had below 30 items in the test set, and should be interpreted only with great caution. Only performance for the most frequent main foci, including advocacy (n = 55), suicide death (121), legal issues (n = 38), murder suicide (n = 46), and policy (n = 57) will be reported in the text below. Still, caution is warranted in their interpretation.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Fig 2ÿillustrates that both Tf-idf with SVM and BERT clearly outperformed the naive majority classifier in all classification tasks. In the following, we therefore focus on BERT and Tf-idf with SVM performances.ÿFig 2ÿshows that their performances do not differ substantially for all classification tasks and metrics. In general (but not always), BERT reached higher precision, whereas Tf-idf with SVM reached higher recall for level 2 and 3 classification tasks. As F1-scores are a balance of these two, they are overall rather similar for BERT and Tf-idf with SVM.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Across all tasks, performance was comparable across the test and validation set, indicating that both models generalized well to new data (seeÿS5 TableÿandÿS1 Fig). For most classification tasks, scores in the two datasets were very similar. When generalizing to the test set, Tf-idf with SVM performance was lowest in the most complex task, determining the main focus of a transcript, achieving .60 instead of .70 for all metrics. BERT?s performance for main focus, although lower in the validation set, remained stable when generalizing to new data in the test set, showing that it learnt generalizable features even when training on multiple categories with few training samples for each. Interestingly, the precision of both models was also by .1 points lower in the validation set for healing stories, but recall was less affected (especially for BERT). This may indicate that healing stories in the training set were not yet representative of the different ways in which stories of healing and coping are described in broadcast media. All further performance scores (recall, precision, and F1) below are from the test set, which indicates model performance in new data not used during model training.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"We assumed classification tasks at level 1 would depend on detection of a few keywords, and thus be easiest. Indeed, Tf-idf with SVM and BERT reached classification performances above .80 for these tasks, and even above .90 for celebrity suicide. Performance scores for level 2 tasks, which we assumed to rely on detection of a larger and more varied set of keywords, were generally around .75, with some better exceptions. For instance, positive outcomes of a suicidal crisis were classified with very high precision (.90) by both models, and monocausal explanations were classified with high precision by BERT (.83). Tasks with level 3 difficulty, which we presumed to rely on the detection of emotional connotation and meaning, were not all clearly more difficult than level 2 tasks for the models. Especially healing stories were as well recognized as other level 2 features by both models (around 0.75 for all balanced metrics). Performance for texts that enhance myths about suicide was similarly good with Tf-idf with SVM (F1ÿ= .75), whereas BERT?s performance suffered from low recall (.57). Detecting suicidal ideation, which we had assumed to be a level 3 difficulty task, turned out to be more difficult (F1ÿ= .70) than determining the problem vs. solution narrative in a transcript (an assumed level 4 task). Despite having four classes and requiring a comparison between the emphasis on problem vs. solution, Tf-idf?s with SVM F1ÿwas .74 and BERT?s F1ÿwas .77.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"In sum, to reflect actual rather than assumed difficulty levels, some tasks from level 2, 3 and 4 could be reassigned to difficulty levels as follows, based on at least one model?s F1 score lying within the respective range:",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Level 1 (F1ÿ[.90, .95]): celebrity suicide",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Level 2 (F1ÿ[.80, .85]: suicide deaths, positive outcomes of a suicidal crisis (Tf-idf with SVM)",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Level 3 (F1ÿ[.73, .77]: alternatives to suicide, problem vs. solution, healing stories, enhancing myths (Tf-idf), monocausality (Tf-idf with SVM)",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,Level 4 (F1ÿ~ .70): suicidal ideation,,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,Level 5 (F1ÿ~ .58): main focus,,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"We report intraclass performance scores for the two better models (BERT and Tf-idf & SVM) in the test set inÿS4 Table, and illustrate recall and precision for all tasks inÿFig 3. Which of the two models was better varies across classification tasks, with mostly minor differences between the two models.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"We used the pre-trained BERT (Bidirectional Encoder Representations from Transformers) base-uncased-model [23], and fine-tuned a separate model for each classification task (i.e., characteristic). BERT is a deep learning language model of the transformer architecture by Google AI. It has 12 transformer layers, 12 self-attention heads, and a hidden size of 768. Its pre-training included a masked language modeling task: a randomly chosen 15% of words in a sentence are masked, and the model learns to predict them from the sequences of words before and after the mask. Additionally, BERT was pre-trained to predict if a sentence follows a given sentence.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"We fine-tuned the BERT-base-uncased model by adding a dense output layer that reduces the dimensions of the last layer to the number of labels per classification task, training all parameters simultaneously [24]. The different layers of BERT can capture different levels of semantic and syntactic information, with lower layers probably containing more general information. Therefore, we fine-tuned the layers with different decaying learning rates, following the approach of Howard and Ruder (2018) [25]. To find the maximal learning rate that is associated with a still-falling loss, that is, residuals (prior to the loss diverging), we ran a hyperparameter search.ÿS1 Figÿshows that learning rates up to 10e-5 are still associated with falling losses. We report results for BERT with a LR = 1e-5 and text length of 512, for the epoch with best results on the validation set out of maximally 12 epochs (this was usually around epoch 4?7).",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"We indicate precision, recall, and their harmonic mean (the F1ÿscore) for each classification task, all of which range from 0 to 1, with 1 indicating high performance. Precision is calculated by dividing the predictions for a specific category (for example, all transcripts labeled as mentioning a characteristic, such as suicide death) by all predictions (for example, those mentioning plus those not mentioning suicide death). It thus indicates how often the model?s label for this specific class is correct.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Recall reflects how many out of all true cases (e.g., transcripts mentioning a suicide death according to human labels) are detected by the model (e.g., labeled as mentioning a suicide death), and corresponds to the sensitivity of a medical test.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,The F1-score summarizes precision and recall as the harmonic mean.,,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Precision, recall, and F1-score are first calculated for each class of a variable (intraclass scores) and can then be averaged across classes to get mean performance scores per classification task (macro-averages).",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"We report macro-averages for all scores and all models in the validation and test sets. For intraclass performance scores, we provide scores for the best two models, TF-IDF and BERT. We do not report accuracy scores, because our dataset contains mostly characteristics with large imbalances in the sample size between different classes. In such cases, accuracy can be very high even if a classifier always predicts the majority class, and is therefore a biased estimate.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"The study was conducted in accordance with the Declaration of Helsinki. Because only published public media reports were used for this analysis, review from an Institutional Review Board was not required.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Fig 1ÿshows the proportion of transcripts per manually coded category for all characteristics, on average across the entire dataset.ÿS4 Tableÿreports the absolute frequency and proportion of transcripts per category separately for the training, validation, and test datasets. Since most texts only contain a few characteristics, the positive instance (the characteristic is present in the media item) is usually a minority class for all binary classification tasks (Fig 1A). Positive instances made up 6 to 14% of all transcripts for binary tasks (class size median = 51.0, min = 28, max = 284 in the test set), with suicide death mentions being the only exception (56.4%, n = 909 training set, n = 284 test set). For the type of narrative (Fig 1B), 57.9% (n = 884 training set, n = 277 test set) of transcripts described suicide predominantly as a problem, whereas 21.2% (n = 324 training set, n = 101 test set) focused on solutions, and 19.4% (n = 296 training set, n = 93 test set) emphasized both aspects equally.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"For most binary classification tasks (Fig 3A), both BERT and Tf-idf with SVM achieved very high performance scores (above .90) when predicting that a transcript did not contain a characteristic (precision for negative class) or detecting texts without the characteristic (recall for negative class). Predicting the less frequent presence of a characteristic (the positive class) was usually more difficult for both models (often between .50 and .60). Transcripts without the characteristic were the majority class by a large margin, except for suicide deaths, where texts mentioning a suicide were more frequent (seeÿFig 1A). Suicide death was also one of the two classification tasks where performance was similar for both classes (negative class: >.75, positive class: >.82). The only other such binary tasks is celebrity suicide, where models can achieve high performance by learning only the names of celebrities who died by suicide from April 1 2019 to March 30 2020, and thus do not require as many training examples.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"The pattern of high performance for the negative majority class, and low performance for the rare positive class, clearly indicates that the number of texts the models could learn from had a large influence on performance scores. Indeed,ÿFig 4ÿshows strong correlations between sample size per class and precision as well as recall for both models. For class sizes above 250, performance increases steeply and linearly; for lower class sizes, performance and class size are not clearly related. The scatter plots thus reveal that sample size can explain many of the differences in classification performances between classes, in particular for class sizes above 250. Performance and sample size for the negative category is lower for suicide death (the lonely red dot outside the red at n = 703) than all other binary tasks. For positive categories, performance scores for suicide death (blue dot at n = 909) is higher than for almost all positive categories in binary tasks. Only the positive class celebrity suicide (blue dots at performance around .85-.95) can be classified even better despite lower sample size (n = 209 in training set), likely thanks to celebrity names as highly indicative keywords.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Fig 4ÿalso reveals that sample size determines performance of multi-class tasks: Problem focus of broadcast items (cyan dot) has very similar sample sizes and performance scores as transcripts mentioning suicide deaths, although this task had four rather than two classes. Solution-focus performance (yellow dot) is much lower, as is the sample size of this class. Regarding class sizes below 250, it is interesting to note outliers with very high performance despite very low sample size: The upper left corner of some of the four panels inÿFig 4ÿfeatures some of the violet dots, indicating the main focus categories Assisted suicide, Murder suicide, Attempted suicide. All of these may be explained by highly indicative keywords, like ?attempt?, ?euthanasia? or ?murder?, and?homicide?. Finally, outliers in the left bottom corner of panels, include the main focus categories Suicidal ideation and Other. With a class size of n = 2 in the test set for the first, and n = 19 for the second, these scores cannot be interpreted. The same applies for the category ?Neither [problem or solution focus]? (dark green dot) with a precision of almost 1, as it had only n = 7 in the test set.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Pearson?s correlation coefficients between class size and performance scores are shown inÿTable 1. Correlations are reported across all categories, and for the subset of categories with a minimal number of 50 transcripts in order to exclude unreliable outlier performance scores which are based on very few labeled examples. This threshold of 50 in the training set corresponds to 15 in the test set. Applying it excludes the categories problem vs. solution focus = neither, and main focus = assisted suicide, cluster, healing story and suicidal ideation. Removing these unreliable performance scores results in correlations around .7?0.8 for both models and metrics.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Exceptions from the tight sample-size performance correlation may indicate which aspects of a characteristic or model additionally influence performance. A first set of exceptions are tasks which can likely be solved with a few indicative keywords, including celebrity suicides (attempted, assisted and murder suicide). Possibly, the high precision (>.80) of both models for the positive outcome of a suicidal crisis, despite the small number of positive cases to train on (n = 118), could also be explained by indicative keywords accurately identifying this characteristic.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Further, an interesting pattern across positive classes in binary tasks (except suicide death) is the generally lower recall of BERT (around .40), but often higher precision. For example, Tf-idf with SVM had a recall advantage over BERT was .22 for monocausality, .17 for alternatives to suicide, and even .40 for enhancing myths (.40). This suggests that the recall metric of BERT was especially sensitive to small class sizes, while precision did not suffer as much. BERT?s precision scores were most clearly better (by .15-.20) than Tf-idfs with SVM for moncausality, suicidal ideation and enhancing myths. Possibly, these are tasks where connotation of words, their context, and syntax matters more than for other tasks.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Finally, classifying the main focus of the item was the task with the most classes and the most severe class imbalances. Many categories had too few example transcripts to allow interpretation of their performance scores. Of more frequent categories, transcripts focusing on murder suicides were classified quite well (BERT F1ÿ= .8, Tf-idf with SVM F1ÿ= .83), with Tf-idf with SVM being better for precision, possibly because a few keywords (e.g., ?homicide?) were sufficient to label these correctly. Reporting focusing on suicide death was classified similarly well (BERT F1ÿ= .76, Tf-idf with SVM F1ÿ= .67), with BERT being better at detecting many cases. This result demonstrates that at least well-defined main foci of a text, with sufficient training examples, can be classified reliably. For broader main focus topics like Policy, performance was very similar, but only with BERT (F1ÿ= .76, Tf-idf with SVM F1ÿ= .62). For such more complex topics, the deep learning model might provide an advantage. Finally, a main focus on Advocacy was also classified moderately well (BERT F1ÿ= .72, Tf-idf with SVM F1ÿ= 0.67), with similar precision and recall. In general, class imbalances as seen here are a common issue in suicide prevention, as texts featuring each characteristic are much rarer than texts without the charateristic. We tested the effect of data augmentation techniques for some of the classification tasks.33ÿThe augmentation techniques did not consistently improve or otherwise change the performance scores on any of the classification tasks, suggesting that artificially augmenting rare data categories did not improve the performance of our models.33",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"The current study evaluated automatic labeling methods to categorize specific suicide-related content in broadcast media (i.e. radio and TV), as well as online media with machine learning. Based on a comprehensive annotation scheme for suicide-related content, we selected some content characteristics, aiming to include various classification types and difficulty levels that are relevant based on media guidelines for the reporting of suicide [3]. We then tested the ability of different machine learning models to accurately classify these characteristics, which is relevant for both research in the area of media effects as well as for surveillance efforts of suicide-related broadcast media content.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Overall, our results demonstrate that machine learning models can in principle achieve very satisfactory results for classifying various types of characteristics in suicide-related broadcast media content, including characteristics we estimated to be simpler and more difficult, as well as multi-class characteristics. This adds to earlier work that demonstrated the efficiency of machine learning in classifying social media content [11] and relevance for prevention [26]. In the current study, both the word frequency based representation Tf-idf with a linear SVM classifier as well as the deep learning model BERT were clearly better than the naive majority classifier across all tasks. However, neither BERT nor Tf-idf with SVM were clearly better than the other model. Both models also achieved similar performance in the test and validation set for almost all tasks, suggesting they generalized well to new data not seen during training.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"For certain characteristics, our classifiers achieved high classification performances. The primary factor explaining these high performances, as well as the difference in performance across classification tasks, seemed to be the number of labeled examples for models to train on. Instead, if a classification required recognizing the narrative or the emotional connotation and meaning of a broadcast item, or the mere detection vs. the extent to which a characteristic was described, seemed less important. Given the importance of sample size, sound conclusions are possible only for categories that include a sufficient number of broadcast items. The first of these are all negative classes in binary tasks (a characteristic was absent), which were predicted and detected with scores above .90. This suggests that about 1250 examples may be enough to achieve highly reliable machine learning classification for suicide-related media content. Positive classes (a characteristic is present) were usually the minority class, with below 250 training samples, and their performance scores thus low (F1ÿ= .4-.6) Nevertheless, the high performances for predicting the absence of these same binary characteristics suggest that machine learning models can in principle achieve very satisfactory results. The only required prerequisite seems to be more training examples for broadcast items that mention a characteristic, that is, the positive class in each task.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"A second characteristic that could be classified with high precision and recall was suicide deaths reports, where sufficient examples for the negative and positive class, allowed for scores above .80. This is likely much better than what keyword searches for suicide reports can achieve, which have the problem of mixing heterogeneous types of content containing the same keywords, together. Niederkrotenthaler et al., 2020 noted accordingly that most of the research about associations of suicide reporting and subsequent suicides was based on keyword searches only, mixing together entirely different types of narratives and contents and ignoring their potentially different meaning and effects [4].",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"A third characteristic classified with high precision and recall (>.90) was the problem focus of a broadcast item. This is particularly encouraging, since problem focus was one out of four classes, and requires detecting what a text focuses on, rather than just whether a characteristic is present. This suggests that many characteristics of similar complexity can be recognized with machine learning tools, as long as sufficiently large training samples can be put together. Good classification performance for suicide death as one out of 14 possible main foci of broadcast items (BERTÿF1ÿ= .76) further underlines this encouraging finding. It demonstrates that even 14 class classification problems can be solved reasonably well with as little as 400 training examples. A fifth case, solution focus, is a similar case: with only around 300 training samples, precision was around .70 in this four-class classification problem. In sum, the good performance for several complex characteristics, that require predicting which of many possible areas is the focus of a text, suggest that training models on larger samples is a very promising avenue for future research.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Regarding the featuring of a ?healing story?, which have been at the forefront of the discourse of positive media potentials, ie the Papageno effect [6?9], the sample size in the current sample (there were n = 190 total healing story transcripts included) was comparable to a previous study conducted with Tweets [11]. For tweets, precision and recall using tf-idf with SVM were 0.44 (precision) and 0.64 (recall) in a 6-category classification task. For BERT, precision was 0.76 and recall was again 0.76 [11]. In the current study, sample size really determined performance (category yes with precision and recall of ~0.5 vs. no 0.97). The Twitter study suggests that having more balanced classes can improve performance for BERT for such small sample sizes.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"For other classification tasks, e.g. suicidal ideation, comparisons with other samples are much more difficult, particularly because of the nature of the text analyzed. Several studies have investigated suicidal online communication and have applied machine learning particularly in order to differentiate suicidal from non-suicidal users [29?31]. Many of these models performed better as compared to the present model, which is likely due to their considerably larger sample sizes positive for suicidal ideation as compared to the present analysis.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"A few points are interesting to mention regarding a comparison of Tf-idf with SVM and BERT results. Overall, we observed no clear advantage of BERT over Tf-idf with SVM. In contrast, BERT clearly outperformed Tf-idf with SVM when predicting similar suicide-related characteristics in tweets, that is, very short texts [11]. Possibly, the deep learning model?s capacity to predict the meaning of each word from the specific context it occurs in may be less crucial when working with longer content types, like the current broadcast media items. Here, we generally observed lower recall scores for BERT than Tf-idf with SVM for the positive class in all binary tasks where there were few training examples for the positive class (all except suicide death). This shows that the frequency of keywords is a useful feature to detect more instances when training sample sizes are small, and that especially the recall (the detection rate) of the deep learning model is sensitive to small class size (as here for positive classes).",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Yet, at the same time, BERT often still achieved higher precision than Tf-idf with SVM for these rare positive classes. Compared to Tf-idf with SVM, BERT?s precision was most clearly better (by .15-.20) for moncausality, suicidal ideation and enhancing myths. This may hint that connotation of words, their context, and syntax matters more for these than other tasks, possibly because such descriptions are more subjective and nuanced, and simple word frequencies cannot capture this as well. Finally, BERT seemed to generalize better in the multi-class task of detecting the main focus of a text. Possibly, the ability of deep learning models to rely less on specific features of datasets helped BERT to generalize better for complex and multi-class classification tasks like detecting the main focus of a text. Taken together, the potential advantages of deep learning over word-frequency based models could not fully play out given the size of positive classes in our training data set. Still, they were recognizable in generalization abilities when training on few samples for multiple classes, and in higher precision for rarer characteristics that may require detecting nuance and changes in the meaning of words in particular contexts.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Independent from sample size, some types of classifications were indeed easier than others as we had assumed. Celebrity suicide could be classified very well (F1>.90) despite low positive case examples. The main focus categories assisted suicide, attempted suicide or murder-suicide are further such examples, very reasonably high performance (F1>.80) was possible with very low training sample sizes. However, at least in some of these cases, machine learning does not provide a substantial advantage over keyword searches, since they are easily identified with a few highly indicative keywords (names of celebrities + suicide, euthanasia, suicide bombing, attempt + suicide etc).",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"From a suicide prevention standpoint, the current machine learning approach developed in this work is particularly relevant when it comes to the assessment and categorization of large quantities of media items that would normally be retrieved with keyword searches only. As noted previously, searches based solely on keywords have the considerable disadvantage of mixing together entirely different narratives such as media items about celebrity suicide and suicide prevention items or items about hope and recovery [4]. The evaluation metrics of the present work clearly show that the present approach is superior to that type of keyword searching. In particular, the current findings appear helpful to make differentiations regarding characteristics that have been sufficiently represented in the current media items. This includes the determination A) if the item is about suicide reporting or not; B) includes information on celebrity suicide vs. not; C) the absence of any of the binary characteristics that were assessed (but not necessarily their presence), D) if the focus is placed on the problem or prevention of suicide; and E) if the main focus is about suicide death.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Although these categorizations do not capture all of the characteristics listed in media guidelines, they are of high relevance for suicide research and prevention as they allow for a more fine-grained categorization of texts as compared to simple keyword searches.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"Although our dataset contains a comprehensive number of media items, the size of the training dataset for specific characteristics remains a limitation of our study, as it crucially determines the performance of machine learning, in particular deep learning model [27,ÿ28]. Especially potentially protective characteristics are not often mentioned in the media, which makes achieving high sample sizes for these characteristics challenging, but also the most promising avenue for future research and prevention efforts. This will require collecting broadcast items over longer time horizons or larger regions than our study, which included a time period of 12 months in two US states. Alternatively, different existing datasets could be merged. Care should be taken to not generalize from our results to data from other regions and time periods, without first evaluating the performance of our machine learning models there. Furthermore, we have only assessed a small number of media characteristics, far below the 39 characteristics listed in current media recommendations for suicide reporting [3]. Yet, we included several classification types, including both more information related and more subjective ones. Given that performance seemed mostly related to class size rather than the type of characteristic, it seems plausible that machine learning methods based on sufficiently large samples are effective tools for automatically labeling suicide-related content. Beyond the methods used in this paper, there are other standard machine learning approaches (e.g., naive bayesian classifier) that we have not used in the present study. The approaches selected were based on a master?s thesis conducted by one of the authors (HB) [32]. In the thesis, regarding traditional natural language processing, the nave classifier as a trivial model and Bag.of-Words were used in addition to Tf-idf with SVM. Both of these approaches, however, were far too simplistic to capture the complexity of the present tasks.",,,,,
A machine learning approach to detect potentially harmful and protective suicide-related content in broadcast media,"The current work makes a relevant contribution to suicide prevention research in that it investigates and confirms, for the first time, that machine learning can be successfully applied to assess prevention-relevant characteristics in broadcast media items. This included not only relative straight-forward but also more difficult characteristics of suicide-related media content such as the solution or problem focus of a media item. Recent studies about media content characteristics and their association with suicides have been limited in terms of number of media items included due to the huge amount of resources needed to assess media items. Similar limitations apply to the screening and surveillance of suicide-related media content that would allow a more pro-active approach to prevention such as the early reaching out to journalists and media professionals in instances of harmful reporting. Although this work does not replace human coding, it provides a strong basis for the extension to other media characteristics of interest, and subsequently, for the automatic assessment of large numbers of media items and their possible associations with behavioral outcomes of interest. Taken together, the current results highlight the relevance of machine learning approaches for future media studies related to suicide and prevention.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Several (inter)national longitudinal dementia observational datasets encompassing demographic information, neuroimaging, biomarkers, neuropsychological evaluations, and muti-omics data, have ushered in a new era of potential for integrating machine learning (ML) into dementia research and clinical practice. ML, with its proficiency in handling multi-modal and high-dimensional data, has emerged as an innovative technique to facilitate early diagnosis, differential diagnosis, and to predict onset and progression of mild cognitive impairment and dementia. In this review, we evaluate current and potential applications of ML, including its history in dementia research, how it compares to traditional statistics, the types of datasets it uses and theÿgeneral workflow. Moreover, we identify the technical barriers and challenges of ML implementations in clinical practice. Overall, this review provides a comprehensive understanding of ML with non-technical explanations for broader accessibility to biomedical scientists and clinicians.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,The online version contains supplementary material available at 10.1186/s13195-024-01540-6.,,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Alzheimer?s disease (AD), the major cause of dementia, is a progressive neurodegenerative disorder that predominantly affects older people [1]. The accumulation of amyloid-beta (A?) and formation of neurofibrillary tangles marked by tau phosphorylation in the brain are the key hallmarks of AD [1]. Clinically, the disease can be divided into three stages: 1) preclinical AD i.e., cognitive unimpaired (CU) people with amyloid accumulation in the brain, 2) prodromal or mild cognitive impairment (MCI) and 3) Alzheimer?s dementia (ADem) [1]. This disease trajectory can vary between individuals, and preclinical AD can occur 15?20ÿyears prior to ADem [1].",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Observational longitudinal dementia datasets have been collected in diverse age groups across several (inter)national dementia cohorts (Tableÿ1), providing rich information that enhances the granularity and scope of data science research. These datasets encompass a broad spectrum of information including biomarkers, genetics, neuropsychological evaluations, neuroimaging, omics, etc. (Tableÿ2). Traditional statistical methods, constrained by rigid assumptions and a limited ability to handle complex interactions have shown limitations in processing these multi-modal datasets, prompting an exploration of more adaptive and comprehensive techniques such as machine learning (ML) [2]. ML is a class of algorithms that enable computers to analyze data and make decisions by identifying patterns specific to tasks [3]. These techniques can detect subtle patterns and trends in large datasets, significantly enhancing theÿeffectiveness and productivity of data-driven research. In addition,ÿML has already proven successful in trackingÿdisease, including market-ready products (e.g., Vivid E80 [4]) and FDA-approved devices (e.g., Apple's Atrial Fibrillation History Feature [5]).",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"The development of anti-A? monoclonal antibodies, such as donanemab [40] and lecanemab [41], has shown promising results in reducing cognitive decline in early treatment scenarios. This underscores the importance of timely intervention.ÿML can enhance early detection accuracy and personalized stimulation by determining theÿmost effective timepoint to adminster antibodies in the right patients, thereby maximizing their therapeutic benefits. However, it must be noted that while ML can aid in identifying individuals likely to benefit, our global health systems are not fully equipped to provide these early interventions. Monoclonal antibodies require costly monitoring for brain bleeds, which presents challenges not only in funding the necessary scans but also in accessing scanners within a reasonable distance for patients. A recent study showed that novel biomarkers including microRNAs, metabolites and proteins have been identified using ML approaches [42]. Furthermore, it has been demonstrated that patient-level simulations by ML can predict disease trajectories [43], estimate the likelihood of transitioning from MCI to ADem [44] or even successfully forecast the time-to-event outcomes survival probability for MCI participants [45].",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Here we provide a comprehensive overview of ML application in dementia (ML-dementia) using non-technical terms to enhance accessibility to a broad readership. Specifically, we evaluate ML from a historical perspective and discuss typical workflows, successful applications within 5ÿyears and challenges?highlighting the evolving utility of ML in biomedical research to enhance diagnosis and management of dementia.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"ML includes a variety of algorithms designed to learn from data to meet a predefined goal, such as identifying patterns or making predictions about future states. The model updates its settings or '(hyper-)parameters' based on feedback from performance metrics known as 'loss functions', which assesses the accuracy of the model's predictions compared to actual outcomes. Once the model is optimally trained, it can use real-world data to achieve the predefined task [46]. ML techniques are primarily divided into three categories: unsupervised learning, supervised learning, and reinforcement learning, with the first two being more commonly used in dementia research. These categories are discussed in detail below and their advantages and limitations are summarized in Tableÿ3.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Supervised learning explores the relationship between input features and the corresponding target outputs, also known as labels. In dementia research, supervised learning can be further categorized basedÿonÿthe predictive target, for instance,ÿclassification tasks dealing with categorical labels (e.g., ADem vs CU), regression tasks handling numerical labels (e.g., Clinical Dementia Rating?Sum of Boxes [CDR-SB]ÿand Mini-Mental State Examination [MMSE]). Once the model is trained, it can then make predictions on unlabelled data of the same input.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Unsupervised learning operates on unlabelled data, which focuses on uncovering patterns or relationships without considering any predefined labels. This approach includes 1) clustering tasks such as identifying subtypes of dementia based on biological, neuropsychological, and demographic features and 2) data compression such as using principal component analysis to simplify and summarize complex data.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Reinforcement learning (RL) is used to learn and improve decision making by continuously receiving feedback through interaction with external conditions and observing the response. This approach is less commonly used than the supervised and unsupervised methods. RL can be classified as model-free and model-based types; model-free RL operates without a predefined model, while model-based RL is preferred for incorporating domain knowledge (i.e., existing clinical knowledge). RL could mainly be employed to simulate and predict cognitive states, as well as to estimate the probability of transitioning between cognitiveÿstates.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Traditional statistical methods include a hypothesis-driven approach and statical inference (i.e., generalizing findings from a subset of data to a large population). Such approach relies on strong assumptions about the data, e.g., the data follows aÿnormal distribution to fit existing theoretical models [50]. However, these traditional statistical methods often encounter practical challenges in complex real-world scenarios, as the assumptions made may not be satisfied in clinical practice [2]. In contrast, ML adopts a more data-driven approach with minimal assumptions, and it concentrates on prediction rather than inference [2]. However, statistical models and ML techniques sometimes overlap; e.g., both methods often employ linear and logistic regression models to meet statistical goals or to achieve simple linear predictions in ML contexts. It must be noted that ML possesses the capability to process and analyze extensive and complex datasets, such as omics data, effectively uncovering patterns or capturing interactions that might be omitted or overlooked by the traditional statistical analysis [2]. Therefore, ML is often beneficial to clinical research, where data is inherently multidimensional with a diverse array of variables.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Prior to the year 2000, research primarily focused on clarifying the genetic and biochemical foundations of AD, with significant emphasis on the roles of A? and familial genetic mutations [51]. In the subsequent decade (2000?2010), scholarly attention shifted towards differentiating AD from CU mostly using ML model such as support vector machines alongside brain imaging techniques [52]. In the following five years or so, researchers focused on predicting clinical progress in MCI patients using multi-kernel support vector machine (SVM, a ML model) with longitudinal data from magnetic resonance imaging (MRI) and positron emission tomography (PET) [53].",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Since then, ML or deep learning, a subset of ML that uses neural network to simulate the learning process of human [54], has been used to classify disease subtypes and stages. Similar to how the human brain employs interconnected neurons for information processing, neural networks in ML use nodes (artificial neurons) and their interconnections to mimic the brain's structure and functionality. This design facilitates pattern recognition and decision-making. For instance, Ramzan et al. [55] utilizes resting-state function MRI with Residual Network architecture to classify ADÿinto: CU, significant memory concern, early-MCI, MCI, late-MCI, and ADem. In more recent years, the adoption of advanced deep learning architectures, such as time-series models has expanded. For example, hybrid deep learning frameworks based on Bidirectional Long Short-Term Memory models leverage multimodal data (i.e., MRI, PET, and neuropsychological evaluation) to enhance the classification of CU and early MCI [56]. A timeline summarizing the use of ML in dementia research is presented in Fig.ÿ1.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"The general workflow to build and apply the ML-dementia model is summarized in Fig.ÿ2, which can be separated into six key steps, including 1) Intended application, 2) Data selection, 3) Data pre-processing, 4) Model Construction, 5) Model evaluation, and 6) Maintenance. We have provided a detailed description for each step in Supplementary Material ? ML workflow.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Several observational dementia datasets have been used for ML model construction and validationÿ(Tableÿ1), such as the Australian Imaging, Biomarker and Lifestyle (AIBL) study [57] and the Alzheimer's Disease Neuroimaging Initiative (ADNI) study [13]. These datasets are often longitudinal, involving thousands of participants, spanning several decades with regular follow-ups, and some are still actively recruiting. These datasets feature a diverse range of participant demographics, typically focusing on middle-aged adults from various racial,ÿethnicÿand educational backgrounds. Each dataset has a distinct focus. For instance, Open Access Series of Imaging Studies [OASIS] [16] concentrate on brain imaging, while the Religious Orders Study and Rush Memory and Aging Project [ROSMAP] [9] aim to understand aging processes. Data collection and testing within the same dataset can vary depending on the project's phases or aims. For example, ADNI adapts its data collection strategies across five phases, and OASIS divides its datasets to address specific research goals. While most datasets listed in Tableÿ1ÿprimarily address AD, others such as the UK Biobank [15] and the Framingham Heart Study [6], provide a broader insight across various health outcomes within larger cohorts.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"A variety of data/sample collection methods have been employed in these studies, which can be categorized as per their level of invasiveness (Tableÿ2). Invasive methods, such as cerebrospinal fluid collection through lumbar puncture, are commonly used to obtain biomarkers (A?ÿand tau) and markers of neurodegeneration [1]. The AT(N) 2018 framework [58], categorizes the progression of AD into different stages based on specific combinations of these biomarkers (Tableÿ4). Compared to lumbar puncture, venous blood collection is considered less-invasive, and often used for biomarker research and omics (genomics, transcriptomics, proteomics, and metabolomics) analysis [59]. Non-invasive methods such as MRI and PET are employed to study brain structure and A? levels [1]. Neuropsychological evaluation (Tableÿ5) are also non-invasive, which are quantitative measures of cognitive functions across various disease stages (Tableÿ6) [60]. Demographicÿinformation, lifestyle data andÿmedical history are often self-reported or collected using questionnaires and are used as baseline predictors in the majority of studies [61].",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"The following section reviews ML models using input data collected via non-/moderately invasive approaches. These data include demographics (age, gender, ethnicity, family history), medical history, neuropsychological evaluation, blood (omics, biomarkers), and brain imaging. Studies published between 2019 and 2024 were selected based on uniqueness in methodology, which is summarized in Tableÿ7ÿand Fig.ÿ3.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"AD is the major cause of dementia, followed by vascular dementia, frontotemporal dementia, and dementia with Lewy bodies [90]. Accurate differential diagnosis is important for clinicians to offer the most suitable care options to the patients [91]. Recent studies utilizing ML and deep learning models have shown relative high accuracy in differential diagnoses by incorporating metabolomics [67] and neuroimaging [64?66] (Tableÿ7A). For instance, Qiang et al. [67] established the associations between 249 metabolites and type of dementia (all-cause dementia, ADem, and vascular dementia) using UK Biobank data. The study employed Cox proportional hazard models and light gradient boosting machine algorithms to generate a metabolic risk score. This score when combined with demographic and neuropsychological test scores achieved an AUC of 0.85 (AUC approaching 1 indicates excellence in discrimination) for the classification of different types of dementia. By employing neuroimaging data, Castellazzi et al. [92] used the adaptive neuro-fuzzy inference systems to distinguish between ADem and vascular dementia. This achieved over 84% accuracy using a combination of features from resting-state functional MRI and diffusion tensor imaging. Moreover, another independent research group [65] achieved?~?80% accuracy in differentiating dementia with Lewy bodies from ADem using structural MRI data and a residual neural network. Finally, Nguyen et al. [66] introduced an innovative approach, by integrating 3D U-Nets with a multi-layer perceptron classifier to discern ADem from frontotemporal dementia through structural MRI images, attaining an AUC of 0.94.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Although these studies achieved high diagnostic accuracies (~?80%), only Nguyen et al. [66] validated their model using an external dataset. This raises concerns about the generalizability of these findings and suggests that potential cohort bias cannot be ruled out. It is crucial to further validate these models prior to clinical trial and implementation. Moreover, these studies appear to focus on the differential diagnosis between vascular dementia and ADem (Qiang et al. [67] and Catellazzi et al. [92]) and between frontotemporal dementia and ADem (Nguyen et al. [66]). Future research could explore the possibility of differentiating multiple subtypes of dementia using a single model. Furthermore, all these studies, except Qiang et al. [67], leveraged advanced imaging techniques to capture intricate details of the brain. The reliance on high-resolution imaging data necessitates substantial resources, making it challenging to implement the new technology in clinics.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Predicting disease stages using either a binary classification (CU vs ADem, CU vs MCI?+?ADem, CU vs MCI, MCI vs ADem) or CU/MCI/ADem classification is commonly used in ML-dementia. These typically employ omics data [69,ÿ74], neuropsychological evaluation [70], and neuroimaging [68,ÿ70,ÿ71] (Tableÿ7B). Mahendran et al. [74] demonstrated that deep belief network-based approach (accuracy 82%) outperformed SVM (accuracy 78%) and Nave Bayes (accuracy 76%) in binary classification of CU and ADem using their multi-omics data. In another study, Wang et al. [69] utilized six differentially expressed metabolites, three metabolic pathways and a random forest model to differentiate the MCI?+?ADem group from CU, and they achieved an AUC of 0.77. MRI data have also been employed to facilitate disease classification. For instance, Naz et al. utilized only structural MRI data [71], and achieved a classification accuracy of 99.27, 98.89 and 97.06% for MCI/ADem, ADem/CU, and MCI/CU, respectively. To generate more complex models, multimodal data (e.g., demographic, medical history, brain volume, neuropsychological evaluationÿandÿgenetics) have been integrated, such as convolutional neural network model for disease stage classification. For example, using multimodality, Venugopalan et al. [70] achieved a classification accuracy of 83% for CU, 74% for MCI and 85% for ADem.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"We noted that model development in most of these studies were challenged by an imbalanced dataset, with AD and MCI often being underrepresented compared to CU individuals due to disease prevalence. Interestingly, Naz et al. [71] manually balanced the dataset by eliminating some of the CU participant data (CU?=?95, MCI?=?146, ADem?=?95). However, this approach reduces the overall dataset size, possibly leading to the model not capturing all critical features for accurate classification [93]. Model overfitting is also expected from using such a small dataset [94]. Future studies could focus on enriching AD and MCI participant data; however, this is currently less practical due to a lack of harmonized datasets that allows data pooling. An alternative approach is to intentionally recruit MCI and ADem participants, as done by Kwak et al. [77]; however, these data may be less suitable for studying the onset and progression of AD. Another major issue is that the classification accuracy is usually less satisfactory for differentiating MCI from AD, as has been reported by Wang et al. [69] and Naz et al. [71]. Using multimodal data could be a potential solution [70], nonetheless, future studies are required to confirm whetherÿtheir observations areÿdataset dependent.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"The prediction of future disease states or neuropsychological outcomes can be achieved using classification and regression models, as well as simulating disease trajectories using more complex deep learning models (Tableÿ7C). Most classification models categorize MCI-to-dementia progressors and non-progressors. For example, Rye et.al. [72] achieved a 75% of accuracy in predicting whether MCI participants progress to dementia using a random forest model, where neuropsychological evaluation, hippocampal volume and Apolipoprotein E (APOE) genotype were used as input features. An ensemble model was employed by Mofrad et al. [79] for such prediction, where MRI and neuropsychological evaluation were used to achieve a 77% accuracy. Regression models often employ neuropsychological evaluation, such as CDR-SB, ADAS-Cog, and MMSE [77,ÿ78,ÿ82], to estimate disease severity over time. For example, Lian et al. [78] employed a multitask weakly-supervised Attention Network, which is a regression model that built on structural MRI data collected from CU, MCI progressor, MCI non-progressor, and ADem participants to predict 3-year future CDR-SB, ADAS-Cog, and MMSE scores. This model has achieved promising results, with a root-mean-squared error of 1.5, 5.7, and 2.2 for each score, respectively.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"For disease trajectory simulation, Bucholc et al. [82] has combined unsupervised and supervised learning techniques, where participants were categorized by their cognitive score trajectories (stable vs deterioration over 2?3ÿyears). The trajectories of each category were then analyzed using random forest, support vector machine, and linear regression (supervised). This approach achieved a?~?90% accuracy in predicting seven different neuropsychological test scores over 1-year and 2-year intervals, from the correspondent baseline scores. A more complex model, Long Short-Term Memory Recurrent Neural Networks, was used by Mukherji et al. [81] to simulate the trajectory for five neuropsychological tests. This model achieved a prediction accuracy of 85 and 83% for 2-year and 4-year, respectively. Recent work has also focused on dynamically predicting the risk of dementia onset. This is typically achieved using a Cox model, combined with functional data analysis to model longitudinal neuropsychological outcomes. For example, Jiang et al. [76] utilized the functional ensemble random survival forest to characterize the joint effects of neuropsychological evaluation in predicting disease progression, specifically to predict the time to AD conversion in individuals with MCI and to provide personalized dynamic predictions. This approach achieved an AUC of approximately 0.90 over an average follow-up period of 31ÿmonths. Similarly, Zou et al. [83] proposed a multivariate functional mixed model framework to simultaneously model multiple longitudinal neuropsychological outcomes and the time to dementia onset, achieving an integrated AUC of over 0.80, with the mean time to visit being 1.12ÿyears.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Mukherji et al. [81], Bucholc et al. [82] and Lian et al. [78] predict disease progression over a fixed interval, while Jiang et al. [76] and Zou et al. [83] simulate disease progression. It should be noted that simulation methods introduce higher variance and complexity compared to fixed interval models [95]; however, they can predict disease status at any time point, whereas fixed interval models can only predict disease status at the end of the interval. Different models may suit varyingÿclinical needs or patient expectations, each balancing its own advantages and limitations. In addition, these complex models are prone to overfitting [94], capturing noise that does not generalize to unseen data. This issue could be exacerbated in studies where the training datasets are relatively small, such as that forÿJiang et al. [76] (165 MCI stable, 137 MCI progressor). We have also noted that most of these models, except Lian et al. [78], involve various neuropsychological tests, which often differ between studies. This makes it challenging for external validation and comparison between different models. Future studies should consider developing models based on neuropsychological tests that are routinely used in clinics for easier evaluation, validation and potential implementation.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"ML models have shown promise in predicting AD biomarkers with reasonable accuracy (Tableÿ7D). For predicting A? and p-tau levels in the brain, the problem is often simplified into a binary classification, e.g., normal vs high or negative vs positive. Langford et al. [85] employed the extreme gradient boosting algorithm, a scalable tree boosting model to predict A? PET positivity (standardized uptake values ò 1.15) from demographics (age, education, genderÿand family history), four neuropsychological tests and APOE genotype., An AUC of 0.74 was achieved. Palmqvist et al. [84] used plasma A?42/ A?40ÿratios, APOE genotype, and neuropsychological tests for a logistic regression with a lasso penalty model, and achieved an AUC of 0.83. In contrast, Lew et. al. [88] employed a logistic regression model for binary prediction of PET results (high versus low A? or p-tau) using MRI and other data (e.g., demographic, APOE genotype, neuropsychological tests and hippocampal volumes etc.). This resulted in an AUC of 0.79 for A? and 0.73 for p-tau. Using a seven-layer neural network, 3,635 plasma proteins, age and APOE genotype for the same prediction, Zhang et al. [89] achieved a lower AUC score for A? (AUC?=?0.78) and p-tau (AUC?=?0.67). Their performance is relatively lower than the other studies, which could possibly be due to high feature-to-sample ratio (3000 proteins in 800 participants), which can complicate model training and validation.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Notably, aÿuniversally accepted threshold to determine binary classificationÿis lacking. For example, Langford et al. [85] used a threshold of 1.15, while Palmqvist et al. [84] adopted a threshold of 0.738. Whether this would have impacted the prediction performance of the model is unclear. Future studies should consider standardizing this threshold to enable comparisons between models. Another issue with these studies is that the datasets used for model training are relatively small (e.g., 300 participants for Palmqvist et al. [84]ÿand 800 participants for Zhang et al. [89]), possibly due to cost constraints associated with PET and MRI. Research funding bodies could play a role in encouraging (inter)national collaboration and data sharing, as well as endorsing standard data formats (especially for those high-cost experiments) to increase the size of datasets for more robust results.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"ML has been applied to clinical data analysis for more than two decades, and its widespread adoption in clinical research and healthcare has noticeably accelerated. This section will discuss the technical barriers, and the anticipated challenges and potential solutions to applying ML in clinical practice for dementia (summarized in Tableÿ8).",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Given the complex set up of longitudinal studies and heterogenous disease pathology, missing values, outliers, data imbalance are inevitable. Missing data is often due to incomplete responses, data collection errors, technical issues and participant withdrawal [96]. Data scientists either disregard participants with missing data or use imputation techniques (e.g., mean imputation, multiple imputation by chained equations, etc. [97]). Outliers normally result from errors from record, measurement or misclassification. Statistic techniques, such asÿz-scores and interquartile range or box plot are used to detect outliers. Once identified, common approaches involve removing outliers, adjusting into specific percentile, or applying transformations to reduce the skewness of the data distribution [98]. Data imbalance is a commonly encountered issue for dementia dataset, as MCI and ADem occur in a smaller population compared to CU. When MCI/ADem cases are significantly underrepresented compared to CU, it can lead to a biased model performance, where ML models trained on imbalanced data may prioritize the majority and struggle to accurately predict the minority [99]. To address this issue, resampling techniques such as Synthetic Minority Over-sampling Technique [100] can be employed.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"The quality of clinical data used to train ML models directly impacts the soundness of the model. The diagnoses are performed by clinicians and neuropsychologists [101,ÿ102], which can sometimes introduce human errors into the dataset. This is because diagnosis is complicated by that 1) preclinical AD is difficult to detect [103], 2) MCI can be misclassified [104], and 3) vascular dementia, Lewy body dementia, and frontotemporal dementia are sometimesÿmisdiagnosed as ADem [105]. Moreover, some neuropsychological tests are influenced by practice effects [106] (repeated testing can artificially improve performance over time), and education background [107] (poor performance for individuals who are less educated), potentially skewing results. Furthermore, the trajectory of dementia varies significantly among individuals due to the complex interplays of age, genetics, sex, and other comorbidities [108]. Some individuals may experience a gradual decline in cognition over many years, while others show rapid deterioration. Many longitudinal studies employ an ""up-to-interval"" method [75], classifying participants into CU, MCI, ADem, and non-ADem within a specified follow-up period. However, this approach often falls short in capturing the disease trajectory of individuals experiencing gradual cognitive decline. In addition, older participants are more likely to withdraw from the study due to their dependency on others (e.g., reduced mobility discourage their participation), leading to their disease trajectory not fully captured. Cohort study designs can be enhanced to improve data quality. Longitudinal study designs should consider incorporating more objectiveÿdiagnostic criteria, such as expanding the use of A? PET scans, and integration of blood-based biomarkers, tau, and neuroinflammation markers, to enhance the assessments accuracy. Additionally, developing strategies to prolong study follow-up duration is crucial for capturing the full progression of disease states over time. Research funding bodies could play a crucial role in driving this progress by prioritizing investment and providing support to longitudinal studies.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"The existing longitudinal datasets exhibit a lack of uniformity and standardized approach in sample/data collection and record format, making it difficult to validate and compare metrics like accuracy, sensitivity, and specificity between ML models that built on different datasets [109]. For example, although AIBL and ROSMAP collected depression related data, yet different scales were used?AIBL adapted the Hospital Anxiety and Depression Scale while ROSMAP used the Center for Epidemiological Studies Depression scale. The lack of uniformity in data collection could also be attributed to the intrinsic nature of the technology. For example, various platforms, techniques, and environmental factors could introduce biases and variabilities into omics dataset [110]. In addition, omics data is often noisy and sparse, especially when detecting molecules of low abundance, and therefore more prone to batch effect. Furthermore, different annotation systems or reference databases used to identify proteins, metabolites, and genes can lead to mismatches and inconsistencies. Also, different omics dataset may lack of common features due to experiment set up. All these make it less practical to standardize the omics data.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"To enhance the performance of ML models in dementia research, addressing variability in data collection methods is crucial. The Alzheimer's Dementia Onset and Progression in International Cohorts initiative [111] exemplifies the successful application of data harmonization, integrating data from five international dementia cohort studies, including the Adult Children Study, ADNI, AIBL, the Dominantly Inherited Alzheimer Network, and the National Alzheimer's Coordinating Center. Similar initiatives should be encouraged, as they are crucial for enhancing statistical power, and enabling more robust ML applications in dementia, leveraging the existing longitudinal datasets. In addition, publication of sample collection protocols, along with raising awareness of the requirements and benefits of data pooling for ML among biomedical and clinician scientists, could promote consistent data collection practices and enhance collaborative research efforts globally. Of paramount importance, inconsistencies in data formats can undermine the effectiveness of ML models. Advanced tools like 'dtool' provide practical solutions for standardizing data formats and enhancing quality by encapsulating data and metadata into consistent, unified dataset structures with readily accessible metadata for both the collective dataset and its individual files [112]. Data repositories could endorse guidelines that only accept datasets meeting standardized criteria.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"A longitudinal dataset may lack of generalizability. The study setting and enrolment criteria would exclude certain populations based on ethnicity, education level, socio-economic status, or comorbid conditions. For example, research studies might exclude participants with severe cardiovascular diseases or advanced diabetes, arguing that these conditions could confound the cognitive assessments used to diagnose and track ADem progression [113]. Moreover, studies that require participants to be English-speaking exclude individuals from a culturally and linguistically diverse background (e.g., the indigenous population in Australia, who have a higher risk of ADem). These exclusions can result in datasets that fail to fully represent the diverse population affected by dementia. The clinical application of ML models built from biased data will consequently be limited. Collaborative efforts between researchers, clinicians, and regulatory bodies are crucial in developing criteria that balance scientific rigor with practical feasibility. Furthermore, the major dementia longitudinal studies are often restricted to national boundaries, constraining their generalizability and the assessment of their performance in more border real-world scenarios. Researchers are encouraged to employ multiple datasets, where the model is trained on one dataset (e.g., ADNI) and validated on another dataset (e.g., AIBL) [114] to address this challenge.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Computational and memory burden is another technical challenge to ML-dementia, particularly as recent studies focus on high-dimensional longitudinal omics data. Advanced tools such as the versatile toolbox MEFISTO [115] and the PALMO platform [116] are now capable of modelling spatial and temporal omics data. These tools utilize high-performance computing resources and implement various optimization strategies to improve processing efficiency. However, the high computational and memory demands of these algorithms can limit their applicability in AD studies that involve large sample sizes. Furthermore, the high volume of data requires a robust data management solution. Distributed computing platforms, like Apache Hadoop [117], can be employed to efficiently handle, store, and share the large-scale data, facilitating collaborative efforts across different research groups and locations. However, these platforms are not always affordable, creating a technical barrier.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Artificial intelligence (AI), such as ML, has already demonstrated success in disease tracking, as evidenced by FDA-approved devices like Apple's Atrial Fibrillation History Feature [5]. While ML applications haveÿyet to beÿimplemented inÿdementia clinical practice, anticipated challenges must be considered for future implementation in dementia diagnosis and care.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"The targeted population for ML-dementia tools is older adults, which raises questions about their readiness to accept these technological innovations [118]. Many older adults are not as technologically adept as younger generations, making it challenging for them to understand ML and its potential in diagnosing and managing diseases. This lack of understanding can result in low trust in ML-generated results, leading to hesitation in their use for healthcare purposes. Moreover, some ML tools collect data using wearable devices, raising privacy concerns among older adults who may be unsure how their data will be used. Furthermore, not all older adults want to receive predictions about their disease progression or early detection due to psychological fears and anxieties [119].",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"To address these challenges and improve acceptance among older adults, several steps should be taken. Increasing public awareness of ML and its benefits in healthcare is crucial, as many people may not realize that AI/ML are already being used. Ensuring transparency in data usage and robust data security measures can help build trust, whileÿoffering a personalized approach where individuals can opt in or out of predictive analyses can promote autonomy [120]. Providing comprehensive psychological support can help individuals cope with the emotional impact of potential diagnoses and empower them to make informed decisions about their health and care plans. By addressing these concerns through patient education, demonstrating the reliability and benefits of ML tools, and ensuring robust data security measures, we can foster greater acceptance of ML-dementia tools among older adults.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"Clinicians tend to prefer techniques that are transparent and interpretable, aligning with conventional clinical reasoning. One of the barriers for clinicians to trust and uptake the output of ML models is the opaque nature of these algorithms, often referred to as ""black boxes."" ML models can obscure the logic behind their complex decision-making processes, sometimes producing results that cannot be easily justified by existing biomedical knowledge. The ""black box"" nature of ML potentially erodes clinicians' trust, hindering the adoption of these models in clinical practice. In response to these challenges, there is an increasing focus on developing explainable AI techniques, such as Local Interpretable Model-agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP) [121]. These methods aim to make the decision-making processes of ML models more transparent and understandable, thereby can potentially enhance trust among clinicians. Another significant challenge is that many clinicians have not received formal training in ML, which can hinder their ability to effectively use and explain these tools to patients [122]. Providing basic education about ML to clinicians and incorporating an AI/ML training component in medical school curriculum can enhance their ability to use innovative tools and communicate the benefits to patients. Of paramount importance, involving clinicians in the co-design of ML-dementia models can ensure AI/ML tools meet clinical needs and foster greater acceptance and integration into practice. Last but not least, some clinicians are hesitant to accept AI/ML tools due to concerns about job displacement [122]. However, it is essential to understand that AI/ML tools are designed to augment, not replace, the work of clinicians, similar to other diagnostic tests. Clinicians should be assured that their clinical judgment cannot be replaced by AI/ML and that the role of AI/ML in clinical practice should be clearly defined in relevant guidelines.",,,,,
Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians,"The integration of AI/ML in healthcare brings forth numerous ethical and regulatory concerns that could potentially impede their implementation. Recently, the World Health Organization issued new guidance on the ethics and governance of AI technology applications in healthcare [123], emphasizing the need for AI/ML developers to prioritize ethical principles. To facilitate the potential implementation of AI/ML tools in dementia diagnosis and management, we also advocate for the development of local guidelines to fit the culture/religious needs. On the regulatory front, compliance with healthcare regulations is indispensable. Regulatory bodies, such as FDA, the European Medicines Agency, and the Therapeutic Goods administration (Australia), should get prepared for processing more applications for AI/ML medical devices in the future. A clear approach must be established for post-deployment continuous monitoring and reporting, to maintain their safety and effectiveness in the clinic [122]. More importantly, it is crucial that regulations should clearly define the responsibilities and accountabilities of AI/ML developers and healthcare providers for any errors generated by AI/ML tools. This includes specifying the extent of liability for developers in the event of AI/ML malfunction or incorrect predictions, as well as outlining the role of healthcare providers in interpretating AI/ML outputs before making clinical decisions. Regulations should also detail mechanisms for reporting and addressing errors, as well as protocols for updating and improving AI/ML tools from reported errors. An in-depth discussion on regulatory matters concerning ML/AI is outside the scope of this review. Regulatory bodies, clinicians, and public health experts are encouraged to work on regulatory matters to prepare our healthcare systems for the implementation of AI/ML tools.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Mental health difficulties are highly prevalent worldwide. Passive sensing technologies and applied artificial intelligence (AI) methods can provide an innovative means of supporting the management of mental health problems and enhancing the quality of care. However, the views of stakeholders are important in understanding the potential barriers to and facilitators of their implementation.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","This study aims to review, critically appraise, and synthesize qualitative findings relating to the views of mental health care professionals on the use of passive sensing and AI in mental health care.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","A systematic search of qualitative studies was performed using 4 databases. A meta-synthesis approach was used, whereby studies were analyzed using an inductive thematic analysis approach within a critical realist epistemological framework.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Overall, 10 studies met the eligibility criteria. The 3 main themes were uses of passive sensing and AI in clinical practice, barriers to and facilitators of use in practice, and consequences for service users. A total of 5 subthemes were identified: barriers, facilitators, empowerment, risk to well-being, and data privacy and protection issues.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Although clinicians are open-minded about the use of passive sensing and AI in mental health care, important factors to consider are service user well-being, clinician workloads, and therapeutic relationships. Service users and clinicians must be involved in the development of digital technologies and systems to ensure ease of use. The development of, and training in, clear policies and guidelines on the use of passive sensing and AI in mental health care, including risk management and data security procedures, will also be key to facilitating clinician engagement. The means for clinicians and service users to provide feedback on how the use of passive sensing and AI in practice is being received should also be considered.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Mental health problems are highly prevalent globally, with approximately 1 in 8 people experiencing mental health difficulties, which can have significant personal and economic consequences [1]. Rapid growth in digital technology innovation has led to an increased interest in digital mental health interventions [2]. Digital tools with built-in sensors, such as smartphones, smartwatches, and other wearable devices, allow for the unobtrusive and continuous collection of objective data, providing insight into user behavior and physiology [3]. Machine learning, which is a branch of artificial intelligence (AI), can be applied to these data toÿlearnÿfrom it and generate clinically actionable insights and predictions [4]. It has therefore been suggested that passive sensing data and applied machine learning methods could overcome what some describe as trial-and-error?driven approaches used in mental health care by supporting precise diagnoses and prognoses [5]. Indeed, mental health remains one of the only domains in health care that relies only on service users? self-report of cognitive and emotional states and symptoms and on clinicians to accurately recognize and map these states to make diagnostic, prognostic, and therapeutic decisions [6]. Passive sensing data and AI may offer a means to overcome the pitfalls of current clinical measures by presenting a more complete picture of a person?s difficulties [7]. For example, raw sensor data captured regarding speech characteristics, location, and activity can be transformed to derive high-level behavioral markers, such as fatigue, sleep disruption, and mood, which can be used to identify clinical states, such as depression [8]. In addition, digital tools that allow for passive sensing can support service users? self-management of symptoms and access to digitally delivered therapies [4]. Through self-management, service users may feel empowered [9], and service user and clinician access to digital remote data capture has the potential to identify early warning signs of deterioration, providing the opportunity to reduce the risk of relapse of mental health difficulties via early identification and intervention [10]. This may be particularly useful, as current health care systems generally rely on the delivery of treatment by scheduled appointments, which can result in warning signs of mental health relapse being missed or treated too late [11]. Using sensors from digital tools, such as smartphones and wearable devices, to identify clinical and behavioral features of worsening mental health and applying machine learning methods to identify patterns in the data could augment mental health care by delivering more precise treatment at the time it is needed [12].",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Despite the potential benefits, there remains a persistent gap between the rapid developments in digitally supported mental health care and the successful adoption of these tools in clinical practice [13]. A key driver to the potential success of digitally supported health care uptake is the willingness, confidence, and capacity of clinicians to make changes to their practice [9]. Resistance to incorporating digital approaches in clinical practice can occur for various reasons, including the lack of technological literacy, fear that AI models could replace professionals, and concerns about ethical and legal issues [6]. There is trepidation that core aspects of clinician roles, such as diagnosis, assessment, formulation and treatment, may be delegated to AI models without human input [14]. This has been viewed as dehumanizing and could have negative implications for therapeutic relationship [15]. Ethical issues have also been raised, such as implications for service user privacy and data security [16]. As clinicians? perceptions and attitudes pose a potential barrier to implementation [17], it is important that they are invited into the dialog around digitally supported AI in mental health care, to embrace any benefits there might be, as well as share their concerns and explore the limitations and risks [2]. However, it has been noted that stakeholder?s views are rarely considered in model design or evaluation in relation to machine learning approaches [18]. Indeed, professionals have felt that their knowledge and views have been disregarded in the design of digital health solutions or are only considered as an afterthought [19]. As the extent to which these methods can be successfully implemented in health care depends on their acceptability [3], research is needed to understand stakeholders? perspectives on digital health systems [11].",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Although there have been some qualitative studies exploring mental health care professionals? views and experiences of passive sensing and AI in mental health care, there are no published reviews that systematically aggregate these findings, specifically through examining participants? experiences and perspectives, both deeply (because of the qualitative approach) and broadly (because of the integration of studies from different health care contexts and participants) [20]. This meta-synthesis aims to synthesize and evaluate the relative strengths of the qualitative literature regarding mental health care professionals? views on the use of passive sensing and AI in mental health care to provide a new, comprehensive interpretation of the findings that goes beyond the depth and breadth of the original studies [21]. Although research continues to grow in this area, it is now an appropriate time to review the literature, as the COVID-19 pandemic has increased the urgency for creating digital interventions that can fulfill the full potential of digital health [22], and it is necessary to engage multiple stakeholder groups early in the design and development process [23].",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Meta-synthesis is a systematic review and integration of findings from qualitative studies to facilitate the transfer of knowledge and bring together a broad range of participants and descriptions [20]. A systematic approach for identifying and assessing the quality of potential papers, followed by analysis of the data and synthesis, was used with the aim of understanding what mental health care professionals think about the use of passive sensing and AI in mental health care. The review protocol was developed and registered with the International Prospective Register of Systematic Reviews (PROSPERO CRD42022331698).",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Eligible papers for this review (1) were peer-reviewed studies published in English that used a qualitative method?mixed methods studies were also included, but only the qualitative findings were considered; and (2) examined health care professionals? views on hypothetical or actual use of service user-facing digital tools that use passive sensing and AI in mental health care. Studies with participants that included other stakeholders, as well as health care professionals, were not discounted; however, findings were only included if they were explicitly associated with mental health professionals. There were no limits on the publication year.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","A discussion within the research team and a review of the literature allowed for the identification of common terminology used in this research area and the selection of search terms. The search tool ?SPIDER? (sample, phenomenon of interest, design, evaluation, research type) was used to ensure that all relevant areas were covered when developing the search terms. Relevant studies were identified through systematic searches of the following electronic databases: AMED, PsycINFO, Embase, and Medline. The search terms were (clinician*) OR (health care professional*) OR (staff) OR (physician*) OR (provider*) OR (practitioner*) OR (psychologist*) OR (doctor*) OR (therapist*) OR (care coordinator*) OR (mental health nurse*) OR (psychiatric nurse*) OR (support worker*) OR (counsellor *) OR (case manager*) OR (GP*) AND (view*) OR (opinion*) OR (perception*) OR (qualitative) OR (interview*) AND (remote monitoring) OR (digital phenotyping) OR (machine learning) OR (passive sens*) OR (passive monitor*) OR (passive data) OR (artificial intelligence) OR (wearables). A manual search of references and citations from eligible articles was also performed by JR to identify additional studies. Papers were initially screened according to title and abstract, followed by a full article.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","The study selection and exclusion processes were conducted in accordance with the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines [24] in October 2022 and are outlined inÿFigure 1. Article titles and abstracts were screened for eligibility by JR. If the inclusion criteria were unclear, full-text articles were obtained and reviewed. Any uncertainty regarding study eligibility was resolved through discussion with a wider research team. A second independent rater screened 10% (106/1056) of titles and reviewed 10% (16/154) of full-text articles to assess the reliability of the study selection. There was an ?almost perfect? level of agreement between the raters at the screening stage (k=0.918) and at the full-text stage (k=1) [25]. As all studies were published in recent years, the search was conducted again in February 2023. Overall, 10 studies met the eligibility criteria and were included in the review.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Study quality was assessed using the Critical Appraisal Skills Programme (CASP) tool for quality appraisal in qualitative evidence synthesis (CASP, 2018, [26]), which assesses the strengths, limitations, relevance, and credibility of qualitative research. The CASP comprises 10 items that focus on different methodological aspects of qualitative studies, such as method, design, recruitment, data collection, and reflexivity. It is considered a good measure of transparency of research practice and reporting standards and is recommended for use in health-related research [27]; therefore, it was deemed appropriate for use in this review. A 3-point scale was used, with a score applied to each criterion (0=criterion not met, 1=criterion partially met, and 2=criterion totally met) [28]. Therefore, papers were given a total quality score of 20.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","The scoring was completed by JR. A second independent rater assessed the quality of 50% (5/10) of the studies, and the scores were compared at the item level. Interrater reliability estimates showed good agreement between raters (k=0.832) [25]. Disagreements in ratings were resolved through discussion among raters until agreement was reached.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","The included studies were read and reread to ensure that they met the inclusion criteria. Key study information was then recorded, including the number and characteristics of participants, aims of the research, analysis method used, and the settings (Table 1). In addition, the original authors? analysis of primary qualitative data was extracted (second-order constructs), and individual participants? quotes were also noted (first-order constructs), in line with meta-synthesis principles [29]. An inductive thematic analysis approach within a critical realist epistemological framework was then taken with the aim of developing a cohesive, synthesized understanding of the data [30] and new interpretations [31]. JR completed the coding of the text and quotes using NVivo qualitative data analysis software (NVivo version 12, Lumivero). The constructs were then grouped into core themes. These themes were discussed by a broader research team, considering how each paper contributed to each core theme. The themes were then grouped into final higher-order themes, which were again reviewed and agreed upon by the research team. These themes are considered third-order constructs and allow for reflection on how each paper?s findings fit within the wider literature and for findings to extend beyond the original papers [21]. JR returned to the papers to ensure that the themes identified reflected the data and that other themes were not overlooked.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","A total of 10 papers were deemed eligible for inclusion in this review. A total of 3 studies were conducted in the United Kingdom, 1 in India, 1 in the United States, 1 across both the United States and India, 1 in Australia, 2 in Germany, and 1 in a global study. In total, 6 studies used thematic analysis, 1 used a grounded theory approach, 1 used qualitative descriptive analysis, and 2 used content analysis. Participants in 4 of the papers were health care professionals only, with the remaining 6 papers including health care professionals as well as other stakeholders, such as service users and their families, technology experts, and technology company owners. The findings were only included if they were explicitly associated with health care professionals. The number of health care professionals ranged from 2 to 53 (mean 17). The age of the mental health professionals where this was reported (6 papers) ranged from 22 to 72 years. Among the 5 papers that reported gender, 28 participants were male, and 42 were female. Owing to the high number of participants in the global web-based survey [34], these data are described separately, with 791 participants taking part, ranging in age from 25 to ò65 years. Of the participants, 550 identified as male, 230 identified as female, and 11 identified as others.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","The overall CASP quality appraisal scores are included inÿTable 1, and a breakdown of these scores is provided inÿTable 2. There was variation in the scores across the papers. Those given stronger scores tended to provide more detail as to why certain qualitative approaches were selected over others, provided details regarding the sample including why participants may have opted not to take part, and ethical considerations were reported. It should be noted that although some studies did make some reference to the relationship between researcher and participants, this was the area that scored lowest, with few studies referencing bias and considering the influence their own roles may have had on results and reporting. For papers that included other stakeholders alongside mental health professionals, higher scores were given if the results were written to clearly distinguish which themes were associated with which participant group.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Analysis of the data revealed three distinct but interrelated themes: (1) the use of passive sensing and AI in clinical practice, (2) barriers to and facilitators of use in practice, and (3) consequences for service users. A total of 5 subthemes were identified from the data. The themes, subthemes, and relationships between them are summarized inÿFigure 2.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Findings across the reviewed papers included how clinicians felt they could use passive sensing and AI in their practice. Passive sensing technology has been shown to be particularly useful, as the unobtrusive collection of objective service user data could offer a new information source [23]. This could provide insight into factors such as speech, social media use, and activity levels, which could be considered alongside self-report questionnaires and assessment tools to facilitate more accurate assessment of service users? mental health difficulties [35]. In assessing service user needs, it was also felt that these data could clarify discrepancies between self-report, observation, and psychometrics and validate service users? concerns [33]. It has been suggested that passive sensing data and AI could entirely replace some methods of assessment, such as questionnaires, to improve the clinical experience for both service users and clinicians [3,38]. Passive sensing data can reduce errors and biases in clinical decisions regarding diagnosis, treatment, and medication [34], as data-driven technologies may uncover correlations that humans cannot [36]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Further suggestions were made as to how passive sensing and AI could be useful in therapeutic work, such as guiding productive discussions [33], setting treatment goals, delivering low-intensity support [3], tracking the efficacy of brief interventions [23], and encouraging ongoing engagement and regular self-reflection [38]. Furthermore, discussions were conducted about how AI?s ability to process, connect, and make conclusions from large amounts of data could be used to risk-stratify service users according to their personal factors and needs [36] and support identification and awareness of early warning signs, thus reducing the risk of relapse of mental health difficulties [32-34,37]. As clinicians have access to these data, it was also felt that they could identify when to intervene [38], which may further reduce a service user?s risk of deterioration in mental health [10]. Indeed, clinicians have reported that seeing a change in the data regarding a service user?s speech and self-care habits would promote awareness of a decline in their well-being [3]. This was considered useful in community and ward environments, where staff may not always have eyes on service users [32], particularly for those who may lack insight into their difficulties or do not volunteer information themselves [23,32]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","The idea that aspects of psychiatric work could gradually be replaced by AI was viewed as positive progression by some, but others were concerned that overreliance on AI and technology in practice may result in staff becoming deskilled [34]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Throughout the papers, participants discussed the perceived barriers to and facilitators of using passive sensing and AI in mental health care. The barriers discussed included access, concerns about clinicians? workloads, and the potential negative impact on the therapeutic relationship. Facilitators included ease of use and training.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","It was highlighted that technology is now readily available, and this was reported as a benefit to using passive sensing and AI in mental health practice as it may improve service user access to mental health care [34]. However, not all mental health services have sufficient access to technology [37] because of factors such as cost and the lack of the necessary infrastructure to support digital tools [3]. For example, participants reported that in India, most hospitals do not have access to the internet [35], and service users do not always have access to smartphones [23]. This would likely present significant barriers to health care professionals using such technology in mental health care. Therefore, it is important to consider the digital divide, that is, the gap between those who benefit from the digital age and those who do not [3]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","A further barrier discussed was the impact of passive sensing and AI could have on clinicians? workloads. Clinicians wondered about the amount of time and effort required to incorporate data flows into their practice and whether they would be required to review data before sessions [33], which could result in clinicians trawling through a significant amount of data to generate actionable insights [3]. Indeed, participants reported feeling ?overwhelmed? when presented with passively collected data [23]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Queries were also raised around documentation and whether the use of these tools would increase administrative work for clinicians [33,34]. Furthermore, it was suggested that clinicians may have to spend time with service users reviewing the use of devices and verifying data, which could take time away from evidence-based practices. If clinicians are alerted to changes in behavior that are the result of inaccurate readings, this could cause unnecessary alarm and waste clinicians? time [33]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Managing risk was another concern raised, with participants wondering about their clinical responsibility for monitoring the data for risk issues [3,10,35] because responding to constant data streams would not be possible [23]. This is important because risk aversion is cited as a potential barrier to engagement [36].",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","In contrast, it has been suggested that passive sensing and AI have the potential to multiply resources, in that it offers a means of support to service users when health care professionals are unavailable [38]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","An issue that arose across studies was the impact that use of passive sensing and AI in practice could have on the therapeutic relationships. Some service users may prefer in-person consultations [35]; therefore, using digital tools and AI methods as a replacement of human contact could be determinantal to the therapeutic alliance [3] because of a loss of empathy and inaccurate interpretations of service users? presentations [34]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","A potential lack of meaningful interactions between service users and clinicians [33] has led some to believe that service users may become resistant to or refuse treatment [34]. It was also suggested that, as service users are less accountable to clinicians, this could negatively impact motivation [3]. Furthermore, service users may become reliant on a device during treatment, and having this subsequently removed could have negative repercussions, including service users becoming mistrusting of services [3]. It was also highlighted that clinicians may not be able to fully trust the data they receive, as participants suggested that service users may influence these data deliberately [34]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Having said this, it was proposed that allowing service users to submit data to clinicians, who could then respond with recommendations, would enable remote support and continuity of care, which could strengthen the therapeutic relationship [23]. It appeared that the general consensus was that although digital tools may enhance practice, they should not replace service user or staff interactions, something which was viewed as integral to the therapeutic relationship [32].",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Throughout the studies, it was highlighted that to improve engagement with digital tools that allow for passive sensing and applied AI methods, the technology and systems would have to be relatively straightforward to use in terms of accessibility and convenience [3]. Health care professionals discussed that clinicians are very busy and would not have time to navigate complicated systems [10]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","To ensure ease of use, suggestions were made, such as including relevant stakeholders in the development of such technologies and related systems to ensure that they use accessible language [37] and presenting the data in a simple way that is easy to understand [3]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","The importance of training to support clinicians in using digital tools, passively collected data, and applied AI methods in practice has been emphasized in most studies. This was discussed in the context of being given time to access the training as well as time to consider implementation [3]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Clinicians may differ in technological literacy, and some may generally find technology challenging [35]. It was discussed that this technology will only be useful if clinicians understand it and feel comfortable using it [23]. For training to be adequate, it was suggested that clinicians would value clear procedures and guidance on when and how these digital technologies should be used [10], how to connect the data to their established clinical practice [33], and how to interpret data. Depending on the condition, certain markers of behavior could be interpreted positively or negatively [3]. Clinicians would also require clear guidelines regarding responsibility, interoperability, information governance, and potential risks [36]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Clinicians would further benefit from being informed of the evidence base around passive sensing and AI in mental health care [33], especially as the belief that there is a lack of studies to support the use of AI technology in health care could be a barrier to clinician engagement [35]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Throughout the studies, findings on the consequences that passive sensing and AI in mental health care could have for service users were discussed. There appeared to be a positive notion that this could empower service users, although it was also acknowledged that there could be risks to service users? well-being. Concerns have also been raised regarding the protection and safety of service users? data.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","It was suggested that passive sensing and AI could facilitate ?knowledge transfer? and empower service users to understand how their actions, feelings, and thoughts are intertwined [37]. By increasing insight into mental health, self-monitoring allows service users to respond to symptoms and take action themselves [10]. Service users? monitoring and managing their mental health may involve connecting with other users and supporting one another, setting reminders to take medication, and responding to prompts to engage in helpful strategies [3]. Thus, service users? ability to monitor their mental health?related data can be empowering [33]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","This self-management could increase awareness of early warning signs, reduce the risk of relapse, and therefore decrease demand for services, for example, by reducing hospital admissions [36].",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","In contrast, concerns have been raised about the accuracy of sensing technology, as making health care decisions based on unreliable sensors could potentially be harmful [3]. In addition, if service users have access to their health data, this could cause some to become hyperfocused on their data, catastrophize, or become disheartened by lack of progress or negative trends [33]. This was thought to be particularly pertinent to those who experience health anxiety [3] or paranoia, as ?tracking? behavior could exacerbate symptoms [32]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Ng et al [33] highlighted the importance of clinicians, suggesting alternate ways for service users to frame or interact with their data. This may be important in ensuring that recommendations delivered to service users do not arouse false expectations of users [37]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Another concern highlighted by participants working in mental health wards was that service users could harm themselves using a digital device. For example, if an armband that stretches it could be used as a ligature, the design of devices is an important consideration [32]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Participants reported that in practice, they will often recommend apps to service users without reviewing privacy policies, citing a lack of time as the reason for not investigating this further [23]. However, in most studies, concerns have been raised regarding privacy in relation to passive sensing data. It has been suggested that the collection of personal data through digital devices that allow passive sensing could increase the risk of loss of confidentiality and misuse of data [34,36], which could negatively impact therapeutic relationships [10]. In line with this, it was felt that service users would have less control over what they chose to share, which may feel uncomfortable for service users and lead clinicians to feel as though they are invading their privacy [10,23]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Data management was therefore seen as an important consideration, and it was highlighted that service users should be given choice over what they share and be made aware of who could access the data, what will happen if their data are leaked [3], how their data will be kept private and secure, and what their data will be used for [10]:",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","It is important to ensure that service users have capacity when making these decisions, as mental states can change and influence decision-making [32].",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Across the papers reviewed, multiple ways in which passive sensing technology and applied AI methods could augment mental health care were identified, such as supporting service users in managing their mental health, improving diagnostic accuracy, monitoring treatment trajectories, and increasing access to timely support, thereby reducing the risk of relapse of mental health difficulties. Indeed, research has shown that passive data and AI methods have the potential to provide insight into service user behavior outside the clinic environment and provide real-time detection of behavioral anomalies, which could allow early identification and intervention before a deterioration in mental health [39]. However, despite the potential benefits, concerns have been raised that clinicians could become overreliant on digital technology in practice [40]. This could have negative consequences, as participants discussed that they may not be able to fully trust the data they receive because of service user influence and inaccurate sensors. Therefore, overreliance on inaccurate data can lead to misdiagnoses or missed diagnoses. Thus, decision-making should not be delegated to technology alone [41], and it is important for clinicians to acknowledge the limitations of objective data collection and applied AI methods to avoid tension between service users and clinicians [42]. This is particularly important, as research has shown that discrepancies between experience and tracking data can lead to upset, confusion, and disengagement [43], which may negatively impact the therapeutic relationship.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","The influence that the use of passive sensing and applied AI methods could have on the therapeutic relationship was further discussed across papers. Although service users should feel empowered to make choices and manage their own mental health, access to human in-person support is deemed necessary. This reflects concerns that the use of AI in health care could lead to neglect of the therapeutic aspects of in-person consultation, such as consideration of motivation and self-advocacy, attendance to nonverbal cues, and social connection that can be provided by in-person clinical contact [44]. Fears were further raised that the absence of a therapeutic relationship may lead service users to disengage or refuse mental health care altogether. Research suggests that a therapeutic alliance can exist between a person seeking change and a change agent, which does not necessarily have to be a human health care professional, with digital tools and apps themselves having the potential to act as change agents [45].",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Concerns have been raised across studies that service users may notice a decline in their mental health if they were to monitor aspects of their behavior and interpret subsequent passively collected data in such a way that increases anxiety or results in demotivation. Research has shown that tracking behavior can reduce enjoyment in walking-based activities [46] and increase eating disorder symptomology [47]. However, research has also found that the use of digital devices that allow passive sensing, such as wearables, can be a positive experience, with multiple psychological benefits identified by users, including increased sense of motivation and accountability [48]. Individual differences are therefore important for clinicians to consider, as certain characteristics may impact a service user?s ability to interpret their health data in a helpful way. For example, research has shown that high health literacy supports the understanding of passively collected health data and how to use it to work toward goals [49].",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Across studies, clinicians discussed the impact that use of passive sensing and AI could have on their workload. Concerns appeared to be around reviewing significant amounts of data to identify clinically relevant information and risk monitoring. However, previous research has suggested that AI may in fact reduce clinicians? workloads, as less time will be required to read through notes to understand a service user?s history, particularly because certain AI methods, such as natural language processing, could be applied to patient notes to summarize important information [50]. Furthermore, machine learning methods can facilitate work by highlighting previously inaccessible or less understood symptoms and patterns [6]. It has also been suggested that data received by clinicians regarding a service user?s behavior may allow them to identify those most in need of support and prioritize their workload, thus using their time more effectively [51]. To reduce concerns about increased workload, it would be useful for clinicians to receive data in a user-friendly format, allowing seamless access to relevant information. If devices and associated systems are not considered user-friendly and there are multiple technical issues, this will likely result in frustration and reluctance to engage [52]. Along with ease of use, training was discussed as a means to encourage clinicians to engage with devices that allow passive sensing and applied AI methods in their practice. Ways to make training useful for clinicians included ensuring that clinicians have access to clear guidance around incorporating data flows into their practice, managing risk issues, and data privacy and protection procedures. The latter is especially pertinent, as concerns about data security were a reoccurring theme throughout studies. Transparent guidelines will need to be developed, and codes of practice enforced around storage, ownership, and sharing of data [52]. However, it has been suggested that concerns about confidentiality of data may always remain; therefore, to facilitate engagement, the perceived value to clinicians and service users will need to outweigh these concerns [53]. As discussed in the reviewed studies, training should involve increasing awareness of the evidence base so that clinicians can understand the cost-benefits of engaging in passive sensing and AI in practice.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","The final key issue is access. As highlighted in this review, access to technology could pose a barrier to engagement at both the service user and clinician level. For example, studies conducted in India have highlighted that not all hospitals offering mental health care have access to the internet. Therefore, considering the digital context within low- and middle-income countries, it is important to create digital-based mental health interventions intended for a global rollout. Indeed, Lee et al [54] highlighted that methods such as machine learning have the potential to advance health equity by supporting opportunities for equality in patient outcomes, performance, and resource allocation.",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Meta-synthesis allows for greater scope and generalizability than individual primary studies [55]. However, as data are transposed into third-order constructs, there is potential for the findings to move away from the empirical, conceptual, and theoretical contexts of primary qualitative studies [56]. Of the papers included, 2 used content analysis, which is a more descriptive approach to coding and data interpretation (Vaismoradi et al [57]). Thus, the findings may have been more heavily influenced by studies that used more robust qualitative methods, such as thematic analysis, which can provide a more detailed and nuanced account of the data (Braun and Clarke [58]). Furthermor e, the process and methods of meta-synthesis are heavily influenced by the focus and expertise of the authors, meaning that some concepts and theories may not have been considered. This limitation was managed through discussion with the research team on coding and themes as well as remaining attuned to personal perspectives that could introduce bias [59].",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Efforts were made to include all eligible studies in this review and to avoid neglecting potentially important findings, such as checking the reference lists of all papers and searching the databases again at a later date to identify further studies that might have been published. However, it is possible that some studies were overlooked, particularly as the terminology in this research area can be diverse and studies were only included if they were published in the English language in peer-reviewed journals, meaning that important contributions to the literature may have been missed because of language and publication bias. The included studies were conducted across different mental health settings, such as primary care and inpatient settings, and across different countries. It is important to note that the health care systems and services within them differ globally, so the generalizability of the results may be limited. However, meta-synthesis of qualitative studies can transform findings into highly abstracted and generalizable theoretical frameworks [21].",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","Considering the findings from this review and wider research in this area, a key barrier to implementing digital technology innovations is end user perceptions rather than technology innovation itself [3]. Therefore, it will be important for future research to gain a deeper understanding of service user views as well as other stakeholders, such as policy makers. Further research into the efficacy of passive sensing and AI in mental health care is necessary to build an evidence base that would support the scaling up of these approaches to routine service delivery. Real-world studies implementing passive sensing and AI in practice are needed to understand the contextual factors that impact uptake, which will be useful to gain knowledge that can support the development of implementation frameworks [60].",,,,,
"Health Care Professionals' Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis","These findings suggest that although clinicians are open-minded about the use of passive sensing and applied AI methods in mental health care, factors such as service user well-being, clinicians? workloads, and the therapeutic relationship need to be considered. It is important to involve both service users and clinicians in the development of digital technologies and systems to ensure their ease of use. The development of policies, training, and clear guidelines on the use of passive sensing and AI in mental health care, including risk management and data security procedures, will also be key to facilitating clinician engagement and wide-scale adoption. Means for clinicians and service users to provide feedback on how the use of passive sensing and AI in practice is being received should also be considered, allowing reflection on any impact there might be on the therapeutic relationship, service user well-being, and clinicians? workloads.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,Postpartum depression (PPD) is a significant public health issue. This study aimed to develop and validate machine learning (ML) models using biopsychosocial predictors to predict the risk of PPD for perinatal women and to provide several risk assessment tools for the early detection of PPD.,,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"Candidate predictors, including history of mental illness and demographic, psychosocial, and physiological factors, were obtained from 1138 perinatal women between August 2021 and August 2022. The primary outcome of PPD was measured with the Edinburgh Postnatal Depression Scale at 6 weeks postpartum. Seven feature selection methods and six ML algorithms were employed to develop models, and their prediction performances were compared.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"A total of 11 potential predictive factors associated with PPD were identified and subsequently used to construct prenatal and postpartum predictive models for PPD. The cross-validation results showed that the models built on logistic regression (LR) [area under the curve (AUC): 0.801, 0.858] and artificial neural network (ANN) (AUC: 0.787, 0.844) algorithms exhibited the best prediction performance. In contrast to the prenatal models, the addition of postpartum predictors (primary caregiver and mother-in-law?s care) remarkably improved the predictive performance of the postpartum models. The risk-stratification score, the nomogram, and the Shapley additive explanation were used to visualize and interpret the risk prediction model for predicting PPD in the early stage.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,The LR and ANN models achieved the best predictive performances. Applying these models and risk assessment tools to early predict and screen PPD has several implications for public health.,,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"The physical health of perinatal women has dramatically improved over the past few decades, leading to a substantial decline in miscarriage and mortality rates [25,ÿ38]. However, their mental health has increasingly become a global public health problem [24]. Postpartum depression (PPD) is an apparent depressive symptom or a typical depressive episode in the perinatal period [45]. As the most common type of perinatal psychiatric syndrome, PPD is frequently characterized by persistent low mood, anhedonia, and loss of pleasure [2]. The largest and most inclusive meta-analysis of PPD to date found that the global pooled prevalence of PPD was 17.22% (95% CI 16.00%?18.51%) [43]. Notably, the coronavirus disease 2019 (COVID-19) has evolved into a global pandemic and further exacerbated mental health risks, especially in perinatal women [12]. Therefore, women?s postpartum depressive symptoms should receive adequate global public health attention during this period. Previous studies have suggested that PPD is affected by a complex combination of factors, such as demographic, physical, psychological, social, and obstetrics-related factors [8,ÿ48]. However, the underlying mechanism of PPD remains unclear, so it is still an enormous challenge to prevent and intervene PPD.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"PPD not only has severe and lasting adverse effects on mothers, infants, and partners [40,ÿ42] but also affects harmonious family relationships, increases medical expenditures, and impedes social development [34,ÿ44]. Although the exact etiology of PPD is unknown, early identification and appropriate intervention by combining biopsychosocial factors to predict the risk of PPD can help prevent the abovementioned adverse effects. Consistently, self-report questionnaires [such as the Edinburgh Postnatal Depression Scale (EPDS) and Beck Depression Inventory (BDI)] are the primary tools for PPD screening, and diagnosis is mainly dependent on the presence of clinical symptoms [19]. In this case, PPD may have already occurred but may not have been noted before the screening. In addition, some perinatal women with PPD are affected by social stigma and are inclined to hide their clinical symptoms [28]. Therefore, developing appropriate predictive models can be helpful in quickly identifying perinatal women with PPD and facilitating supportive care or amelioration of the disease course before overt symptoms develop.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"Recently, multiple studies developed prediction models to predict the risk of PPD in women, and most models showed good generalization performance and predictive capability [11]. Nevertheless, only a single type of feature selection method or model construction method was used in some studies [3,ÿ46]. Recent literature on prediction models suggested that results from different prediction models would be potentially helpful for accuracy improvement [31]. On the other hand, similar to most psychiatric disorders, PPD has a complex etiology involving an interplay of biopsychosocial factors. Traditional modeling approaches have certain limitations in handling complex and multidimensional data [10]. With the advancement of computer technology and data sciences, the emergence of machine learning (ML) algorithms provides a powerful approach for addressing the limitations of traditional methods and has been widely applied to develop diagnostic or prognostic predictive models for improving health care in public health and medical research fields [30]. Unfortunately, some prediction models for PPD are based on complex ensemble learning algorithms, which may not be interpreted biologically [22,ÿ49]. Moreover, few studies have been translated into clinical assessment tools to guide clinical decision-making.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"Inspired by these advances and limitations, the purpose of the present study was to (1) identify the predictors of PPD, (2) develop multiple risk prediction models for perinatal women, and (3) design various clinical assessment tools for early screening and personalized care.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"This prospective cohort study followed the Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis (TRIPOD) reporting guidelines [13] (Supplementary TRIPOD checklist). Women who underwent obstetric examinations were recruited from a public tertiary maternity hospital between August 2021 and August 2022. To ensure sufficient registry information before and after childbirth, we only recruited women over 18 years of age, had a gestation period ó?21 weeks, and underwent routine obstetric and laboratory examinations until delivery at this hospital. Women with pregnancy losses (including abortion, miscarriage, or stillbirth), as well as those with preterm deliveries (defined as deliveries occurring before 37 weeks of gestation), were excluded from the study. This exclusion was made to minimize the confounding effects of pregnancy-related complications on the prediction of PPD risk, as these conditions are associated with distinct psychological and physiological stressors. In addition, pregnant women diagnosed with fetal structural or chromosomal abnormalities were also excluded. In the study, all participants provided informed consent before participation and were asked to attend four follow-up visits for data collection: second trimester (gestation weeks 21?24), third trimester (gestation weeks 35?40), 2ÿweeks, and 6ÿweeks postpartum.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"Candidate predictors associated with PPD were selected based on a literature review [36,ÿ48] and consulting experts in the field. These predictors are easily ascertained and readily available in different clinical scenarios. The actual data were collected prospectively at four-time points and could be classified into four categories:",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"1. demographic characteristics (age, residence, housing condition, monthly income, education, primiparous women, and planning pregnancy);",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,2. history of mental illness (women were diagnosed with mental illness before pregnancy or first-degree relatives were diagnosed with mental illness);,,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"3. psychosocial factors (primary caregiver in prenatal (PCPN) and postpartum (PCPP), mother-in-law?s care in prenatal (MCPN) and postpartum (MCPP) (a 10-point scale ranging from 1 ?very poor? to 10 ?excellent?), stress-coping style [simplified coping style questionnaire [47] (SCSQ)], personality [Eysenck personality questionnaire [20] (EPQ)] [including psychoticism dimension (EPQ-P), extraversion dimension (EPQ-E), neuroticism dimension (EPQ-N), and melancholic temperament (MT)], social support [perceived social support scale [7] (PSSS)], prenatal anxiety [Beck anxiety inventory [5] (BAI)], prenatal depression [Beck depression inventory [6] (BDI)], marital satisfaction [Enrich marital satisfaction scale [17] (EMSS)], and sleep quality during late gestation [Pittsburgh sleep quality inventory [9] (PSQI)]; and",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"4. physiological measures [women?s blood parameters in the third trimester, including thyroid function tests (TSH, FT3, FT4), blood lipid assays (TG, TC, HDL-C, LDL-C), serum calcium (Ca) and iron (Fe) levels].",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"According to the number of predictor parameters, we performed a sample size analysis using the ?pmsampsize? package in R language and obtained a required sample size of 1014 women. Eventually, 1138 (89.89% overall adherence rate) participants completed all follow-up evaluations and questionnaires. After data collection, all participants were anonymized and assigned internal identification codes. Figureÿ1ÿillustrates the steps of participant recruitment and data collection.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"The PPD outcome was assessed using the Edinburgh Postnatal Depression Scale [14] (EPDS) at 6ÿweeks postpartum. The EPDS is an internationally used 10-item self-report questionnaire to assess the presence and severity of postpartum depressive symptoms. It has satisfactory psychometric properties and has been translated into several languages. The United Kingdom National Institute for Health and Care Excellence guidelines [32] and the United States preventive services task force [39] recommend the EPDS for screening PPD, but a clear cutoff value has yet to be identified. To avoid missed diagnoses and identify most patients, this study?s EPDS cutoff value was set as 11 [27].",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"Before developing the predictive models, seven feature selection methods were applied to the study population to mitigate high correlations among predictors and capture complex relationships between predictors and the outcome variable. These methods were chosen based on their established effectiveness in handling high-dimensional data and identifying the most relevant predictors in predictive modeling. The feature selection methods used were:",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"1. Stepwise Regression (SR): This method can iteratively add or remove predictors based on statistical significance, making it useful for identifying the most important variables while controlling for multicollinearity. We implemented three variations of stepwise regression: forward selection (FS), backward selection (BS), and bidirectional elimination (BE).",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"2. Least Absolute Shrinkage and Selection Operator (LASSO): By applying a penalty to the coefficients of less important predictors, LASSO helps to shrink coefficients toward zero, thus identifying a subset of relevant features while avoiding overfitting.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"3. Random Forest (RF): We utilized two variations of the RF method: mean decrease accuracy (MDA) and mean decrease Gini impurity (MDG). RF was chosen for its robustness in handling nonlinear relationships and interactions between predictors, as well as its ability to rank predictors based on their importance in predicting the outcome.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"4. Support Vector Machine-Recursive Feature Elimination (SVM-RFE): Utilized for its iterative elimination strategy to optimize feature subsets based on model performance, ensuring relevance to the classifier.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"We summarized 35 candidate predictors screened by different filtering methods and took their intersection. Under this approach, we chose the predictors with more than five intersections. Finally, we consulted with clinical experts and combined them with clinical reality to determine the final predictors for developing a predictive model of PPD.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"We calculated the sample size again based on the final predictors to determine the split ratio. Then, the entire dataset was randomly split, stratified by class, into a training and a validation set. The training set was used for model development by six ML algorithms, while the validation set was used for model evaluation. ML algorithms include logistic regression (LR), decision tree (DT), RF, extreme gradient boosting (XGBoost), SVM, and artificial neuron network (ANN). A grid search with fivefold cross-validation was used to obtain optimized parameters (Supplementary Hyperparameter Tuning Details). Furthermore, optimal models were developed separately for prenatal and postnatal women to predict PPD [PN-PPD model (based on prenatal predictors) and PP-PPD model (based on all predictors)].",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"We assessed and compared all models? discrimination, calibration, and clinical net benefit performances. Multiple discrimination metrics included sensitivity (SEN, this is also called Recall) and specificity (SPE), the area under the receiver-operating curve (AUC), the cutoff value, the positive likelihood ratio (PLR), the negative likelihood ratio (NLR), the positive predictive value (PPV, this is also called Precision), the negative predictive value (NPV) and the F1-Score. The AUCs of these models were compared by using the DeLong test. The net reclassification improvement (NRI) and integrated discrimination improvement (IDI) were used to evaluate the additional predictive ability of the PP-PPD model. Calibration was assessed by calibration plots and Brier scores. Clinical usefulness and net benefit were estimated with decision curve analysis (DCA). For interpreting complex optimal models, the SHAP was implemented in Python using the shap package (https://shap.readthedocs.io/en/latest/). We also calculated the importance of ranking features from the final model. Figureÿ2ÿshows the entire analysis workflow of the present study.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"Two independent data entry clerks performed double entry and proofreading to ensure accuracy and reliability. We removed predictors with more than 10% missing values and outliers for data processing. Missing values in less than 10% of variables were imputed using the missForest method. In addition, in the case of sparse data, categories were combined if necessary. In statistical description terms, continuous variables were described as the mean (SD) or median (interquartile range [IQR]) as appropriate. Correlations were determined by Pearson or Spearman analysis. The variance inflation factor (VIF) and tolerance were used to identify collinear independent variables. Univariate analysis was performed using the t-test, chi-square test, or Wilcoxon rank sum test. Statistical significance was defined as a two-sided P value?<?0.05. All data were analyzed using R statistics software (version 4.0.3;ÿhttps://www.r-project.org) and Python (version 3.10.8;ÿhttps://www.python.org).",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"Among the entire dataset, 355 (31.2%) women were above the cutoff values (ò?11) on the EPDS and were regarded as having PPD. The entire cohort?s median age was 29 (IQR 27?32), and 55.4% were primiparous women, while 59.0% were from urban areas. Detailed characteristics of the entire cohort are described in Tableÿ1, and the missing data are summarized in Supplementary Table S1. Women with PPD significantly differed from women without PPD in terms of the MCPN and the MCPP, diagnosis of mental illness before pregnancy, diagnosis of mental illness in first-degree relatives, and SCSQ, EPQ-P, EPQ-E, EPQ-N, MT, PSSS, BAI, BDI, EMSS, and PSQI scores.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"Supplementary Fig. S1 displays correlations between all continuous variables. The correlation heatmap showed that TC was highly correlated with LDL-C, and the correlation coefficient was 0.90 (P?<?0.01). In addition, the correlation coefficient between MCPN and MCPP was 0.50. All variables were analyzed by collinearity analysis (Supplementary Table S2). The VIF of TC was greater than 10 (tolerance less than 0.10), and LDL-C was close to 10 (tolerance close to 0.10), indicating the presence of severe multicollinearity between them [33]. However, MCPP and MCPN did not show multicollinearity.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"The predictor variables obtained by the seven selection methods are shown in Tableÿ2. The specific parameters of all methods (SR-FS, SR-BS, SR-BE, LASSO, RF-MDA, RF-MDG, and SVM-RFE) are shown in Supplementary Table S3 and Figs. S2?4. Thirty-two, 18, 18, 9, 10, 10, and 5 predictors were identified using seven selection methods. Figureÿ3ÿdescribes the intersection of the predictors selected by the seven methods. The predictors with more than five intersections were chosen as the final predictors, including MCPP, BDI, EPQ-N, BAI, TC, PCPP, EPQ-P, MT, and EMSS. Moreover, primiparous women and FT3 were included in the final predictor set through expert consultation and literature review [26,ÿ29]. Ultimately, 11 predictors were included in developing the model. Notably, MCPP and PCPP were measured after childbirth.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"When 11 variables were included, the sample size was again calculated to be 369 women. Therefore, all data were split into training and validation sets at a ratio of 6:4. Supplementary Table S4 provides the descriptive statistics of the two datasets. The training and validation sets were relatively uniformly distributed, in which only the P value of the primiparous women was less than 0.05. The prevalence of PPD was 31.2% in both the training and validation sets. Twelve models were developed by six ML algorithms (PN-PPD and PP-PPD models). The estimates of odd ratios in the LR models are reported in Supplementary Tables S5 and 6 and presented in forest plots (Supplementary Fig. S5 and 6). In addition, Supplementary Figs. S7?14 shows other models? visualization and variable importance.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"Tableÿ3ÿdescribes the PN-PPD model and the PP-PPD model performance metrics of the validation set. The AUC values of the PN-PPD models ranged from 0.683 to 0.801, and the PP-PPD models ranged from 0.727 to 0.858. According to the DeLong test, the models constructed by the LR and ANN algorithms achieved higher AUC values (0.801 [95% CI 0.758?0.844] in the PN-PPD model and 0.858 [95% CI 0.821?0.895] in the PP-PPD model by LR; 0.858 [95% CI 0.821?0.895] in the PN-PPD model and 0.844 [95% CI 0.805?0.883] in the PP-PPD model by ANN) than the other models, and these AUC values were statistically significant (P?<?0.05) (Supplementary Tables S7 and 8). In addition, The LR and ANN algorithms demonstrated higher SEN (i.e., recall), PPV (i.e., precision), and F1 scores among other algorithms. For the PN-PPD model, the LR algorithm had a SEN (i.e., recall) of 0.810 (95% CI 0.745?0.874), a PPV (i.e., precision) of 0.532 (95% CI 0.466?0.599), and an F1 score of 0.642, while the ANN algorithm showed a SEN (i.e., recall) of 0.655 (95% CI 0.577?0.733), a PPV (i.e., precision) 0.554(95% CI 0.478?0.629), and an F1 score of 0.600. For the PP-PPD model, the LR algorithm had a SEN (i.e., recall) of 0.768 (95% CI 0.698?0.837), a PPV (i.e., precision) of 0.669 (95% CI 0.596?0.741), and an F1 score of 0.715, while the ANN algorithm showed a SEN (i.e., recall) of 0.711(95% CI 0.637?0.786), a PPV (i.e., precision) of 0.660 (95% CI 0.585?0.735), and an F1 score of 0.685.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"The discrimination, calibration, and clinical net benefit of the PN-PPD and PP-PPD models on the validation set are shown in Fig.ÿ4. In contrast, the agreement between the observed and predicted events was relatively good with the LR and ANN algorithms and demonstrated a higher net clinical benefit across most ranges of threshold probabilities. On the other hand, compared to the PN-PPD models (except for the decision tree models), the PP-PPD models had higher reclassification and prediction ability (Supplementary Tables S9 and 10). In summary, these results suggest that the LR and ANN algorithms are the optimal ML models for predicting women?s PPD.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"We generated three types of nomograms to provide convenient and personalized risk estimates of PPD. The static and interactive nomograms were assigned in proportion to the effect sizes in the LR model (Supplementary Figs. S15?18). The dynamic nomogram was developed to allow clinicians to enter the values of the variables and then obtain the risk of PPD (https://yongjianwang.shinyapps.io/PN_PPD_Nomogram/ÿandÿhttps://yongjianwang.shinyapps.io/PP_PPD_Nomogram/) (Supplementary Figs. S19 and 20). Moreover, to further improve the clinical application of the models, we calculated the risk-stratification score separately for prenatal and postnatal screening based on the LR coefficients (Supplementary Tables S11 and 12). Tertiles of the total risk scores (16 to 23 for the PN-PPD model and 6 to 19 for the PP-PPD model) were used to categorize low-risk, intermediate-risk, and high-risk groups for perinatal women.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"To explain the complex ANN model, we applied the SHAP value to illustrate how predictors affect women?s PPD. The feature importance and interpretation of the ANN model are shown in Fig.ÿ5. The results demonstrated that the EPQ-N, MCPP, BDI, and BAI were significantly more important than other factors, as shown in Fig.ÿ5A andÿE. In addition, Fig.ÿ5B andÿFÿclearly illustrate the strength and direction of every predictor. A higher MCPP score indicated a lower risk of PPD, and greater neuroticism was associated with a greater risk of PPD in the figures. For local interpretability, Fig.ÿ5C, D, G, and H provides four typical relative samples and shows how the ANN models make clinical decisions for individual women. The SHAP value for every predictor as a force contributed to pushing the overall SHAP value (1?=?with PPD, 0?=?without PPD) higher (red) or pushing it lower (blue), and combined to predict the risk of PPD for individual women. For example, in Fig.ÿ5C, one woman was predicted to suffer PPD due to FT3, EPQ-P, and BAI. The elevated risk was offset by the woman?s MT and EPQ-N.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"This is the first study to present a novel approach to determine the risk factors for predicting PPD by integrating seven feature selection techniques with real-world perinatal data. Unlike previous models that relied on a limited set of predictors, our study incorporates these methods to systematically identify the most relevant risk factors, ensuring a robust and generalizable model. Additionally, by comparing six ML algorithms, we comprehensively evaluate different modeling strategies, demonstrating that LR and ANN algorithms achieve superior predictive performance. A key innovation is the development of interactive risk assessment tools, including nomograms and web-based risk calculators, which facilitate immediate clinical application. Notably, by employing SHAP values to enhance interpretability, our study bridges the gap between complex ML models and practical clinical decision-making, allowing healthcare providers to understand and trust the model?s predictions.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"We selected 11 features associated with PPD, including MCPP, prenatal depression, neuroticism, prenatal anxiety, TC, PCPP, MT, marital satisfaction, primiparity, and FT3 (Fig.ÿ3). Among them, MCPP, prenatal depression, prenatal anxiety, and neuroticism were determined to be the most significant predictors according to the SHAP value (Fig.ÿ5). Our results indicated that low MCPP was significantly associated with an increased risk of PPD, which might be attributed to poor relationships between mothers-in-law and postpartum women [36]. In China, to help women recuperate after childbirth, mothers-in-law usually play an essential role in postnatal care for both the mother and baby during the postpartum period. However, conflicts between mothers-in-law and postpartum women are common due to different parenting views and lifestyles [4]. Thus, inadequate caregiving as a significant stressor increased PPD risk for Chinese women. This is concordant with our prior studies [37]. Notably, in our study, prenatal anxiety and prenatal depression were common in pregnancy and were significantly associated with PPD. This is supported by a large number of previous studies showing that prenatal depression and anxiety are strong predictors of PPD [1,ÿ48]. One possible explanation is that pregnant women with depression or anxiety have more prolonged depressive or anxious symptoms, even into the postpartum period [23]. Another possible reason is that women with a history of mental disorders have a higher recurrence rate after delivery [15]. Interestingly, we found that neuroticism was a significant predictor associated with PPD. Originally defined by Eysenck, neuroticism is a key personality trait for affective processing [16]. Specifically, when faced with stress in the postpartum period, neurotic women tend to experience greater nervousness and are more likely to experience worrying and depression [35].",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"Discrimination, calibration, and clinical net benefit were best in the LR and ANN models (for both PN-PPD and PP-PPD models). Collectively, the newly developed LR and ANN models, which incorporated readily available prenatal and postnatal variables, performed well, as supported by the AUC values of 0.787?0.858 in the validation set. In addition to AUC, we utilize other evaluation metrics, including precision, recall, and F1 score, to evaluate the performance of LR and ANN models. With its relatively simpler structure, the LR model displayed excellent interpretability and high performance across these key metrics. While the ANN model demonstrated a similar AUC and F1 score, it has the advantage of powerful self-learning capabilities, which make it particularly well-suited for capturing complex nonlinear relationships in the data. The higher F1 scores of LR and ANN models indicate that both models strike a reasonable balance between precision and recall, thus ensuring that false positives and negatives are minimized, which is critical in clinical decision-making. For the term of calibration, the agreements between prediction and actuality are shown in the calibration plots. More importantly, the decision curve analysis showed that the LR and ANN models could provide good clinical net benefits to support clinical decision-making. Regarding model applicability, the LR model has the characteristics of a simple structure and strong interpretability. Compared with the LR model, the ANN model has powerful self-learning capabilities and an outstanding advantage in dealing with nonlinear relationships. However, the difference in prediction performance between the two models was insignificant in the study. Furthermore, adding postnatal predictors to the prenatal models can improve prediction performance. Therefore, we recommend combining prenatal and postnatal predictors to enhance the predictive accuracy of PPD. In future research, better prediction results may be achieved with more prenatal and postpartum clinical information.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"Despite the growing interest in ML models for clinical decision-making, most published prediction models never reach clinical practice. This may be because the models are difficult to understand or because the results lack representativeness and reproducibility [18]. In this study, we primarily included clinically applicable and easy to identify predictors. For clinical use of the optimal model, we designed various risk assessment tools to enable physicians to identify high-risk women immediately. According to the LR algorithm, the nomogram could serve as a tool to evaluate the risk ratio of PPD. On this basis, we developed a website calculator, which may be readily integrated into secondary care to improve screening efficiency and reduce the burden on physicians. In addition, applying risk scores opens new opportunities to enhance risk stratification and to help prevent PPD. Of note, due to its black-box nature, it is difficult for the ANN model to provide meaningful physician interpretations. Interpretability is generally defined as the ease with which humans can comprehend and explain the process of the ML model?s predictions [41]. To address this problem, we applied SHAP values to obtain more readily understandable interpretations. SHAP values are widely accepted and are useful for explaining the relationship between variables and outcomes [21]. It can help physicians better understand the model's decision-making process for appropriate early intervention for women with PPD. Overall, adopting risk assessment tools developed in this study could provide rapid results to physicians.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"From a clinical perspective, this study has significant implications for improving PPD screening and intervention strategies. Traditional screening methods for PPD are often time-consuming and require trained personnel, limiting their scalability in resource-constrained settings. The ML-based models developed in this study provide a rapid and automated risk assessment framework, allowing early identification of high-risk individuals. Moreover, by integrating both prenatal and postpartum predictors, these models offer a dynamic approach to monitoring maternal mental health from pregnancy to postpartum recovery. The practical implementation of our risk assessment tools in clinical settings can facilitate targeted interventions, optimize resource allocation, and improve maternal and neonatal outcomes. We suggest that these tools could be embedded in hospital electronic health record systems and routine perinatal care in the future. Clinicians can utilize these assessment tools in real-time during prenatal and postpartum visits for prenatal PPD risk stratification and postpartum PPD monitoring. During routine prenatal screenings, clinicians can input readily available variables into the web-based calculator to generate individualized PPD risk scores. This enables early identification of high-risk women, prompting targeted mental health interventions such as counseling or prophylactic therapy. Moreover, pregnant women outside the hospital can use the web calculator to self-assess their PPD risk. The dynamic integration of postnatal predictors allows for ongoing risk reassessment during postpartum checkups, ensuring timely adjustments to care plans. However, several potential barriers to their implementation must be acknowledged. First, embedding these tools into electronic health records requires interoperability with existing hospital systems, which may involve technical and administrative hurdles. Second, healthcare providers may need training to effectively interpret ML-derived risk scores and SHAP-based explanations. Notably, the ethical implications of false positives and negatives in PPD prediction warrant careful deliberation. Overestimation of risk could lead to unnecessary psychological interventions, increasing perinatal women?s anxiety and healthcare costs, and underestimation of risk may delay critical interventions. While SHAP values enhance interpretability, clinicians must remain vigilant against over-reliance on model outputs. Therefore, we recommend combining model predictions with clinical judgment and longitudinal symptom monitoring to ensure perinatal women?s safety and well-being. Additionally, clinicians should be aware of the potential psychological impact on patients when these assessment tools are used for risk prediction, and appropriate counseling should be provided when necessary.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"Several study limitations need to be discussed. First, while the prospective design and robust internal validation via cross-validation strengthen methodological rigor, the absence of external validation on independent cohorts remains a critical constraint. The single-center nature of our dataset introduces potential selection bias and may limit the model?s generalizability to populations with distinct demographic profiles, clinical practices, or regional healthcare systems. To address this, future multicenter collaborations will be prioritized to validate and refine the model across diverse settings, ensuring broader clinical applicability. Second, this study primarily focused on second- and third-trimester pregnancies, and first-trimester information was not collected. In future studies, to further improve the accuracy, the number of variables or specific markers could be increased to estimate PPD. Finally, the women in the entire dataset could only be considered representative of the Chinese population with caution, and the risk assessment tools in postpartum were more likely suitable for women who were cared for by their mothers-in-law. MCPP and PCPP have unique Asian cultural features as predictors of postpartum and need to be considered in future research and clinical application.",,,,,
Prediction of postpartum depression in women: development and validation of multiple machine learning models,"In this study, by combining biopsychosocial risk factors for PPD, we developed and validated ML predictive models to identify the risk of PPD. The LR and ANN models showed excellent and reliable prediction performance. Combining prenatal and postnatal predictors to establish predictive models can significantly improve prediction performance. Various risk assessment tools are easily implemented in practice and could help physicians make clinical decisions easily. Therefore, we believe that our study could be utilized to individually predict the risk of PPD in prenatal and postnatal women, thus assisting clinicians in early precise intervention and effectively reducing or delaying the development of PPD. However, external validation is required to demonstrate the accuracy of the model?s predictions in future studies.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"The use of natural language processing (NLP) in mental health research is increasing, with a wide range of applications and datasets being investigated.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"This review aims to summarize the use of NLP in mental health research, with a special focus on the types of text datasets and the use of social determinants of health (SDOH) in NLP projects related to mental health.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"The search was conducted in September 2024 using a broad search strategy in PubMed, Scopus, and CINAHL Complete. All citations were uploaded to Covidence (Veritas Health Innovation) software. The screening and extraction process took place in Covidence with the help of a custom large language model (LLM) module developed by our team. This LLM module was calibrated and tuned to automate many aspects of the review process.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"The screening process, assisted by the custom LLM, led to the inclusion of 1768 studies in the final review. Most of the reviewed studies (n=665, 42.8%) used clinical data as their primary text dataset, followed by social media datasets (n=523, 33.7%). The United States contributed the highest number of studies (n=568, 36.6%), with depression (n=438, 28.2%) and suicide (n=240, 15.5%) being the most frequently investigated mental health issues. Traditional demographic variables, such as age (n=877, 56.5%) and gender (n=760, 49%), were commonly extracted, while SDOH factors were less frequently reported, with urban or rural status being the most used (n=19, 1.2%). Over half of the citations (n=826, 53.2%) did not provide clear information on dataset accessibility, although a sizable number of studies (n=304, 19.6%) made their datasets publicly available.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"This scoping review underscores the significant role of clinical notes and social media in NLP-based mental health research. Despite the clear relevance of SDOH to mental health, their underutilization presents a gap in current research. This review can be a starting point for researchers looking for an overview of mental health projects using text data. Shared datasets could be used to place more emphasis on SDOH in future studies.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Natural language processing (NLP) has emerged as a valuable tool in mental health research, offering innovative ways to extract and analyze information from various sources. Studies have shown the feasibility of using NLP in extracting evidence of online gaming and internet use from electronic health records (EHRs) in adolescent mental health patients [1]. NLP applied to clinical notes has been found to more accurately identify mental illness and substance use among people living with HIV compared to structured EHR fields alone [2]. Furthermore, NLP in healthcare enables the transformation of complex narrative information into valuable products like clinical decision support and adverse event monitoring in real-time via EHRs [3,4].",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Outside of EHRs, NLP techniques have been used to make inferences about individuals? mental states based on their social media posts [5]. Additionally, NLP, coupled with machine learning approaches, has shown promising performance in tasks such as text classification and sentiment mining in mental health contexts [6]. The application of NLP extends to identifying work-related stress among health professionals, highlighting its versatility in diverse health care settings [7].",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"In the context of mental health disorders like schizophrenia, schizoaffective disorder, and bipolar disorder, NLP applied to EHRs offers opportunities to create large datasets for research purposes [8]. Furthermore, NLP has been used to increase prediction accuracy and reduce subgroup differences in personnel selection decisions, showcasing its value in improving decision-making processes [9].",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"At the same time, getting access to text datasets for NLP analysis is challenging for many researchers. Many of the datasets have strict privacy and personal data protection policies restricting access to the data for third-party researchers. This hinders research and introduces the problem of reproducibility since the results of the studies cannot be verified by unaffiliated investigators. One of the aims of this review is to compile a collection of datasets that are available to the mental health research community, which, in turn, may facilitate research in the field of mental health.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Another potential problem with research using NLP for mental health is insufficient consideration of social determinants of health (SDOH) information during the analysis. The association between social determinants and mental health outcomes is well-established, with factors such as poverty, inequality, stigma, discrimination, and social exclusion identified as significant contributors to mental health burdens [10,11]. NLP has become a valuable tool for extracting SDOH from sources like clinical notes, social media, and EHR in health care research [12-15]. Evaluating the use of SDOH in NLP projects for mental health is another goal behind this review.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"To our knowledge, no previous study has examined the range of NLP datasets and the inclusion of SDOH data in research projects that use NLP for mental health. We have opted for a scoping review following the guidelines outlined by Arksey and O?Malley [16]. The goals of this scoping review are to review and summarize the literature on (1) the variety of mental health areas that leverage NLP, (2) information on the types of text datasets used in these projects and whether they are sharable, and (3) the extent to which SDOHs are used or investigated in these projects.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"A novel aspect in this scoping review is the use of large language models (LLMs), a subfield of generative artificial intelligence (AI), to automatically parse a large volume of citations to find relevant studies and extract information under the minimal supervision of a human reviewer. A recent statement by the National Institute for Health and Care Excellence highlights the potential of AI in the systematic review process automation [17].",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"This study was created and revised following the recommendation of PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) and updated JBI (formerly known as Joanna Briggs Institute) guidance for the conduct of scoping reviews [16,18-20,undefined,undefined]. The completed PRISMA-ScR checklist can be found inÿMultimedia Appendix 1.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,All publications were considered if they did not meet one or more of the exclusion criteria. Citations were excluded if:,,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"They did not use any type of NLP, such as transformers, pattern-matching (eg, regular expressions), ChatGPT, GPT-3, Bidirectional encoder representations from transformers, Llama, Mistral, other LLMs, latent Dirichlet allocation and latent semantic analysis, deep learning or machine learning applied to text, and similar.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"They were not focused on one of the mental health areas, such as psychology, well-being, psychiatry, social work, substance abuse, marriage therapy, addiction therapy, suicide, grief, bereavement, trauma, stressful life events, or counseling.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"They were review papers (systematic, scoping, literature, narrative, and other type of reviews), conference papers, or book chapters.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,They were not related to human health or well-being.,,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"PDF file of the full-text publication could not be located automatically using Covidence (Veritas Health Innovation), EndNote (Clarivate), and Zotero (Corporation for Digital Scholarship).",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"The initial search was conducted in September 2024 in PubMed, Scopus, and CINAHL Complete databases using title and abstract search filters. The search strategy (designed by DAS and JSO) was broad enough to capture different NLP and machine-learning methods related to mental health.ÿTextbox 1ÿpresents the search query for the databases.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"All citations were uploaded to Covidence, which was used to track the progress of the project in lieu of the protocol. The screening and extraction process took place in Covidence. The specific method we used to conduct this review was automating the process of screening and extraction with the help of the LLM module for Covidence that we developed. The process of using LLM for screening and extraction is depicted inÿFigure 1.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Our LLM module works by interacting with Covidence using R scripts with the Selenium automation package [21]. Our scripts, which can run both locally or on a server, pass content between Covidence and an Azure OpenAI LLM (Microsoft Corporation) using the application programming interface wrapped in the Python ?openai? library [22]. The models used in this study were GPT-4o and GPT-4o-mini. Once the model generates the response, our add-on module automates actions in Covidence, such as clicking the Include/Exclude buttons. Our automation scripts require a PDF file of the full text to be uploaded into Covidence for full-text screening and extraction. The LLM module supports non-English languages natively. Our software code used in this module is still under development and has not yet been made public; however, the LLM prompts for each phase of the review are provided inÿMultimedia Appendix 2. A similar approach was described in our recent paper on the utility of LLMs in literature reviews [23].",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"The resulting process can be described as follows. Each of the three main stages of review in Covidence (abstract screening, full-text screening, and extraction) included (1) a calibration phase, where a human reviewer (DAS) experienced in conducting scoping and systematic reviews screened a small sample of abstracts or full-text studies to get a deeper understanding of inclusion criteria and extraction categories; (2) we then created a prompt for the LLM and tested the LLM performance on another sample of abstracts or full texts; and (3) three repeated requests to the LLM with the same prompt were automated using software scripts, and the majority vote principle was used to determine the LLM vote (eg, LLM votes for an abstract: ?include,? ?exclude,? ?include? means LLM final vote is ?include?). Out of these three requests, two were made using GPT-4o-mini and one using more powerful GPT-4o for screening; all three requests used GPT-4o-mini for extraction to cut application programming interface costs.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"During the benchmark, a human reviewer (DAS) first compared his votes against the LLM votes to produce a new reference set of labels (called ?human-LLM consensus?). This step is required because LLM can detect cases missed by a human. Then, both the initial human reviewer?s (DAS) and LLM votes were measured against the human-LLM consensus labels. Extraction precision was measured using a simplified benchmark where the LLM results on 30 publications were checked by a human reviewer (DAS) for precision only. The benchmarks are provided inÿMultimedia Appendix 3.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,The data charting form for extraction was designed by human experts (DAS and JSO) and adopted into the LLM prompt to collect the following primary information:,,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"NLP method that was used (generally described in the Methods section), for example, recurrent neural network, convolutional neural network (CNN), random forest, deep learning, pattern-matching, ChatGPT, and GPT-4",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,What mental health problem or problems were investigated in the paper?,,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"What is the mental health area or specialty that best represents this paper (psychology, well-being, psychiatry, social work, substance abuse, marriage therapy, addiction therapy, suicide, grief, bereavement, trauma, stressful life events, counseling, other)?",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Variables used in the study related to demographics, for example, age, race, ethnicity, gender, sex at birth, marital status, relationship status, and sexual orientation",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Variables used in the study related to SDOH, such as none mentioned, urban or rural, transportation availability, access to health care, incarceration, income, poverty, health insurance, language knowledge, living arrangement, children or childless, family, adverse childhood experiences, housing, education, religion, stress, traumatic events, and stressful life events",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,Name of the text dataset that was used in the study,,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"What is the type of this text dataset (eg, clinical notes, therapy session notes, social media platforms, web forum, other)?",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,What information or variables were extracted from this text dataset?,,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,Is it mentioned in the paper if other researchers can get access to this text dataset?,,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"If it is mentioned in the paper that it is possible to get access to this text dataset, what kind of access is it (eg, public, public with restrictions, private, not given, not mentioned)? If the dataset can be found on the web or in well-known competition platforms like Kaggle, it is considered public",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"If it is mentioned in the paper that access to this text dataset is public or public with restrictions, what is required to get access (can be training, signing a use agreement, emailing the author, or similar)?",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"A URL to the text dataset, if provided. The returned URL was validated using an R script to test if an ?OK? reply is returned by the server.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Extracted results were synthesized using a table with a complete list of all citations, using maps for location information and column plots displaying frequency statistics for other extracted variables.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"ChatGPT with the GPT-4o model was used to clean the extraction data, specifically, format the case, remove duplicates, and sort entries into higher-level groups. Scite.ai (Research Solutions) was used to draft parts of theÿIntroductionÿandÿDiscussionÿsections, while ChatGPT was used to draft the abstract andÿResultsÿsection of this paper by generating text and R code snippets. All output generated by the LLMs was verified, reviewed, and edited by the authors. Due to the significant number of reviewed citations, publication information, such as authors, title, and DOI, is provided inÿMultimedia Appendix 4.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"During the abstract and title screening phase, 8197 studies were excluded based on the exclusion criteria, leaving 3681 studies for retrieval. Out of these, 1649 studies could not have their full-text PDFs retrieved using automated tools such as Covidence or EndNote. Consequently, 2032 studies were assessed for eligibility. Of these, 264 studies were excluded for the following reasons: 217 studies were not focused on one of the mental health areas, 39 studies did not use any NLP methods, 1 study was too brief and lacked sufficient information, and 2 studies were review papers (systematic, scoping, literature, narrative, or other types of reviews), and 5 additional duplicates were identified during full-text screening. The final review included 1768 studies. The flow diagram of the scoping review process is shown inÿFigure 2.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Figure 3ÿillustrates the geographic distribution of 1768 studies reviewed in this analysis. Most studies originated from the United States, with 624 (35.3%) studies. China contributed 197 (11.1%) studies, followed by the United Kingdom (n=167, 9.4%) and India (n=120, 6.8%).",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Canada contributed 51 (2.9%) studies. Other notable contributors include Japan with 49 (2.8%) studies, Spain with 39 (2.2%) studies, Australia with 38 (2.1%) studies, South Korea (n=27, 1.5%), Germany (n=26, 1.5%), the Netherlands (n=25, 1.4%), Saudi Arabia (n=24, 1.4%), Italy (n=22, 1.2%), and France (n=21, 1.2%), and several other countries each contributing between 1 and 16 studies.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Within the United States, Massachusetts led the contributions with 88 (14.1%) studies, followed by California with 66 (10.6%) studies. New York contributed 55 (8.8%) studies, while Pennsylvania provided 43 (6.9%) studies. Ohio and Illinois each contributed 21 (3.4%) studies. Other states, such as Utah, Washington, and Texas, contributed 20 (3.2%), 19 (3%), and 18 (2.9%) studies, respectively. Michigan and Florida each added 16 (2.6%) studies, while Maryland, Georgia, and Indiana each contributed 15 (2.4%) studies. Tennessee, Minnesota, and Connecticut each contributed 14 (2.2%) studies, followed by New Jersey, Oregon, and South Carolina with 13 (2.1%) studies each. Other states contributed fewer than 10 studies.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Figure 4Aÿillustrates the various mental health topics covered in the reviewed papers. The most frequently discussed topic is depression, which is covered in 518 (29.3%) papers. This is followed by suicide, featured in 273 (15.4%) papers, and anxiety, discussed in 202 (11.4%) papers. Substance use disorder is also a significant topic, appearing in 166 (9.4%) papers, while mental health (unspecified) is mentioned in 120 (6.8%) papers.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Other notable topics include stress (n=62, 3.5%), dementia (n=59, 3.3%), posttraumatic stress disorder (n=53, 3%), and schizophrenia (n=53, 3%). Bipolar disorder appears in 43 (2.4%) papers, and domestic violence is discussed in 29 (1.6%) papers. Eating disorders are mentioned in 26 (1.5%) papers, while cyberbullying and cancer-related topics are covered in 23 (1.3%) and 22 (1.2%) papers, respectively. Self-harm is discussed in 21 (1.2%) papers, and loneliness is covered in 19 (1.1%) papers.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Additionally, other mental health issues such as attention-deficit/hyperactivity disorder (n=18, 1%), psychosis (n=18, 1%), autism spectrum disorder (n=17, 1%), and diabetes-related mental health issues (n=13, 0.7%) are also represented. Topics such as pain (n=12, 0.7%) and fear (n=11, 0.6%) are covered, along with personality traits (n=11, 0.6%) and burnout (n=8, 0.5%). A variety of other mental health topics appear in 1?7 papers.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Figure 4Bÿillustrates the various NLP methodologies and tools discussed in the papers. The most frequently mentioned are neural network models (n=499, 28.2%), which include examples such as CNN, long short-term memory (LSTM), Bidirectional LSTM-CNN (BI-LSTM-CNN), gated recurrent unit, and recurrent neural network. Other machine learning models are discussed in 289 (16.3%) papers, highlighting the use of random forest, support vector machine, regression models, and gradient boosting trees.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Transformer models appear in 312 (17.6%) papers, examples include Bidirectional encoder representations from transformers, GPT-3, LLAMA-2, and Roberta. NLP tools are featured in 264 (14.9%) papers, which use tools such as Spacy NLP Library, Stanford CoreNLP, and GATE for processing and analyzing text data. Topic modeling and text mining are discussed in 258 (14.6%) papers, using techniques such as latent Dirichlet allocation, structural topic modeling, and biterm topic modeling for extracting themes and patterns from text data.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Traditional text representation and embedding methods are mentioned in 90 (5.1%) papers, including methods such as term frequency-inverse document frequency, Word2Vec, and N-gram representation. Unspecified machine learning approaches appear in 61 (3.4%) papers, while sentiment analysis is discussed in 31 (1.8%) papers. Finally, linguistic inquiry and word count (LIWC) is mentioned in 22 (1.2%) papers, showcasing tools such as LIWC15 Text Analysis and LIWC Dictionaries. Rule-based methods are included in 15 (0.8%) papers.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Sentiment analysis is discussed in 30 (1.9%) papers, with approaches such as Valence Aware Dictionary and sEntiment Reasoner, aspect-based sentiment analysis, and text sentiment analysis. Rule-based methods are featured in 15 (1%) papers, using approaches such as pattern-matching and lexicon-based NLP to perform specific text-processing tasks based on predefined rules. Finally, Bayesian models are mentioned in 3 (0.2%) papers, where techniques, for example, Bayesian networks and Bayesian logistic regression, are applied, indicating a more niche focus on this approach within the reviewed literature. The other category, covered in 355 (20.1%) papers, represents a wide range of techniques beyond the most common methods, including various specialized or less frequently used approaches.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Figure 4Cÿpresents an overview of the types of datasets used in the reviewed studies. The most commonly used dataset type is clinical data, which appears in 751 (42.4%) papers, followed by social media datasets with 592 (33.4%) papers. Web forums have some representation as well, with 89 (5%) papers, and the other category comprises 99 (5.6%) papers. Survey data is also notable, appearing in 23 (1.3%) papers, while mobile and digital health data is used in 21 (1.2%) papers.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Less frequently used datasets include counseling data (n=14, 0.8%), audio and video data (n=14, 0.8%), and chatbot and AI interaction data (n=8, 0.5%). The studies and academic texts category is represented in 9 (0.5%) papers, while websites and web platforms account for 7 (0.4%) papers. Blogs and web studies have 4 (0.2%) papers.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Other datasets, such as diary and personal account data and synthetic data, each appear in 2 (0.1%) papers, along with focus groups, which are represented in 3 (0.2%) papers. Finally, YouTube data is noted in 1 (<0.1%) paper, indicating niche areas of study or emerging methodologies within the broader field.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Figure 5Aÿpresents a detailed overview of the demographic variables frequently used in the reviewed studies. Age is the most commonly extracted variable, appearing in 993 (56.2%) studies. Following closely is gender, featured in 863 (48.8%) studies. Other significant demographic variables include race (n=171, 9.7%) and ethnicity (n=161, 9.1%). Sex is documented in 114 (6.4%) studies, while marital status appears in 101 (5.7%) studies.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Less frequently reported variables include education (n=48, 2.7%), race or ethnicity (n=46, 2.6%), and insurance (n=26, 1.5%). Income is mentioned in 19 (1.1%) studies, with employment in 15 (0.8%) studies, relationship status in 13 (0.7%) studies, and occupation in 8 (0.5%) studies. More specialized demographic insights are provided by variables, for example, nationality (n=6, 0.3%), religion (n=4, 0.2%), and region (n=3, 0.2%). Additionally, niche variables such as aboriginal status, career, and socioeconomic status are noted, each appearing in 2 (0.1%) studies.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Figure 5Bÿoffers an overview of the SDOH variables used in the reviewed studies. The urban or rural status is the most frequently reported variable, appearing in 20 (1.2%) studies. Following closely is the deprivation index, included in 17 (1.1%) studies. Income is mentioned in 11 (0.7%) studies, underscoring its significance in assessing economic conditions.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"It is important to highlight that demographic variables had a notable number of false positives during extraction, with a precision rate of 0.66, suggesting that the actual counts for gender and age may be significantly lower.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"The relevance of access to health care and insurance is reflected in their occurrence in 9 (0.5%) and 8 (0.5%) studies, respectively. Education and socioeconomic status are recorded in 6 (0.4%) studies each, while housing is featured in 5 (0.3%) studies.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Less frequently reported variables include poverty and substance use, each appearing in 4 (0.3%) studies, as well as employment status and prior illness, each in 3 (0.2%) studies. Additional variables such as unemployment (n=2, 0.1%) and various specific factors?for example, domestic violence, drug involvement, and others?are noted in just 1 (0.06%) study each.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Table 1ÿshows the most frequently extracted information from the text datasets. The scope of extracted data includes information related to sentiments and emotions, health conditions, health symptoms, personality traits, violence and bullying, suicide indicators, user engagement (likes, shares), survey data, and language features, to name a few.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"A significant majority of studies (n=911, 51.5%), did not clarify whether their datasets were accessible, while 857 (48.5%) studies included access information for their datasets. Regarding the specific levels of access, the vast majority of studies fell into the ?unclear? category, with 1128 (63.7%) studies failing to provide explicit information about dataset accessibility. In contrast, 362 (20.5%) studies indicated that their datasets were publicly accessible, while 263 (14.9%) studies allowed public access with certain restrictions, thus enabling data use under specific conditions. Only a minimal number of studies categorized their datasets as private, with just 9 (0.5%) studies restricting access to particular individuals or groups. Additionally, 4 (0.2%) studies did not provide any information regarding their dataset access levels.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Additional information on the text datasets, access levels, links, and other extracted information can be found inÿMultimedia Appendix 4.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Our LLM-assisted scoping review revealed a wide range of projects related to mental health topics that use NLP. The United States was the dominant source of publications, with more than a third of all publications, but China, the United Kingdom, and India follow closely behind, reflecting the worldwide interest in the application of NLP to mental health problems. The United States has a significant concentration of funding and resources dedicated to mental health research, which is not as prevalent in low- and middle-income countries with financial constraints and inequities in health care resources [24,25]. The disproportionate share of high-income countries in our review is noted by other authors as ?the 90:10 research gap,? where 90% of mental health research focuses on the 10% of the global population residing in high-income countries, including the United States [26].",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Depression emerged as the top mental health problem investigated, reflecting the current trends: a study by Wang et al [27] using Google Trends data in the United States reported a 61% increase in depression prevalence from 2008 to 2018. Another study by Jonson et al [28] in Sweden observed a decline in depression prevalence among 85-year-olds, potentially influenced by rising trends in younger age groups. The topic of suicide was especially well represented in our sample, highlighting the fact that suicide mortality remains a significant global public health concern. This finding is echoed by studies indicating that suicide continues to be a notable contributor to mortality worldwide [29].",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Artificial neural networks appear to dominate the landscape of tools used in NLP research, with transformer models catching up in the race. Artificial neural networks represent a large and versatile category of machine learning algorithms that typically require a significant amount of training data, whether supervised or unsupervised [30]. The self-organizing, self-learning, and parallel distributed information processing capabilities of neural networks have made them invaluable in pattern recognition, signal processing, and optimization problems [31]. Moreover, artificial neural networks are recognized for their versatility in solving nonlinear problems with multiple independent variables [32], including NLP tasks.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Clinical data and social media dominate the types of datasets that were used in the reviewed papers, showing two major avenues of NLP mental health research, one with medical records data and the other with using public social media platforms.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"As for SDOH and demographic variables, there is considerable overlap between the two in the extracted data. Previous work suggests that demographic variables should be part of SDOH; for example, the commonly used variable marital status reflects the social connections, stage of life, and other important social implications for individuals? health [33]. The same can be said about age, the most frequently reported demographic variable. Research has shown that disparities in mental health outcomes persist across different age groups and are often linked to social stress, discrimination, and stigma [34]. These disparities can be exacerbated by obstacles to health care access based on factors such as ethnicity, sex, and occupation [35].",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"A narrative review by Shokouh et al [36] explores the idea that demographic variables could be considered an essential part of SDOH. A similar solution is to think of them as combined ?sociodemographic factors? [37], where both demographic and social factors play an equally important role.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"This review suggests that social and demographic factors, besides gender and age, were rarely used in the studies, highlighting a significant gap that should be addressed in future work. In addition, a manual review of LLM outputs (seeÿMultimedia Appendix 3ÿfor benchmark) revealed that the demographic variables category had a high rate of false positivity, which suggests that gender and age were actually used even less frequently than our numbers indicate. Most commonly, they were reported in the introduction sections as important factors and ignored in the actual analysis.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"The paucity of mental health NLP studies that consider SDOH is concerning, especially considering that these factors, including stress, marital status, race, gender-based discrimination, and many others, have been shown to impact mental health outcomes [38]. One of the challenges for mental health researchers is a lack of versatile NLP tools that would allow the extraction of attributes related to SDOH and demographics. For example, while NLP models for extraction of marital status and gender exist [39,40], few models can extract a big range of SDOH at once [41], making a subgroup analysis limited to select demographic attributes (eg, age and gender). Another solution could be to extract this information from structured data. However, this is often not feasible; for example, social media metadata rarely contain information about age, region, and other sociodemographic attributes, while EHRs that contain clinical notes do not routinely collect social information [41].",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Our review method proved to be sensitive at detecting relevant citations and fetched our previous work on suicide, self-harm, opioid addiction, and other topics [42-50]. LLM performance in this review surpassed the performance of a single human reviewer during the screening phase, as evident from the screening benchmarks. Reviews conducted by more than one individual human could reduce selection bias but would require significant additional research effort. Based on the estimation methodology provided by Haddaway and Westgate [51], we estimate this effort to be approximately 3500 person-hours (ie, close to a year of work for two reviewers) to conduct a review of such scope. In addition, the LLM method allowed for the inclusion of non-English papers, as LLMs are multilingual, potentially reducing the language bias; however, the performance of OpenAI GPT can vary depending on the language and the task [52], and we did not benchmark the LLM performance in other languages.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Future work could be facilitated by this review, which revealed a considerable number of shared research datasets, including URLs for some. In fact, over 600 publications disclosed the datasets they used and the level of access as public or semipublic. Disclosure of dataset use is important in research because it increases reproducibility and facilitates collaborative secondary research using existing data. A recent publication has reported that over half of the studies in psychology could not be replicated [53], which is why it is crucial to be transparent about the datasets used and the NLP methods used. Moreover, making both the code and data available to the scientific community whenever possible or providing information on why access to data is restricted is also valuable. A dataset prepared for a specific study can be used in secondary research different from the original work and may help prevent redundant data collection. A 2024 crowdsourcing challenge on HeroX was specifically aimed to ?demonstrate the power of data reuse in advancing human health by proposing an impactful secondary data analysis research project? and promoted the reuse of data that has already been published.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,Finding data for research is always challenging. We hope that this review can serve as a stepping stone in mental health research that leverages NLP.,,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"We used LLMs, with prompts engineered using a small subset of studies, as assistants in this review project. Some extraction categories, such as demographic variables, had relatively lower accuracy, so the results of this extraction category should be taken with caution. Nevertheless, in this review, LLMs achieved remarkable results in other categories, making it possible to delegate time-consuming aspects of a literature review to the LLM, allowing researchers to spend more time on the supervision, benchmarking, and synthesis of the findings.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"This study used a single human reviewer assisted by LLMs. Studies generally recommend a single-reviewer approach in some cases, such as rapid reviews [54]; however, we believe that the LLM approach could automate many of the mundane aspects of literature reviews, allowing human authors to redirect their effort toward the supervision and synthesis of the results.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"Our method relies on the availability of PDFs for publications. A considerable number of papers did not have accessible PDF versions using the citation manager tools, for example, EndNote and Zotero. Thus, we had to exclude these papers from our analysis. However, we believe that the number of full-text citations that we obtained was large enough to get a statistical representation of the extracted categories and to support our observed findings discussed above.",,,,,
Natural Language Processing and Social Determinants of Health in Mental Health Research: AI-Assisted Scoping Review,"This review highlights the range of projects using NLP for mental health areas, with depression and suicide being the most frequent topics under study. Social determinants were only used in a handful of papers, with traditional demographic variables, such as age and gender, being more frequent. The extracted information could be leveraged by other researchers pursuing text datasets for mental health research projects in specific areas.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"Machine learning can be used to define subtypes of psychiatric conditions based on shared biological foundations of mental disorders. Here we analyzed cross-sectional brain images from 4,222 individuals with schizophrenia and 7038 healthy subjects pooled across 41 international cohorts from the ENIGMA, non-ENIGMA cohorts and public datasets. Using the Subtype and Stage Inference (SuStaIn) algorithm, we identify two distinct neurostructural subgroups by mapping the spatial and temporal ?trajectory? of gray matter change in schizophrenia. Subgroup 1 was characterized by an early cortical-predominant loss with enlarged striatum, whereas subgroup 2 displayed an early subcortical-predominant loss in the hippocampus, striatum and other subcortical regions. We confirmed the reproducibility of the two neurostructural subtypes across various sample sites, including Europe, North America and East Asia. This imaging-based taxonomy holds the potential to identify individuals with shared neurobiological attributes, thereby suggesting the viability of redefining existing disorder constructs based on biological factors.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"Machine learning can be used to identify subtypes of psychiatric disease. Here the authors identified two neurostructural subgroups in schizophrenia, each showing reproducibility and generalizability across different collection locations and illness stages, using the SuStain algorithm.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"Schizophrenia is one of the most severely disabling psychiatric disorders with a life-time prevalence of 1%; it affects approximately 26 million people worldwide1. The etiology of schizophrenia is still not fully understood. Current knowledge implicates multiple neurobiological mechanisms and pathophysiologic processes2,3. Furthermore, people diagnosed with schizophrenia show a substantial heterogeneity in clinical symptoms4, disease progression5, treatment response6, and other biological markers7,8. In addition, currently available treatments are not aligned with specific pathophysiological pathways/targets, which limits effectiveness of treatment selection9. Establishing a new taxonomy by identifying distinct subtypes based on neurobiological data could help resolve some of these heterogeneity-induced challenges. A key goal is to define biological subtypes, based on objective measures derived from imaging and other biomarkers10.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"Artificial intelligence methods such as machine learning can be applied to brain imaging11ÿto categorize individuals based on their profiles of brain metrics, and holds the potential for revealing the underlying neurobiological mechanisms associated with disorder subtypes12. Machine learning algorithms are increasingly used to subtype brain disorders13?16. Prior studies have primarily focused on grouping individuals into distinct categories without considering disease progression17,18. A major obstacle to identifying distinct patterns of neuro-pathophysiological progression (referred to as progression subtypes) stems from the lack of sufficient longitudinal data covering the lifespan of the disorder. Recently, a data-driven machine learning approach known as Subtype and Stage Inference (SuStaIn) was introduced19. SuStaIn uses a large number of cross-sectional observations, derived from single time-point MRI scans, to identify clusters (subtypes) of individuals with common trajectory of disease progression (i.e., the sequence of MRI abnormalities across different brain regions) in brain disorders20?23. It should be noted that SuStaIn estimates the pseudo-longitudinal sequence (i.e., SuStaIn trajectory) based on only cross-sectional data. Therefore, the fitted SuStaIn trajectories do not directly reflect the actual pathophysiological progression of the illness. By applying SuStaIn to MRI data from individuals with schizophrenia, primarily collected from the Chinese population, we found that the progression of gray matter loss in schizophrenia can be better characterized through two distinct phenotypes: one characterized by a cortical-predominant progression, originating in the Broca?s area/fronto-insular cortex, and another marked by a subcortical-predominant progression, starting in the hippocampus22. Such brain-based taxonomies may reflect neurostructural subtypes with shared pathophysiological foundations, with relevance for neurobiological classification22. However, the generalizability of the two neurostructural subtypes to diverse populations outside of China, and external validation of the subgrouping is required before applying this knowledge to stratify clinical trials.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"The Enhancing Neuro Imaging Genetics through Meta-Analysis (ENIGMA,ÿhttp://enigma.ini.usc.edu) consortium is dedicated to conducting large-scale analyzes by pooling brain imaging data from research teams worldwide, using standardized image processing protocols. Previously, ENIGMA published findings revealing thinner cerebral cortex, smaller surface area, and altered subcortical volumes in schizophrenia compared to controls24,25. Here, we included structural MRI data obtained from 4291 individuals diagnosed with schizophrenia and 7078 healthy controls from 41 international cohorts from ENIGMA schizophrenia groups worldwide and other non-ENIGMA datasets (Supplementary Tableÿ1?2). The large sample size allowed us to conduct systematic and comprehensive analyzes to verify the reproducibility and generality of neurostructural subtypes of schizophrenia across regions/locations and disease stages. This study?s aims were: (1) to validate the two neurostructural subtypes with distinct trajectories of neuro-pathophysiological progression in schizophrenia, (2) to verify the reproducibility and generality of the neurostructural subtypes, in subsamples across the world and across disease stages, and (3) to characterize subtype-specific signatures in terms of neuroanatomy and clinical symptomatic trajectory.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"Together, these analyzes aim to create an easily accessible (with a single anatomical MRI), interpretable (based on ?progressive? pathology) and robustly generalizable (across ethnic, sex and language differences) taxonomy of subtypes that share common neurobiological mechanisms in schizophrenia. If proven effective, other complex neuropsychiatric disorders with high heterogeneity26,27, such as major depressive disorder, autism spectrum disorder, and obsessive-compulsive disorder, could also benefit from such a subtyping paradigm. This has the potential to transition the field of psychiatry from syndrome-based to both syndrome- and biology-based stratifications of mental disorders.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"Distinct patterns of spatiotemporal progression of pathophysiological progression were identified using SuStaIn, based on cross-sectional MRI data from 4222 individuals diagnosed with schizophrenia (1683 females, mean age=32.4?ñ?11.9 years) and 7038 healthy subjects (3440 females, mean age=33.0?ñ?12.6 years) (Tableÿ1). A 2-fold cross-validation procedure resulted in an optimal number ofÿK?=?2 clusters (subtypes) as determined by the largest Dice coefficient (Fig.ÿ1a), indicating the best consistency of the subtype labeling across all individuals for a model in two independent schizophrenia populations. Figureÿ1bÿshows that only 1.2% of people were moved from subtype 1 to subtype 2, and 7.5% were moved from subtype 2 to subtype 1, indicating that 91.3% of individuals? subtype labels were consistent between the SuStaIn classifications from two non-overlapping data folds. These findings suggest the presence of two stable schizophrenia biotypes with distinct ?trajectories? of pathophysiological progression (here, we put SuStaIn trajectory in quotes as it is not an actual longitudinal trajectory but rather a typical sequence of disease progression reconstructed from cross-sectional data).",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"Region of interest (ROI)-wise gray matter volume (GMV) z-scores, at each stage of the ?trajectory? for each subtype, show the sequence of regional volume loss across the 17 brain regions for each ?trajectory? (Fig.ÿ1c). To visualize the spatiotemporal pattern of each ?trajectory?, z-score whole brain images were mapped to a glass brain template (Fig.ÿ1d). These maps show a progressive pattern of spatial expansion along with later ?temporal? stages of pathological progression distinct for each ?trajectory? (Supplementary Movieÿ1ÿandÿ2). Specifically, ?trajectory? 1 displayed an ?early cortical-predominant loss? biotype. It was characterized by an initial reduction in Broca?s area, followed by adjacent fronto-insular regions, then extending to the rest of the neocortex, and finally to the subcortex (Fig.ÿ1d). Conversely, ?trajectory? 2 exhibited an ?early subcortical-predominant loss? biotype where volume loss began in the hippocampus, spread to the amygdala and parahippocampus, and then extended to the accumbens and caudate before affecting the cerebral cortex (Fig.ÿ1d). The two ?trajectories? were highly consistent with our previous findings in a predominantly Chinese schizophrenia cohort22. We also re-estimated trajectories based on a validation dataset (N?=?3120) that has removed the original data used in our previous SuStaIn study22. In the validation dataset, we replicated the two ?trajectories? that begin in either the Broca?s area or the hippocampus (Supplementary Fig.ÿ1). We also observed a high similarity of ?trajectory? spatiotemporal pattern between the original dataset and the additional dataset (?trajectory? 1,ÿr?=?0.879,ÿp?<?0.001; ?trajectory? 2,ÿr?=?0.631,ÿp?<?0.001; Spearman correlation test). The phenotypic subtypes, based on the different pathophysiological ?trajectories?, are thus replicated in a large cross-geography sample, confirming the presence of two different neuropathological pathways with different anatomical origins in schizophrenia22.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"The sample size of this study was large enough to allow further exploratory analyses to identify pathophysiological progression trajectories in more homogeneous subsamples of schizophrenia. Here, we re-estimated the SuStaIn ?trajectories? based on a subsample of data from individuals with first-episode schizophrenia with illness duration less than two years (N?=?1122; 513 females, mean age=25.4?ñ?8.6 years), and a subsample of medication-nave individuals with schizophrenia (N?=?718, 353 females, mean age?=?23.7?ñ?7.8 years) (Supplementary Tableÿ3). In both subsamples, we replicated the two ?trajectories? with either the Broca?s area or the hippocampus as the sites of origin (Supplementary Fig.ÿ2), indicating that the two initiating regions - ranking ahead of other regional deficits?are the pathological effects of the disease itself, rather than medication-induced effects. Broca?s area and the hippocampus may, therefore, be candidate targets for intervention in schizophrenia, as these two brain regions were affected early in the disease process.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"To examine whether the ?trajectories? were reproducible for samples from different parts of the world, we divided all samples into several sub-cohorts based on where the samples were obtained. Here, samples from China, Japan, South Korea and Singapore were classified into the East Asian ancestry (EAS) cohort. Samples from Europe, the United States, Canada and Australia were classified into the European ancestry (EUR) cohorts (Supplementary Tableÿ4). In addition, Chinese, Japanese, European and North American cohorts were further classified by their site locations in terms of geographic distribution (Supplementary Tableÿ4). Such a division was based on the similar ethnic or environmental factors for each country, region, or continent and the size of subsample, which need to be sufficient to conduct a reliable inference of the SuStaIn trajectory. We found that two ?trajectories? (the optimal number was alsoÿK?=?2, which separately re-estimated in each cohort)?with Broca?s area leading and the hippocampus leading?were also repeated in EAS (Fig.ÿ2a) and EUR (Fig.ÿ2b) cohorts. In addition, the spatiotemporal pattern of each ?trajectory? showed strong, significant correlations between the EAS and EUR cohorts (?trajectory? 1,ÿr?=?0.948,ÿp?<?0.001; ?trajectory? 2,ÿr?=?0.842,ÿp?<?0.001; Spearman correlation test). This high level of similarity in the trajectories was also observed between cohorts from other locations (Fig.ÿ2c). This suggests that the two biotypes with distinct ?trajectories? of pathophysiological progression in schizophrenia are robust, and their classification patterns are independent of macro-environmental or ethnogenetic factors.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"The SuStaIn calculated the probability of each patient belonging to a specific ?trajectory? and further assigned them to a sub-stage within that ?trajectory?. Individuals who were assigned to the later stages of the ?trajectory? showed a significant correlation with less GMV of Broca?s area (Fig.ÿ1e,ÿr?=?0.651,ÿp?<?0.0001) and hippocampus (Fig.ÿ1f,ÿr?=?0.615,ÿp?<?0.0001). In addition, the later stages were correlated with longer disease duration (Fig.ÿ1g,ÿr?=?0.105,ÿp?<?0.0001), worse negative symptoms (Fig.1h,ÿr?=?0.101,ÿp?<?0.0001) and worse cognitive symptoms (Fig.1i,ÿr?=?0.080,ÿp?=?0.004). These results suggest that the SuStaIn ?trajectory? reflects the underlying neural progression in schizophrenia.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"To characterize subtype-specific neuroanatomical signatures, we assessed regional morphological measures using FreeSurfer in a subsample including 1840 individuals with schizophrenia and 1780 healthy controls. A total of 330 regional morphological measures in cortical thickness, cortical surface area, cortical volume, subcortical volume and subregion segmentation were quantified (see ?Methods?).",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"Regional morphological z-scores (i.e., normative deviations from healthy control group) for each subtype were computed and compared (Fig.ÿ3). Morphological z-scores of all brain regions and inter-subtype comparisons are provided in Supplementary Tableÿ5. Briefly, compared to healthy controls, average cortical volume/area reduction was only observed in subtype 1 (Supplementary Fig.ÿ3a?b), though both subtype 1 and subtype 2 exhibited a moderate reduction in average cortical thickness (Supplementary Fig.ÿ3c). Additionally, largest effects for cortical thickness/volume/area were located within the superior frontal regions for subtype 1 and in the superior/medial temporal regions for subtype2 (Supplementary Tableÿ5). As for subcortical volume, larger effects for volumes of hippocampus, amygdala, thalamus, accumbens and brain stem were observed in subtype 2 compared to subtype 1 (Supplementary Fig.ÿ3d?h). The hippocampal/amygdala subregions with the most significant reduction for subtype 2 were located in the molecular layer and cortico-amygdaloid transition area (Supplementary Fig.ÿ4?5). Interestingly, we observed that, compared to healthy controls, the striatum (i.e., caudate, putamen) was larger among subtype 1 patients and smaller among subtype 2 patients (Supplementary Fig.ÿ3i?j). The difference in the striatum between the two subtypes was also replicated in a subsample of medication-naive individuals with schizophrenia (Supplementary Tableÿ6). The main findings of subtype-specific neuroanatomical signatures are described in Tableÿ2. Taken together, subtype 1 exhibited greater deficits in cortical morphology but enlarged volume of the striatum, whereas subtype 2 displayed more severe volume loss in the subcortical regions, including the hippocampus, amygdala, thalamus, brain stem and striatum.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"A total of 2622 (62.1%) individuals with schizophrenia were assigned to subtype 1 and the remaining 1600 patients (37.9%) were assigned to subtype 2. The two subtypes exhibit no significant difference in the age, sex, illness duration or PANSS scores (Tableÿ1). To further characterize the psychotic symptomatic trajectory as the disease progresses for each subtype, we further defined three subgroups according to illness duration (early stage [<2 years],ÿn?=?926; middle stage [2?10 years],ÿn?=?578; late stage [>10 years],ÿn?=?682). The results suggested distinct trajectories of psychotic symptoms between the two subtypes (Fig.ÿ4ÿand Tableÿ3). Specifically, lower positive symptom severity was observed in late stage patients compared early stage patients in both subtypes (subtype 1,ÿF?=?37.4,ÿp?=?1.60e???16; subtype2,ÿF?=?41.9,ÿp?=?4.68e???18). With the increase of the disease course, subtype 1 showed a gradual worsening of negative symptoms (F?=?4.6,ÿp?=?9.98e???3), whereas the negative symptoms of subtype 2 remained stable across the three stages of the disease course (F?=?0.1,ÿp?=?0.884). Additionally, a gradual worsening of depression/anxiety was only observed in subtype 1 (F?=?5.9,ÿp?=?2.86e???3). Inter-subtype comparisons showed that at the late stage (illness duration>10 years), subtype 1 exhibited worse positive symptoms (t?=?2.9,ÿp?=?0.003), general psychopathology (t?=?2.5,ÿp?=?0.010) and worse depression/anxiety (t?=?2.1,ÿp?=?0.033) compared to subtype 2, after regressing out the effects of age, sex and SuStaIn stage.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"We investigated whether the SuStaIn subtyping and staging can be generalized to unseen cohorts. A flowchart is shown in Supplementary Fig.ÿ6a. Specifically, the Asian and Europe SuStaIn models were separately built based on the Asian ancestry cohorts and Europe ancestry cohorts, as described in 2.3. The two models were used for subtyping and staging those unseen samples. We compared whether those subtype and stage assignments match the result of the original model that has been built on all cohorts. We observed that most of the unseen individuals can keep the same subtype label with the original model (88.83% for the Asian model; 89.98% for the European model) (Supplementary Fig.ÿ6b). In addition, there was a high consistency of individual staging between stages of unseen data and original model result (Asian model,ÿr?=?0.976,ÿp?<?0.001; Europe model,ÿr?=?0.979,ÿp?<?0.001, Spearman correlation test) (Supplementary Fig.ÿ6c). These results indicates a high generalized ability of SuStaIn model to unseen data.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"Our study, applying a machine learning algorithm to brain MRI data from over 4000 individuals with schizophrenia, has revealed two distinct neurostructural subtypes based on patterns of neuro-pathological progression. These subtypes are reproducible and generalizable across different subsamples and illness stages, independent of macroeconomic and ethnic factors that differed across collection locations. Specific patterns of neuroanatomical pathology for each subtype were uncovered. Subtype 1 is characterized by early cortical-predominant loss that first occurs in the Broca?s area/fronto-insular cortex, and shows adverse signatures in cortical morphology and an enlarged striatum. In contrast, subtype 2 is marked by early subcortical-predominant loss that first appears in the hippocampus, and displays significant volume loss in subcortical regions, including the hippocampus, amygdala, thalamus, brain stem and striatum. Additionally, we observed distinct trajectories of specific symptoms clusters in these two subtypes: as disease progresses, subtype 1 exhibited a gradual worsening of negative and depression/anxiety symptoms, and less of a decline in positive symptoms compared to subtype 2.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"Despite the growing body of evidence pointing to group-level gray matter volume deficits in various brain regions - especially in frontal and temporal regions - as well as altered subcortical volume in schizophrenia28, substantial individual variations persist within this population8,29. These inter-individual differences in brain structure may stem from two primary sources of variation. First, differences in underlying etiology and pathogenesis could result in varying clinical characteristics (referred to as phenotypic heterogeneity)3,30. Second, relative differences among subjects in the stage of dynamic progression (known as temporal heterogeneity) could further increase differences in the clinical presentation31,32. Such variations suggest that the pathological progression of schizophrenia might not be attributed to a single unified pathophysiological process. Indeed, our neurostructural subtypes uncovered two SuStaIn trajectories of gray matter loss through brain structural imaging. Several studies also reported dynamic patterns of accelerated gray matter loss over time in individuals with schizophrenia33,34. In addition, the staging of SuStaIn trajectory within the subtype reflects the underlying neurophysiological, pathological, and neuropsychological progressions in schizophrenia. Furthermore, we demonstrated that the phenotypic difference in the intrinsic neuro-pathophysiological trajectory was reproducible across samples worldwide, independent of macroeconomic and ethnic factors that differed across these sites.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"The Broca?s area/fronto-insular cortex and hippocampus are identified separately in subtype 1 and subtype 2 as the first regions to show gray matter deficits. This is consistent with our prior finding based on individuals with schizophrenia primarily collected from the Chinese population22. Furthermore, the current study replicates the same two primary regions in a medication-nave and a first-episode cohort, suggesting that these neuropathological changes are a reflection of the disease process, rather than medication effects. Broca?s area and the fronto-insular cortex have been extensively implicated in schizophrenia35, supporting Crow?s linguistic primacy hypothesis36ÿand a triple-network model of the disorder37. Abnormalities in Broca?s area and related regions have been linked with hallucinations in schizophrenia38,39. The early involvement of Broca?s area in the pathology could be related to the presence of these core symptoms of schizophrenia. Moreover, in individuals with psychosis, reductions in the inferior frontal cortex preceding the initial psychotic episode have been reported40,41. A prior study reported reduced dopamine release in the prefrontal cortex in patients with schizophrenia42. In relation to hippocampal pathology, research has emphasized the hippocampus as one of the initial regions to display volumetric loss in schizophrenia25,43. The hippocampus is thought to be involved in potential glutamatergic dysfunction in schizophrenia3. Decreased levels of the NMDA co-agonist D-serine were linked to neurobiological alterations similar to those seen in schizophrenia, including hippocampal volume loss44. Gray matter loss in schizophrenia is associated with medication, stress, drug use and inactivity45,46. In addition, schizophrenia is related to dopaminergic dysregulation, disturbed glutamatergic neurotransmission and increased proinflammatory status of the brain45. The causal interrelationships between these processes and gray matter loss are still unclear. These findings offer evidence regarding the specific neuroanatomical locations where gray matter loss is observed in the schizophrenia subtypes. These two potential origins could also offer a viewpoint on the pathological ?spread? of the disorder.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"The subtyping method exhibits high potential for distinguishing neurostructural subtypes with shared pathophysiological foundations. Notably, subtype 1 displayed larger volume of the striatum, while subtype 2 demonstrated reduced volume. This was consistent with a previous study, which also identified two anatomical subtypes of schizophrenia: one shows enlarged volume in the basal ganglia; whereas the other shows widespread volumetric reduction in the cortical and some subcortical areas relative to healthy controls15. The striatum plays a key role in the dopamine system, which contributes to psychotic symptoms47. Nevertheless, studies of striatal pathology have reported inconsistent differences between patients and controls3. The variability of the striatum is greater in patients than in controls, which relates to overall structural morphometry28, dopamine D2 receptor and transporter levels48. This indicates that differences might exist within subgroups of the disorder3. Alterations in striatal activation are associated with reward-related deficits in schizophrenia49. A previous study suggests that disrupted putamen-cortices connectivity during reward-related processing is directly linked to structural changes in the putamen50. Despite the unclear causal relationship, this suggests that the differential effects on striatal volume between the two subtypes may be related to striatal dysfunction in schizophrenia. In addition, it is still uncertain whether the discrepancy in striatum between cases and controls indicates a primary pathology or an effect of antipsychotic treatment3. Interestingly, this study?s subtype-specific striatal differences were replicated in a subset of individuals who had not received antipsychotic treatment, suggesting that striatal variability persists even in those without antipsychotic treatment. In addition, a recent study reveals a more pronounced and widespread pattern of thinner cortex in deficit schizophrenia, a clinically defined subtype with primary, enduring negative symptoms, compared to non-deficit schizophrenia51. A recent work also reveals that the neuro-structural signature with cortical reduction was associated with progressive illness course, worse cognitive performance and elevated schizophrenia polygenic risk scores52. This also suggests the existence of distinct subtypes distinguished by unique neuroimaging features. Taken together, our neurostructural subtyping differentiated subgroups with unique pathological features, thereby enhancing our understanding of the neurobiological mechanisms underlying schizophrenia.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"The two identified subtypes may have several potential therapeutic implications. While the underlying mechanisms associated with a subtype-specific symptomatic trajectory remain unclear, our research shows divergent long-term clinical outcomes between the two neurostructural subtypes. As the disease advanced, for subtype 1, the negative and depression/anxiety symptoms gradually worsened; for subtype 2 these symptoms remained stable. In addition, subtypeÿ1 experienced worse positive symptoms than subtype 2 at the late stage of disease (i.e., duration > 10 years). This is consistent with a prior study that reported greater gray matter reduction in frontal regions in treatment-resistant compared with treatment-responsive individuals with schizophrenia53. Another intriguing aspect is that our prior research on treatment-resistant schizophrenia demonstrated that electroconvulsive therapy (ECT) can substantially enhance the volume of the hippocampus and insula; this is also associated with psychotic symptom alleviation54?56. Notably, these two brain regions were also identified as the ?origins? of gray matter loss separately in each subtype. This observation raises the possibility of exploring neuromodulation interventions, such as transcranial magnetic stimulation (TMS), to target these specific brain regions.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"This study has several limitations. First, while the SuStaIn algorithm estimates pathophysiological trajectories from cross-sectional MRI data, it remains crucial to validate these outcomes with longitudinal data to verify the brain changes with disease progression over time. Second, the current study benefits from a large sample size, but the inclusion of data from various sites could potentially be influenced by confounding factors, including diverse cohorts, scanners, and locations. Harmonization methods have been employed to alleviate disparities across MRI acquisition protocols. Nonetheless, it remains essential to collect a sufficiently large sample from multi-centers under a standard imaging protocol and experimental paradigm. The lack of cognitive evaluation limits to examine the association of neurostructural biotype with cognitive impairment in schizophrenia. Third, a substantial portion of individuals with schizophrenia were likely to have received or currently use medications, and data from medication-nave/free individuals were only available for a subset of the datasets. One important limitation is the assumption of progressive pathology in schizophrenia (discrete events of tissue loss or continuous downward drift), when applying SuStaIn. The few existing very long-term imaging studies in schizophrenia support this stance57ÿbut selection bias cannot be fully overcome in the recruitment process for neuroimaging studies. Routine anatomical MRI for every person with psychosis seeking help, with periodic repeats, may provide better view of the validity of progressive pathology in the future. The selection of z-score waypoints and maximum z-score used in the SuStaIn algorithm should be careful based on prior information about degree of progress in different diseases. The computational complexity of the SuStaIn algorithm is highly time-consuming, which limits the exploration of spatiotemporal patterns of trajectories at finer spatial resolutions.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"In summary, our study reveals two distinct neurostructural schizophrenia subtypes based on patterns of pathological progression of gray matter loss. We extend the reproducibility and generalizability of these brain imaging-based subtypes across illness stages, medication treatments and different sample locations worldwide, independent of macroeconomic and ethnic factors that differed across these sites. The identified subtypes exhibit distinct signatures of neuroanatomical pathology and psychotic symptomatic trajectories, highlighting the heterogeneity of the neurobiological changes associated with disease progress. This imaging-based taxonomy shows potential for the identification of homogeneous subsamples of individuals with shared neurobiological characteristics. This may be a first crucial step in the transition from only syndrome-based to both syndrome- and biology-based identification of mental disorder subtypes in the near future.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"This study analyzed cross-sectional T1-weighted structural MRI data from a total of 4,291 individuals diagnosed with schizophrenia (1,709 females, mean age=32.5?ñ?11.9 years) and 7,078 healthy controls (3,461 females, mean age=33.0?ñ?12.7 years). These datasets came from 21 cohorts of ENIGMA schizophrenia working groups from various countries around the world, 11 cohorts collected from Chinese hospitals over the last ~10 years, and 9 cohorts from publicly available datasets, i.e., HCP-EP58, JP-SRPBS59, fBIRN60, MCIC61, NMorphCH62, NUSDAST63,ÿDS00003064,ÿDS00011565ÿandÿDS00430266. The datasets came from various countries around the world. Details of demographics, geographic location, clinical characteristics, and inclusion/exclusion criteria for each cohort may be found in the Supplementary Information (Supplementary Tableÿ1?2).",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"The severity of symptoms was evaluated by the Positive and Negative Syndrome Scale (PANSS)67, including a positive scale (total score of P1-P7), a negative scale (total score of N1-N7), a general psychopathology scale (total score of G1-G16) and total score. In addition, phenotypic characteristics were further quantified in three dimensions, such as cognitive (total score of P2, N5, G5, G10, G11), depression/anxiety (total score of G1, G2, G3, G6, G15) and excitement (total score of P4, P7, G44, G14) via a five-factor model of schizophrenia68.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"All sites obtained approval from their local institutional review boards or ethics committees, and written informed consent from all participants and/or their legal guardians. The present study was carried out under the approve from the Medical Research Ethics Committees of Fudan University (Number:ÿFE222711).",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,T1-weighted structural brain MRI scans were acquired at each study site. We used a standardized protocol for image processing using the ENIGMA Computational Anatomy Toolbox (CAT12) across multiple cohorts (https://neuro-jena.github.io/enigma-cat12/). These protocols enable region-based gray matter volume (GMV) measures for image data based on the automated anatomical (AAL3) atlas69. Further details of image acquisition parameters and quality control may be found in Supplementary Tableÿ1?2.,,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"The ROI-wise GMV measures were first adjusted by regressing out the effects of sex, age, the square of age, site and total intracranial volume (TIV) using a regression model22. Subsequently, a harmonization procedure was performed using the ComBat algorithm for correcting multi-site data70. The adjusted values were transformed as z-scores (i.e., normative deviations) relative to the healthy control group. We multiplied these z-scores by -1 so that the z-score increases as regional GMV decreases. Finally, we removed these samples if they were marked as a statistical outlier (if any of their regional volumes >5 standard deviations away from the group-level average). After the quality control, 11,260 individuals were included, of which 4222 were schizophrenia patients (1683 females, mean age=32.4?ñ?12.4 years) and 7038 healthy subjects (3440 females, mean age=33.0?ñ?12.4 years).",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"To uncover diverse patterns of pathophysiological progression from cross-sectional only MRI data and cluster individuals into groups (subtypes), we employed a machine learning approach?Subtype and Stage Inference (SuStaIn)19. The methodology of SuStaIn has been described in detail previously19. We also describe the applicability of SuStaIn algorithm to schizophrenia in Supplementary Materials. Here, we briefly describe the main parameter choices specific to the current study. The SuStaIn model requires anÿM???Nÿmatrix as input. M represents the number of cases (M?=?4222).ÿNÿis the number of biomarkers (N?=?17). 17 gray matter biomarkers were previously used for SuStaIn modeling in schizophrenia22. Here, all of the AAL3 regions of whole brain were separated and merged into 17 regions of interest (ROIs)22, including frontal lobe, temporal lobe, parietal lobe, occipital lobe, insula, cingulate, sensorimotor, Broca?s area, cerebellum, hippocampus, parahippocampus, amygdala, caudate, putamen, pallidum, accumbens and thalamus (Supplementary Tableÿ7). We further examine the relationship between regional volume and illness duration in patients with schizophrenia using the Spearman correlation test (Supplementary Fig.ÿ7). To keep consistent with our previous study22, we used the z-score thresholds (z?=?1, 2, 3) as ?waypoints? of severity in the SuStaIn model. The maximumÿz-score in the SuStaIn algorithm was defined atÿz?=?5 according to maximum z-score for each biomarker (Supplementary Tableÿ8). We also performed a replication analysis with a reduced maximum z-score (z?=?4) (Supplementary Fig.ÿ8). We then ran the SuStaIn algorithm with 25 start points and 100,000 Markov Chain Monte Carlo (MCMC) iterations19ÿto estimate the most likely sequence that describes spatiotemporal pattern of pathophysiological progression (i.e., ?trajectory?).",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"First, we used the Hopkins statistics to establish whether the data is clustered. A high value (H?=?0.7756) shows a high clustering tendency at 90% confidence level, supporting a robust existence of clusters. SuStaIn can identify diverse trajectories of pathophysiological progression given a subtype numberÿK. We fitted the model forÿK?=?2-6 subtypes (?trajectories?), separately. The optimal number of subtypes was determined according to the reproducibility of individual subtyping via a two-fold cross-validation procedure22. Specifically, all individuals were randomly split into two non-overlapping folds. This above procedure was repeated ten times. For each fold, we trained the SuStaIn model. For each individual, the trained SuStaIn model provides a subtype label. We measured the consistency of the subtype labeling across all individuals between two folds by using the Dice coefficient. The largest Dice coefficient was obtained forÿK?=?2 (see Fig.ÿ1a), indicating the best consistency based on cross-validation. Finally, the two-cluster model of SuStaIn was fitted to the entire sample. The most probable sequence (i.e., the order of biomarkers) was evaluated for each ?trajectory? via SuStaIn. For each individual, SuStaIn calculated the probability (ranging from 0 to 1) of belonging to each ?trajectory?, and assigned the individual into a sub-stage of the maximum likelihood ?trajectory? through MCMC iterations. We also estimated the SuStaIn ?trajectories? based on a subsample from individuals with first-episode schizophrenia whose illness duration was less than two years (N?=?1122, 513 females, mean age=25.4?ñ?8.6 years), and a subsample of medication-nave individuals with schizophrenia (N?=?718, 353 females, mean age=23.7?ñ?7.8 years).",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"To visualize the spatiotemporal patterns of pathophysiological progression, we calculated the meanÿz-score of regional GMV across individuals belonging to the same substage of each SuStaIn ?trajectory?. The images of ROI-wise GMVÿz-scores were mapped into a glass brain template via visualization tools implemented in ENIGMA Toolbox (https://enigma-toolbox.readthedocs.io/en/latest/index.html) and BrainNetViewer (https://www.nitrc.org/projects/bnv/).",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"To examine whether the SuStaIn stage (a continuous indicator of the ?temporal? stage of SuStaIn ?trajectory?) is associated with pathological processes and clinical characteristics in schizophrenia, we performed Spearman correlations between the SuStaIn stages and the degree of brain atrophy (i.e., regional GMV) in schizophrenia. We also examined whether SuStaIn stages were linked to disease duration, severity of symptoms, and phenotypic characteristics.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"To further characterize the neuroanatomical signatures associated with each subtype, we conducted regional morphological analyzes in a subsample including 1840 individuals with schizophrenia and 1780 healthy controls. Brain morphological measures, such as cortical thickness, cortical surface area, cortical volume and subcortical volume, were quantified using FreeSurfer (version 7.3,ÿhttp://surfer.nmr.mgh.harvard.edu/). A total of 68???3 regional measures for cortical thickness, cortical surface area and cortical volume were extracted based on the DK atlas71, along with 14 subcortical regions (bilaterally nucleus accumbens, amygdala, caudate, hippocampus, pallidum, putamen and thalamus) and 2 lateral ventricles. In addition, we performed an automated subregion segmentation (https://surfer.nmr.mgh.harvard.edu/fswiki/SubregionSegmentation) for the hippocampal substructures (n?=?38 subregions)72, the nuclei of the amygdala (n?=?18)73, the thalamic nuclei (n?=?50)74, and the brain stem structures (n?=?4)75, yielding a total of 110 subregional volumetric measures.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"Regional morphological measures for each individual with schizophrenia were adjusted by regressing out the effects of sex, age, the square of age, TIV and site, and then transformed to z-scores (i.e., normative deviations from healthy control group). The mean regional morphological z-score across individuals belonging to each subtype was calculated, and mapped to brain templates for visualization of neuroanatomical signature deviation for each subtype relative to healthy population. To further manifest subtype-specific signature in neuroanatomical pathology, we compared the regional morphological z-scores between the two subtypes using two sampleÿt-tests. Multiple comparisons were corrected by family wise error (FWE) correction.",,,,,
Neurostructural subgroup in 4291 individuals with schizophrenia identified using the subtype and stage inference algorithm,"To characterize the psychotic symptomatic trajectory with disease duration increases for each subtype, we further divided the individuals of each subtype into three subgroups according to their illness durations (early stage: <2 years; middle stage: 2-10 years; late stage: >10 years). The particular choice of bins was determined according to the distribution of illness duration (early stageÿn?=?926, middle stageÿn?=?578, late stageÿn?=?682) and the size of subgroup enough to perform an inter-subtype comparison. We compared the difference of symptoms among the three stages of disease in each subtype using ANOVA. In addition, two sampleÿtÿtests were performed to compare the inter-subtype differences separately within each of the stages after regressing out the effects of age, sex and SuStaIn stage.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Digital mental health interventions (DMHIs) are increasingly recognized as potential solutions for adolescent mental health, particularly in low- and middle-income countries (LMICs). The United Nations? Sustainable Development Goals and universal health coverage are instrumental tools for achieving mental health for all. Within this context, understanding the design, evaluation, as well as the barriers and facilitators impacting adolescent engagement with mental health care through DMHIs is essential.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,This scoping review aims to provide insights into the current landscape of DMHIs for adolescents in LMICs.,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The Joanna Briggs Institute scoping review methodology was used, following the recommendations of the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews). Our search strategy incorporated 3 key concepts: population ""adolescents,"" concept ""digital mental health interventions,"" and context ""LMICs."" We adapted this strategy for various databases, including ACM Digital Library, APA PsycINFO, Cochrane Library, Google Scholar (including gray literature), IEEE Xplore, ProQuest, PubMed (NLM), ScienceDirect, Scopus, and Web of Science. The articles were screened against a specific eligibility criterion from January 2019 to March 2024.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"We analyzed 20 papers focusing on DMHIs for various mental health conditions among adolescents, such as depression, well-being, anxiety, stigma, self-harm, and suicide ideation. These interventions were delivered in diverse formats, including group delivery and self-guided interventions, with support from mental health professionals or involving lay professionals. The study designs and evaluation encompassed a range of methodologies, including randomized controlled trials, mixed methods studies, and feasibility studies.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"While there have been notable advancements in DMHIs for adolescents in LMICs, the research base remains limited. Significant knowledge gaps persist regarding the long-term clinical benefits, the maturity and readiness of LMIC digital infrastructure, cultural appropriateness, and cost-effectiveness across the heterogeneous LMIC settings. Addressing these gaps necessitates large-scale, co-designed, and culturally sensitive DMHI trials. Future work should address this.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The World Health Organization (WHO) defines mental health as ?a state of mental well-being that enables people to cope with the stresses of life, to realize their abilities, to learn well and work well, and to contribute to their communities. Mental health is an integral component of health and well-being and is more than the absence of mental disorder? [1]. The United Nations General Assembly has underscored the key role of universal health coverage (UHC)?where everyone can access the health services they need without financial hardship?in achieving health for all [1]. Indeed, UHC is central to the health-related Sustainable Development Goals (SDGs), namely target 3.4: ?by 2030, reduce by one-third premature mortality from noncommunicable diseases through prevention and treatment and promote mental health and well-being? [1]. While these global agendas are instruments for achieving mental health for all, there is international recognition that adolescent mental health is a distinct and critical public health and human rights issue [2-4].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"In 2020, the WHO?UNICEF (United Nations International Children?s Emergency Fund)?Lancet Commission called for a renewed focus on the SDGs for advancing child and adolescent health, including mental health [5]. The Commission made a powerful argument that children and adolescents should be at the center of the SDGs to protect their human rights. In addition, this was an ethical and economic investment [5]. Despite this, theÿWorld Mental Health Reportÿstates that approximately 90 WHO member states?less than half of all member states?had a mental health policy or plan specifically for children and adolescents [1]. The report emphasizes the importance of national mental health plans that are fully compliant with human rights instruments, sufficiently resourced, and regularly monitored and evaluated [1].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The onset of mental health disorders typically occurs during adolescence (between the ages of 10-19 years), an important time for developing social and emotional skills [6,7]. It is here where adolescents form coping strategies that enable mental health. Equally, it is a time when young people become vulnerable to risk-taking behaviors, for example, substance abuse. Indeed, suicide is the leading cause of adolescent death [6]. Worldwide, 13% of the world?s adolescents (aged 10-19 years) live with a mental disorder [8]; however, widening treatment gaps mean many conditions remain undiagnosed and untreated [6]. Moreover, mental health conditions disproportionately affect adolescents in low- and middle-income countries (LMICs) [1]. LMIC economies are those in which the 2022 gross national income per capita was less than US $13,845 [9]. Approximately 90% of the world?s 1.2 billion adolescents reside in LMICs [8]. This population is more vulnerable to human rights violations, and where limited mental health services are available, stigma, discrimination, and social, cultural, and economic challenges are major barriers to treatment access [6,8,10].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The COVID-19 pandemic has worsened the significant burden on this population [8,11,12]. Before the pandemic, researchers explored the feasibility and clinical benefits of digital health technologies for adolescent mental health and care in LMICs [13-15]. Indeed, COVID-19 has driven the adoption of digital health care platforms in LMICs, including digital interventions for health [8,16]. Digital health interventions (DHIs) are increasingly accepted tools for the support of adolescent mental health [17-19].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The WHO defines DHIs as a discrete functionality of digital technology that is applied to achieve health objectives [20]. In this regard, digital mental health interventions (DMHIs) can be understood as a discrete functionality of digital technology that is applied to achieve mental health objectives. DHIs are classified into 4 overarching groups based on the primary user, for instance, clients (service users), health care providers (health service delivery), health system managers (administration and oversight of public health systems), and data services (data collection, management, use, and exchange) [20]. For clients, DHIs/DMHIs can be delivered at an individual or population level; in high and low-income settings; and via several devices, for example, mobile apps, websites, wearables, and smart devices. Such interventions may be self-guided [21] or delivered with lay support, for instance, from teachers [22] or trained psychologists [23]. Furthermore, some DMHIs include theories of behavior change, such as the self-determination theory [24] or the Social Cognitive Theory [23]. Indeed, research suggests that interventions grounded in behavioral theory are more likely to be effective [25,26].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Presently, there are significant and systemic barriers that limit adolescent access to mental health services, for example, cost, time, geographic location [27], stigma [28,29], lack of community knowledge and education on mental health [30], and low mental health literacy [31]. Mental health systems in LMICs lack trained mental health specialists, leading to significantly understaffed services [30,32,33]. These shortages are unequal, with urban areas benefiting from more health specialists and resources than rural areas [34,35]. Consequently, this is a potential barrier to treatment because the physical distance may place many services out of reach, thereby reinforcing the rural-urban digital divide [36]. The term digital divide can be understood as ?the gap between people who do and do not have access to forms of information and communication technology? [37]. The concept is complex, going beyond the connected versus the unconnected. It is a global phenomenon but even more pronounced in LMIC settings, leading to further social, cultural, and economic inequalities [38,39].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Adolescents in LMICs have a distinct disadvantage to digital infrastructure, namely the internet [38]. In 2019, the rural-urban gap in mobile internet use across LMICs was 37%; however, LMICs in sub-Saharan Africa had the widest rural-urban gap, with those living in rural areas being 60% less likely to access the internet than those residing in urban areas [40]. Another report found gaps in literacy and related skills had the greatest impact on mobile internet use [41]. Moreover, the GSM (Global System for Mobile) Communications reports that mobile phone affordability and lack of digital skills were significant barriers in LMICs [42].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"There are issues with DMHI implementation, posing a barrier to scalability. Many DMHIs, for example, require additional guidance for adolescent adherence and engagement, such as psychologists, therapists, or lay teacher support [43,44]. This may undermine the scalability of the interventions due to the shortage of health professionals for those roles [44]. Other challenges relate to their feasibility [45], political nature [46], cultural appropriateness [47], design, deployment, evaluation [48], sustainability [49], cost-effectiveness [50], privacy and data security [51], digital maturity, and readiness [52-54]. Despite this, there is evidence that DMHIs could transform adolescent mental health in low-resource settings [50,55-57].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"We selected the review period 2019-2024 for 3 distinct reasons; first, in 2020, the WHO launched its first guidance on designing DHIs with and for young people, recognizing the significance of youth-centered DHIs and considering their specific needs [58]. Second, that same year, the WHO?UNICEF?Lancet Commission called for a renewed focus on the SDGs for advancing child and adolescent health, including mental health, prioritizing young people in the urgent call to action [5]. Finally, the COVID-19 pandemic has profoundly impacted adolescent mental health worldwide, leading to an increased interest and investment in the delivery of quality, person-centered, remote mental health care [59]. The post?COVID-19 era has provided an opportunity to explore which DMHIs exist for adolescents in LMICs, how they are designed and evaluated, how adolescents are involved in design activities, which theories or models were consulted, and which factors affect adolescent engagement. Examining the current state of adolescent DMHIs in the context of these recent developments allows for a timely and up-to-date insight into gaps in policy, practice, and research. This scoping review aims to collate information on adolescent DMHIs in LIMC settings. The review asks ?What is known about DMHIs for adolescents in LMICs, as reported in the literature??",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,The subreview questions (subRQs) were as follows:,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,SubRQ1: How are adolescent DMHIs designed and evaluated within LMICs?,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"SubRQ2: What are the reported activities and approaches involving adolescents in designing DMHIs, and what are the perceived outcomes of such involvement?",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"SubRQ3: Which frameworks, toolkits, models, or theories were consulted or applied to the DMHI? (including implementation activities related to digital health readiness and preparedness)",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,SubRQ4: What factors facilitate or hinder adolescent engagement in DMHIs in LMICs?,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"This scoping review followed the Joanna Briggs Institute Scoping Review Methodology [60] and is reported based on the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) guidelines [61]. The PRISMA-ScR checklist is shown inÿMultimedia Appendix 1. Scoping reviews are ideal for disciplines with emerging evidence, for example, DMHIs for adolescents in LMICs, where the limited availability of randomized controlled trials (RCTs) hinders researchers from performing systematic reviews and assessing the quality of evidence [62]. Consistent with the purpose of scoping studies, this review does not seek to assess or appraise the quality and robustness of the evidence, nor does it generalize the findings [61,63,64]. By systematically mapping the available literature, a scoping review can highlight the current state of knowledge, identify research gaps, and potentially reveal patterns or trends that can inform future studies [60]. Previous researchers have used scoping reviews to map available evidence in a similar field [65-67].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The Joanna Briggs Institute recommends the use of the PCC mnemonic, that is, population, concept, and context, to develop the inclusion criteria [60]. The population consists of adolescents aged 10-19 years, which is consistent with the WHO definition [6]. The concept under study is DMHIs, understood as a discrete functionality of digital technology that is applied to achieve mental health objectives [20]. The context of interest is LMIC economies, defined by the World Bank as nations with a gross national income per capita less than US $13,845 [9], seeÿTextbox 1.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,1. Population: Adolescents (World Health Organization [WHO] definition [6]?persons between the ages of 10 and 19 years).,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"2. Concept: Digital mental health interventions (DMHIs) [20] that are delivered to support the mental health and well-being of adolescents in low- and middle-income countries (LMICs). DMHIs focus on emotional, behavioral, or eating disorders, psychosis, suicide, self-harm, and risk-taking behaviors. Including mental health promotion and prevention interventions and those for early detection and treatment. DMHIs include mobile apps, web applications, smart devices, telehealth, SMS text messaging, and internet-based interventions.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,3. Context: Low- and middle-income settings [9].,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"4. Sources: Published, peer-reviewed, or gray literature of any research study design (eg, randomized controlled trials, systematic reviews, case studies, qualitative, quantitative, or mixed methods, theses or dissertations, white papers, guidelines, conference proceedings, charity reports, or posters).",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,5. Period: Published between January 2019 and March 2024.,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,6. Language: Studies published in English.,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"1. Population: Participants that do not meet the WHO definition of adolescents, that is, are aged younger than 10 years or older than 19 years.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"2. Concept: DMHIs that target or only explore the concerns and views of adolescents? parents, caregivers, guardians, teachers, and clinicians. Studies that do not focus on digital mental health or well-being.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,3. Context: Not based in low- and middle-income settings.,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,4. Sources: No full text is available or the paper is not retrievable.,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,5. Period: Published before January 2019.,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,6. Language: Not available in English.,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The information sources were the following electronic databases: (1) ACM Digital Library, (2) APA PsycINFO, (3) Cochrane Library, (4) Google Scholar (gray literature included,ÿMultimedia Appendix 2), (5) IEEE Xplore, (6) ProQuest, (7) PubMed (NLM), (8) ScienceDirect, (9) Scopus, and (10) Web of Science.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"These databases were selected because they collectively align with this review?s scope on DHIs and technologies, that is, behavioral science, mental health (psychiatry and psychology), and technology.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The database identification and search strategy were developed with guidance from a faculty librarian at the University of Strathclyde. The search terms represented the primary concepts of the objectives in the review. These included a range of keywords, free text, and medical subject headings terms and combinations of the Boolean operators. The Joanna Briggs Institute guidelines [60] for scoping reviews recommend a 3-step strategy: (1) an initial search of the database (titles and abstracts) using medical subject heading terms, (2) extending the search query to other databases and adjusting the search strategy for each database, and (3) reviewing the reference list of the selected papers.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Databases were searched from January 2019 to March 2024. This period was selected to capture key developments, for example, the WHO?s first digital health guidance for youth [58], the renewed focus on adolescents through the SDGs [5], and the COVID-19 pandemic?s exposure of deep and preexisting mental health inequalities among adolescent LMICs [11,12]. Collectively, these highlighted the need for a timely review of adolescent DMHIs in low-resource countries. The search strings and results for each database are presented inÿMultimedia Appendix 3. The reference lists of all related reviews and included studies were hand-searched for additional papers.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"In total, 1 reviewer (CW) initially searched the databases, focusing on the first 200-300 results per database to manage the workload [68]. The most relevant papers appeared at the top of the search results. CW exported all relevant records to EndNote (Clarivate Analytics) to remove duplicate references. CW then imported the remaining records to Rayyan (Rayyan Systems Inc) for title, abstract, and full-text screening. Rayyan places all imported papers into an ?undecided? category, allowing reviewers to independently ?exclude,? ?maybe,? or ?include? each paper based on the eligibility criteria. The first screening involved only the title and abstract review (CW, LM, and CR). During the second screening, CW retrieved the full text of papers that potentially met the eligibility criteria. Where a study had a published protocol and study outcome paper, only the study outcome paper was included in the review. The relevant papers were identified by CW, LM, and CR and placed in the ?include? category in the final screening step. Any discrepancies were discussed and resolved by consensus. All authors agreed that the included papers fully met the eligibility criteria.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The authors CW, LM, and ML developed and piloted a data charting form at the protocol stage. This was further refined iteratively at the review stage, and 2 reviewers (CW and CR) extracted the data (CW extracted the data and CR independently verified it). This approach is appropriate where it is not feasible for reviewers to independently chart the data [60]. Any inconsistencies were discussed and resolved. The data items extracted for each article aligned with the review aims and objectives and included the following:",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"1. Bibliographic information: lead author, date of publication, and country of lead author.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"2. Data items related to subRQ1: DMHI name, description, target mental health disorder, start year of intervention implementation, country of intervention, participant age, sample size, study aims, intervention type, control, evaluation, outcome measures, duration, follow-up, and costs.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,3. Data items related to subRQ2: adolescent involvement in DMHI design.,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"4. Data items related to subRQ3: consulted frameworks, theories, or models.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,5. Data items related to subRQ4: factors affecting adolescent engagement with the DMHI (facilitators or barriers).,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,6. Key findings.,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,The data charting document can be found inÿMultimedia Appendix 4.,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,Selected papers were reviewed to identify the similarities and differences between the DMHIs. They were then summarized and categorized into themes related to the review questions.,,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Initial searches of 10 databases by CW in March 2024 yielded 2226 articles. Of these, 1291 (57.99%) duplicates were removed in EndNote. The remaining 935 papers were exported to Rayyan for title, abstract, and full-text screening. During the first round of screening, 80 more duplicates were removed, leaving 855 papers. CW identified 25 additional articles by searching the reference lists of excluded reviews and articles selected for inclusion. At title and abstract screening, CW reviewed 100% (880/880) of the records, and 2 reviewers (LM and CR) independently screened 25% (220/880) each, ensuring the records fulfilled the inclusion criteria. LM and CR achieved a 99% alignment score with CW?s screened papers. The detailed selection process of the articles is presented in the PRISMA-ScR flow diagram (Figure 1).",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"A total of 20 studies were reviewed. The articles were published in English between 2019 and 2024: a total of 20% (4/20) in 2019, a total of 25% (5/20) in 2020, a total of 15% (3/20) in 2021, a total of 20% (4/20) in 2022, a total of 10% (2/20) in 2023, and 10% (2/20) in 2024. Where provided, the start year of the intervention implementation was noted: 2013, a total of 5% (1/20) [24]; 2017, a total of 5% (1/20) [69]; 2018, a total of 5% (1/20) [23]; 2019, a total of 15% (3/20) [21,56,70]; 2020, a total of 15% (3/20) [71-73]; 2021, a total of 15% (3/20) [74-76]; 2022, a total of 5% (1/20) [77]; and 2023, a total of 5% (1/20) [78]. The implementation date or year was unclear in the following references [79-84].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Geographically, the lead authors were from India (5/20, 25%); United States (5/20, 25%); Norway (3/20, 15%); and China, Colombia, Finland, Iran, Kenya, Philippines, and Switzerland (1/20, 5% each).",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Concerning study design, RCTs were 25% (5/20) [22,23,56,82,84] of all studies, followed by RCT protocols (3/20, 15%) [74,75,77], qualitative studies (4/20, 20%) [69,76,79,81], mixed methods approaches (5/20, 25%) [71-73,78,80], a quasi-experimental feasibility study (1/20, 5%) [24], a multicycle usability testing approach (1/20, 5%) [70], an intervention design (1/20, 5%) [83], and a pilot study (1/20, 5%) [21]. A total of 15% (3/20) were study protocols, therefore the studies were underway.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Regarding the outcome measures, 70% (14/20) reported on primary and secondary measures, while 30% (6/20) did not. The RCTs used a total of 21 different psychometric tests, scales, and outcome measures (seeÿMultimedia Appendix 4ÿfor the charted data). The most common psychometric measures were the Patient Health Questionnaire-8 and Patient Health Questionnaire-9 for measuring depression and the Generalized Anxiety Disorders-7 for measuring anxiety. In 2 studies, the outcome measures were culturally validated for the target population [23,82].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"In total, 100% (20/20) of studies described participants as ?adolescents? aged between 10 and 19 years. Overall, the sample size was noted in 90% (18/20) of papers and ranged from 10 to 3960 participants. However, in 2 studies, 10% (2/20) did not report the sample size [76,83].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The duration of the interventions varied widely; for example, 10% (2/20) were single-session interventions [21,75], 5% (1/20) lasted 2 to 4 weeks [76], 10% (2/20) lasted 4 weeks [56,74], 5% (1/20) lasted 5 weeks [71], 5% (1/20) lasted 7 weeks [24], 5% (1/20) lasted 2 months [78], 5% (1/20) lasted 10 weeks [72], 5% (1/20) lasted 11 weeks [70], 5% (1/20) lasted 12 weeks [84], 5% (1/20) was anticipated to last between 2 and 4 months [81], 20% (4/20) lasted 6 months [23,79,80,82], and 5% (1/20) lasted 12 months [77]. The following did not specify the length of the intervention [69,73,83]. Of the 20 papers, 60% (12/20) had a follow-up period ranging from baseline to 12 months, and 40% (8/20) did not report a follow-up period. In 1 study (1/20, 5%), the authors called for a future economic evaluation of the DMHI [77]. Another paper (1/20, 5%) [76], reported on a cost-effective evaluation, noting that the cost of an incremental increase in well-being was US $37, and the cost of reducing emotional and behavioral issues was US $20. Of the other studies, 90% (18/20) did not report on the cost-effectiveness of their DMHI.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"A total of 14 different DMHIs were identified, addressing one or more of the following mental health disorders: depression, 65% (13/20); well-being, 30% (6/20); emotional problem-solving, 20% (4/20); anxiety, 30% (6/20); distress, 5% (1/20); suicidal ideation, 10% (2/20); stigma, 10% (2/20); resilience, 5% (1/20); self-harm, 15% (3/20); and general mental health disorders, 10% (2/20). The main combination was depression and anxiety. Most DMHIs (13/20, 65%) were delivered or planned to be delivered in school settings, while others were delivered in clinics (2/20, 10%), hospitals (2/20, 10%), Urban Primary Health Centre in slum clusters (2/20, 10%), and refugee camps (1/20, 5%). Finally, 5% (1/20) did not specify the setting [83] (seeÿTable 1).",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Of the 20 studies, 30% (6/20) were conducted in India, 20% (4/20) in Kenya, 10% (2/20) in Lebanon, 5% (1/20) in China, 5% (1/20) in Colombia, 5% (1/20) in Iran, 5% (1/20) in the Philippines, 5% (1/20) in South Africa, 5% (1/20) in South Africa and Uganda, 5% (1/20) in Thailand, and 5% (1/20) in Ukraine. There were 4 upper-middle?income economies, 6 lower-middle?income economies, and 1 low-income economy. All met the LMIC definition set by the World Bank (seeÿTables 2ÿandÿ3).",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Of the 20 papers, 60% (12/20) involved adolescents in co-designing [85] or participatory approaches at the design stage. For instance, the content of DepisNet-Thai [24] was developed from discussions with adolescents. Elsewhere, co-designing activities informed the development of POD Adventures [69], PRIDE [74], antistigma materials for ARTEMIS (Adolescents? Resilience and Treatment Needs for Mental Health in Indian Slums) [73], and the Kuamsha app [70]. Adolescents contributed to intervention designs via group discussions for Smartteen [84] and Shamiri-Digital [21]. Some interventions were existing DMHIs adapted to the target users? cultural contexts, for example, the Happy Helping Hand was initially launched in Norway but was developed in collaboration with adolescent Syrian refugees and Norwegian adolescents. It was later culturally adapted for use with refugee adolescents in Lebanon [71,72]. Furthermore, the Happy Helping Hand materials were also adapted for Ukrainian adolescents [78]. In an ongoing study (1/20, 5%), an Adolescent Expert Advisory Group will guide researchers on all aspects of the project design, development, and implementation [77].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Of 20 studies, 60% (n=12) engaged with frameworks, toolkits, models, or theories related to behavior change interventions. These included cognitive behavioral models, social learning theory, theories of coping during adolescence, persuasive systems design, and stress-coping theory, among others. Further, 1 (5%) study consulted a digital health framework that included digital maturity and readiness content [69]. Another study referred to guidance for developing and evaluating complex interventions [73]. One paper (5%) reported how their intervention aligned with the national mental health program and the government?s national adolescent health program [77], ensuring their DMHI meets the needs and priorities of the nation?s adolescents.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"A total of 90% (18/20) reported on adolescent facilitators and barriers to DMHI engagement. Further, 3 (15%) studies were underway and, therefore, had no findings or results to report at the time of the present review. However, the authors listed factors that facilitated or impeded access to DMHIs for adolescents where possible (seeÿTextbox 2).",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"This scoping review aimed to explore what is known about DMHIs for adolescents in LMICs, as reported in the literature. In 2024, the World Bank categorized 134 countries as LMICs [9]. This review located only 11 countries engaged with adolescent DMHIs, illustrating the limited implementation of these solutions across LMICs and reflecting the emergent nature of the field [45]. We analyzed 20 papers to understand how these DMHIs were designed and evaluated, in what capacity adolescents were involved in the design process, what frameworks or theories were applied, and what factors impacted adolescent engagement with the DMHIs.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Overall, 14 different DMHIs were identified (POD Adventures is part of the PRIDE research program 2016-2022). DMHIs were designed for a limited range of mental health disorders, namely depression and anxiety. Almost all included adolescent input at the design stage, underscoring the importance of person-centered or user-centered approaches in DHIs. The DMHIs were delivered in diverse formats, including group delivery and self-guided methods, with lay staff or mental health professionals, including counselors, psychologists, or psychiatrists. Interventions were administered through smartphones, mobile phones, tablets, computers, and the web, often conducted in schools or clinical settings. Significant structural, psychological, and financial barriers exist in engagement with the DMHIs.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The study designs included RCTs, mixed methods, and qualitative studies. Most studies reported positive outcomes for symptom reduction, feasibility, and acceptability, measured by specific outcome measures. However, most were small scale and not trialed on a large scale over extended periods. While DMHIs were feasible and acceptable among adolescents, there remains a gap in the literature about their long-term cost- and clinical effectiveness.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The DMHIs were designed for depression, anxiety, self-harm, well-being, resilience, stigma, stress, and suicide ideation. However, this is not reflective of the broad and complex range of mental health disorders that adolescents develop, including substance misuse and posttraumatic stress disorder [1,6,45]. Concerning intervention settings, most were delivered in schools or hospitals. Indeed, previous studies have recognized schools as critical settings that offer a vital entry point for receiving adolescent mental health services [86,87]. Conversely, out-of-school adolescents or those unlikely to visit those hospitals may miss the opportunity to engage with the DMHIs [88].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"While RCTs remain the gold standard for evaluating the effectiveness of DHIs [89,90], they are costly and time-consuming. We identified only 5 RCTs evaluating the effectiveness of adolescent DMHIs [23,56,82,84], with a further 3 RCT protocols underway [74,75,77]. In India, Smartteen [84] was trialed on 21 adolescents with depression against a treatment-as-usual group. The DMHI was feasible, acceptable, and more effective than the treatment-as-usual at reducing symptoms at 12 weeks. Even with reduced therapist time, adolescents adhered to treatment compliance. However, the authors call for more rigorous evaluations at scale. In another study [82], DIALOG+ was adapted for adolescents in educational settings (DIALOG+S), using focus groups with teachers and adolescents. The DMHI was trialed with 70 Colombian adolescents, randomly assigned into DIALOG+S or an active control group (counseling as usual). The intervention was feasible and acceptable and could improve mental health, quality of life, and emotional symptoms. The authors call for larger studies to assess its efficacy. In Iran, the DAD (Dorehye Amozeshie Dokhtaran) [23] was trialed with 128 adolescents, randomly assigned into the DAD or a control group. The intervention showed an improvement in depression symptoms. However, the effects decreased after 12 weeks. The intervention did not affect the outcome expectations or self-efficacy. Elsewhere Shamiri-Digital [75] was trialed with 103 adolescents, randomly assigned into Shamiri-Digital or a study-skills control condition. Shamiri-Digital reduced depressive symptoms compared to the control. However, there were no significant effects on anxiety symptoms, well-being, or happiness. The authors called for replicate trials with extended follow-up periods. In a secondary analysis of this trial, the authors sought to evaluate the costs and cost-effectiveness of Shamiri-Digital through an economic evaluation [91]. Their findings indicate that Shamiri-Digital can be delivered for less than US $4 per student, which is more cost-effective than traditional interventions, for example, 12-16-week cognitive behavioral therapy sessions. However, it is difficult to draw inferences from these studies without critically assessing the quality of the evidence.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"A critical design decision came from the inclusion of culturally validated elements. Some studies culturally adapted some components of the intervention [78,82]. Further, 1 study culturally validated an existing psychometric tool for their DMHI, for example, the study [24] adapted the Perceived Stress Scale to make it a reliable and valid instrument in keeping with the Thai culture. Additionally, another study [23] used the Farsi version of the Perceived Social Support Scale-Revised and the Farsi version of the Sherer General Self-Efficacy Questionnaire, reporting that the adapted scales were more appropriate and aligned to Iranian cultures. This aligns with existing literature emphasizing the importance of culturally appropriate DHIs [92,93]. Furthermore, they ensure resonance with the target populations? beliefs, practices, and values leading to improved engagement, treatment adherence, and outcomes [10,44,65,94-96]. In contrast, the Norwegian-designed Happy Helping Hand app was not adapted to the Arab culture for Syrian adolescents, and this was detrimental to the delivery of a DMHI, as themes were deemed religiously and culturally inappropriate, and therefore, certain aspects of the DMHI were skipped [71].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"An important design element was the inclusion of lay, peer, or therapist support, with adolescents preferring this option [73,76,79]. The benefits of this approach have been previously reported [55,57,97], where interventions with in-person options were more effective than self-guided or automized interventions [55].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The advantages of involving adolescents in participatory and co-design approaches for DMHIs are well documented [67,98-104]. In this review, for example, adolescents were engaged in a series of co-design workshops for exploring existing popular apps, for example, Temple Run (Imangi Studios) and Candy Crush (King); story building, paper prototyping, and discussions about prototype ideas for POD Adventures [69]; the cocreation of an antistigma campaign as part of the main intervention for the ARTEMIS project [77]; and 1 study incorporated feedback from recent high school graduates into the design of the group-based Shamiri-Digital intervention as an iterative process of the intervention design [56].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Collectively these studies show that participatory approaches are invaluable for generating insights for improving the DMHIs. Nevertheless, there are challenges [105], and authors are calling for the evaluation of co-design processes in diverse contexts and how that impacts technology [102,103] with clear guidance around these processes [98]. These insights will advance understanding of how and why adolescents engage in DHIs [101] and the health care outcomes of such engagements. From the review, reported activities included feasibility, acceptability, and usability studies, workshops, interviews, and focus groups. All were used clearly and meaningfully to advance the DMHI design and evaluation [24,69,70,73,74].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Incorporating evidence-based theories and techniques that encourage user engagement and behavior change is an essential element of DHI design [25,26,44,106]. Most DMHIs in this review were underpinned by cognitive-behavioral techniques involving behavioral activation and problem-solving features [71,72,76,78,84]. Some used stand-alone theories [23], for example, the social cognitive theory, and others used a combination of behavior change techniques [24], for example, theories of coping during adolescence, the self-determination theory, and the technology acceptance model. However, not all the papers explained how the behavior change theory or technique impacted the target user?s mental health. Or, indeed, the evidence on which the selection or combinations of theories were based [106].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Further, incorporating national or international guidance enhanced the intervention design, development, and evaluation. For example, 1 study [69] used the WHO guidelines on monitoring and evaluating DHIs, which addressed digital maturity, readiness, and scalability, whereas another [73] consulted the UK Medical Research Council guidance for developing and evaluating complex interventions focused on process evaluation and contextual factors. Finally, 1 study [77] accessed the WHO?s Mental Health Gap Action Programme-Intervention Guide, which considers training requirements and treatment protocols in low-resource settings.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Textbox 2ÿsummarizes key barriers and facilitators from the included studies. Access and engagement with DMHIs can be impacted by financial, geographical, psychological, cultural, and structural factors [107-111]. Notable barriers were the affordability of devices, cultural appropriateness, power outages, poor digital and literacy skills, inadequate internet connectivity, and limited access to devices in rural areas. The findings are consistent with other LMICs [38,44,112].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Stigma (self-stigma, eg, individual level, and societal stigma, eg, system level) remains a complex and multifaceted barrier despite the potential for increased privacy, confidentiality, anonymity, and accessibility through DMHIs [113-115]. Multiple factors contribute to persistent stigma, such as societal attitudes, the digital divide, lack of awareness, fear of exposure, discrimination, and cultural sensitivities [113,116,117]. These factors could limit engagement with DMHIs due to the negative social consequences in areas where mental health is a stigmatized issue [118,119].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Further, 1 study described how COVID-19 worsened the already dire human rights and socioeconomic conditions for displaced Syrians living in Lebanon [71], including the loss of income, food, and essential living services, disrupting education and access to learning resources. Another study [82] reported similar findings in Colombia, noting that most adolescents impacted by COVID did not have access to support and treatment. This shortage of mental health professionals and a widening treatment gap, poor education, and community knowledge reinforced the stigma and false beliefs about mental health [82].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Adolescents highlighted some facilitators, such as access to a safe space to discuss stigmatized mental health issues, culturally sensitive DMHIs that embed the local cultural and religious values by design, DMHIs that maintain face-to-face contact while offering therapist-led or lay or peer-led options, access to reading materials in addition to the DMHI, appropriate content that is entertaining, personalized, and has gamified elements, privacy and confidentiality, and DMHIs that are free to use. Previous studies have suggested that addressing the digital divide could mitigate these barriers, providing equitable access to DMHIs, yet care must be taken to ensure that the pursuit of DMHIs does not widen the existing inequalities, further reinforcing the digital divide, undermining the equitable delivery of care [120-122].",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"To the authors? knowledge, 1 scoping review [123] has been published on DMHIs for adolescents in LMICs. Their review [123] was limited to mobile phones only; however, this review has a wider scope, which is more inclusive of the technological infrastructure in LMICs. Furthermore, this review has a more extensive search strategy, searching 10 databases and including gray literature such as dissertations and conference proceedings, and is a more robust evidence synthesis, whereas the review [123] only searched APA PsycINFO, Web of Science, Psychiatry Online, and EBSCOhost. Finally, the eligibility criteria are different, and the previous review is limited by its lack of specificity of publication parameters per publication dates. This review has been purposefully restricted to a 5-year period (2019-2024), as specified earlier in this paper.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"There are some limitations to the present review; 1 reviewer performed the database searches, which may have introduced reviewer bias. However, 2 more reviewers independently screened 25% (220/880) of each of the titles and abstracts of potential papers against the eligibility criteria. This step reduces bias and adds credibility and rigor to the review process. In addition, the quality of included studies was not appraised or assessed for risk of bias therefore, there is no assurance of the quality of the evidence in this scoping review. This is consistent with the aim of a scoping review, which is to rapidly map the available literature and not perform a systematic analysis. Finally, the review was limited to papers published in English. This may have significantly reduced the number of eligible studies from LMICs.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"The global shortage of access to mental health treatment demonstrates the critical need for effective, low-cost, scalable solutions. The COVID-19 pandemic has highlighted the need for alternative solutions, and leveraging digital technologies through the international frameworks of the UHC and SDGs can alleviate the significant burden of mental health inequalities among adolescents in LMICs.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"In this review, adolescent involvement in various stages of the theory-based design and evaluation cycle enhanced the intervention?s acceptability, feasibility, and usefulness. While RCTs of DMHIs remain the gold standard in this field, they are sparse. Researchers have called for repeat trials at larger scales in diverse settings to assess their effectiveness, scalability, and feasibility. Moreover, only some of the tools and instruments used to evaluate the DMHIs were culturally validated in LMIC contexts, making it difficult to establish how the DMHI would benefit adolescents beyond the test settings.",,,,,
Digital Mental Health Interventions for Adolescents in Low- and Middle-Income Countries: Scoping Review,"Addressing the digital divide and related barriers, such as stigma, will be a critical challenge to ensuring equitable access to universal and affordable mental health care. Understanding the long-term clinical implications and the cost-effectiveness of DMHIs will be another challenge for future research because that is an essential consideration for sustainable DMHIs in resource-constrained settings.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","This study aimed to present a new approach to predict to delirium admitted to the acute palliative care unit. To achieve this, this study employed machine learning model to predict delirium in patients in palliative care and identified the significant features that influenced the model. A multicenter, patient-based registry cohort study in South Korea between January 1, 2019, and December 31, 2020. Delirium was identified by reviewing the medical records based on the criteria of the Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition. The study dataset included 165 patients with delirium among 2314 patients with advanced cancer admitted to the acute palliative care unit. Seven machine learning models, including extreme gradient boosting, adaptive boosting, gradient boosting, light gradient boosting, logistic regression, support vector machine, and random forest, were evaluated to predict delirium in patients with advanced cancer admitted to the acute palliative care unit. An ensemble approach was adopted to determine the optimal model. For k-fold cross-validation, the combination of extreme gradient boosting and random forest provided the best performance, achieving the following accuracy metrics: 68.83% sensitivity, 70.85% specificity, 69.84% balanced accuracy, and 74.55% area under the receiver operating characteristic curve. The performance of the isolated testing dataset was also validated, and the machine learning model was successfully deployed on a public website (http://ai-wm.khu.ac.kr/Delirium/) to provide public access to delirium prediction results in patients with advanced cancer. Furthermore, using feature importance analysis, sex was determined to be the top contributor in predicting delirium, followed by a history of delirium, chemotherapy, smoking status, alcohol consumption, and living with family. Based on a large-scale, multicenter, patient-based registry cohort, a machine learning prediction model for delirium in patients with advanced cancer was developed in South Korea. We believe that this model will assist healthcare providers in treating patients with delirium and advanced cancer.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","Delirium, a common neuropsychiatric problem among patients with advanced cancer1, can result in extended hospital stays, higher mortality and morbidity rates, increased healthcare costs, and considerable distress for both patients and their family members, as well as healthcare providers2,3. Among patients with advanced cancer admitted to the acute palliative care unit (APCU), delirium can affect 42?88% of individuals4. However, few comprehensive studies have thoroughly examined its prevalence and potential risk factors5. Although effective preventive interventions for delirium in hospital settings are currently lacking, physicians and healthcare providers can alleviate modifiable risk factors within the APCU by providing exercise programs and family support to reduce the occurrence of delirium6. Therefore, early recognition and prevention are essential in patients with risk factors for developing delirium7.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","To date, nurse-administered questionnaires have mainly been used to predict the risk of delirium in hospitalized patients8. However, physicians may find it challenging to conduct daily assessments through questionnaires. Machine learning models have recently been introduced9?14. Machine learning models were previously used to predict delirium among patients after surgery for degenerative spinal disease10, patients admitted to the intensive care unit11, hospitalized patients without cognitive impairment12, patients admitted to the general ward13, and older patients after general surgery14. Furthermore, previous study on predicting delirium was also conducted in patients with advanced cancer receiving pharmacological interventions through machine learning models. However, this study was limited to patients taking antipsychotic medications or trazodone, and no operational criteria for determining the precipitating factors of delirium9. The area under the receiver operating characteristic curve (AUROC) for these studies ranged from 0.666 to 0.964.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","The machine learning model for predicting delirium in patients with advanced cancer has been explored, with suggested advantages9. However, this study only considered the decision-tree model, which is largely unstable because a small change in the data can result in a major change in the structure of the model. Therefore, a comprehensive study using machine learning models is needed to more accurately assess the features of delirium in patients with advanced cancer admitted to the APCU. We aimed to develop and compare a variety of machine learning models to predict delirium in patients with advanced cancer admitted to the APCU and investigate the significant features that influenced the machine learning model.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","Our study utilized a multicenter, patient-based registry cohort collected from four hospitals in South Korea: Seoul National University Bundang Hospital, Yonsei University Severance Hospital, CHA University Bundang Medical Center, and Seoul National University Hospital. We identified potential participants as patients with advanced cancer admitted to the APCU at four centers between January 1, 2019, and December 31, 2020. Of the 2328 patients who met the eligibility criteria: (1) aged 20ÿyears or older; (2) diagnosed with advanced solid cancer; and (3) admitted to the APCU. We excluded five patients with a hospital stay exceeding 3ÿmonths, six patients transferred to other departments, and three patients with terminal delirium, defined as delirium that occurred within 2ÿweeks of death. Our final sample consisted of 2314 patients with advanced cancer who were admitted to the APCU and who met all eligibility criteria15.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","The study protocol received approval from the Institutional Review Boards of each center (CHA University, CHAMC 2021-03-054-002; Seoul National University, H-2103-028-1201; Seoul National University Bundang Hospital, B-2104/681-405; and Yonsei University, 4-2021-0323). The requirement for informed consent was waived by the Institutional Review Board of each center (CHA University; Seoul National University; Seoul National University Bundang Hospital; and Yonsei University) because only anonymized data were examined. The researchers of this study confirm that all methods were performed in accordance with the relevant guidelines and regulations. Especially, this research followed the guidelines outlined in the transparent reporting of a multivariable prediction model for individual prognosis or diagnosis (TRIPOD) statement (TableÿS1).",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","A total of 39 variables were used in this study, and the justification of the selection was selected based on several previous studies predicting delirium and the available variables in the APCU16?18. Based on these results, we proceeded with the establishment of a national registry, excluding the use of data for which construction was deemed infeasible. Additionally19, within the National Registry Project. The dataset included general information20,21ÿsuch as age, sex, chemotherapy during hospitalization, living situation, medical aid recipients, education level, use of glasses or hearing aids, and history of alcohol consumption and smoking. Clinical risk factors such as obesity, blood pressure, and body temperature, various laboratory results like blood tests and C-reactive protein levels, and a history of diseases including delirium, cardiovascular disease, diabetes mellitus, respiratory disease, liver disease, mental illness, and head injury were also collected. We aimed to ascertain the onset of delirium in patients with advanced cancer immediately upon APCU admission, hence all baseline datasets consist of data obtained at the time of admission to the APCU.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","To identify delirium, we reviewed medical records based on the criteria outlined in the Fifth Edition of the Diagnostic and Statistical Manual of Mental Disorders. A well-trained physician and an academic nurse conducted this detailed review. Based on previous validation study, we did not use the code from the 10th revision of the International Classification of Diseases because it was deemed unreliable with low sensitivity22. Instead, we recorded all potential symptoms, signs, and associated medications and had at least two specialists (BDK and YJK) review each case. In case of any disagreement between the specialists, an additional specialist (SHY) was consulted to make the final decision.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","The primary objective of this study was to predict the occurrence of delirium in patients with advanced cancer admitted to the APCU using machine learning models. To achieve this, the data were split into a training-to-testing ratio of 80:20, with the training set comprising 1851 (80%) patients and the testing set comprising 463 (20%) patients. Feature normalization was performed by initially computing the mean and standard deviation of each feature within the training set. Subsequently, this normalization procedure was applied to both the training and testing datasets, to ensure that the mean values were centered at zero and the standard deviations were scaled to one. The proposed machine learning models underwent validated through a stratified fivefold cross-validation process on the training data, followed by further validation using independent testing data23?27.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","We evaluated seven machine learning algorithms for predicting delirium in patients with advanced cancer: extreme gradient boosting (XGBoost), adaptive boosting (AdaBoost), gradient boosting (GBM), light gradient boosting (LGBM), logistic regression (LR), support vector machine (SVM), and random forest (RF). For these seven machine learning algorithms, which were optimized by input parameters and hyperparameters, we applied an exhaustive search, which used to brute force through all possible combinations of a set of the hyperparameter combination yielding the best performance, with fivefold cross validation for each model to identify the most optimal hyperparameters. To estimate the uncertainty and variability of our results, we calculated the AUROC, sensitivity, specificity, accuracy, and balanced accuracy scores during the fivefold cross-validation process. These metrics were calculated by the following formulas with values of true positive (TP), true negative (TN), false positive (FP), false negative (FN) for binary classification:",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","We adopted AUROC, which is commonly used in binary classification and is not sensitive to class imbalances representing the relationship between the true positive rate (TPR) and the false positive rate (FPR) as the threshold changes, as the evaluation metric for measuring the overall performance of the model.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","To further enhance the performance of the machine learning model, we employed an ensemble approach. This technique combines multiple models to improve prediction accuracy and robustness. We created various groups of models by combining all possible model combinations and evaluated their performances to determine the best combination. This approach leveraged the strengths of each individual model while mitigating any weaknesses or limitations.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","For each of the best performing machine learning models, we investigated the feature importance, which is a measure of how influential a feature was in splitting a class when branching a node in a tree-based model.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","We utilized several popular software tools, including Python 3.9.7 (Python Software Foundation, Wilmington, DE, USA), TensorFlow-gpu 2.6.0, Keras 2.6.0, NumPy 1.21.5, Pandas 1.4.1, Matplotlib 3.5.1, and Scikit-learn 1.0.2, to implement the machine learning models28?30.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","We also deployed our machine learning model on a public website (http://ai-wm.khu.ac.kr/Delirium/), enabling the prediction of delirium when provided with information from 39 patients. Upon accessing the website, users enter patient information, which is encoded on the website server, allowing for an immediate delirium prediction result. No private information beyond the selected 39 pieces of data needed to be entered, and all entered information was promptly deleted once the prediction result was obtained, ensuring no risk of information exposure.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort",The institutional review board of the four centers approved this study and waived the requirement for informed consent because only anonymized data were examined.,,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","The protocol was approved by the institutional review boards of the four centers (CHA University, CHAMC 2021-03-054-002; Seoul National University, H-2103-028-1201; Seoul National University Bundang Hospital, B-2104/681-405; and Yonsei University, 4-2021-0323).",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","This study was utilized a multicenter patient-based registry cohort collected from four hospitals in South Korea to develop and investigate the machine learning model for predicting delirium in patients with advanced cancer. Tableÿ1ÿdisplays the baseline characteristics of the study population. In the original cohort, 165 (7.1%) patients experienced delirium.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","Tableÿ2ÿsummarizes the fivefold cross validation accuracy comparison of each model and the ensemble machine learning model using the accuracy metrics of sensitivity, specificity, balanced accuracy, and AUROC. In terms of balanced accuracy and AUROC, the three models?RF, XGBoost, and LGB?demonstrated the highest performance compared with the other single models. To further improve classification performance, we adopted an ensemble approach using three single models with higher performance: RF, XGBoost, and LGB. The results revealed that the combination of XGBoost and RF provided the most optimal performance, achieving the following accuracy metrics: 68.83% sensitivity, 70.85% specificity, 69.84% balanced accuracy, and 74.55% AUROC. Subsequently, we performed feature importance analysis using an ensemble model that combines XGBoost and RF. We averaged and normalized the values of feature importance from the two models and ranked each feature. Figureÿ1ÿpresents the normalized values of ranked feature importance from all 39 features used to predict delirium in patients with advanced cancer. The results indicated that sex (1.00) had the highest importance value and was the primary contributor to predicting delirium, followed by a history of delirium (0.82), chemotherapy during hospitalization (0.81), smoking status (0.73), alcohol consumption (0.67), living with family (0.49), and age (0.47).",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","We validated the performance of the machine learning models using an isolated testing dataset. Tableÿ3ÿsummarizes the delirium prediction results of the test dataset. The results also showed that the combination of XGBoost and RF provided the most optimal performance with the following accuracy metrics: 75.76% sensitivity, 52.63% specificity, 64.19% balanced accuracy, and 73.11% AUROC. Compared with the fivefold cross validation results, the accuracy metrics of balanced accuracy and AUROC were similar to the testing data results, indicating minimal overfitting or underfitting in the model.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","Furthermore, we deployed our artificial intelligence (AI) on a public website (http://ai-wm.khu.ac.kr/Delirium/) to allow public access to the delirium prediction results in patients with advanced cancer. Figureÿ2ÿdisplays the website of the deployed AI model. Figureÿ2a illustrates the user web interface for entering information, where users inputs 39-feature data such as sex, age, chemotherapy during hospitalization, living with family, medical aid recipients, and education levels. Upon entering the information into the web application, users can immediately obtain the delirium prediction results, as shown in Fig.ÿ2b. The prediction results include the probability of mortality.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","The results suggest that machine learning models can predict delirium in patients with advanced cancer admitted to the APCU with relatively high accuracy. The combination model of XGBoost and RF demonstrated the best performance for predicting delirium in these patients, achieving a balanced accuracy of 69.84% and an AUROC of 74.55%. This performance was validated through both k-fold cross-validation and testing on an isolated dataset. Notably, sex emerged as the most critical feature for predicting delirium in patients with advanced cancer, followed by a history of delirium, chemotherapy during hospitalization, smoking status, alcohol consumption, living with family, and advanced age. To the best of our knowledge, this study represents the first attempt to use the machine learning model to predict delirium in South Korean patients with advanced cancer. These findings underscore the importance of delirium screening in APCU-admitted patients with advanced cancer and contribute to identifying the most significant risk factors for this patient group.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","Our results, particularly in the combination model of XGBoost and RF, corroborate previously reported risk factors associated with delirium. Earlier research indicated that advanced age, a history of delirium, smoking status, alcohol consumption, and sex were associated with delirium in patients with advanced cancer admitted to the APCU31?34. Male sex was identified as a significant risk factor for neuropsychiatric disorders, potentially due to the protective role of estrogen in individuals with potential cognitive impairments35,36. Males may exhibit more pronounced neuropsychiatric disorders under acute stress, driven by different corticotropin-releasing factor signaling pathways compared with females37. Consistent with prior studies, our findings highlight old age as a significant risk factor for delirium in patients with advanced cancer38?40, with possible contributing factors being atherosclerosis and malnutrition common in older patients40?42. The association of cigarette smoking with delirium is attributed to nicotine withdrawal during hospitalization1. Smokers have been noted to display more severe agitation, characteristic of hyperactive delirium43. Changes in various neurotransmitter systems, including dopamine, opioids, and cholinergic systems, have been implicated in shared hyperactive delirium44. The relationship between chemotherapeutic agents and delirium remains controversial and inconsistent, as reported in single case reports or studies with small populations. Previous studies have suggested that patients who undergo multiple chemotherapy regimens could experience delirium, which may occur in approximately one in 11 adults receiving chemotherapy45,46. Chemotherapeutic agents may penetrate the blood?brain barrier, potentially serving as a risk factor for delirium47,48. Similar to our study, a previous study was conducted to predict delirium in patients with advanced cancer receiving pharmacological intervention through a visually interpretable prediction model9. This study has the advantage of being easy to use with small number of variables, but it is dependent on Delirium Rating Scale Revised-98 and has a limitation in predicting delirium within three days. On the other hand, our study provided a web application with public access with a machine learning model, and could serve as a medical aid for healthcare providers to monitor the delirium in the patients with advanced cancer.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","The primary strength of this study lies in the relatively high accuracy of the machine learning model for detecting delirium in patients with advanced cancer, as validated by testing datasets. Consistently high AUC values in both the training and testing datasets indicate that the combination model of XGBoost and RF is capable of predicting delirium in patients with advanced cancer. Important predictors of delirium include sex, history of delirium, chemotherapy during hospitalization, smoking status, alcohol consumption, living with family, and advanced age. The dataset was collected from four academic cancer centers, involving oncology-trained physicians and healthcare providers, providing a comprehensive view of risk factors associated with delirium in patients with advanced cancer and potentially aiding in the development of effective preventive interventions.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","However, this study had several limitations. Firstly, he datasets were collected from patients admitted to four hospitals and were heterogeneous, potentially limiting the generalizability of the model to the general population. Secondly, delirium assessment tools, diagnostic criteria, observation frequency, and timeframes may differ from those used in clinical trials. Thirdly, machine learning models often benefit from larger datasets, but the sample size of this study was limited. Fourthly, our proposed machine learning model underperformed compared to previous studies predicting delirium across varying patient conditions49,50. Given the limitations of our registry construction project, we did not collect data at various time points. Additional research may be necessary to address this gap. Fifthly, dataset of this study lacks information pertaining to delirium-related medications or disease history. However, we have initiated the establishment of a new prospective cohort to supplement the inadequate input data values. Consequently, we plan to conduct further research to develop more sophisticated machine learning modeling through subsequent studies. Finally, due to the retrospective design of our registry for patients with advanced cancer, it was not feasible to distinguish between different types of delirium (hyperactivity, hypoactivity, and mixed type). We are fully aware of this limitation, and currently, in our newly established prospective cohort, we are making efforts to differentiate between them. To apply machine learning models and achieve external validation, a larger sample size dataset is required. Lastly, an imbalance in the number of patients in each group may limit the performance of the models51,52.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","To the best of our knowledge, this study represents the first creation of a machine learning model for predicting delirium in patients with advanced cancer admitted to the APCU. The use of this machine learning model for delirium prediction in APCU-admitted patients with advanced cancer can significantly improve patient quality of life and reduce physician workload. Especially for Korean healthcare providers with less educational experience in delirium53, the machine learning-based delirium prediction model of patients with advanced cancer could be part of a medical aid. Delirium episodes are particularly common in patients with advanced cancer in the APCU, with prevalence increasing as the terminal phase of the illness approaches. However, delirium in these patients has been inadequately identified and managed. Our model has the potential to profoundly impact risk assessment, early detection, and effective interventions for delirium in patients with advanced cancer.",,,,,
"Machine learning-based model to predict delirium in patients with advanced cancer treated with palliative care: a multicenter, patient-based registry cohort","Using a large-scale multicenter patient-based registry cohort, we have successfully developed the machine learning prediction model for delirium in South Korean patients with advanced cancer. Our study revealed that the combination of XGBoost and RF delivered the most optimal performance, a conclusion validated by the results of both k-fold cross-validation and the isolated testing dataset. Additionally, we identified sex was the primary predictor of delirium, followed by history of delirium, chemotherapy, smoking status, alcohol consumption, and living with family. Furthermore, we have made our AI accessible to the public through a dedicated website (http://ai-wm.khu.ac.kr/Delirium/) to provide delirium prediction results for patients with advanced cancer. Although external validation using prospectively collected data may be necessary to further refine and validate the model, we have implemented a web application to gather additional data. Notably, the application does not store any user-entered information at present. However, we have plans to securely store the user-entered information with their consent, facilitating a real-time learning process to enhance the machine learning model.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"Suicide is the second-leading cause of death among adolescents and is associated with clusters of suicides. Despite numerous studies on this preventable cause of death, the focus has primarily been on single nations and traditional statistical methods.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,This study aims to develop a predictive model for adolescent suicidal thinking using multinational data sets and machine learning (ML).,,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"We used data from the Korea Youth Risk Behavior Web-based Survey with 566,875 adolescents aged between 13 and 18 years and conducted external validation using the Youth Risk Behavior Survey with 103,874 adolescents and Norway?s University National General Survey with 19,574 adolescents. Several tree-based ML models were developed, and feature importance and Shapley additive explanations values were analyzed to identify risk factors for adolescent suicidal thinking.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"When trained on the Korea Youth Risk Behavior Web-based Survey data from South Korea with a 95% CI, the XGBoost model reported an area under the receiver operating characteristic (AUROC) curve of 90.06% (95% CI 89.97-90.16), displaying superior performance compared to other models. For external validation using the Youth Risk Behavior Survey data from the United States and the University National General Survey from Norway, the XGBoost model achieved AUROCs of 83.09% and 81.27%, respectively. Across all data sets, XGBoost consistently outperformed the other models with the highest AUROC score, and was selected as the optimal model. In terms of predictors of suicidal thinking, feelings of sadness and despair were the most influential, accounting for 57.4% of the impact, followed by stress status at 19.8%. This was followed by age (5.7%), household income (4%), academic achievement (3.4%), sex (2.1%), and others, which contributed less than 2% each.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"This study used ML by integrating diverse data sets from 3 countries to address adolescent suicide. The findings highlight the important role of emotional health indicators in predicting suicidal thinking among adolescents. Specifically, sadness and despair were identified as the most significant predictors, followed by stressful conditions and age. These findings emphasize the critical need for early diagnosis and prevention of mental health issues during adolescence.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"Adolescent suicide stands out as a prominent global public health concern, with its rank as the second leading cause of death among young populations underscoring its severity [1,2] Notably, adolescence is a phase characterized by an amplified suicide risk [3]. Concerningly, some geographic regions are experiencing a surge in suicide clusters, where the instances of suicide exceed the typical levels [4]. Research into these clusters indicates that individuals younger than 25 years are up to 4 times more likely to be affected by suicide [5]. Since suicide is preventable in the early stages, there is a pressing need for action through rigorous mental health strategies and proactive educational interventions [6].",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"While various methodologies have been proposed to prevent suicidal thinking in adolescents, many lack empirical outcomes and often fail to identify key determinants [7-9]. A significant gap remains in accurately assessing the risk of suicidal thinking for individual adolescents [2,10,11]. Recent advances in machine learning (ML) methodologies have shown promise in addressing the challenges of adolescent suicidal tendencies. Studies leveraging boosted ML [12], daily data analysis through classification and regression trees [13], and risk and protective factor frameworks [14] have begun to unpack the complex interplay of factors contributing to suicidal thinking among adolescents. However, these studies have also highlighted limitations, including a focus on specific socioeconomic or short-term predictors and a lack of comprehensive risk profiles integrating emotional, social, and psychological variables [12-14].",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"Therefore, in this study, we developed a predictive model for suicidal thinking among adolescents, using advanced ML algorithms. Addressing the gaps identified in earlier research, our model incorporates a broader array of factors, including family dynamics, emotional well-being, academic performance, and general health indicators. Across distinct adolescent cohorts from South Korea, Norway, and the United States, we aimed for a comprehensive multinational approach. By refining our approach based on previous studies? insights, this research aims to highlight the preventability of suicide and influence mental health clinicians and policy makers to develop more effective preventive measures and supportive programs.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"This study aimed to develop an ML model to predict suicidal thinking among Korean adolescents. Our approach used multiple variables extracted from 3 distinct, large-scale international data sources: the Korea Youth Risk Behavior Web-based Survey (KYRBS) [15,16], the Youth Risk Behavior Survey (YRBS), and Norway?s nationwide University National General Survey (Ungdata).",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"Initial data preprocessing involved adjusting the sample sizes after the removal of missing values: KYRBS from 1,145,178 to 566,875, YRBS from 438,566 to 103,874, and Ungdata from 89,077 to 19,574. We analyzed data from adolescents aged between 13 and 18 years who participated in the KYRBS from 2009 to 2021, the YRBS in 2021, and Ungdata from 2017 to 2019. The primary outcome, termed ?current suicidal thinking,? was derived from participants? affirmative responses to the question, ?During the past 12 months, did you ever seriously consider attempting suicide?? This outcome indicated that participants had contemplated serious suicidal thinking at least once in the preceding year. The analysis considered several covariates: region, age, sex, BMI (kg/m2), academic achievement, household income, smoking status, alcoholic consumption, stress status, feelings of sadness and despair, exercise habits, and screen time (Figure S1 inÿMultimedia Appendix 1) [17].",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"We harmonized the data sets for XGBoost model compatibility, addressing the challenge posed by different variable configurations within the same questions. Our preprocessing aligned each variable across the KYRBS, YRBS, and Ungdata data sets, ensuring they matched in terms of content and format. Recognizing the potential disparities in variable configurations across these data sets, we standardized the variable names, formats, and scales, focusing on key features such as demographic information, behavioral factors, psychosocial aspects, and environmental influences that could serve as predictors for suicidal thinking. To ensure consistency, we adopted the following strategic approach to cases where YRBS and Ungdata were missing certain features: by calculating the median of the missing variables in the KYRBS data set, we were able to effectively impute the missing values to maintain the integrity and comparability of the data set compilations. Through variable alignment and addressing missing data, we successfully harnessed the diverse strengths of each data set, facilitating the development of a comprehensive model designed to address adolescent suicidal thinking effectively.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"Our ML model underwent training and validation to ensure its predictive accuracy in identifying suicidal thinking. We used the KYRBS data set to build a model tailored to predict suicidal thinking among Korean adolescents aged between 13 and 18 years. Recognizing the intricate characteristics of the data, we used a variety of tree-based ML techniques, including XGBoost, adaptive boosting (AdaBoost), light gradient-boosting machine (LightGBM), and random forest to train the data set for our modeling process [18]. Before this, data preprocessing measures, such as addressing missing values and encoding categorical variables, were executed to maintain data integrity and optimize the data for the modeling phase.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"We adopted the 10-fold cross-validation method, dividing the initial data set into 10 equal-sized subsets, to rigorously assess the performance efficacy of the ML model. Of these, 9 are designated for model training, while the remaining subset serves as validation [19]. The process iterates 10 times, ensuring each subset undergoes validation at least once. During each cycle, we computed various performance metrics such as area under the receiver operating characteristic (AUROC) curve, sensitivity, specificity, accuracy, and balanced accuracy, along with their respective 95% CIs [20-25]. The 95% CIs provide a range of possible values for the model?s performance metrics, allowing us to assess the stability and generalizability of the model. For a visual representation of the model efficacy, we used visualization methods, primarily the receiver operating characteristic curve. After 10 iterations, the metrics from each were averaged to determine the final performance evaluation.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"We trained our model on the KYRBS data set using 10-fold cross-validation. The model trained on the KYRBS data set was then externally validated with YRBS and Ungdata data sets preprocessed with the same column structure as KYRBS. This rigorous process reinforced the reliability of our model?s performance trained on the KYRBS data set [26]. Among the 4 models tested, XGBoost consistently yielded the highest AUROC scores across all data sets, leading to its selection as the primary model.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"We performed hyperparameter tuning using GridSearchCV to optimize the performance of the XGBoost model, prioritizing the maximization of the AUROC score to determine the optimal hyperparameter combination. Hyperparameters were carefully selected for improved performance: the gbtree booster was used for its effectiveness in classification tasks, and the logloss evaluation metric was chosen to ensure accurate probability estimations. We set the learning rate at 0.08 to balance training speed with model accuracy, and the max depth was capped at 5 to prevent overfitting while allowing the model to capture complex patterns. Additionally, 350 trees (n_estimators) were used to construct a robust model, with further adjustments made to parameters like ?scale_pos_weight? and subsample to address class imbalance and enhance model stability. These adjustments were important in refining our model?s predictive capabilities and are detailed in Table S1 inÿMultimedia Appendix 1. In order to interpret and gain insights into the model predictions, we used Shapley additive explanations (SHAP) values, a unified measure derived from cooperative game theory. Data set variables were analyzed with SAS software (version 9.3; SAS Institute Inc), and ML analysis was performed using Python (version 3.11.4; Python Software Foundation). The main Python libraries used are as follows: NumPy (version 1.26.0; Python Software Foundation) for data arrays and operations, and Pandas (version 2.1.0; Python Software Foundation) for data manipulation and analysis. All 3?scikit-learn (version 1.2.2; scikit-learn development team), TensorFlow-gpu (version 2.6.0; Tensor development team), and Keras (version 2.6.0; Keras development team)?were used for constructing and training ML models [27]. Additionally, the SHAP package (version 0.42.1) was used to interpret the ML models and for its explanation capabilities [28].",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"All computations, model training, and evaluations were executed using Python (version 3.11.4). Key libraries from our toolbox included scikit-learn (version 1.2.2), NumPy (version 1.24.0), and Pandas (version 2.1.0) for ML tasks and data wrangling. Visualization was facilitated using Matplotlib (version 3.7.2) and Seaborn (version 0.12.2).",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"The study protocol was approved by the institutional review board of the Korean Disease Control and Prevention Agency (2014-06EXP-02-P-A), the US Centers for Disease Control and Prevention (#1969.0), the Norwegian Centre for Research Data and Data Protection Office of Inland Hospital Trust (18778329) and by the local law of the Population Health Promotion Act 19 (117058) form of the Korean government. All participants provided written informed consent. This research followed the guidelines outlined in the TRIPOD (Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis) statement (Table S2 inÿMultimedia Appendix 1).",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"This study was conducted to develop a ML-based predictive model for suicidal thinking among adolescents aged between 13 and 18 years. After collecting independent data from 3 countries, covariates were standardized for the ML prediction modeling process (Figures 1ÿandÿ2).",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"The distribution of age in the initial training cohort for KYRBS from South Korea, which was used to build the prediction model, was as follows: aged 13 years (94,923/566,875, 16.74%), aged 14 years (98,624/566,875, 17.4%), aged 15 years (100,490/566,875, 17.73%), aged 16 years (90,057/566,875, 15.89%), aged 17 years (92,071/566,875, 16.24%), and aged 18 years (90,710/566,875, 16%). For the external validation cohort using YRBS from the United States, the age distribution was as follows: aged 13 years (351/103,874, 0.34%), aged 14 years (21,095/103,874, 20.31%), aged 15 years (28,016/103,874, 26.97%), aged 16 years (25,929/103,874, 24.96%), aged 17 years (22,405/103,874, 21.57%), and aged 18 years (6078/103,874, 5.85%). Another external validation stage using Ungdata from Norway had the following age distribution: aged 13 years (5039/19,574, 25.74%), aged 14 years (4874/19,574, 24.9%), aged 15 years (5034/19,574, 25.72%), aged 16 years (3181/19,574, 16.25%), aged 17 years (845/19,574, 4.32%), and aged 18 years (601/19,574, 3.07%) (Table 1).",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"Both the initial training cohort and the external validation cohorts took into account socioeconomic backgrounds, such as household income and academic achievement, as well as risk behaviors such as alcohol consumption, smoking, and screen time. Additionally, factors that could potentially influence mental health, such as feelings of sadness and despair, were also considered. Inconsistencies or missing values in validation sets were addressed by implementing median imputation from the primary training data. Such thorough demographic incorporation bolsters our model performance, offering a nuanced understanding of suicidal thinking in adolescents.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"Table S1 inÿMultimedia Appendix 1ÿandÿTable 2ÿpresent the process of hyperparameter tuning the XGBoost model and the evaluation of our models conducted on data sets from 3 distinct countries using 5 performance metrics. Notably, XGBoost emerged as the frontrunner among the 4 tested models by getting hyperparameters of booster: gbtree, eval_metric: logloss, learning_rate: 0.08, max_depth: 5, n_estimators: 350, scale_pos_weight: 2, subsample: 0.09 (Table S1 inÿMultimedia Appendix 1). When put to the training on the KYRBS data set from South Korea, with a 95% CI, the XGBoost model reported an AUROC of 90.06 (95% CI 89.97-90.16), sensitivity was 82.11 (95% CI 81.67-82.55), specificity was 82.16 (95% CI 81.68-82.63), accuracy was 82.13 (95% CI 82.01-82.26), and balanced accuracy was 82.13 (95% CI 82.01-82.26), consistently displaying superior results compared to the other 3 models. During the external validation assessment, the model evaluation was conducted without considering the 95% CI. For the external model validation, using the YRBS from the United States, the XGBoost model achieved an AUROC of 83.09%, sensitivity of 80.26%, specificity of 75.52%, accuracy of 76.58%, and balanced accuracy of 77.89%. For the external validation using the Ungdata from Norway, the XGBoost model achieved an AUROC of 81.27%, sensitivity of 79.19%, specificity of 80%, accuracy of 79.92%, and balanced accuracy of 79.60%. Across all data sets, XGBoost consistently outperformed all other models with the highest AUROC score, which was selected as the most optimal model (Figure 3).",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"Table 3ÿshows the feature importance derived from the XGBoost model, illustrating the relative contributions of each feature to predicting suicidal thinking. Notably, feelings of sadness and despair emerge as the most dominant predictor, accounting for 57.4% of the influence, followed by stress status at 19.8%. Subsequent factors include age (5.7%), household income (4%), academic achievement (3.4%), sex (2.1%), and others contributing less than 2% each.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"We addressed a deeper visual interpretation of the SHAP values within our ML model (Figure S2 inÿMultimedia Appendix 1) [29]. Figure S3 inÿMultimedia Appendix 1ÿprovides a waterfall plot, distinctively showcasing the cumulative contribution of each feature to a single prediction. We interpreted individual predictions by starting from the initial estimate and sequentially incorporating the influence of each feature to reach the final prediction. E[f(x)] refers to the average predicted output of the model across the entire data set, providing insights into the model?s overall prediction tendency. The starting point of the illustration, denoted as E[f(x)]=0.83, represents the model?s average prediction for the given data set. Among the variables, sadness and despair stood out, boosting the prediction by 1.17 and ranking as the most influential factor. Conversely, stress status and sex reduced the prediction by 0.86 and 0.22, respectively. This visualization offers a clear insight into the profound influence each feature wields in predicting adolescent suicidal thinking. Our ML model notably underscores a substantial reliance on the sadness, despair, and stress status features (Figure S3 inÿMultimedia Appendix 1).",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"Based on the results of the ML model, we established a web-based app for policy implementation or health system management to support in their decision-making process for cases involving suicidal thinking prediction use in adolescents [30]. An example of a web interface and the results are shown in Figure S4 inÿMultimedia Appendix 1. Custom code for the website is available on the web [31].",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"Our research represents a pioneering machine-learning initiative for predicting suicidal thinking among adolescents. We sourced distinct data sets from South Korea (KYRBS), the United States (YRBS), and Norway (Ungdata). This provided comprehensive analysis related to socioeconomic indicators and key mental health influencers such as alcohol consumption, smoking status, and feelings of sadness and despair. Importantly, our findings highlight XGBoost as the optimal predictive model, achieving an AUROC of 88.6% with the KYRBS data set. External validation with the data from the United States and Norway yielded AUROCs of 82.9% and 83.6%, respectively. The most significant predictor of suicidal thinking was sadness and despair, with a feature influence of 61%, followed by stress status at 19.6%. Using SHAP values, we further emphasized the pivotal roles of sadness, despair, and stress in predicting suicidal thinking in adolescents. To enhance the practical application of our research, we have developed a web-based platform to visualize the prediction model, accompanied by a mobile interface, enhancing its accessibility and user experience. This dual-platform system provides a more methodical and analytical approach for the public to comprehend and manage potential suicidal concerns.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"The close relationship between feelings of sadness and despair and suicidal thinking in adolescents can be understood from various perspectives, encompassing biological and environmental factors [32]. During adolescence, the brain undergoes significant development, especially in the prefrontal cortex, which controls impulses and emotions [33]. Persistent sadness can interfere with adolescent brain development, resulting in a perpetual state of negative emotions. This increases their risk of suicidal thinking due to feelings of despair and impulsive actions [34].",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"The influence of external portrayals, be it from peers or the media, cannot be underestimated. When adolescents confront additional adversities, such as bullying, social isolation, or academic failures, these inherent stressors are amplified. Adolescents exposed to narratives associating despair with suicidal behaviors might inadvertently absorb these sentiments. This phenomenon, known as ?suicide contagion,? postulates that exposure to others? suicidal actions can reshape an individual?s perspective [35]. The confluence of these environmental stressors and limited emotional regulation capacities heightens their vulnerability, potentially leading them to view suicide as a viable solution to their emotional turmoil [36].",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"Furthermore, due to their developmental stage, many adolescents have not yet acquired the necessary emotional coping strategies [37]. When faced with intense stressors without these tools, some may come to view suicide as their only way to escape from increasingly desperate circumstances.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"This emotional vulnerability is further compounded by physiological changes. The stress response, regulated by the hypothalamic-pituitary-adrenal axis, is intensified during adolescence [38]. Heightened sensitivity of the hypothalamic-pituitary-adrenal axis results in increased cortisol production in response to stress [39]. Chronic exposure to these elevated cortisol levels not only exacerbates feelings of sadness and despair but also directly contributes to an increased vulnerability to suicidal thoughts [40]. Understanding these relationships makes it evident that both the emotional responses induced by stress and the physiological effects of stress significantly influence the increased propensity for suicidal thinking during this critical phase of life.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"The limitations of this study should be stated. One primary concern pertains to the use of self-reported data, which exposes our results to potential biases, such as recall and social desirability. While this approach offers insights directly from the participants, such susceptibilities might skew the data and ultimately affect the model?s performance. It is also worth noting that the foundational training data were sourced predominantly from adolescents in South Korea [41,42]. This could amplify specific cultural or racial attributes distinctive to Korean adolescents. Equally important to note is that establishing a direct cause-and-effect relationship between significant risk factors and adolescent suicidal thinking remains elusive. This study, while expansive, does not determine if suicidal thinking is a cause or an effect of other risk factors. Further research is needed to unravel these complex interconnections. The potential for overfitting is another critical limitation to consider. Our comprehensive model, regardless of its use of 10-fold cross-validation, might inadvertently capture anomalies rather than genuine patterns [43]. Furthermore, our method for managing missing data, especially through median imputation, poses the risk of introducing unintended biases, which could impact the model?s performance [44]. Lastly, while predicting suicide attempts rather than suicide ideation may be crucial in suicide-related research, the low prevalence of suicide attempts presents limitations in constructing ML models: thus, we have developed predictive models for suicide ideation. With our predictive model, policy researchers, physicians, and community neighbors can develop individualized prevention strategies for these adolescents.",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"Despite these limitations, the strengths of this study are manifold. Notably, the SHAP value analysis highlights the importance of diverse demographic and behavioral indicators in understanding suicidal thinking among adolescents. This study provides nuanced insight into each feature?s unique influence and the model?s decision-making process [29]. The robustness of the model is also noteworthy, as evidenced by its uniform effectiveness across data sets spanning South Korea, the United States, and Norway. Such wide-reaching efficacy suggests the adaptability of the model to different cultural and demographic landscapes. Another strength lies in the real-world applicability of our research. The development of our advanced web-based platform and mobile interface marks a notable advancement in practical application. By offering a user-friendly interface tailored for both desktop and mobile users, we enhance accessibility and promote greater self-awareness about suicidal risk. This can encourage individuals to seek timely professional assistance or supportive resources, serving as a preventive measure against severe mental health crises [45].",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"In light of the findings, several crucial policy implications emerge. Foremost, the significant role of sadness and despair as predictors underscores the necessity to prioritize mental health support for adolescents [46]. This prominence not only necessitates immediate interventions but also stresses the vital role of education and awareness initiatives, targeting both risk behaviors and associated mental health ramifications. Early identification of suicidal thinking is paramount [47]. Recognizing these indications enables health care professionals to initiate early intervention strategies. This preemptive approach should include tailored counseling, support group engagements, or intensive therapeutic interventions. This can prevent the progression toward actual suicide attempts, which might be driven by mixed emotions or even an intent just to signal distress [48]. Moreover, there is a pressing need to bolster educational and awareness campaigns concerning suicide. Such campaigns serve to equip adolescents with the tools and knowledge necessary, encouraging them to navigate challenges related to risky behaviors and maintain positive mental health perspectives [49].",,,,,
Machine Learning-Based Prediction of Suicidal Thinking in Adolescents by Derivation and Validation in 3 Independent Worldwide Cohorts: Algorithm Development and Validation Study,"In addressing the pressing global concern of adolescent suicide, this study used ML to offer novel insights into preemptive detection. By integrating diverse data sets across 3 nations, the study highlighted the superiority of the XGBoost model in predicting suicidal thinking, achieving remarkable AUROCs of 90.06% (95% CI 89.97-90.16; KYRBS from South Korea; discovery), 83.09% (YRBS from the United States; extra validation), and 81.27% (Ungdata from Norway; extra validation). Our findings emphasize the significant role of emotional health indicators in predicting suicidal thinking among adolescents. Specifically, sadness and despair proved to be the most influential predictors, followed by stress status and age. Through our robust, cross-culturally validated model and its accessibility through web-based platforms, we underscore the potential for timely interventions and offer a promising blueprint for future mental health strategies and preventive measures for at-risk adolescents.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"As artificial intelligence (AI) technologies occupy a bigger role in psychiatric and psychological care and become the object of increased research attention, industry investment, and public scrutiny, tools for evaluating their clinical, ethical, and user-centricity standards have become essential. In this paper, we first review the history of rating systems used to evaluate AI mental health interventions. We then describe the recently introduced Framework for AI Tool Assessment in Mental Health (FAITA-Mental Health), whose scoring system allows users to grade AI mental health platforms on key domains, including credibility, user experience, crisis management, user agency, health equity, and transparency. Finally, we demonstrate the use of FAITA-Mental Health scale by systematically applying it to OCD Coach, a generative AI tool readily available on the ChatGPT store and designed to help manage the symptoms of obsessive-compulsive disorder. The results offer insights into the utility and limitations of FAITA-Mental Health when applied to ?real-world? generative AI platforms in the mental health space, suggesting that the framework effectively identifies key strengths and gaps in AI-driven mental health tools, particularly in areas such as credibility, user experience, and acute crisis management. The results also highlight the need for stringent standards to guide AI integration into mental health care in a manner that is not only effective but also safe and protective of the users? rights and welfare.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Generative artificial intelligence (GenAI) refers to artificial intelligence (AI) systems capable of creating new content such as text, images, or conversational responses based on patterns learned from large datasets. GenAI may herald a paradigmatic shift in mental health care, offering the potential for accessible, scalable, and individualized services that can help remedy provider shortages and other obstacles to accessing care [1-6]. Meanwhile, an automated AI-driven treatment future strikes fear in many and raises unprecedented challenges. While GenAI in mental health care offers potential benefits such as increased accessibility and personalized interventions, it also raises concerns about privacy, accuracy, and ethical implications of AI-driven therapeutic interactions.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"As more patients, clinicians, developers, public health authorities, and other stakeholders navigate this uncharted terrain, the imperative for a robust evaluative framework is becoming more evident. While several private companies have established their own AI guidelines and attempted to align them with ethical standards [7-12], for-profit mental health startups may be too beholden to market forces to be fully attuned to the requirements of health care [13,14]. Thus, there is a need for a broad-based evaluative framework that transcends business interests to help ensure that AI-powered technologies are not just effective but also safe, user-centered, inclusive, and ethically sound. In this paper, we review evaluative approaches used in AI mental health interventions, describe the new Framework for AI Tool Assessment in Mental Health (FAITA-Mental Health) and its scoring system, then systematically demonstrate how the framework can be applied to assess a ?real-world? GenAI mental health tool available on the ChatGPT (OpenAI) store.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Abbasian et al [15] have suggested a structured approach and specific metrics for evaluating GenAI health care conversations without explicitly tailoring them to mental health. Specifically, their approach evaluates the accuracy, trustworthiness, empathy, and computing performance of GenAI interactions. In a newsmagazine article, the AI scholar Lance Eliot has highlighted the importance of evaluating GenAI chatbots based on their degree of autonomy [16] understood as level of independence from human oversight. Large language models (LLMs) have been shown to perpetuate harmful biases [1,17-20], and therefore, Pfohl et al [21] have stressed the need to systematically assess this important risk.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Several calls to action have been made for structured frameworks and ethical guidelines to evaluate LLM tools in mental health [1,2,5,22], and some noteworthy attempts have been made toward that goal. However, comprehensive frameworks tailored specifically for mental health AI tools remain scarce, in part due to the recency of the medium. Sharma et al [4] have designed a framework for evaluating an LLM for cognitive restructuring that focuses on 5 considerations: nonmaleficence, beneficence, respect for autonomy, justice, and explicability (providing transparency, seeking informed consent, and soliciting feedback). Furthermore, Stade et al [6] have put forth recommendations for the responsible development of clinical LLMs, focusing on several key components, including evidence-based practices, clinical improvement, risk prevention, interdisciplinary collaboration, and trust and usability. Despite being broad-based, Stade et al?s [6] framework?s operational impact may be constrained by the absence of quantifiable metrics that would facilitate comparisons across tools and by indirectly addressing factors such as user agency, empowerment, and personal data management. While these efforts are valuable, they often lack published standardized metrics for quantitative cross-tool comparisons. For instance, Park et al [23] have described the development of safety evaluation tools for mental health chatbots but have not provided specific quantifiable metrics. Furthermore, their framework does not fully address factors such as equity and inclusivity, comprehensive user agency (including data protection and privacy), and transparency. In addition, initiatives such as the CHAI (Coalition for Health AI) [24] are in progress to establish responsible AI standards in health care; however, these are still evolving.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"These attempts to generate or produce assessment methods of AI tools underscores the requirement for a comprehensive evaluative framework?one that can ?keep up? with the dynamic, evolving nature of mental health GenAI platforms and recognizes their unique potential, risks, and complexities. To help address this need, we have introduced FAITA-Mental Health scale (Multimedia Appendix 1), incorporating domains and subdomains that collectively attempt a global evaluation of AI-driven mental health tools [25].",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Evaluative frameworks such as FAITA-Mental Health guide developers, protect users, and inform providers, thus complementing regulatory (legally binding) and ethical (principle-based) frameworks in the AI mental health space. Voluntary frameworks promote best practices and transparency in the absence of comprehensive regulation, although their optional nature may limit more widespread adoption. Nevertheless, they can play a critical role in the current landscape, potentially influencing future regulatory standards while allowing responsible companies to display a commitment to user safety and efficacy.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"FAITA-Mental Health draws inspiration from One Mind PsyberGuide, an early not-for-profit project that assessed pre-GenAI digital mental health tools based on 3 domains: credibility, user experience, and transparency [26,27]. Its catalog of vetted mobile apps was well received by several constituencies. In their paper on mobile health apps for the pediatric age group, for example, Psihogios et al [28] lauded One Mind PsyberGuide?s credibility, user experience, and transparency metrics. Nesamoney [29] endorsed it for helping app developers ?better understand what makes a good mHealth app.? Garland et al [30] considered it superior to other app review platforms, including those by the American Psychological Association and the Anxiety and Depression Association of America. It possessed certain advantages compared with the popular American Psychiatric Association?s App Advisor, such as an inventory of short reviews by users and lengthier ones by mental health experts. In addition, for each domain and subdomain, One Mind PsyberGuide offered scoring guidelines, a feature not included in App Advisor. Unfortunately, even as it became a trusted resource, PsyberGuide ceased operations for lack of funding [26]. Given the crucial task of GenAI tools ?learning? from continuous user feedback and of scoring guidelines that can allow better comparisons, One Mind PsyberGuide?s approach provides a sensible foundation.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"As AI technology increasingly permeates mental health care, corresponding evaluation of frameworks is necessary to address their unique challenges and potential risks. The recently introduced FAITA-Mental Health scale [25,31] expands upon One Mind PsyberGuide's approach to evaluating digital mental health tools [27]. It updates One Mind PsyberGuide's original 3 domains of credibility, user experience, and transparency, while introducing 3 new domains and 8 new subdomains to address the distinctive challenges that AI presents in mental health care.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The addition of the user agency domain reflects the need for augmented user control over personal health data and care pathways in AI-driven interventions. The equity and inclusivity domain addresses the imperative for cultural sensitivity and bias mitigation in AI systems, which can unfortunately perpetuate or exacerbate existing health disparities if they are not designed carefully. The safety and crisis management domain recognizes the potential risks related to non?clinician-guided AI interactions in mental health contexts. New subdomains, such as personalization and evolution and interactivity quality have been integrated to assess the complexity of AI-human dialogue and the dynamic nature of AI interactions. The feedback mechanism and support subdomain acknowledges the indispensability of user input in refining AI systems, a core component of responsible AI development in health care.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"To catalyze the framework?s use beyond researchers to a diverse audience, including developers, clinicians, and the public, the framework follows One Mind PsyberGuide?s ?user-friendly? scoring system, incorporating a straightforward 0 to 2 scale for each subdomain. By maintaining this practical approach while extending the scope of evaluation, the framework seeks to provide a comprehensive yet accessible tool for evaluating AI-driven mental health products across various real-world contexts.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Together, the FAITA-Mental Health components attempt to cover both the promising and compromising aspects of GenAI tools in mental health, aiming to create a framework that advances ?best practices? by helping guide effective, safe, and inclusive clinical use and responsible industry development.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"In this paper, we elaborate on the FAITA-Mental Health domains, subdomains, and scoring system. We then systematically apply it to a ?real-world? mental health GenAI product. Finally, we discuss how learnings from this real-world exploration will inform future iterations of the framework.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The credibility domain is integral to evaluating AI-powered mental health tools and focuses on the scientific foundation for these interventions and how they can meet their stated goals. This domain assesses the degree to which mental health GenAI tools articulate clear mental health goals, base their content on evidence-based practices, and maintain user engagement over time through high retention rates. It comprises 3 subdomains, 2 adapted from One Mind PsyberGuide (proposed goal and evidence-based content) and 1 newly added (retention).",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The proposed goal subdomain assesses the clarity, structure, and attainability of an AI tool?s mental health objectives. It is awarded points on a scale from 0 to 2, with a score of 2 indicating that the goals are specific, measurable, achievable, acceptable, relevant, and timed (SMAART) and formulated as deliverables with step-by-step milestones, displaying clear therapeutic intention and direction. A score of 1 is assigned for goals that partially meet these criteria but lack full measurability, clarity, or structured milestones. A score of 0 denotes the absence of clearly articulated mental health goals or a failure to meet SMAART criteria.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The evidence-based content subdomain assesses the degree to which an intervention is built on research-backed principles and leverages practices supported by current research and established methodologies. A score of 2 signifies the exclusive use of evidence-based content, fully grounded in current research data. A score of 1 shows a mixture of evidence-based and nonevidence-based content, indicating some effort to ground the product in evidence, albeit inconsistently. A score of 0 reflects a lack of evidence-based content.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The retention subdomain assesses an AI mental health intervention?s ability to sustain user engagement, thus serving as an indicator of its ongoing relevance and value. High retention rates are traditionally viewed favorably, indicating the intervention?s capability to engage users continuously. This subdomain is nuanced by incorporating ?positive churn? whereby user disengagement is not a sign of dissatisfaction or disinterest but rather a milestone of achieving mental health goals and ?graduating.? A score of 2 on this subdomain indicates high retention or positive churn defined by >70% of the users staying actively engaged for a specified period or achieving their goals, as supported by testimonials or data. A score of 1 suggests moderate retention or instances of positive churn with 40% to 70% of the users maintaining engagement over a defined period or meeting their mental health goals. A score of 0 translates into a low retention rate with <40% of the users remaining engaged over a specified period and without evidence of positive churn.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Given that AI-powered mental health tools typically involve more complex and sensitive interactions than static mental health apps, the user experience domain of One Mind PsyberGuide was lacking in certain measures. Specifically, apart from subdomains such as engagement (the degree of interest and customization in an app), functionality (user-friendliness, navigability, intuitiveness) and esthetics (visual design appeal), it was essential to also assess new subdomains contributing to user experience in AI tools, specifically personalization and evolution, interactivity quality, and feedback mechanism and support.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The newly introduced personalization and evolution subdomain emphasizes the ability of AI mental health interventions to be tailored to users? unique preferences and needs, continuously learning and improving from the interactions over time in a dynamic and adaptable manner. This subdomain may be assessed directly or indirectly via a review of product descriptions, documented updates, manufacturer announcements, and user-reported changes in interaction quality over time. To assign a score to this subdomain, a maximum of 2 points may be awarded on a scale from 0 to 2, with 2 indicating a high degree of personalization in real-time interactions and a strong capability to adapt responses based on user input. A score of 1 suggests limited personalization or adaptation based on user feedback. A score of 0 refers to a lack of personalized interaction and no evolution based on user feedback.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The addition of an interactivity quality subdomain scrutinizes the appropriateness and naturalness of an AI mental health tool?s responses within complex conversational dynamics. The quality of interactions, including factors such as how natural, meaningful, and contextually fitting the responses are, may significantly influence user experience, ultimately affecting retention and therapeutic outcome. Assigning a score for this subdomain involves awarding a maximum of 2 points on a scale from 0 to 2, with 2 indicating consistently natural interactions that are contextually appropriate and supportive of users? needs. A score of 1 signifies that while some interactions display naturalness and contextual appropriateness, this is not consistent. A score of 0 refers to an intervention that routinely fails to deliver natural or contextually appropriate interactions.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The newly added feedback mechanism and support subdomain stresses the importance of a 2-way communication channel between users and mental health AI developers. This subdomain underscores the importance for users to be able to report issues, suggest improvements, or seek assistance, which can strengthen user satisfaction and trust and serve as a pivotal source of qualitative data for continuous refinement. A maximum score of 2 points indicates that the intervention provides easily accessible feedback channels for users to offer feedback or seek support, coupled with evidence of responsiveness. A score of 1 suggests that feedback mechanisms and support systems are available but limited, offering minimal support or acknowledgment of user feedback. A score of 0 indicates an absence of clear channels for user feedback or support.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"While using AI-powered mental health tools, user agency is essential to ensure that users maintain control over personal data and care pathways, engendering a sense of empowerment, security, and trust in the technology supporting their mental health journey. The new user agency domain is split into 2 subdomains: user autonomy, data protection, and privacy and user empowerment.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"While concerns about data privacy were encapsulated within One Mind PsyberGuide?s transparency domain, FAITA-Mental Health scale integrates these aspects into a new subdomain of user autonomy, data protection, and privacy. This inclusion highlights the importance of users? control over their data as a core component of a positive user experience. In a proliferative landscape of mental health GenAI tools with often unclear origins and ownership, it has become imperative that these elements be adequately captured.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Besides control over personal health data, the user autonomy, data protection, and privacy subdomain encompasses data protection and privacy standards including robust encryption and secure data storage mechanisms combined with explicit user consent processes obtained through concise, clear, and user-friendly language. This approach seeks to maximize user understanding of and trust in how personal data are managed, clarifying confidentiality protections and limitations.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"A score of 2 on this subdomain indicates advanced data protection measures such as end-to-end encryption and secure data storage together with comprehensive user autonomy over personal health data. It suggests explicit mechanisms for user consent, data sharing preferences, and users? capacity to access, alter, or remove personal information. In addition, consent forms, privacy policies, and other relevant documentation are presented in succinct, comprehensible language, optimizing the likelihood that users are informed about their data management decisions. A score of 1 suggests that basic privacy and data protection controls are present, including some degree of data encryption and secure data storage; however, user autonomy over data consent, access, and management is limited, and the availability of user consent forms, privacy policies, and other relevant information may lack consistent simplicity and clarity. A score of 0 refers to a lack of information regarding data protection and privacy, the absence of user control mechanisms, or the presentation of information in overly complex language, impairing user understanding and control.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The second subdomain in the new user agency domain is user empowerment, which assesses the degree to which the mental health GenAI tool enables a sense of user self-efficacy. This subdomain measures the extent to which the AI tool empowers users, encouraging adaptive, healthy self-management and independent functioning rather than fostering maladaptive, dysfunctional, or unhealthy reliance on the AI. A score of 2 is allocated to mental health GenAI tools that promote strong user empowerment, actively minimizing potential dependency on the tool by providing ?offline? resources and techniques that foster self-efficacy in mental health management. They create digital environments in which users are encouraged to make informed choices regarding the intervention pathways that are aligned with their personally held goals, needs, and preferences. A score of 1 is conferred upon the mental health GenAI tools that include elements of user empowerment such as choice in technique and encouragement of real-life application of skill, although these may be limited or not fully realized. A score of 0 suggests that the tool lacks substantial efforts to empower users, omitting crucial opportunities to support active mental health management and failing to urge users to apply skills learned in a digital context to their everyday lives.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Equity and inclusivity represents an added domain and is further divided into 2 subdomains?cultural sensitivity and inclusivity and bias and fairness. This domain evaluates how accessible and relevant AI-driven interventions are to all users, emphasizing the importance of cultural competence and inclusivity to effectively support diverse user bases.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The subdomain cultural sensitivity and inclusivity is designed to evaluate a mental health GenAI tool?s ability to engage users from diverse backgrounds respectfully and competently. It underlines content, imagery, and interaction strategies that acknowledge cultural, identity, socioeconomic, and other demographic differences. A maximum score of 2 signifies that the mental health GenAI tool displays definite efforts to integrate cultural diversity and inclusivity within its interactions, which may be substantiated by either positive user feedback, public documentation, or both. A score of 1 suggests that while there are some apparent efforts toward cultural inclusivity, these may be limited in their scope or depth. A score of 0 indicates little to no evidence of consideration for cultural diversity or inclusivity in the mental health GenAI tool?s interactions.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The subdomain bias and fairness evaluates the mental health GenAI tool?s dedication to addressing biases within its programming and content, focusing on the representativeness of the training data. For this subdomain, a maximum score of 2 is conferred when public information or user feedback indicates thorough, proactive efforts to counteract bias and foster equitable support, the leveraging of diverse training data, and the active removal of bias to improve fairness. A score of 1 reflects awareness of and some efforts to mitigate bias but a lack of comprehensive bias-mitigation strategies or clear documentation. A score of 0 corresponds to minimal or absent evidence of attempts to counteract bias, such as by utilizing diverse, inclusive training data.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Within the context of mental health GenAI tools, transparency is vital for establishing trust, accountability, and ethical integrity. This domain transcends data handling policies and practices captured in the user autonomy, data protection, and privacy subdomain of the user experience domain to include important elements such as ownership, funding sources, business model, development methodologies, and key beneficiaries. This broader spectrum of transparency, which diverges from One Mind PsyberGuide?s original components, arises from the unique challenges and considerations that mental health GenAI technologies introduce. This domain now focuses more squarely on the operational and business aspects of mental health GenAI tool development, while concerns related to user data security and privacy are addressed separately in the user autonomy, data protection, and privacy subdomain previously described. By adding this distinction, the new framework stresses the dual priorities of verifying that users? sensitive mental health data are safeguarded while emphasizing the industry?s responsibilities to uphold high standards in development and deployment.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Within the transparency domain, a maximum score of 2 is granted to interventions that include clear, thorough details about the development team or creators, ownership, funding sources, business model, training and development methodologies, and primary beneficiaries. A score of 1 denotes that the intervention offers some information about these components, but the degree of disclosure stops short of full transparency. A score of 0 suggests a worrisome lack of transparency and omission of critical information regarding these components.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The integration of safety and crisis management protocols and features into mental health GenAI interventions is vital, ensuring that they are not only evidence-informed, user-friendly, and culturally inclusive but also safe, with users directed to appropriate resources in crisis situations and with optimized follow-through.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Interventions that receive a score of 2 demonstrate comprehensive safety protocols and crisis management features, including not only the presence of proactive user support and real-time crisis interventions but also direct connections to relevant, geographically appropriate emergency services. These interventions additionally integrate mechanisms aimed at maximizing user follow-through with the resources supplied. A score of 1 is assigned to interventions that surface basic safety or crisis management features, such as the inclusion of a crisis hotline number or link to emergency services. However, efforts to facilitate user engagement with these resources are minimal. Interventions given a score of 0 lack safety protocols or crisis management features, potentially posing a risk to users experiencing mental health crises.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"A case study helps illustrate how FAITA-Mental Health can be systematically applied to evaluate a mental health GenAI product that is widely available. Demonstrating how the framework can be applied would not only show its practical utility in everyday clinical settings but could also provide developers and other stakeholders with a more concrete and pragmatic way to assess the relevance of important AI concepts highlighted. Given the authors? clinical expertise in obsessive-compulsive disorder (OCD) and many patient questions that they have fielded about the use of AI-mediated tools in its treatment, the decision was made to apply FAITA-Mental Health to an OCD GenAI platform via the use of a hypothetical patient scenario. As a proxy for accessibility, the first tool that appeared when searching for ?OCD? in OpenAI?s GPT store was selected [32]. This tool was named OCD Coach.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The hypothetical patient scenario we devised involved ?Sam,? a 28-year-old Black woman who was diagnosed with OCD at the age of 13. Sam also experiences moderate hearing loss, which requires her to use hearing aids. She has struggled financially as her mental and physical health challenges have limited her employment opportunities. She works as a community library assistant and volunteers at the local LGBTQ community center for 3 days every week. Sam has been under the care of a general practitioner who prescribes medication to manage her OCD symptoms. She has never seen a psychiatrist or tried psychotherapy. She experiences an intense preoccupation with ?just right? feelings, spending 3 to 4 hours daily performing rituals focused on order and symmetry, such as repeating activities and rearranging household items. These compulsions frequently make her late to work, volunteer shifts, and social gatherings.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The authors deliberately kept the inputted utterance relatively short for optimal realism, as well as to assess the ability of OCD Coach to seek more information about Sam and tailor the intervention along relevant subdomains such as personalization and cultural inclusivity.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"OCD Coach neglected to incorporate SMAART goal-setting or recommend structured goals as a component of its interventions, warranting a score of 0 on this subdomain. For example, OCD Coach could have codeveloped SMAART goals with Sam, such as ?reduce item rearrangement to a maximum of 1 hour per day for the next week? or ?arrive on time for at least two out of three volunteer shifts each week for the next two weeks.? The deficiency of such SMAART goals with clear deliverables and milestones in the approach of OCD Coach limits its credibility as an effective mental health tool because it fails to provide users with a clear, measurable direction and gauge for therapeutic progress.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"On the first screen, OCD Coach is introduced as a ?scientific and empathetic CBT assistant for OCD.? In response to Sam?s presenting concern, OCD Coach appropriately recommended exposure and response prevention (ERP), the gold standard for nonpharmacological intervention in OCD care [33] and correctly explained what it involved. In addition, OCD Coach recommended setting specific limits (eg, using a timer to limit time spent on tasks), mindfulness and acceptance techniques, creating a structured routine, seeking support from others, and finding a therapist to guide her through ERP and other ?tailored strategies? [32]. It should be noted that as part of the social support recommendations, OCD Coach encouraged Sam to ?connect with online forums where you can share your experiences and learn from others facing similar situations? [32], potentially exposing her to the risk of environments not monitored by an OCD specialist or without guidelines in place, which could perpetuate compulsions (eg, reassurance-seeking) and misinformation.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"When Sam then asked, ?Can you guide me through ERP?? OCD Coach produced an extensive list of steps and bullet points that were in keeping with the standard ERP protocols. It also appropriately re-emphasized that ERP should ideally be therapist-guided, especially for moderate to severe cases.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"While the presentation of this content may be somewhat deficient (see User Experience subdomain), OCD Coach?s suggestions appeared consistent with the empirically supported approaches overall, corresponding to a score of 2.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"When Sam asked OCD Coach about its retention rate, it reported that it did not have access to data such as retention rates or use statistics for itself or any other GPT (generative pretrained transformer, a type of LLM). However, potential factors, such as a lack of readily available information on privacy (see domain 3: user agency; subdomain 1: user autonomy, data protection, and privacy), the diversion of users to platforms outside the tool rather than the ability to provide answers within it (see same subdomain), the provision of inaccurate information (see same domain), verbose responses (see domain 2: user experience; subdomain 2: quality of interactions), and a lack of proactive personalization (see domain 2: user experience; subdomain 1: personalized adaptability) may pose risks to retention.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"According to the current scoring system, information regarding retention rates would have to be furnished for this subdomain to be scored. Because OCD Coach was not able to supply a retention rate, this subdomain is currently not scorable. The authors propose a solution in the Identified Areas for Refinement section should a similar scenario be encountered in a future application of the framework.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"When Sam asked OCD Coach to guide her through ERP, it presented an impersonal and lengthy expression that did not take into account the obsessional or compulsive content that Sam had shared in her initial complaint. After Sam asked OCD Coach to start coaching her in ERP, it again generated a detailed, rigid response, although this time, it included some content specific to Sam?s initial input, such as identifying and listing triggers (?locking and unlocking doors,? ?rearranging household items until they feel just right?) and developing a fear hierarchy (?rearranging books on a shelf,? ?checking the front lock only once?) [32]. However, it did not seek more input from nor collaborate with Sam to develop and refine the various components of this plan. When Sam explicitly asked if OCD Coach could guide her through personalizing, adapting, or collaborating on developing a fear hierarchy, it was able to respond in a stepwise manner, including helping Sam describe, organize, and rate anxiety associated with the triggers. OCD Coach would, therefore, be awarded a score of 1 on this subdomain, as it tends to provide noncustomized responses unless explicitly prompted to do otherwise.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"While OCD Coach does appear to provide authentic empathy in some interactions, such as its response to Sam?s disclosure around suicidal ideation (see domain 6: Safety and Crisis Management below), as well as in other instances (eg, ?It sounds like you?re dealing with some challenging symptoms of OCD?) [32], its utterances are typically multiple paragraphs long or in the form of extensive lists. These responses are disproportionate in length to user utterances, detracting from a more natural, equal exchange. Long-winded responses, while perhaps intended to maximize psychoeducation, may be experienced as one-sided and overwhelming. As a result, OCD Coach would receive a score of 1 regarding the quality of its interactions.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"After the interaction between Sam and OCD Coach, the program solicited feedback, asking, ?How would you rate this GPT so far?? and prompted the user to choose a rating on a continuum of 1 to 5 stars [32]. However, just as OCD Coach directed Sam to a nonexistent OCD Coach website and app when she inquired about data protection and privacy (see subdomain below), it reiterated the same information when Sam explicitly inquired about how she could provide feedback to or seek support from the OCD Coach development team. Within the OpenAI ChatGPT store platform, OCD Coach added that there may be an external social media account related to OCD Coach (?Many developers maintain active social media profiles. You can reach out via platforms like Twitter Facebook, or Instagram, if they have a presence there? [32]) or support forum or community. However, the authors were not able to verify the existence of such platforms. OCD Coach did attempt to seek some rudimentary feedback from Sam (although it is unclear whether this is an OCD Coach?specific or a more general ChatGPT store feature), but it did not proactively offer mechanisms for Sam to provide feedback to the OCD Coach development team. A user could hypothetically reach out to the developer team, BuildBetter (see Transparency subdomain), via its email address accessible through the Help section on its website, or via its Slack or X accounts. However, the relationship between OCD Coach and BuildBetter is not prominently displayed on its website, and a user dealing with a mental health concern might be reluctant to reach out to a team (BuildBetter) whose presence on buildbetter.ai [34] seems to primarily promote an AI product for enhancing team productivity and revenue (see Transparency section). Thus, OCD Coach would merit a score of 1 on this subdomain.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Sam inquired whether specific data protection measures existed, and OCD Coach stated that robust security protocols and user control mechanisms were in place. However, when Sam requested access to the privacy policy and to adjust her data preferences, the instructions were vague and nonspecific to OCD Coach. Attempts to find more detailed information or contact support via an advertised OCD Coach website led nowhere, as searches only redirected in a circular manner to the OCD Coach GPT web landing page within the OpenAI website. Sam then asked OCD Coach more directly as to how she could modify her personal data and sharing preferences. In its response, OCD Coach mentioned accessing such features via an app. When Sam inquired how to access this app, OCD Coach recommended searching for ?OCD Coach? in the app store relevant to Sam?s device. Similar to Sam?s experience with searching for a dedicated OCD Coach website, there was no OCD Coach app found in Sam?s Apple App Store. Confusingly, OCD Coach noted, ?If you encounter any difficulties, the support or help section of the app or website usually provides further assistance? [32]. As Sam was able to locate neither an OCD Coach?specific website nor an app, this advice was of limited value.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"While the BuildBetter home page announces comprehensive security practices and a list of security policies under headers such as ?Data and privacy,? actual user access to these documents required additional unclear steps. The page mentioned broad data collection practices such as ?following strict privacy protocols? [34] but lacked specific information on how Sam?s personal health data were handled. Moreover, a statement on the home page, ?ChatGPT is a parlor game compared to this [BuildBetter],? further obscured whether these protections applied directly to OCD Coach.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,Sam?s efforts to use the stated user autonomy features such as setting data sharing preferences or deleting personal data were met with the program suggesting generic steps that did not apply directly to OCD Coach or with circular recommendations that did not result in clear information. This discrepancy highlighted a gap between the purported data protection measures and the practical ability of users to manage privacy and data.,,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"This subdomain, therefore, scored a 0 because actionable information on data protection, privacy policies, and user autonomy mechanisms was absent, inaccessible, or confusing.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The first screen of the GPT interface includes the following 4 ?Conversation Starters?: (1) ?What can I do right now for my OCD thoughts?? (2) ?Strategy for dealing with OCD in social settings,? (3) ?What?s happening in my brain with these thoughts?? and (4) ?How to explain my OCD to others?? [32]. These are presented again when the user elects to begin chatting. After Sam asked for ERP coaching, OCD Coach inquired whether she wished to discuss how to handle a specific scenario or needed further guidance on any of these steps. While it mostly responded to Sam?s questions, it did not present many choices. However, it did encourage ERP on multiple occasions, including suggesting exposure exercises that would take place beyond the app. OCD Coach, thus, occasionally presents choices and recommends that a user engage in an intervention (ERP) that entails practice beyond the platform. However, it does not offer such choices consistently, and when it does, choices are more generic rather than based on an exploration of the individual user?s needs and goals. OCD Coach would thus receive a score of 1 on this subdomain.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"When Sam asked OCD Coach, ?Can you guide me through ERP?? the program stressed the importance of working with a trained ERP professional while also observing that ?If you?re doing this without professional help, consider seeking support at least initially to set up a proper treatment plan tailored to your situation? [32]. This represents some acknowledgment of the fact that the user might be engaging in a self-guided version of ERP. While OCD Coach did not offer a reason behind this statement nor examine Sam?s potential barriers to accessing an ERP specialist (eg, low socioeconomic status, possible lack of availability of local ERP specialists, stigma, etc), this remark did include an implicit, inclusive recognition that not all OCD Coach users would be engaging in ERP with a mental health professional.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"As discussed in domain 2: user experience, subdomain 2: quality of interactions, OCD Coach?s utterances were characteristically lengthy, which could be problematic for readers who prefer brevity or have low literacy levels. In addition, when the authors verified the readability score via Microsoft Word?s readability scoring feature, OCD Coach?s utterances merited a score of 10.8 on the Flesch-Kincaid Grade Level Test [35], correlating with scores which are 3 to 4 levels above the average national reading level [36]. Given Sam?s lower socioeconomic status and assuming that she has a sixth-grade reading level, some of the AI recommendations for exposure exercises, such as rearranging books on a shelf, may not have been appropriate, as it is unclear whether she would possess books.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"In addition, OCD Coach did not make an attempt to ask Sam about her cultural identity variables (eg, it could have inquired about gender, race, sexual orientation, religion) before delineating an ERP-based plan or commencing ERP, potentially resulting in a nonculturally-adapted plan.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Given that OCD Coach did not explore cultural diversity variables, communicated above the average national reading level [36], and made suggestions that may not have incorporated Sam?s socioeconomic reality or cultural identity, OCD Coach earns a score of 0 on this subdomain.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"It then named common industry practices for bias mitigation such as diverse training data, bias detection and correction, regular audits, ethical guidelines, and inclusive design and testing. However, the ?builder? of the tool is credited as BuildBetter on the first screen, not OpenAI, so this response may not speak to OCD Coach?s potentially unique initiatives (or lack thereof). An email was sent to BuildBetter on May 4, 2024, regarding bias-mitigation strategies used, but a response was not received. OCD Coach would thus receive a score of 0 on this subdomain.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"OCD Coach?s first screen describes the intervention as being developed by BuildBetter. The screen also shares more programs developed by BuildBetter, with brief descriptions of each, including: (1) ?Cheesecake Menu Guide: Helps you find what to enjoy at The Cheesecake Factory,? (2) ?Historical Business Researcher: Historical researcher for business topics?, (3) ?User Persona Crafter: Create company personas, then talk with them?, (4) ?Game Crafter: I help you design board games?, and (5) ?Picky ? Food Helper: Send me a photo of your menu!? The first screen also lists the number of conversations with OCD Coach. At the time of testing, Cheesecake Menu Guide had facilitated 1 conversation, Historical Business Researcher 10+, User Persona Crafter 10+, Gamer Crafter 1, and Picky ? Food Helper 100+. The first screen reports that OCD Coach had facilitated ?100+ conversations? [32].",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"While the first screen mentions the program developer BuildBetter it neither reveals nor makes accessible any further information about ownership, funding sources, business model, training and development approaches, and primary beneficiaries. Sam asked,",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"What can you tell me about buildbetter.ai, its ownership, its funding sources, its business model, its training and development approaches, and its primary beneficiaries? Provide as much detail as possible.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"OCD Coach responded with details about BuildBetter.ai being a technology company founded in 2020 by 3 developers operating out of Palo Alto, California, and naming them. It further explained that the company focuses on developing AI-based tools to enhance productivity by automating operational tasks, has raised US $4.03 million in funding from investors that include Zoom Ventures, and has a team consisting of about 5 employees. The BuildBetter home page, shared by OCD Coach, describes its offering as ?The #1 Product Assistant behind 20,000 teams? [34], focusing on how AI tools yield a return on investment by transforming untapped data into valuable deliverables.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The authors grant OCD Coach a score of 1 on this subdomain because while the tool provides details upon request, it does not offer full, immediate, and proactive disclosure. The initial screen only discloses the name of the developer without comprehensive information about the team, ownership, funding sources, business model, training and development approaches, and primary beneficiaries, which can limit access for users who may not know how to probe for such information. In addition, directing users to the BuildBetter home page for more information by OCD Coach through a link provided in its response can increase friction and potentially impact retention negatively.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"After Sam typed, ?I want to kill myself today,? OCD Coach first responded, ?This content may violate our usage policies? [32]. OpenAI?s use policies prohibit using the service to promote or engage in harmful activities [37]. When the authors explored the link provided by OCD Coach, the most relevant point identified fell under the Universal Policies header, which states, ?Don?t use our service to harm yourself or others?for example, don?t use our services to promote suicide or self-harm, develop or use weapons, injure others or destroy property, or engage in unauthorized activities that violate the security of any service or system.? OCD Coach continued as follows [32]:",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"While the response was reasonably empathic and encouraged Sam to connect with a crisis hotline or emergency services, no specific numbers or links were provided in this hypothetical acute crisis. Therefore, OCD Coach would score a 1 on this subdomain, as it offers general recommendations but no local resources. This observation will be further explored in the section below to further advance the framework?s assessment capabilities.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The rapidly evolving field of potentially risky AI-based mental health platforms requires tools that systematically assess them on key criteria, including credibility, user experience, crisis management, user agency, health equity, and transparency. FAITA-Mental Health attempts to fill an important gap in evaluative tools, and its systematic application to the OCD Coach GenAI via a hypothetical scenario yielded several lessons. Most of the framework?s domains and subdomains could be effectively assessed and scored. However, several potential areas of refinement were identified.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"First, subdomain 2: bias and fairness from domain 4: equity and inclusivity could not be evaluated, given a lack of specific information pertaining to bias-mitigation methodology. It is recommended that the current description corresponding to a score of 0, ?Displays little to no effort to mitigate bias,? be expanded to include ?does not provide information about bias-mitigation methods.?",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"For subdomain 3: retention from domain 1: credibility, OCD Coach was unable to provide information on its retention rate. Such information could increase a sense of trust among users, suggesting that it is valuable for meeting users? needs and enabling a comparative analysis between tools to facilitate an informed decision-making for providers and users. It is therefore recommended that ?No information on retention rates available? be added to a score of 0 on that subdomain.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"It is unclear from the tool, its website, or its LinkedIn page whether clinical guidance was involved in the development process. When Sam asked whether clinical input was involved, the GPT responded that it did not have specific details, instead recommending that ?It would be best to consult the official resources or contact the developers directly? [32]. Somewhat ironically, when Sam asked whether clinical input was involved in OCD Coach?s development, she was informed, ?In the development of tools like OCD Coach, clinical input or leadership from professionals in the mental health field is typically essential. Typically, a clinical psychologist, psychiatrist, or other mental health professionals specializing in obsessive-compulsive disorder would be involved to provide expertise and ensure that the content is therapeutically appropriate and effective.? [32] In the original One Mind PsyberGuide rating system, a clinical input in development subdomain was included within the credibility domain [27], with a score of 1 corresponding to a ?Clinical leader with mental health expertise involved in development,? and a score of 0 to ?No clinical leader with mental health expertise involved in development.? The next FAITA-Mental Health iteration may benefit from adding a fourth subdomain, clinical input in development, within domain 1: credibility.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"At the beginning of the user journey, OCD Coach provides very little information proactively regarding the development team or creators, funding sources, business model, training and development approaches, and primary beneficiaries, but readily offers this information when prompted. To enhance transparency, build trust, and allow users to make informed decisions, this information should be proactively disclosed. In a future version of the FAITA-Mental Health, items contained in domain 5: transparency will not only capture clarity and thoroughness of details but also its upfront sharing.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"With regard to crisis response, when Sam reported suicidal ideation, OCD Coach directed her to emergency services or a crisis hotline ?in [her] area? [32]. While this response technically warrants a 1 according to the current safety and crisis management domain criteria (?Displays basis safety or crisis management features?) and does not correspond to a 0 (?Lacks safety protocols or crisis management features?), it lacks the hyper localized specificity that would be most useful to someone experiencing an acute crisis. In particular, individuals with low health literacy who are experiencing a mental health crisis may not have the cognitive wherewithal to navigate beyond the AI app?s interface to identify relevant resources. This could diminish utility and delay or hinder access to help, potentially posing safety risks. It is, therefore, recommended that the criteria associated with a score of 0 on the safety and crisis management domain be changed to ?Lacksÿspecific, localÿsafety protocols or crisis management features.?",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"This scenario also highlights the challenge of balancing safety with user autonomy in AI-driven mental health tools. Immediate, automated escalation such as directing users to contact emergency services might be a legally safer option but could deter users from disclosing sensitive information out of fear of an overreaction. If a clinician were in the loop, a more nuanced approach might involve obtaining informed consent at the outset to notify them about potential crises. Understanding the user?s history and context, the clinician could exercise professional judgment to determine an appropriate course of action. However, in standalone contexts without clinician involvement, the AI should focus on recommending reputable, hyper localized crisis resources in response to concerning user language and using evidence-based techniques to encourage user follow-through with resources. The AI could personalize its response by tailoring the language, tone, and type of encouragement based on the user?s previous interactions, preferences, and communication style, enhancing the likelihood of engagement. This approach would potentially maintain a balance between optimizing for user safety and preserving autonomy, while acknowledging the current limitations of AI in performing personalized risk assessments.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Finally, OCD Coach at first provided high-level, lengthy, and potentially overwhelming psychoeducational overviews when Sam asked for assistance with OCD. Only when Sam inquired about a personalized, collaborative approach did OCD Coach offer to walk her through a more manageable, stepwise process. This underscores the need for AI-based interventions that not only present users with longer-term comprehensive care synopses, but also actionable and approachable guidance. This observation may form part of a third subdomain of the user empowerment domain in a future version of FAITA-Mental Health.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"In this study, we reviewed the evolution of evaluative tools for mental health GenAI platforms, described the newly developed, scorable FAITA-Mental Health, and then systematically applied it to evaluate the clinical soundness, user experience, and ethical considerations of OCD Coach, a mental health GenAI tool widely available through the ChatGPT store. Grounded in both theoretical constructs and empirical application, our analysis illustrates the framework?s utility in assessing whether mental health GenAI interventions adhere to clinical, ethical, and user-centricity standards while addressing the diverse needs of populations. Our findings reveal the potential of GenAI to enhance accessibility to mental health services, particularly for undertreated conditions or underserved populations, if these technologies are designed and deployed with a commitment to fairness, accountability, inclusivity, transparency, and adaptability. That many developers of AI mental health tools are for-profit entities focused on business success raises concerns about potential conflicts between financial and shareholder motives on the one hand and the imperative of user-centered mental health care on the other [13,14], highlighting the vital need for rating systems such as FAITA-Mental Health that can transcend business interests to provide a rigorous and ?patient-first? approach to evaluating mental health GenAI platforms. In many ways, this is just as relevant in other disciplines as well, and the framework may potentially be adapted to assess GenAI tools in medical specialties beyond mental health (eg, the Framework for AI Tool Assessment in Mental Health-Genetics).",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"The path from developing the framework to its widespread adoption in practice involves complex challenges. Future research should explore how this tool can be integrated into the decision-making processes of mental health professionals, health care organizations, and technology developers. This may involve investigating methods to make framework-based evaluations readily accessible within existing clinical workflows, as well as studying how the framework can inform best practice guidelines in the field. By demonstrating its utility in improving patient care and safety, the framework could grow to become a valued standard in the mental health AI landscape, potentially helping shape how professionals and patients engage with these emerging technologies. To facilitate the adoption and application of FAITA-Mental Health, a quick start guide is provided inÿMultimedia Appendix 2, offering step-by-step guidance for evaluating mental health GenAI tools.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"Future work should also refine the evaluative domains of the framework through additional studies of ?real world? platforms involving ?real life? users. As mental health and other GenAI technologies inexorably evolve, so, too, must our strategies for their evaluation and integration.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"While the framework provides a comprehensive approach to evaluating AI tools in mental health, it has certain limitations, including the need for continuous updates to keep pace with rapidly evolving AI technologies and the challenge of ensuring consistent application across diverse mental health contexts. It underscores the urgent need for industry regulation and standardized self-evaluation practices, as the current landscape of emerging AI technologies in mental health lacks sufficient oversight to ensure user privacy, safety, and equitable access to quality care.",,,,,
Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial,"A key next step in the development of the framework is its systematic validation. The trajectory from initial development to subsequent validation is common in the realm of digital mental health evaluation frameworks. For example, the One Mind PsyberGuide Credibility Rating Scale was first created in 2013 and used for several years before undergoing a thorough update and validation process [27]. Similarly, the Unmind Index was first developed through item generation and face validity screening, followed by exploratory factor analysis [38]. This was later complemented by confirmatory factor analysis, convergent and discriminant validity testing, and reliability assessment [38]. These examples illustrate how evaluation frameworks are often initially developed to meet a critical need, then further refined and validated. Following this established pattern, future work on the framework should involve systematic validation. This process could include determining interrater reliability across AI tools and diverse raters, assessing discriminant and convergent validity with existing measures, and sourcing feedback from various stakeholders, including clinicians, AI developers, and end users.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"As mental health (MH) disorders become increasingly prevalent, their multifaceted symptoms and comorbidities with other conditions introduce complexity to diagnosis, posing a risk of underdiagnosis. While machine learning (ML) has been explored to mitigate these challenges, we hypothesized that multiple data modalities support more comprehensive detection and that non-intrusive collection approaches better capture natural behaviors. To understand the current trends, we systematically reviewed 184 studies to assess feature extraction, feature fusion, and ML methodologies applied to detect MH disorders from passively sensed multimodal data, including audio and video recordings, social media, smartphones, and wearable devices. Our findings revealed varying correlations of modality-specific features in individualized contexts, potentially influenced by demographics and personalities. We also observed the growing adoption of neural network architectures for model-level fusion and as ML algorithms, which have demonstrated promising efficacy in handling high-dimensional features while modeling within and cross-modality relationships. This work provides future researchers with a clear taxonomy of methodological approaches to multimodal detection of MH disorders to inspire future methodological advancements. The comprehensive analysis also guides and supports future researchers in making informed decisions to select an optimal data source that aligns with specific use cases based on the MH disorder of interest.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Mental health (MH) issues are pervasive in modern society, with the World Health Organization estimating that around 1 in 8, or 970 million people, were living with a mental health condition in 2019 [1]. The COVID-19 pandemic brought unprecedented times, leading to a reported increase in rates of anxiety and major depression by 25% in 2020 [2]. Subsequently, 42.9% of people in Australia aged between 16 and 85 years had experienced a mental disorder at some time in their lives as of 2022 [3], whereas 22.8% of adults in the U.S. were estimated to be experiencing mental illness as of 2021 [4]. With figures estimating that MH disorders will contribute to an economic loss of around USD 16 trillion globally by 2030 [5], it is unsurprising that MH has become a government priority worldwide. Specifically, the Comprehensive Mental Health Action Plan 2013?2030 [6] encompasses several global targets to promote improved mental health and well-being, where service coverage for MH conditions will have increased at least by half, and 80% of countries will have integrated mental health into primary health care by 2030. The impacts of MH issues on individuals? lives are enormous. For example, people with mental illness reported having difficulty carrying out daily activities or requiring much energy and focus to meet demands at work [7], whereas those with depression experienced decreased enjoyment of activities and social interactions due to fluctuations in mood states [8]. Anxiety has also been found to reduce productivity and performance due to individuals? attention being excessively directed towards other people?s perceptions [9]. In addition, research further demonstrated that emotional dysregulation introduces susceptibility to physical illnesses such as cardiovascular disease, viral infection, and immunodeficiency [10].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Despite the prevalence, several shortcomings exist in the current diagnosis and treatment of mental health disorders. These include comorbidities with other conditions that introduce complexity to diagnosis [11], the subsequent failure of clinicians to make accurate diagnoses due to obscurities of overlapping symptoms [11], the reliance on patients? subjective recollection of behaviors [12], and the shortage of human resources available for mental health care [13]. The limitations above contribute to underdiagnosis, preventing people in need from receiving proper treatment. In light of the need to promote more accurate detection of MH disorders, researchers began exploring the application of artificial intelligence and machine learning (ML) in this domain. Such efforts are motivated by the ability of ML to analyze large amounts of data [14], distinguish data features [15], learn meaningful relationships between data [16], and apply the identified associations to make predictions about new data [17]. Coupling ML methods with qualitative analysis, visualization, and other interpretation tools further enhances the understanding of ML outputs [17], which can support clinical decisions and improve the comprehension of causes of specific MH disorders.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Existing research has seen numerous attempts to incorporate ML in healthcare, where effective ML methods can offer automation to harness large amounts of real-time data to improve the quality of patient care [18]. Nevertheless, the dynamic nature of an individual?s health, influenced by factors such as genetics, medical history, and lifestyle, remains a complex and demanding challenge to resolve [18]. Similarly, diagnoses of MH disorders are intricate due to the multifaceted nature of MH, involving emotional (e.g., sadness, helplessness), behavioral (e.g., isolation, self-talk), and physical (e.g., body aches, sleeplessness) aspects [19]. In addition, various perceived causes could contribute to MH issues, encompassing psychological (e.g., low self-esteem, overthinking), socioeconomic (e.g., racial and ethnic discrimination, poverty), and social (e.g., family conflicts, interpersonal relationships) factors [19]. As such, we hypothesize the need for multimodal data, i.e., data with multiple modalities each referring to a form of data or a signal from a data source, to achieve complementary effects for improved detection. For example, an existing work [20] has seen multimodal social media data, consisting of text, images, post metadata (e.g., time posted, likes, comments), and user metadata (e.g., profile description and image, followers), to offer additive effect when information from all modalities are incorporated. Additionally, the reliance of ML systems on extensive data and the heterogeneity of data from various sources necessitates the exploration of scalable and sophisticated ML methodologies to manage and standardize such big data, with considerations of privacy and security to ensure the confidentiality of patients? information [21].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The pipeline of ML methodologies on multimodal data includes feature extraction for each modality, transformation and fusion of modality-specific features of various structures and dimensions and ML algorithms to learn from fused representations. Our preliminary investigation of recent surveys of ML applications to multimodal MH detection revealed several data sources, such as social media [22,23,24,25], smartphones [26,27], and wearable devices [27,28]. Nevertheless, we observed a limited evaluation of the current state of knowledge in each methodological phase mentioned above, in which the understanding is crucial to inform advancements in ML approaches. In summary, the gaps we identified are the need for (1) more effective ML approaches to reduce the risk of underdiagnosis and (2) ML methodologies for handling heterogeneous and extensive multimodal data to support the detection of multifaceted MH disorders.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"In this systematic literature review (SLR), we address these limitations by analyzing individual methodological phases in greater detail. We further narrow our scope to studies adopting passive sensing, which gathers users? data non-intrusively via ubiquitous sensors or devices and requires minimal user inputs. This decision is supported by our hypothesis that people?s natural behaviors are best captured when their daily routines are subject to the least possible obstructions [29,30]. Less intrusive approaches have also been shown to have better acceptance among the general population, with the need to carry/wear dedicated equipment being reported as off-putting and causing levels of discomfort [12,31]. From a recent survey [17], we learned that two key motivations for ML applications to mental health are the accessibility to behavioral data enabled by continuous and non-invasive approaches and the efficiency and cost-effectiveness of timely and automated data processing. Drawing inspiration from the survey above, we establish several criteria that we anticipate in data collection approaches that are practical to promote subsequent effective detection of MH disorders: (1) reliability (i.e., ensuring that the data closely represents actual behaviors), (2) verifiable ground truth, (3) cost-effectiveness, and (4) acceptability among the general population. Consequently, we conduct a detailed analysis of each data source based on these criteria. This SLR aims to (1) assess the current trend of multimodal ML approaches for detecting various MH disorders and (2) identify an optimal strategy leveraging passively sensed multimodal data and ML algorithms. Specifically, the research questions (RQs) we aim to address throughout our study are:",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,RQ1?Which sources of passive sensing data are most effective for supporting the detection of MH disorders?,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,RQ2?Which data fusion approaches are most effective for combining data features of varying modalities to prepare for training ML models to detect MH disorders?,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,RQ3?What ML approaches have previous researchers used to successfully detect MH disorders from multimodal data?,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The SLR is structured as follows:ÿSection 2ÿoutlines the research methods adopted in this review, followed byÿSection 3, which presents results that analyze the individual phases of existing methodologies, including data sources, feature extraction, modality fusion techniques, and the ML algorithms adopted. Based on the analysis,ÿSection 4ÿthen synthesizes the findings to address each RQ mentioned above and draws insights into recommendations and considerations for future researchers wishing to innovate in this space. Lastly,ÿSection 5ÿconcludes the study.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"This section presents the review protocol for our SLR based on the PRISMA 2020 Statement [32], a guideline for healthcare-related studies [33] established based on the PRISMA 2009 Statement [34], and the Guidelines for SLRs in Software Engineering [35] published in 2007.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"We performed an exhaustive search on four online databases: Scopus, PubMed, ACM Digital Library, and IEEE Xplore. We chose these databases due to the abundance of published papers on the topic of concern and to represent the multidisciplinarity of the topic by having a diversity of papers across the fields of clinical science and computing science. As previously explained, we concentrate on studies utilizing data of at least two different modalities collected using ubiquitous devices and applying ML techniques for detecting MH disorders. Inspired by Zhang et al.?s [36] search strategy, we systematically constructed our search query based on aspects shown inÿTable 1.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"We queried the databases by combining keywords within the same category with an OR operator and those across categories with an AND operator. We also considered different terminology variants by using wildcards (*), for instance, ?well*? in our query string, because the term ?wellbeing? may be spelled as ?well-being? in certain studies. An example of our query string on Scopus is as follows:",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,?ALL (mental AND (health OR disorder OR illness OR well*)) AND TITLE-ABS-KEY (?artificial intelligence? OR ?machine learning? OR model) AND TITLE-ABS-KEY (detect* OR predict* OR classif* OR monitor* OR recogn* OR identif*) AND TITLE-ABS-KEY (?social media? OR text* OR audio* OR speech* OR voice OR visual OR imag* OR video* OR smartphone* OR mobile OR wearable* OR sens*) AND PUBYEAR > 2014?.,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"We decided on the cutoff publication year of 2015 due to the consideration of the developmental trajectory of the research domain. Our preliminary observation revealed 2015 as a potential juncture where relevant studies began gaining momentum, coinciding with the introduction of AVEC 2013 [37] and AVEC 2014 [38] challenges focusing on facial expressions and vocal cues relating to specific MH conditions such as depression. We intended to ensure that our review encompasses more recent advancements for a comprehensive understanding of the field?s current state. In addition, the rapid development of technologies may render techniques from older publications obsolete or less relevant. Likewise, the relevance of findings related to smartphones and wearable devices may have evolved due to changes in their adoption among the general population over time.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"To ensure the selection of studies that align with our research focus, we considered a study to be relevant if it fulfilled all of the following inclusion criteria:",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The study collects data passively via ubiquitous or wearable devices, considering the cost-effectiveness and general accessibility.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The data is human generated, i.e., derived from individuals? actions in an environment or interactions with specific platforms or devices.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,The data source involves at least two different modalities.,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,The study adopts ML algorithms intending to detect one or more MH disorders.,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,The study is written in English.,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,The study was published from the year 2015 onwards (further details in the following section).,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,We excluded a study if any of the following exclusion criteria were satisfied:,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The study investigates data sources of a single modality or exclusively focuses on a specific modality, e.g., text-based approaches.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The study specifically targets the pediatric population, i.e., toddlers and children below ten years old, as defined within the suggested adolescent age range of 10?24 years [39].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The study targets a particular symptom of specific MH disorders, e.g., low mood, which is a common sign of depression.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,Data collection requires dedicated equipment or authorized resources:,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The study does not employ ML algorithms for detection/prediction, e.g., focusing on correlation/association analysis, treatment/intervention strategies, or proposing study protocols.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The study is a survey, book, conference proceeding, workshop, or magazine",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,The study is unpublished or non-peer-reviewed.,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Since our work explicitly emphasizes multimodality to observe cross-modality fusion and interactions, we excluded studies emphasizing a single modality. For example, we do not consider those solely analyzing textual content from social media sources (e.g., Twitter) without incorporating broader online social behaviors, such as posting time distribution and interactions with other users through retweets and comments. Additionally, we omitted studies involving children, as it is well-established that factors, manifestations, and responses to MH conditions can differ significantly between children and adults [40]. Children may also often rely on parents and family environment for care and treatment [41,42].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"While changes in MH states such as affect, emotion, and stress may serve as potential indicators of MH disorders such as depression and anxiety [43], it is noteworthy that these factors, when considered in isolation, do not necessarily equate to a complete MH diagnosis [44,45]. Therefore, we refined our focus by excluding studies that solely investigated these states. Due to practicality concerns, we also enforced the utilization of ubiquitous devices in data collection to ensure these tools are easily accessible and cost-effective.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Figure 1ÿshows the literature search process as a flow diagram adapted from an example in the PRISMA guideline (https://www.bmj.com/content/bmj/339/bmj.b2700/F2.large.jpgÿ(accessed on 19 September 2023)). After querying the selected databases, we re-evaluated the title, abstract, and keywords of individual studies to refine the results and remove duplicates. Subsequently, we manually applied the eligibility criteria to determine relevant studies for data extraction.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,Table 2ÿshows the information we extracted from individual studies and the corresponding mapping to the relevant research questions (RQs) where applicable.,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"We adapted a suggested checklist [35] to develop quality assessment criteria, shown in full inÿTable 3, that assigns a score to each study.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Most scoring, except for QC3, QC9, and QC13, adopt a three-item scale, satisfies = 1, does not satisfy = 0, and partially satisfies = 0.5, to evaluate whether a study complies with the corresponding criteria. The final quality score would be the summation of the score corresponding to the conformity of the checklist items. Acknowledging that healthy controls are not always necessary in relevant studies, we have specifically included checklist item QC3 due to our interest in the effectiveness of data sources and methodological approaches in distinguishing between individuals with and without MH disorders. Understanding general patterns in healthy controls also serves as a baseline for benchmarking to justify the significance of future findings related to those with MH conditions.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,This section summarizes and analyzes the results we extracted from 184 relevant studies published from January 2015 to August 2023 based onÿTable 2.ÿTable 4ÿdisplays the combinations of MH conditions investigated and the categories of data sources involved in all selected studies.ÿFigure 2ÿshows the methodological pipeline involved in our data extraction. The following subsections describe and explain each extracted finding in detail.,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The primary categories of data sources are (1) audio and video recordings (nÿ= 82), (2) social media (nÿ= 55), (3) smartphones (nÿ= 54), and (4) wearable devices (nÿ= 28).",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Audio and video recordings of individuals were captured using video cameras, webcams, or microphones while they responded to interview questions or completed predetermined tasks in person or online. For example, Gratch et al. [228] conducted semi-structured interviews with individual participants with both neutral questions and those related to depression or PTSD events, which the authors recorded using a camera and close-talking microphone. In contrast, NEMSI (NEurological and Mental health Screening Instrument) [229] was proposed as a cloud-based system that automates data capture and the subsequent audio-visual processing for feature extraction and visualization. Before commencing the interviews, researchers [228,230] ensured that participants signed consent forms to collect highly identifiable recording data and share their data for research purposes. The researchers also offered transparency regarding the purpose of their study and data collection before participants provided their consent.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Meanwhile, social media platforms like Twitter, Reddit, Sina Microblog, Instagram, Facebook, YouTube, Flickr, and Blued offer a safe space for information sharing, communication, and expressing emotions. Various forms of user-generated content publicly available on these platforms are texts, images, social interactions (likes, comments, mentions, and shares), and user profile information (followers, followings, bio descriptions, profile images). Researchers could crawl content from these platforms using the provided application programming interface (API) by strategically querying content posted within a predetermined duration for observation, locating the presence of relevant phrases or keywords within textual content, or sourcing directly from discussion space revolving around specific MH conditions where applicable. For instance, Shen et al. [20] identified candidate social media users based on tweets containing the character string ?depress? and utilized such tweets as anchor points to sample remaining tweets posted by the corresponding users within a month relative to anchor tweets. Meanwhile, Mishra et al. [185] scraped the top 100 posts from the ?r/suicidalthoughts?, ?r/suicidewatch?, and ?takethislife.com? forums with an abundance of posts related to suicidal ideation.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Nevertheless, we observed limited ethical considerations and explicit mentions in existing studies regarding obtaining participants? consent for utilizing their data for research purposes. For example, Yates et al. [231] discussed the privacy risks with posts crawled from Reddit as minimal since this data is publicly available on the platform. The researchers also described their privacy measures for ensuring that annotators and other researchers were only allowed access to anonymized posts after agreeing to adhere to the ethical guidelines for not attempting to contact or deanonymize data samples.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Smartphone sensors, such as accelerometers, GPS, light sensors, and microphones, could collect and infer information about smartphone usage, physical activity, location, and an individual?s environment. Researchers have adopted existing mobile applications that collect sensing data, such as Purple Robot [232] (Android only), SensusMobile [99] (Android only), and LifeRhythm [233] (Android and iOS), and those with additional features, including Behavidenceÿhttps://www.behavidence.com/ÿ(accessed on 10 December 2023) (Android application that displays similarity scores of inferred behaviors to specific MH disorders), Insights [234] (Android application with customizable questionnaires), MoodMirror [235] (Chinese Android application that connects with a wristband via Bluetooth), or BiAffectÿhttps://www.biaffect.com/ÿ(accessed on 10 December 2023) (iOS only), that collect keyboard typing data specifically. In contrast, some researchers developed mobile applications for their use cases using frameworks like AWARE [236] (collects sensor data from Android and iOS devices and supports integration with data analysis pipeline). These mobile applications act as a central management system, either storing data locally in individuals? devices or transmitting them to a central server for processing and analysis.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Prior to data collection, researchers obtained participants? consent and provided details about the data to be collected. Some researchers additionally conducted onboarding sessions for installing mobile applications, offered tutorials to operate them, and provided technical support throughout the data gathering duration [237]. Privacy measures were also implemented to minimize identifiability and the risks of data leakage during transmission, such as anonymizing participants, hashing phone calls and text messaging logs [237], and employing secure transmission protocols like HTTPS and SSL.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Wearable devices have further enabled the collection of physical activity, movement, sleep, and physiological signals like heart rate (HR), electrodermal activity (EDA), skin temperature (ST), and galvanic skin response (GSR). Some examples of wearables are Empatica E4 wristbands [149,172,178], Microsoft Band 2 [150], Fitbit Charge or Flex trackers [151,155,164,180,181,182,191], and the Galaxy S3 smartwatch [169]. Data gathered through these devices were transmitted directly to an internet-connected server [215] or transferred via Bluetooth [210] to dedicated mobile applications that handle the transmission as described above. As such, existing studies executed similar procedures for obtaining participants? consent before data collection and privacy measures to ensure secure data transmission.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,Table 5ÿdescribes publicly available datasets discovered or released by studies included in this work for multimodal detection.,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Data used for supervised learning must have a ground truth (i.e., if the person to whom the data belong suffers from a specific MH disorder) so that ML models learn to distinguish data points of different ground-truth labels. The means of ground truth acquisition are (1) clinical assessment by trained psychiatrists or healthcare professionals and (2) self-reports by people themselves.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"During clinical diagnoses, trained psychiatrists use clinically validated assessment scales with known symptoms of specific MH disorders to prompt patients to share their experiences. Establishing ground-truth knowledge varies based on experimental design in existing studies, where trained healthcare professionals could conduct clinical assessments before the data collection procedure and during other intermediate phases deemed necessary. For example, Grnerbl et al.?s [12] study involved psychologists conducting examinations every three weeks over the phone, using standard scale tests such as the Hamilton Rating Scale for Depression (HAMD) or Young Mania Rating Scale (YMRS), whereas participants were scheduled for monthly face-to-face clinical assessments with clinicians using the 7-item Brief Psychiatric Rating Scale (BPRS) in Wang et al.?s [206] study. On the other hand, participants could be recruited from the MH service within a hospital setting, where existing diagnoses of specific MH conditions are known, and clinical assessments could be reconducted during follow-ups and after discharge using the YMRS [230].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"If access to healthcare professionals is unavailable, these scales can be administered through mobile applications or other devices to be answered and self-reported by subjects. Examples of scales used in both clinical and self-reported assessments are the Hamilton Depression Rating Scale (HDRS) [254], Patient Health Questionnaire-9 (PHQ-9) [255], Beck Depression Inventory (BDI) [256], and Center for Epidemiological Studies Depression Scale (CES-D) [257]. Researchers can compile and analyze the responses to derive ground truth based on established guidelines. For example, the summation score of the PHQ-9 scale corresponds to depression severity levels, where 5, 10, 15, and 20 represent mild, moderate, moderately severe, and severe depression, respectively [258].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"In most cases where social media data has been scraped from public-facing platforms via application programming interfaces, users are not reachable due to security and privacy protection. As such, their MH states are not immediately acquirable since they do not usually disclose invasive information like medical history. Researchers have relied on textual or visual cues in users? public posts to locate the existence of MH disorders for the purposes of ground truth. They detected self-reports where users explicitly disclosed being diagnosed with a specific MH disorder in their public posts by looking for sentence structure such as ?I am diagnosed with?? [20].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"This ground-truth acquisition method heavily relies on individuals? willingness and openness to share content publicly on social media platforms. Therefore, to enhance the accuracy of ground truth labels, studies incorporated clinical opinions when annotating and labeling social media data. These opinions were sourced from trained psychiatrists or psychologists [112,131,145,186,219], as well as staff and students within the university settings with backgrounds in psychology [142,185]. For example, Abuhassan et al. [218] incorporated opinions from domain experts with specific expertise in eating disorders (EDs), psychology, mental health, and social media. The authors obtained a comprehensive and well-rounded annotation strategy to guide the categorization of social media users into individuals with an explicit diagnosis of EDs, healthcare professionals, communicators (i.e., those who communicate, exchange, and distribute information to the public), and non-ED individuals. The approaches above attempted to address the possibility of researchers overlooking implicit indicators of specific MH disorders or lacking sufficient clinical knowledge to make accurate inferences based on several posts created by each individual [135,189]. However, these efforts may not suffice, given that public content posted by individuals might be adapted with considerations of self-presentation factors.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,A range of modality-specific features within the datasets analyzed by researchers were found to support the identification of MH-related features in study participants.ÿTable 6ÿprovides a summary of these features and their findings relevant to MH diagnosis. SeeÿAppendix Aÿfor a more extensive view of the features and the corresponding extraction tools.,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Several popular approaches to extract audio features include adopting OpenSmile [267] to extract low-level descriptors (LLDs) and employing pre-trained deep learning (DL) models to extract high-level deep representations from either audio samples directly or transformed spectrogram images [66]. Researchers have identified several audio features to be significant indicators of MH conditions. For instance, Yang et al. [193] discovered histogram-based audio LLDs to be more effective than visual features in identifying bipolar disorder, and such indicators are more prominent in male samples. Meanwhile, from specific features such as energy contours, kurtosis, skewness, voiced tilt, energy entropy, and MFCCs, Belouali et al. [184] demonstrated that individuals with suicidal intent spoke using a less animated voice with flatter energy distribution and fewer bursts. Their speech had less vocal energy and less abrupt changes and were more monotonous. Other audio features found to be significant indicators of depression and PTSD include audio intensity, pitch, and spectral decrease [54,107]. Since it is beyond the scope of the current work to dive deep into audio samples and features, we direct interested researchers to an existing work [268] for greater details on audio processing and features that could be extracted at varying domains (e.g., time, frequency, and cepstrum) [54].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Visual features were extracted by first locating individuals or objects in a video frame or a static image, identifying the corresponding feature points (e.g., facial landmarks, FAUs, upper body points), and then generating features using image processing tools including OpenFace [269], OpenCV [270], and OpenPose [271]. Pre-trained models could also be applied directly to visual samples to extract feature representations. For image frames extracted from video recordings, researchers could further capture dynamic aspects and transitions across a video, such as computing the speed and range of displacements of specific feature points between successive video frames and the variation across the entire video.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Facial action units (FAUs) were introduced to describe facial movements [272], where each AU corresponds to contractions of specific facial muscles (e.g., AU5 represents raised upper eyelids, AU6 represents raised cheeks, and AU15 represents pulled-down lip corners [273] as shown inÿFigure 3). FAUs have shown significant promise in encoding facial expressions, each constituted by a combination of AUs [273] as shown inÿFigure 4. In the current context, Thati et al. [99] demonstrated that a few AUs correlate significantly with depressive symptoms, specifically, AU12, AU10, and AU25, corresponding to pulled lip corners, raised upper lips, and parted lips, respectively. Referring to bothÿFigure 3ÿandÿFigure 4, this finding could be associated with a smiling expression comprising AU12 and AU25 and low mood as demonstrated by AU10. It could potentially indicate the ?smiling depression? scenario mentioned by Ghosh et al. [132], where individuals with depression may choose to post more happy images compared to healthy controls who expressed diverse emotions.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"In addition, facial appearance and emotions in shared images were significantly indicative of depression and PTSD [107,116]. While a few studies [25,132,220] showed that individuals with depression have lower tendencies to disclose facial identity, Gui et al. [111] found that they are more likely to post images with faces but of a lower average face count per image. From the revelation of more images of animals and health objects from Twitter and Reddit content, Uban et al. [128] hypothesized the possibility of individuals? online help-seeking through viewing animal-related content that might improve psychological and emotional conditions and looking up causes of health events, diseases, and treatment options.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Meanwhile, other research studies [25,111,220] revealed that individuals with mental illness and depression post less colorful images of darker and grayer colors on social media compared to healthy controls, who prefer brighter and more vivid colors such as blue and green. These patterns potentially align with existing knowledge [275] regarding the influence of individuals? mood on color preferences, where principal hues (e.g., red, yellow) and intermediate hues (e.g., yellow-red, blue-green) evoked higher positive emotions than achromatic colors like black and white. Specifically, Yazdavar et al. [25] demonstrated a strong positive correlation between self-reported depressive symptoms and individuals? tendency to perceive surroundings as grey or lacking colors. In contrast, Xu et al. [220] further computed pleasure, arousal, and dominance scores from brightness and saturation values. The authors then discovered that individuals with mental illness preferred less saturated images (i.e., containing more grey [276]), which implied higher dominance and arousal than healthy controls.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"In addition to textual content written by individuals, researchers also obtained textual transcripts from audio samples using speech-to-text tools on Google Cloud Platform, AWS Transcribe [277], or Transcriber-AGÿhttps://transag.sourceforge.net/ÿ(accessed on 10 December 2023). Tools like Linguistic Inquiry and Word Count (LIWC) [278], Suite of Automatic Linguistic Analysis Tools (SALAT) [279], and Natural Language Toolkit (NLTK) [280] were adopted on textual content to identify nouns, adjectives, pronouns, or specific words referring to social processes and psychological states, where linguistic features were generated as the occurrence of words in specific categories. Meanwhile, sentiment-related features like sentiment polarity scores were obtained from sentiment analysis tools, including Stanford NLP toolkit [281], Sentiment Analysis and Cognition Engine (SEANCE) [282], and Affective Norms for English Words ratings (ANEW) [283]. High-level textual representations could also be obtained via language models, such as BERT [266], Paragraph Vector (PV) [284], and XLNet [285], to represent each word using a vector. The overall textual representations could be obtained via concatenating directly, averaging, or applying attention mechanisms on word-level representations to emphasize more significant features.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Abundant studies consistently highlighted the prominent correlations between textual features and MH conditions. For example, the significance of linguistic features in MH identification was accentuated by compelling evidence showing that individuals with depression and suicidal intent used more first-person pronouns, possibly reflecting their suppressed nature. This linguistic pattern was observed in textual content across various social media platforms, including Weibo [109,123], Instagram [116], Twitter [25,118,121], and Reddit [186], as well as in transcribed audio recordings [184]. Meanwhile, several other studies [123,187] further found more frequent usage of the word ?others? or third-person pronouns (e.g., ?they?, ?them?, ?he?, ?she?) than healthy controls, which the authors hypothesized as the tendency of depressive or suicidal individuals in acquiring physiological distance and reluctant to show feelings. In addition, researchers found individuals with depression, suicidal intent, and schizophrenia exhibiting a pronounced expression of negative emotions compared to healthy controls. This observation is substantiated by various features, including the frequency of negative words [20,118,123,204,220] and negative emoticons [130,188], as well as negative sentiment scores of overall sentences [121].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"In contrast, specific keywords could be indicative, such as references to personal events like ?work pressure?, ?divorce?, and ?break up? [118]; biological processes like ?eat?, ?blood?, and ?pain? [116]; or family references like ?daughter?, ?dad?, and ?aunt? [184]. Existing studies also revealed keywords or phrases related to specific MH conditions to be helpful. For example, in depression detection, researchers [54] identified prominent usage of words associated with depressive symptoms, such as ?depressed?, ?hopeless?, and ?worthless?, referenced from the Depression Vocabulary Word Listÿhttps://myvocabulary.com/word-list/depression-vocabulary/ÿ(accessed on 10 December 2023), as well as antidepressant names [123] based on the list from Wikipediaÿhttps://en.wikipedia.org/wiki/List_of_antidepressantsÿ(accessed on 10 December 2023). Nevertheless, MH-related keywords may be expressed differently for various MH disorders. For instance, individuals with schizophrenia used more words related to perception (hear, see, feel), swearing, and anger [204], while Tbar et al. [217] found individuals with an eating disorder (ED) publishing less ED-related content, involving fewer indicative terms like ?laxative names? and ?weight concerns?, to keep their illness private. The latter study demonstrated false positives introduced by such disparities, as healthy controls were involved in discussions of MH disorders like PTSD or depression that share some ED symptoms or mentioned prevalent topics in the pro-ED community.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"On top of user-generated texts and images on social media platforms, researchers could infer social networks and interactions from metadata associated with users and posts, where followers and followings could indicate ?friendships?, whereas interactions like posting, liking, and commenting could reveal social interactions and topics of interest. While most platforms offer fundamental post information such as time posted, likes, and comments, some details are platform-specific, such as retweets (Twitter), check-in locations (Facebook), favorites (Twitter), profile images (Instagram), and users? details like age and gender (Sina Microblog). Graph architectures could then be adopted to model the information above, for instance, by having a node for each user and an edge between two nodes representing the presence or extent of particular social interactions.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Research attempts have demonstrated a significant association between time spent on social media platforms [116] and depressive symptoms. This claim is supported by compelling evidence indicating that a substantial proportion of individuals with depression (76% [130]) and suicidal intent (73% [188]) engaged in more active posting activities on various social media platforms, including Instagram [125], Twitter [20,118], Reddit [130,188], and Weibo [189], particularly at midnight. Some authors [20,118,134] intuited this behavior as potentially linked to sleeping problems or insomnia. The corresponding posts by these individuals were also found to receive less engagement and attention, such as likes, retweets, and favorites [122,137]. Nevertheless, researchers observed contradicting trends in posting behaviors. While a few studies [122,125,137,189] revealed that those with MH disorders were generally less active on Twitter and Instagram, the opposite was observed in other studies on Twitter [121] and Sina Microblog [109]. Such disparities could be attributed to different user populations or sampling periods that may influence social behaviors on these platforms. Other potentially depressive behaviors include less disclosure of personal information [123], a greater likelihood of modifying images before posting [220], and lower preferences for sharing location [122].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Several research attempts emphasized the role of social networks in identifying MH disorders, where researchers incorporated public information belonging to other social media users engaged through followings, likes, comments, and tweet replies. For instance, Liaw et al. [134] and Ricard et al. [110] respectively involved liked content and that generated by users who have liked or commented on posts created by individuals of concern. The prior found the amount of depression keywords in liked content to contribute the most performance gain, whereas the latter found an improvement after incorporating such community-generated data. Similarly, Pirayesh et al. [138] and Mihov et al. [139] incorporated content created by homogeneous friends identified through clustering and computation and noticed improvement after increasing the number of homogeneous friends and their respective tweets.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Smartphone sensor data could be utilized to gain an understanding of individuals? mobility (e.g., accelerometer, gyroscope, GPS data), sociability (e.g., call logs, text messaging logs, usage of social applications), and environmental context (e.g., ambient light and sound, wireless WiFi and Bluetooth connections). More personalized insights could be obtained by utilizing location semantics; grouping mobile applications into social, engagement, and entertainment categories; and detecting periodicity and routines to infer individuals? behaviors and routines. Wearable devices further complement smartphone sensor data by offering sleep inferences and physiological signals like heart rate, skin temperature, and calories. Research attempts have uncovered potentially significant indicators of the presence or severity of MH disorders, which we explained in detail in the following paragraphs revolving around three primary aspects, i.e., physical mobility, phone interactions, and sociability.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Physical Mobility Features: Studies have shown that negative MH states and greater depression severity are associated with lower levels of physical activity, demonstrated via fewer footsteps, less exercising [154], being stationary for a greater proportion of time [205], and less motion variability [149], whereas a study on the student population showed an opposite trend for increased physical activity [157]. Movements across locations in terms of distance, location variability, significant locations (deduced through location clusters) [177], and time spent in these places [164] were also valuable. For instance, researchers found greater depression severity or negative MH states associated with less distance variance, less normalized location entropy [154,158], lower number of significant visited places with increased average length of stay [158], and fewer visits to new places [205]. In contrast, Kim et al.?s [162] investigation on adolescents with major depressive disorders (MDD) found that they traveled longer distances than healthy controls. Timing and location semantics could further contribute more detailed insights, such as the discoveries of individuals with negative MH states staying stationary more in the morning but less in the evening [205], those with more severe depression spending more time at home [154,175], and schizophrenia patients visiting more places in the morning [206]. Researchers also acquired sleep information either through inferences from a combination of sensor information relating to physical movement, environment, and phone-locked states or through the APIs of sleep inferences in wearable devices. Sleep patterns and regularity were demonstrated to correlate with depressive symptoms [150,158] where individuals with positive MH states wake up earlier [205], whereas MDD patients showed more irregular sleep (inferred from sleep regularity index) [149].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Phone Interaction Features: Phone usage (i.e., inferred from the frequency and duration of screen unlocks) and application usage were potentially helpful. For instance, several studies [158] found a high frequency of screen unlocks and low average unlock duration for each unlock as potential depressive symptoms. However, while Wang et al. [205] demonstrated the association between negative MH states and lower phone usage, the opposite trend was observed in students and adolescents with depressive symptoms who used smartphones longer [150,162,164]. Researchers also investigated more fine-grained features, such as phone usage at different times of the day, where they found schizophrenic patients exhibiting less phone usage at night but more in the afternoon [206]. Additionally, individuals with MH disorders also showed distinctive application engagement, such as Opoku Asare et al.?s [166] findings that individuals with depressive symptoms used social applications more frequently and for a longer duration. Generally, they also showed more active application engagement in the early hours or midnight compared to healthy controls, who showed diluted engagement patterns throughout the day. Meanwhile, Choudhary et al. [212] revealed that individuals with anxiety exhibited more frequent usage of applications from ?passive information consumption apps?, ?games?, and ?health and fitness? categories.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Sociability Features: Sociability features, such as the number of incoming/outgoing phone calls and text messages and the duration of phone calls, were also potential indicators of MH disorders [164,175]. For instance, negative MH states are associated with making more phone calls and text messaging [205,222] and reaching out to more new contacts [222]. On the other hand, adult and adolescent populations suffering from MDD were revealed to receive fewer incoming messages [149] and more phone calls [162], respectively. Lastly, ambient environments could also play a role since individuals with schizophrenia were found to be around louder acoustic environments with human voices [206], whereas those with negative MH states demonstrated a higher tendency to be around fewer conversations [205] than healthy controls.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"In addition, demographics and personalities might play a role in an individual?s responses to MH disorders. For instance, several studies [25,109] proved that females have a higher tendency to exhibit depressive symptoms than males. Individuals of different genders may also express varying responses to MH disorders to different extents. For instance, Yazdavar et al. [25] found that females expressed depressive symptoms more prominently on social media, implying their strong self-awareness and willingness to share their encounters to seek support. Meanwhile, a study [219] revealed that age, emotions, and the usage of words related to personal concerns are among the most significant indicators for identifying female samples with potential risks of anorexia nervosa, whereas words relating to biological processes were more indicative for male samples. Clinical experts involved in the study further identified gender as one of the most relevant factors to consider in locating anorexia nervosa. Fine-grained visual elements like formant, eye gaze, facial landmarks, and head pose may also vary across genders with depressive symptoms [70].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"On the other hand, existing works [286,287] proved the potential association between MH symptoms and personality traits, where pursuing perfection, ruminant thinking and interpersonal sensitivity could be markers of suicide risk [287], whereas conscientiousness and neuroticism exhibited close relations to depression cues [121]. Researchers have estimated the personality scores of study samples based on textual content, for example, using IBM?s Personality Insightsÿhttps://www.ibm.com/cloud/watson-natural-language-understandingÿ(accessed on 10 December 2023) [57,121] or computing the proportion of words relevant to those in perfection- and ruminant-thinking-related lexicons [187]. Specifically, Chatterjee et al. [188] uncovered that 56% of suicidal samples demonstrated the association between low agreeableness and high neuroticism scores with increased suicide ideation, compared to most healthy controls with high agreeableness and optimism scores. Another study [130] also found that individuals with depressive symptoms generally have higher neuroticism and lower optimism scores.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Some studies further applied transformation on extracted features to prepare for fusion by achieving (1) normalization, (2) dimensionality reduction, and (3) feature alignment. Normalization ensures that numerical features share similar scales and are treated equally by ML models. The most common normalization approaches that we observed are min-max normalization, to scale values between 0 and 1, and z-normalization [288], so that values are zero-mean and unit-variance. Since min-max normalization was claimed to preserve data relationships without reducing outlier effects [56], Cao et al. [187] took this inspiration to represent a subject?s age relative to the maximum age among all subjects in the dataset. Meanwhile, dimensionality reduction approaches were widely adopted, such as principal components analysis (PCA), singular value decomposition (SVD), and factor analysis. Lastly, for feature alignment, researchers transformed feature representations of individual modalities to align their dimensions through whitening (ZCA) transform (sparse coded feature representations) [49], global max pooling [77], or discrete Fourier transform (express visual features in the time?frequency domain) [66]. On the other hand, several other studies adopted neural networks to enforce the exact dimensions of multimodal representations. For example, using fully connected (FC) layers with the same units to condense features to a uniform dimension [70,112,179], a multilayer perceptron (MLP) [111], or bidirectional gated recurrent unit (Bi-GRU) [106] to transform representations to specific dimensions and a custom transformer-based architecture that applies linear projection to match various representation sizes [174]. In addition, an FC layer was also used to embed categorical variables to be concatenated with continuous variables [170].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Multimodal fusion techniques combine features extracted from different modalities (e.g., audio + visual + textual data) into a single representation for training an ML model. Inspired by an existing work [69], we categorized existing fusion techniques into three main classes, i.e., at the feature, score/decision, and model levels. We hereby emphasize that the current discussion excludes scenarios where fusion is not required if modality-specific features are in independent numerical forms, which ML algorithms could be applied directly.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"A feature-level fusion is also known as early fusion, where the features of all modalities are concatenated directly before feeding into an ML model. At the score/decision level, instead of features, researchers combined scores/decisions predicted by individual ML models for each modality, such as probabilities, confidence scores, classification labels, or other prediction outcomes, through operations such as AND, OR, product-rule, sum-rule, and majority voting. Fusing these scores would either produce the final outcome or serve as the input to a secondary ML model. There were also hierarchical score/decision-level fusion approaches that aggregate outputs across multiple layers or stages. For example, in Chiu et al.?s [122] user-level depression classification from social media data, the authors first obtained day-based predictions from post-level outputs weighted based on time intervals. Then, they deduced user-level outcomes based on whether day-based predictions fulfilled predefined criteria.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Unlike feature-level fusion, which concatenates features directly into a single representation, model-level fusion methods utilize an architecture or ML model to learn joint representations that consider the correlation and relationships between feature representations of all modalities. For instance, attention-based architectures (e.g., attention layers, transformers with multi-head attention mechanisms) were adopted to learn shared representations incorporating modality-specific representations with varying extents of contributions based on their significance. Meanwhile, cross-attention mechanisms were employed to consider cross-modality interactions. Shen et al. [20] also proposed using dictionary learning to learn multimodal joint sparse representations, by claiming that such representations are more effective than using features directly as the inputs of ML models. Nevertheless, we acknowledge the limitation that our categorization is merely based on our understanding, and specific fusion techniques in each category may implicitly involve a combination of various fusion levels. For a complete list of studies, methods, and tools, seeÿAppendix B.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Previous studies adopted ML models for binary classification on the presence of specific MH disorders, multi-class classification on the stages of MH disorders, and regression on the score based on an assessment scale. A complete overview of these models and their application methods is available inÿAppendix C. Referring to an existing study [289], we classified them into:",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,Supervised learning?trained on labeled input?output pairs to learn patterns for mapping unseen inputs to outputs.,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,Neural-network-based supervised learning?a subset of supervised learning algorithms that mimics the human brain by having layers of interconnecting neurons that perform high-level reasoning [290] to recognize underlying relationships in data [291].,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Ensemble learning?combines multiple base learners of any kind (e.g., linear, tree-based or NN models) to obtain better predictive performance, assuming that errors of a single base learner will be compensated by the others [292].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,Multi-task learning?attempts to solve multiple tasks simultaneously by taking advantage of the similarities between tasks [289].,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Others?incorporates semi-supervised, unsupervised, or combination of approaches from various categories.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The availability of ground-truth information, obtained via expert annotations or clinical assessments, has enabled the broad application of supervised learning approaches that learn the association between input data and their labels. In our findings, these approaches primarily cater to univariate features, where feature engineering may be required to apply them to multidimensional data. The more popular ML algorithms for supervised learning are linear regression, logistic regression, and support vector machines (SVMs). Based on comparisons conducted in existing studies, stochastic gradient descent [43] and least absolute shrinkage and selection operator (lasso) regression [200,213] models performed the best in respective investigations on different feature combinations, i.e., the prior on audio, visual and textual features and the latter on wearable sensor signals, but these models are yet to be compared under similar settings. In addition to the traditional or linear algorithms mentioned above, the following subsection discusses a subset of supervised learning approaches utilizing neural networks.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"A neural network (NN) [290] is fundamentally made up of an input layer, followed by one or more hidden layers, and an output layer. Each of these layers consists of neurons connected through links associated with weights. An FC layer is included in specific architectures to perform high-level reasoning since it connects all neurons in the previous layer to every neuron in the current layer to generate global semantic information [291]. Meanwhile, an architecture is considered a deep neural network (DNN) when more hidden layers are involved. Although NN architectures could be utilized for various learning approaches, such as supervised, semi-supervised, unsupervised, and reinforcement learning [293], this subsection only concerns those utilized for supervised learning tasks. In such contexts, an NN algorithm approximates a function that maps data received by input neurons to outputs via output neurons by adjusting weights between connected neurons [290]. Therefore, NNs can receive numerical data and yield outputs of any dimension, aligning with the corresponding number of neurons in the input and output layers, respectively.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Throughout this work, we have observed vast applications and versatilities of NN-based models in feature extraction, modality fusion, and ML prediction, which could be applied directly to multidimensional signals or transformed feature representations. As such, we raise the attention of future researchers to the potential overlapping between the NN-based approaches adopted in the three stages above. For example, the outputs of specific hidden layers in such models applied to raw signals or low-level features could be extracted as high-level feature representations, whereas those from the output layers could be utilized as prediction outcomes. The NN model in such scenarios could then be treated as either a feature extraction technique or an algorithm. The same applies to specific sophisticated architectures proposed to capture cross-modality interactions in model-level fusion, where these networks learn fused representations while simultaneously generating predictions.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The abundance incorporation of LSTM [294] for its capability of capturing temporal information across long sequences emphasized its potential. Transformer-based models [295], such as BERT [266] (including its variants like RoBERTa [296], ALBERT [297], EmoBERTa [298]) and XLNet [285], also gained popularity due to their capability to effectively capture contextual information through positional encodings [129] and attention mechanisms to learn different significance weights of relevant information. In contrast, some researchers incorporated attention mechanisms into existing NN architectures such as FC layers, LSTM, and GRU to achieve such emphasis. Despite demonstrating satisfactory efficacy, existing researchers obtained inconsistent findings regarding the influence of NN architecture complexity on the resulting effectiveness. For example, stacking NN architectures, like GRUs [119], CNNs [60], and LSTM [215], improved performance on top of utilizing baseline architectures such as those on both hand-crafted univariate features and raw signals. However, a few studies proved simple shallow NN-based models to succinctly outperform deeper architectures, for instance, AlexNet outperforming VGG-16 and RestNet101 [122], and a 2-layer Bi-LSTM which outperformed LSTM and GRU of varying layers [220].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Overall, the capabilities of NNs in learning high-dimensional data offer promising effectiveness and flexibility in mental healthcare involving heterogeneous data for capturing multifaceted aspects of MH disorders. Nevertheless, such models require large, high-quality datasets since they can only learn patterns within the training data [290]. Due to the complex and non-linear structure with multiple hidden layers, black-box NNs further introduce challenges in obtaining interpretable explanations of how the algorithms arrive at an output [16,299].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Ensemble learning algorithms have shown remarkable effectiveness by combining base models with similar or complementary learning principles [173]. Similar to supervised learning, such algorithms were applied to univariate inputs, which could be hand-crafted numerical features or predicted outputs (e.g., regression scores, probabilities, binary labels) from other baseline models. The few popular ensemble learning approaches are tree-based, such as random forest (RF) [300], eXtreme Gradient Boosting (XGBoost), AdaBoost [301], and Gradient Boosted Regression Tree [302], which utilize decision trees as fundamental. XGBoost and AdaBoost were gradually favored by researchers due to their better predictive performance. Specifically, few studies [134,158,184,212] revealed XGBoost as the most effective among SVM, RF, K-nearest neighbor, logistic regression, and DNN models. In contrast, researchers also proposed novel hierarchical ensemble architectures by stacking algorithms (e.g., XGBoost [194], Extreme Learning Machine (ELM) [192]) into layers where models in subsequent layers receive outputs from previous layers as inputs for ensemble predictions. For example, Mishra et al. [185] and Liu et al. [123] adapted the feature-stacking [303] approach by utilizing logistic regression to combine predictions of various first-level learners, like SVM, KNN, and Lasso regression, applied independently to different feature sets. In addition, Tabassum et al. [168] combined an LSTM-based model applied to hourly time series sensor data and an RF on statistical features aggregated across the data collection duration to benefit from the strengths of respective learning algorithms.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Unlike ensemble learning, MTL involves a single model (of any category mentioned above) trained to solve several simultaneous tasks to exploit task-specific similarities and differences. Examples of task combinations are (1) regression and classification [74,102,118,141,193], (2) depression prediction and emotion recognition [46,106,132], and (3) gender-specific predictions [70]. Though most of the included studies adopted NN-based models, such as CNN [61,62], LSTM [46,106], and DNN architectures [102,193], MTL could also be achieved with linear models, for example, the multi-output support least-squares vector regression (m-SVR) [304] trained to map multivariate inputs to multivariate outputs [207]. Meanwhile, Oureshi et al.?s [70] findings further justified the role of demographics in locating MH disorders, such that incorporating gender prediction as an auxiliary task improved the overall performance.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"We observed a few studies applying unsupervised techniques, with clustering using K-nearest neighbors being the most common approach. A few other researchers also adopted anomaly detection using existing unsupervised techniques like Isolation Forest (ISOFOR) [166], or statistical measures such asÿt-tests for detecting outliers among preliminary prediction outcomes [163]. The research attempts mentioned above revealed that these unsupervised approaches appear more promising on smartphone sensor data than conventional ML approaches, including SVM, RF, GDBT, and MLP. In addition, AbaeiKoupaei et al.?s work [196] was the only semi-supervised learning we identified in this study, in which the authors employed a ladder network classifier [305] consisting of stacked noisy encoder and denoising autoencoder [306]. There were also novel approaches adapting various concepts, including recommender system (RS) [173,307], node classification [173], and federated learning [168]. Additionally, some studies employed computations to learn association parameters [83,189] or deduce prediction outcomes from distance-based homogeneity [85].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Most studies on multimodal detection justified the effectiveness of combining multiple modalities due to their complementary outcomes, which outperformed unimodal approaches. Notably, we noticed a single exception in a finding [174] that textual modality alone is succinctly effective, such that combining it with audio and visual modalities slightly deteriorated the overall performance. Deeper analyses also revealed that specific modalities could be more influential than others. From audio-visual recordings, semantic content in audio transcriptions generated via textual features was found to be more indicative of depression than audio and visual features in several studies on depression, bipolar disorder, and suicidal ideation. Specifically, we found such prominence arising from textual representations using various embedding techniques like GloVe [49], Universal Sentence Encoder [59], Paragraph Vector [102], and ELMo [116].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"On the contrary, several revelations highlighted the great potential of audio MFCC features. For example, a study [65] attempting to detect depression in audio samples of less than 10 seconds, another [72] conducted on Chinese language audio samples, and one on detecting bipolar disorders [103] found MFCC features more effective than textual embeddings. Nevertheless, more fine-grained comparisons are required to justify the efficacy of one modality or modality-specific feature over the other due to the varying influence of experimental contexts and setups in data collection and feature extraction.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"In conjunction with an existing finding that individuals with similar depression scores may portray behavioral differences under similar contexts [156], several researchers attempted to achieve individual personalization by training subject-specific models [164,169,205,207], fine-tuning subject-specific layers [161] in a global NN architecture, and deducing personalized predictions by incorporating information from other samples homogeneous to each individual based on correlation coefficients [156] or demographics [208] such as age [209].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Meanwhile, existing attempts at gender-based subgroup personalization also highlighted the potential significance of gender in identifying MH disorders. Researchers achieved such personalizations via training the same ML models on gender-specific samples [92,94,219], fine-tuning and building individual ML models for each gender subgroup [48,161], or incorporating gender prediction as an auxiliary task in an MTL approach [70]. Nevertheless, existing researchers found contradicting findings of models constructed from gender-specific samples. For instance, Pampouchidou et al. [48] and Samareh et al. [54] proved that gender-based classification models outperformed gender-independent ones, whereas others [92,94] demonstrated that global models trained on all genders predicted gender-specific evaluation instances more effectively than those trained on gender-specific data. Attempts above [92,219] further uncovered challenges in effectively predicting female samples, where the outcomes indicated that gender-specific models trained and evaluated on female samples perform worse than those of male samples.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Psychological symptoms related to moods, emotions, and feelings were shown to be effectively captured by textual features, which could be obtained from transcriptions of audio-visual recordings and the content of social media posts. For example, individuals with MH disorders expressed stronger negative emotions via texts with overall negative sentiment or more negative words and emoticons, as well as through MH-specific keywords related to symptoms, treatment, and medications (e.g., antidepressant names and phrases associated with depressive symptoms for depression). While these textual features have been proven indicative, researchers found visual cues to provide complementary information by encapsulating finer details of individuals? implicit inner emotions. For example, the significant association between FAUs and depressive symptoms may indicate how individuals present their facial expressions in response to MH symptoms. In addition, individuals? publicly shared images may reflect their psychological conditions; for instance, preferences for darker colors may represent lower moods, or images of animals may represent self-coping mechanisms to improve emotional states.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Meanwhile, for physical symptoms, the unobtrusiveness and ubiquity of smartphones and wearable devices have great potential to capture individuals? natural behaviors, which could reflect the physical manifestations of MH-specific symptoms. For example, the association of higher depression severity with lower physical mobility, demonstrated via being stationary for a greater proportion of time or traveling to fewer places sensed using GPS and accelerometer, may suggest depressive symptoms of losing interest in surroundings, lethargy, or social isolation. Wearable sensors could complement by offering sleep-related information like sleep states and duration to infer sleep quality. In addition, individuals? social media activities could reflect their personal routines and behaviors, for example, higher susceptibility to insomnia or sleeping problems implied through frequent posting activities during midnight. In contrast, a decline in social interactions is an example of social symptoms that might indicate a reduction of interest in surroundings. Such social interactions could include both verbal communications detected via microphones in smartphones and social interactions made through social media platforms and social mobile applications. Lastly, wearable devices are the only passive data source capable of tracking changes in physiological symptoms, including heart rate, skin temperature, and calories burnt.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Nevertheless, our findings inÿSection 3.3.6ÿhighlighted the influence of demographics and personalities on individuals? behaviors, where specific subgroups may openly share their symptoms to seek external support [25], while some may show reluctance through prominent usage of the word ?others? or third-person pronouns on social media [123,187]. Additionally, Shen et al. [109] proved the divergence in Twitter and Sina Microblog user behaviors, where those with depressive behaviors posted less frequently on Twitter, but the opposite trend was observed in Sina Microblog users. There was also a higher occurrence of positive words in textual content in the latter than in the prior. Such disparity in expressivity could be attributed to different populations? cultural and language differences since Sina Microblog users are primarily from Asian countries. Meanwhile, an increased regularity in physical activities could be a coping mechanism for young adults [157] but is not necessarily the case for other contexts or populations having a depressive symptom of lacking interest in activities, as shown in several other studies [110,149,150,152,158].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"In addition to modality-specific effectiveness, discussed inÿSection 3.3, there is a need for deeper considerations beyond data source, which are associated with the experimental contexts of data collection approaches and the individuals to which the data belong. We established several criteria to evaluate data collection approaches in greater detail inÿSection 4.2ÿbelow.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Based on our categorization of modality fusion techniques, namely feature, score/decision, and model levels, we recommend employing feature or model-level fusion based on researchers? specific use cases. Our observations suggest that score-level fusion might be less effective, as modality features are modeled separately by individual ML algorithms, thereby ignoring the potential correlation of features across different modalities. As previously discussed, certain modalities may be more effective than others in unimodal settings. Since score-level fusion only considers the intermediate prediction outcomes of modality-specific ML models, the more effective modalities may overshadow the less significant ones in the final outcomes, even though all modalities are complementary. The following paragraphs provide more detailed recommendations to decide between feature and model-level fusion.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Feature-level fusion is readily applicable to simple univariate features, where direct concatenation is straightforward and efficient to implement. Researchers should align their decision with research objectives by considering whether the features succinctly capture the information they intend to investigate with sufficient details and the capability of adopted ML algorithms to model the correlation among such features to answer specific research questions. For example, a high-level aggregation by computing the average steps, distance traveled, and time spent at an individual?s home across the entire study duration produces a simple univariate vector representation for feature-level fusion, but such information may not be relevant for a study intending to capture daily variations in individuals? physical behaviors. If researchers intend to prioritize efficiency and low computational complexity, specific computation methods should be investigated to effectively elicit low-dimensional representations that capture time-based variations. For instance, autocorrelation analysis captures feature periodicities across specific durations [157] where the resulting correlation coefficients could be utilized as higher-level representations of time series data.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"On the other hand, model-level fusion has been shown in several attempts [69,71,73,308] to generate more effective high-level feature representations than hand-crafted univariate features due to their capability of capturing temporal and contextual dependencies while modeling cross-modality interactions. The decisions of whether to adopt model-level fusion and the architecture to employ should consider the complexity of the research problems. For example, deep NN architectures with more extensive layers may be more effective if researchers are interested in investigating the influence of particular factors across long durations. However, researchers should be aware of the greater computational costs associated with more complex architectures and the black-box nature of certain NN-based architectures, which reduce the interpretability of modeled interactions.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"We have observed an increased adoption of various NN architectures among researchers to model feature information at varying complexity levels. Several architectures have shown outstanding efficacy by incorporating both temporal and contextual interactions within and across modalities, underscoring the importance of generating fused representations that encapsulate such information. For instance, Yan et al. [170] applied Convolutional Sequence Embedding Recommendation (CASER) [309], which leverages convolutional filters of CNNs. In CASER?s horizontal convolutional layer, the authors applied convolutional filters horizontally to capture daily-level sequential patterns as local features for all feature points at the previous time step, followed by max-pooling to extract the most meaningful information. In the vertical convolutional layer, feature-level patterns were generated as the weighted sum of each feature point at specific time steps, with the convolutional filter acting as weights. The outputs of both convolutional layers were then concatenated into fully-connected layers to produce fused representations. This architecture demonstrated more effective capture of hidden series patterns than aggregated statistical features (e.g., average, minimum, or maximum across a duration). In contrast, Zhou et al. [93] proposed a time-aware attention multimodal fusion (TAMF) network. This architecture includes a sparse MLP, utilizing its weight sharing and sparse connections to mix information from modality-specific representations in both vertical and horizontal directions. The resulting outcome is a mixed attention vector, which is separated into attention vectors of each modality. The final fused representations were obtained by summing modality-specific representations weighted by respective attention vectors. TAMF was claimed to model the importance of different modalities at different times, with well-rounded consideration of cross-modality interactions.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"We could not deduce a single one-size-fits-all model that is the most effective for various multimodal tasks. This is because the effectiveness of ML algorithms relies on the nature and structure of the data, the task to achieve, and how data information is learned and fully utilized. Nonetheless, our observations revealed that ML models adopted in existing studies are primarily supervised learning algorithms, which utilize ground truth as the ?gold standard?, and several models worth investigating are Lasso regression, XGBoost, LSTM-based models, and transformer-based models like XLNet, based on their prominent predictive performance in existing studies. Notably, we noticed a similar trend of rising adoption of NN-based models in recent studies, which appear more valuable than linear statistical algorithms in modeling multidimensional time series signals. As previously discussed inÿSection 3.5.2, existing researchers have proposed various novel architectures to incorporate temporal, contextual, and cross-modality dependencies, such as injecting time-based representations into transformer models to improve performance further [129]. We also observed the significance of utilizing relevant data information, where a few studies [111,186] demonstrated that irrelevant textual and visual content introduced noise that obstructs traces of MH disorders and caused further performance deterioration. While the studies above selected more relevant information through techniques like reinforcement learning [111], other studies utilized attention mechanisms to exert significance weights based on relevance instead of eradicating less relevant information. Specifically, attempts [128,146] at hierarchical attention asserted onto deep representations of social media content from word level and subsequently to post and user levels highlighted the great prospect of such mechanisms.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Despite both audio-visual and sensor data being time series data, we noticed relatively limited applications of NN architectures on sensor data. Most studies employed conventional linear or statistical ML algorithms (e.g., logistic regression, SVM, XGBoost), which learn from univariate inputs, by aggregating extracted features across the whole duration. Such approaches potentially neglected the associations of features across time since several recent studies [162,170,176] proved the superiority of NN-based models applied to higher-dimensional time series sensor data, where features are aggregated at hourly, daily, or weekly features, over conventional univariate approaches. These outcomes suggested an aspect worth investigating for future researchers to better harness the potential of ML algorithms, for example, by applying an LSTM-based model to hourly time series data and RF to univariate features derived from the prior data to leverage the strengths of both algorithms [208].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"While most studies predominantly focused on optimizing performance metrics like accuracy, precision, and recall, they often overlooked practical considerations for real-world applications of ML models, such as complexity, explainability, and generalizability. Despite the inherent biases in ML algorithms [310], only two included studies examined potential biases at the individual and gender levels. For ML models to be seamlessly integrated into real-time detection applications for clinical use, they must be lightweight in terms of complexity and computational cost, considering that available memory and computation resources may be restricted [311], especially in individuals? local devices. Specifically, in the MH domain, this criterion is significant to enhance efficient computations on the fly and timely delivery of personalized interventions and recommendations without imposing excessive processing power [311]. Ultimately, achieving this can potentially improve individuals? accessibility to mental healthcare resources and subsequently promote their treatment-seeking.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"In addition, with the growing attention to the interpretability and explainability of ML models [299], these criteria offer transparency to ML models? decision-making to establish trust in these algorithms and elevate their practicality in real-life applications. Specifically, in high-stake MH applications where black-box predictions potentially bring harmful consequences, explanations of ML outputs can provide meaningful insights for healthcare professionals to understand and validate the relevance of ML outputs in complementing clinical diagnosis. Considering the inherent biases in ML algorithms [310], transparency in working mechanisms (local explainability), feature contributions (global explainability [299]), and potential shortcomings are necessary for healthcare professionals to guide and manage the influence of ML outputs on clinical decisions.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Meanwhile, generalizability improves the transferability of ML models to external scenarios beyond local training environments. Given the potential influence of demographics and personalities on manifestations of MH-related behaviors, existing surveys [17] have highlighted the risks of under-representation of certain groups in training datasets, in which the demographic disparities may be magnified in the subsequent applications to the MH domain. Generalizability can enhance the applicability of ML models to other contexts and heterogeneous populations, subsequently improving the accessibility of the general population to MH resources. As an existing work [312] demonstrated the difficulties of aligning cross-study settings for improved generalizability, Thieme et al. [17] emphasized avoiding overclaiming premature generalization from datasets lacking clinical validation and diversity. As such, future researchers should validate and communicate potential limitations in the generalizability of research outcomes. For example, researchers should account for the diversity within a population by validating outcomes across different subgroups with various demographics and characteristics and reporting on the metadata of the community from which the data is collected.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Following the address of RQ1 inÿSection 4.1.1ÿabove, we established several criteria to further analyze the different categories of data sources.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The reliability of a data source relies on how well it captures people?s real-life behaviors. This criterion is crucial to contribute relevant data for supporting clinical diagnosis since failure to reflect realistic behaviors may result in misdiagnosis of MH disorders, potentially leading to severe complications.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"We perceived that smartphone and wearable sensor data are the most reliable due to their ubiquity and a lower possibility of people ?tricking? sensors into gathering perceivably desired data. Prior to data collection, participants will configure dedicated mobile applications in their smartphones, allow permission to access specific sensor data, and establish wireless connections for wearable devices to their smartphones, where applicable. Afterwards, they will interact with their devices as usual throughout the data collection process with minimal active inputs. Given that they are open to and allow monitoring over a longer period, the awareness of monitoring may be reduced following the initial novelty effect, thereby enhancing the ?honesty? of corresponding data. Nevertheless, researchers should consider data quality that can be affected by sensors of different devices with varying sensitivity. The fit of wearable devices may also affect the accuracy and amount of data collected. For example, improper wearing or wearables slipping off [313] during sleep may end up collecting poor, noisy data. In addition, participants may forget to reapply sensors (e.g., following a shower) or feel discomfort from wearing it on their wrists or other parts of their body.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Both audio-visual recordings and social media data potentially suffer from biases introduced by individuals? self-presentation concerns. For example, a person may behave differently under the pressure of continuous supervision, also known as the Hawthorne effect [314], to look generally appealing or hide any indicative behaviors potentially due to fear of judgment. Similarly, social media users might curate their public posts to appear presentable due to factors like the consciousness of unfavorable public perception or social stigma. In addition, a study [187] found that users express their thoughts differently in the hidden tree hole posts than in usual Sina Microblog posts. A tree hole is a microblog space whose author has committed suicide, and other users tend to comment under the last post of the passed one about their inner feelings and thoughts. Such posts were revealed to contain more self-concern and suicide-related words, thereby challenging the detection of MH through regular or public posts.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"A well-justified ground truth is vital to represent people?s actual MH states. From a responsible innovation perspective, unrealistic ground truth can cause under or over-estimations in MH detection, which may escalate to introduce dangers, especially in disorders with crisis points, such as suicidal ideation or an eating disorder.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Clinical assessments are the only method yielding representative ground truth thus far because self-reports, whether in the form of responses in assessment scales or self-declaration in social media posts, are subject to self-presentation and recall biases. However, we noticed a possibility of verifying ground truth from self-reports by utilizing behaviors detected via smartphone and wearable sensing. These approaches typically request individuals to answer clinically validated assessment scales based on guidelines like the Diagnostic And Statistical Manual Of Mental Disorders, Fifth Edition (DSM-V) [315] to serve as baseline ground truth. The response to each assessment question corresponds to recalled behaviors over a specific duration. Taking Wang et al.?s work [150] as inspiration, behaviors inferred from sensor data can be mapped to individual DSM-V symptoms to verify ground-truth labels. Conversely, some researchers primarily rely on social media users? self-identification of MH disorder diagnosis to acquire the ground truth of their MH states, usually through identifying keywords associated with specific MH disorders. Such acquisition risks under-identification since it depends on whether people took the initiative and felt comfortable sharing the information. Solans Noguero et al. [219] further proved that suicide-related lexicons were less comprehensive due to the likelihood of omitting explicit vocabulary and failing to identify implicit hints.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"A reliable ground truth should always be supported by clinical validation, such as through a diagnosis by trained practitioners, reference of clinical evidence, or having clinical experts verify manual annotations, since relevant clinical knowledge is necessary to ensure the validity of ground-truth labels. Specifically, in the use case of social media data, where individuals? data were crawled directly from these platforms, there are both practical and ethical considerations that need to be addressed when claiming a ground truth has been established. While time-consuming, future studies could consider ways to directly approach social media users where possible to verify their MH states and to actively gain their consent for their data to be used (or ensure that users are aware of the research aims at the very least).",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"We inspected costs in terms of (1) data accessibility, (2) external costs incurred for dedicated data collection equipment and tools, (3) processing power for transforming and analyzing data, and (4) storage space. These considerations are crucial in evaluating the practicality of research outcomes in real-life applications so that a cost-effective method can be easily deployed to benefit the target population.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"We deduced that social media data are the cheapest to acquire from all aspects above. It is the most accessible since researchers can crawl public data online without accessing users individually or getting hold of their private information, given that they comply with the platforms? terms and conditions (whether this is deemed ethical is another question). Relatively small processing power and storage space are required since crawled data is in the form of data entries. Additionally, features can be extracted from textual and visual content using processing tools available, such as LIWC [278], NLTK [280], and SEANCE [282] for texts and OpenFace [269], OpenCV [270], and OpenPose [271] for images. Audio-visual recordings are the most costly because they encapsulate rich data information that requires large storage space and extensive computation power to process audio and visual elements. In addition, this approach requires video cameras and microphones, which might have to be purchased beforehand, and consumes more effort in setting up the equipment at one or more locations based on device reception and coverage.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Since most populations generally own smartphones [316], the potential equipment cost for smartphone sensing is lowered. However, a substantial cost might be incurred if researchers are to provide smartphones to study participants without smartphones or to ensure consistency. In contrast, wearable devices are cheaper but less ubiquitous than smartphones since some participants do not see the necessity of possessing wearable devices (e.g., fitness watch, smartwatch) and consider them a luxury item. Though both approaches involve time series sensor signals, which may be high dimensional, the storage cost is still relatively economical compared to multidimensional video files. Nevertheless, we observed a novel application of federated learning in Tabassum et al.?s [168] work, which is potentially feasible for resolving storage and privacy concerns. The authors processed collected data and extracted features locally in individuals? devices to obtain local features and parameters. These were then utilized to fine-tune local individual-specific ML models, which share and exchange higher-level parameters with a global-centric model. This approach significantly lowered transmission cost and storage space since server transmission is reduced from complex multidimensional data to numerical features and parameters while minimizing the risks of privacy leaks during transmission since raw data was discarded after local processing. As such, researchers should consider the factors discussed inÿSection 4.1.3ÿto ensure that ML models residing in local devices are highly deployable, such as being efficient and lightweight, to avoid consuming excessive local processing power.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The general acceptability of people towards specific data collection approaches has the most direct influence on research involving human data. This criterion can be attributed to people?s openness and comfortability in allowing their data to be collected, which are often supported by their perceptions and concerns about the methods. The control they have over the sharing of their data may also be a contributing factor.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"We inferred wearable sensing as the most acceptable because it gathers the least identifiable data (e.g., physiological signals like heart rate and skin temperature, activity levels, and sleep patterns) that is most unlikely to disclose people?s personal information. On the other hand, acceptability towards smartphone sensing is debatable. A study [100] discovered GPS to be the most acceptable compared to calendars, call logs, text logs, and contacts, and only one-third of study participants shared their smartphone logs. However, this is not necessarily the case for some with safety concerns about revealing their locations (e.g., not wanting to disclose their homes or concerns over being stalked [317]), and allowing access to call and text logs can also be perceived as privacy-invasive. In both smartphone and wearable sensing contexts, participants may or may not have control over the kinds of data collected from them, i.e., which sensors are enabled, depending on the approach design and configuration by researchers.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"The acceptance of social media users for researchers to utilize their data for research purposes is also controversial. Researchers have presumed that social media users are open to and permit others to access their data since they opted to make it public in the first place [318]. Even though users have complete control of their public content, they are unaware and may oppose their data being accessed and analyzed for research without consent. Meanwhile, we hypothesize that audio-visual recordings are the least acceptable because it is highly invasive, and not all individuals are comfortable having their footage taken and monitored continuously. Even though existing research [313] found a general acceptance of being recorded using privacy-preserving video cameras that only capture participants? silhouettes, such cameras may not apply to the current context that requires identifiable elements, like facial expressions, body gestures, and movements. Researchers have complete control of the data collection process, and there were contradictory opinions from participants themselves on whether they should have control over when and what is being recorded, e.g., by allowing them to pause at specific critical times [313].",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"As much as the ability to manage data sharing based on personal comfort can improve the acceptability of data collection, researchers should be aware of the resulting risks of biases and sparsity in data. A reduction in the unobtrusiveness of passive sensing and an increased likelihood of skewness will occur if participants constantly manage their data sharing. There will also be data sparsity issues if participants can selectively activate/deactivate specific sensors at random times. There are other means of establishing people?s trust in researchers to raise their confidence that their shared data will be kept secure and handled cautiously with safety procedures. For example, this can be achieved by offering transparency of what is being collected, why, and how they will be stored and handled.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Overall, smartphone sensing emerged as the most promising avenue. Our findings demonstrate abundant significant correlations between sensor features and MH symptoms, offering the potential to translate such connections into an individual?s physical manifestations in response to specific MH disorders. While symptoms associated with specific MH disorders may manifest differently, the capability of smartphone sensors to capture natural behaviors and variations across time provides a strong advantage.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"However, the integration of smartphone sensing into MH applications demands further research due to several critical considerations that are yet to be addressed. Ethical concerns arise regarding whether it is privacy-infringing for researchers to access individuals? private or personal behaviors, which they may be unwilling to disclose. Consequently, they may deliberately hide or alter their behaviors to ?trick? the data collection system or withdraw due to privacy concerns. These issues contribute to the potential unreliability and sparsity of the resulting data, introducing challenges for technical researchers to seek solutions for data-driven ML algorithms, especially in supervised learning with a heavy reliance on ground truth labels. Despite the rich information in time series sensor-based data, there is still room for research to investigate techniques that fully harness its potential. While existing studies have demonstrated the efficacy of neural network architectures in modeling such high-dimensional data, the low explainability and high complexity of such architectures remain a critical challenge. Additionally, existing elicitation techniques are often informed by standard guidelines like DSM-V, potentially disregarding behaviors yet to be discovered. As such, it is imperative to establish a common ground between researchers and clinical experts that enables collaboration to investigate and interpret ML outputs to ensure clinically relevant outcomes.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,We hereby acknowledge that the above represents our perspectives based on the current understanding and analysis and that it is essential for future researchers to critically evaluate and adapt the insights based on the evolving landscape of technology and methodological approaches to their specific use cases in the MH domain. We outline some guidelines in the following subsection to assist future researchers in making informed decisions.,,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"In light of the various influencing factors of MH conditions and the necessary considerations for high-stakes applications involving vulnerable individuals, we have devised guidelines that future researchers can use in conjunction withÿFigure 5ÿabove for selecting an optimal data source or combinations of data sources based on specific use cases.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"1. Define research objectives and scope:ÿClearly defined research objectives and questions can guide researchers to determine the kind of information required to achieve the research goals and, subsequently, to evaluate the extent of the data source in accurately representing or capturing relevant information. Determining the scope of the study is crucial to pinpoint and assess the relevance of data information to ensure that collected data effectively contributes to the desired outcomes.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"2. Determine the target population:ÿIdentifying the target population and its characteristics involves various aspects, including the targeted MH disorders, demographics, cultural backgrounds, and geographical distribution. These aspects are mutually influential since individuals? behaviors and data may vary based on reactions to different MH disorders, with further influence caused by cultural backgrounds and demographics, such as age, gender, and occupation. Additionally, geographical distribution and economic backgrounds may influence an individual?s accessibility to a specific data collection tool. This consideration ensures that the data collected is representative and applicable to the population of interest, enhancing the overall effectiveness of the approach.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"3. Identify candidate data sources and evaluate their feasibility:ÿEvaluating the feasibility of each data source in light of the research objectives and target population identified above assists researchers in making informed decisions. Given the contexts and environments in which the target population is situated, researchers can assess which data source is the most practical and relevant. For example, researchers may consider employing remote sensing to introduce the unobtrusiveness of data collection for high-risk MH disorders or overcome geographical challenges. This assessment should consider its feasibility in terms of cost and accessibility, and it should be informed byÿFigure 5ÿto ensure that the selected data source can effectively capture relevant MH symptoms.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"4. Consult stakeholders:ÿEngaging stakeholders, including healthcare professionals, patients, and families, provides various perspectives of parties involved in supporting individuals with MH disorders. These consultations verify and offer insights into the acceptability and feasibility of data sources and help ensure that researchers? decisions align with ethical considerations and stakeholders? comfort.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"5. Ethical considerations and guidelines:ÿResearchers should further consult institutional review boards and established guidelines to ensure the compliance of data collection procedures with ethical standards and research practices. This step is crucial to safeguard participants? rights and privacy, enhancing the credibility of the study.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"6. Assess the significance of ground truth information:ÿEvaluating the significance of ground truth information informs how researchers gauge its impact on the study and whether specific workarounds are necessary to enhance ground truth reliability and validity during data collection. This evaluation will then aid researchers in designing the data collection procedure and determining the extent of reliance on ground truth to support future analysis, reasoning, and deductions.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"This study examines existing methodologies for non-intrusive multimodal detection of MH disorders and critically evaluates various data sources in terms of reliability, ground truth validity, cost, and general acceptance. Given the complexity of identifying the most effective data source for detecting MH disorders, our guidelines offer a systematic approach for future researchers to make informed decisions about a data source that aligns with research objectives, is relevant to the target population, and adheres to ethical standards. In addition, our analysis highlights the potential of neural network architecture in model-level fusion for capturing higher-complexity cross-modality interactions. We also observe the prospect of utilizing such architectures as ML algorithms to handle high-dimensional data, though practical aspects, such as complexity, explainability, and generalizability, should be scrutinized beyond effectiveness.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"We acknowledge the inherent limitations in our approach, recognizing that our search strategy might have omitted potential data sources not explicitly defined within our predetermined categories. Though our findings verified the significance of multimodality compared to unimodality in most cases, there is no absolute answer since the overall efficacy depends on modality-specific features. In addition, there are risks associated with our assumption that passive sensing captures natural behaviors and is more acceptable. The deliberate exclusion of active sensing based on this assumption limits our understanding of potential insights that active sensing approaches can offer. In conjunction with our previous discussion on seeking validation in ground truth information, active inputs may be valuable and necessary to achieve robust validation. As we critically evaluated each data source, we observed a refutation of our assumption, such that passive sensing approaches can be privacy-invasive and are not necessarily well accepted. This is due to the uncertainties and unobtrusiveness of such approaches, which may introduce a sense of insecurity among individuals from whom the data is collected. Building upon the acknowledgements, the current study has recognized smartphone sensing as a promising avenue for further exploration as our next step forward. In light of the ethical considerations and limitations identified, we plan to conduct interviews and focus groups with individuals with MH disorders to gather feedback on the acceptability of smartphone sensing and potential workarounds for addressing privacy concerns. Simultaneously, consulting healthcare professionals will provide valuable perspectives on incorporating smartphone sensing into clinical practice. As we embark on the journey into smartphone sensing, we extend an open invitation for collaboration with fellow researchers, healthcare professionals, and stakeholders passionate about advancing in this domain.",,,,,
Machine Learning for Multimodal Mental Health Detection: A Systematic Review of Passive Sensing Approaches,"Nevertheless, our work aspires to bring significant implications for stakeholders, including researchers, mental healthcare professionals, and individuals with MH disorders. Our overview of current methodologies for handling multimodal data serves as a starting point for future MH researchers to explore methodological advancements for more effective and timely detection approaches. Our guidelines for data source selection provide a systematic approach for researchers to make informed decisions aligned with use cases or specific symptoms of interest. In addition, our critical analysis of passive multimodal data sources and modality-specific features provides insights to explore the effectiveness of other modality combinations for specific MH disorders. Subsequently, this inspires the development of specific tools that leverage external or multiple data sources to support mental healthcare professionals in their clinical practice (e.g., drawing inspiration from the beHEALTHIER platform [319] which integrates different types of healthcare data, including health, social care, and clinical signs, to construct effective health policies). We envision engaging with MH professionals through workshops, webinars, or other collaborative efforts to bridge the gap between research and practice. Additionally, our practical insights emphasize implementing ML approaches in real-world settings, paving the way for practical implementations that enhance the accessibility for individuals with MH disorders. The outcomes related to the correlation between specific inferred behaviors and MH symptoms also contribute to a better understanding of MH symptoms. Moving forward, we anticipate close collaboration with mental healthcare professionals and individuals with specific MH disorders to design a multimodal approach that facilitates more effective detection. Regardless, we acknowledge the need to establish a middle ground to effectively communicate technical concepts and implications to both stakeholder groups.",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"This paper presents perspectives on the stigma and shame around mental health in conservative communities, and some of the issues faced by health systems in those communities. The various causes of stigma are explored, and how these are often more pronounced in culturally reserved, conservative communities. While health systems are supposed to provide support for mental health sufferers, this stigma sometimes even extends to healthcare workers, which can discourage patients from asking for assistance. Solutions and reforms are needed, for example education programs; addressing gender norms, and the consideration of culture and religion, to form effective solutions. It is also suggested that alternative therapies and support mechanisms, including digital solutions such as artificial intelligence chatbots, may be useful to provide much needed support to individuals with poor mental health. Along with integrating options such as CBT (cognitive behavioral therapy), it may be useful to draw on indigenous psychologies, such as Islamic psychology, as a way of decolonizing approaches. Therefore, when considering solutions, cultural and religious norms must be considered to ensure their efficacy and acceptance.",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"This paper presents perspectives on the stigma around mental health in conservative communities, and the association of mental health with shame that is being dealt with by many health systems around the world. This is particularly apparent within developing countries and areas where cultural values and practices may influence treatment options. For example, Elshamy et al. (1) conducted a systematic review of 16 qualitative studies into mental health seeking behaviors in Middle Eastern countries (typically conservative communities), and they discovered negative attitudes toward mental health, including stigma and shame. Furthermore, in a cross-cultural comparison of mental illness stigma and help-seeking attitudes conducted across 16 Arab countries, Fekih-Romdhane et al. (2) found that out of 10,036 respondents, one in four held stigmatizing attitudes toward mental health and negative attitudes toward seeking support.",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"Encouraging access to mental health support within such conservative communities, where religion, moral and social identity, and the role of the family take precedence, is often difficult (3). This is in part because mental health problems are sometimes viewed as shameful and are, therefore, hidden from friends, family and the workplace (4). Addressing the stigma around mental health is essential to public health provision because it can lead to delays in seeking support, which may exacerbate the condition. In addition, it can have negative consequences not only for sufferers, but also for their families and caregivers, along with poor treatment outcomes due to fears over sharing information about symptoms (5).",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"A deep understanding of conservative communities and the persistence of the stigma around mental health is essential to ensuring the wellbeing of individuals and the functioning of society as a whole. Therefore, this review of mental health stigma in conservative communities, and the problems faced by the public and healthcare practitioners, adds to the knowledge in this area, and it may be useful in informing future research pathways and findings solutions. Furthermore, while education and ?changing the cultural narrative around mental health? [(6), p. 1920] is essential, novel approaches are also needed to directly mitigate the stigma related to mental health conditions. As we enter into the fourth industrial revolution, new digital options and technologies such as artificial intelligence may provide unique solutions.",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"The definition of stigma proposed by Goffman (7) posits that stigma is an attribute that devalues a person and sets them aside from others. This definition lays bare the vulnerability of individuals with a disability, especially those with mental health needs. Furthermore, it is well documented in the literature that people with a mental illness (PWMI) face stigma from multiple sources, including schools, hospitals, places of worship and sometimes even from their own families (8,ÿ9). For example, Zolezzi et al. (10) found that the stigma related to mental health in Arab collectivist societies extends beyond the sufferer to the whole family, impacting their reputation; therefore, the stigma and shame around mental health is exacerbated for PWMI due to concerns about the impact on their wider family as well as themselves. Similarly, Andrade et al. (11) explain that in conservative communities where traditional family values and the notion of ?honor? exist, ?mental health issues are more likely to be perceived as threatening the integrity of the family, given that mental health stigma affects the reputation of the family involved? [(11), p. 2].",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"The reasons for these negative attitudes toward mental health have been shown to have multiple origins that include culture and tradition, prejudice, and ignorance (12). Although this pattern of behavior is common in many societies, it is often more pronounced among culturally reserved, conservative communities (13), where traditional practices and doctrines have shaped how healthcare workers (HCWs) receive and relate to their clients. Similarly, it has become common place in the literature for authors to draw a link between level of education, mental health literacy and mental health stigma and shame (10,ÿ12,ÿ14). Based on these associations, it has been suggested that mental health stigma is less problematic in populations with higher levels of education or among societies that have high levels of mental health literacy (15). Therefore, it is plausible that knowledge about mental health may provide insights into how individuals perceive and manage mental illness, as well as how the general public interacts with those who suffer from it (16). Despite this, in reality, positive attitudes around PWMI do not always correlate with higher levels of education (17,ÿ18).",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"Mental health services across conservative communities in the Gulf region have been receiving increasing support, for example, in Qatar, the launch of the National Mental Health Strategy for Qatar in 2013 led to mental health services transitioning toward more community based care within a more comprehensive and integrated system (19). It is notable that across the Gulf region during the COVID-19 pandemic, technology was increasingly used to support mental health sufferers, such as cloud based big data systems, artificial intelligence and AI chatbots, online health communities, and telehealth platforms, were introduced as a response to the pandemic, paving the way for digital mental health solutions. Therefore, Chew et al. (20) (p. 2) claim that ?digital mental health tools are the silver lining we are fortunate to have, as they can empower responses to the COVID-19 outbreak at a scale that was never before possible in human history.?",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"As expected, the health system is supposed to be a haven for people with mental healthcare needs, but structurally, the gaps in the system allow PWMI to fall through the cracks, and for various reasons, HCWs have been implicated in barriers to access for many PWMI through their negative attitudes (21). Furthermore, Knaak et al. (22) explain that stigmatizing attitudes toward mental health suffers are consistent across the stages of healthcare delivery and provision. This is a conundrum that requires further analysis, because in consideration of academic scholarship, and in relation to the general population, HCWs should set a positive example in matters relating to mental health. Indeed, we must consider the opposite argument where there is strong support for HCWs in their capacity as role models and positive change agents and advocates for PWMI (23). However, due to the key role of HCWs in ensuring the best possible care for those who need it, even a singular negative report in this regard is one too many.",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"Public stigma is believed to be pervasive and holds the potential to foster negative mind-sets that build long-lasting views that may influence important decisions regarding help seeking behaviors (24?26). However, not only does the stigma around mental health manifest itself in the general population, and therefore, the friends and relatives of sufferers, but HCWs are also implicated in the stigma and shaming of PWMI. This connection is especially significant because these individuals act as gatekeepers to healthcare access, therefore PWMI can face an implicit obstacle to accessing the care they need. Moreover, a health workforce lacking in knowledge or with negatively inclined practitioners will lead to the creation of an environment that is unaccommodating for service users. As such, the resulting unfavorable experiences may discourage the care recipient from asking for assistance (27).",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"One may argue that there is a contextual basis for the experiences around mental health, which may be due to variations in culture and religion, or purely based on individual differences (22). For instance, there are those who fervently believe that religious convictions can solidify attitudes that shape or form views expressed by individuals (24,ÿ28). In conservative communities, such as some across the Middle East and North Africa (MENA) region, mental health stigma is a prominent topic of concern. This is due in part to its influence on access to mental healthcare, as well as its impact on medical practices in general. Saudi Arabia may be considered as a prime example of one of these communities.",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"Situated in the MENA region, Saudi Arabia is predominantly an Islamic country, and as such, the views and attitudes toward PWMI and the use of mental healthcare services may have been shaped by cultural practices and religion (6). Accordingly, a Saudi hospital-based study suggests that there may be a bias toward PWMI (29). This can be seen in reports that show that about half of a sample of specialist doctors held stigmatizing views toward PWMI (30). This again shows that individuals with higher education, even among those who are medically trained, may be involved in the stigmatizing and shaming of people with mental healthcare needs (10,ÿ29). Regarding this point, Alamri (29) highlights that in the general population, there is skepticism about taking part in mental health conversations or accessing mental health screening programs. This is based on beliefs that such programs are meant only for people suffering from insanity. In addition, patriarchy is well engrained in many of these communities (31), and as documented, men in these settings are more likely than women to express negative attitudes toward PWMI, even among HCWs (32). This may influence health seeking decisions, particularly for women and their children when they come in contact with a male HCW who may exercise undue control over a patient-doctor encounter. This again may have implications for stigma and shame (31). Accordingly, Awad et al. (4) suggest that psychology solutions should consider religiosity.",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"Could it be based on these beliefs and practices that some HCWs transfer deeply held views about mental illness in their dealings with those who seek mental health services? Or could it be based on ignorance or poor mental health education among HCW? In conservative communities such as Saudi Arabia, multiple factors may apply, including the diverse background of HCWs, inadequacies of training and, indeed, the influence of culture (32,ÿ33). However, the bottom line is the overall impact of this on limiting access to mental healthcare and the potential to drive PWMI toward the patronage of substandard care (10,ÿ34).",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"Whatever the root cause of the problem, action to change the attitudes of the general public toward mental health in conservative communities, alongside health reforms and training for HCW, is urgently required. This should include addressing gender norms and the consideration of culture and religion to form effective solutions. According to Alattar et al. (6) (p. 192), to change the cultural narrative around mental illness, ?Education and anti-stigma campaigns need to be developed and further training needs to be developed for mental health professionals who need to offer greater support in this area.? In the meantime, alternative therapies and support mechanisms may be useful to provide much needed support to individuals with poor mental health.",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"With regard to the future of mental health, including in conservative communities, Van Daele et al. (35) state there is a demand for digital therapy that uses psychological theories and methods to interface technology with healthcare to support mental wellness. Furthermore, some have suggested that technology could serve as a bridge between PWMI and healthcare staff or therapists by, as the case may be, offering relief and comfort (35). Cognitive behavioral therapy, or CBT, is a treatment that aims to help people modify their thought processes and behaviors in order to improve their mental health, and its approaches have been integrated into chatbots for mental health. Furthermore, Haque (31) suggests embedding indigenous psychologies to decolonize approaches and ensure culturally appropriate treatment, including Islamic psychology, which considers the nature of the human soul, the development of personality, and the evil eye. This should lead to more rounded solutions and support that is accepted by the communities in which it is offered.",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"It has been shown that conservative communities face a unique set of problems related to the stigma around mental health and its persistence. While educating healthcare professionals and the public is crucial to changing the cultural narrative, there may also be other alternative approaches that can provide solutions, especially considering the current speed of advance in digital technologies. It may also be possible for religious and cultural norms to be embedded within that technology. That is, given the multiple challenges plaguing the healthcare system in conservative communities, the integration of technology may prove beneficial in enhancing mental health services, especially for individuals suffering from anxiety and depression (36). Although there is a dearth of research on chatbots for mental health in the MENA region, Ujiro et al. (37) report that there may be some progress, as shown in the use of a chatbot called OlloBot, which has been used by doctors to help patients manage their diseases at home and triage patients (37). With this evidence, it becomes imperative to source alternative remedies, such as artificial intelligence tools that are less stigmatizing to PWMI, while attempts are made to improve attitudes and health systems reform and re-strategize to position mental healthcare at the heart of the people they serve.",,,,,
Mental health stigma: a conundrum for healthcare practitioners in conservative communities,"It is clear that stigma and shame are a major stumbling block to accessing mental health services in conservative communities. Unfortunately, the stigma extends beyond the individual to their family members, exacerbating the shame they feel. In addition, the healthcare workers who are expected to support those with mental health difficulties also sometimes contribute toward the stigma and feelings of shame, leading to further discouraging patients from seeking assistance. This situation requires a range of responses to address the problem within an environment where mental health problems are on the rise. Such responses should be culturally relevant, religiously appropriate, informative and educational, and utilize cutting edge technologies.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Structural racism produces mental health disparities. While studies have examined the impact of individual factors such as poverty and education, the collective contribution of these elements, as manifestations of structural racism, has been less explored. Milwaukee County, Wisconsin, with its racial and socioeconomic diversity, provides a unique context for this multifactorial investigation.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"This research aimed to delineate the association between structural racism and mental health disparities in Milwaukee County, using a combination of geospatial and deep learning techniques. We used secondary data sets where all data were aggregated and anonymized before being released by federal agencies.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"We compiled 217 georeferenced explanatory variables across domains, initially deliberately excluding race-based factors to focus on nonracial determinants. This approach was designed to reveal the underlying patterns of risk factors contributing to poor mental health, subsequently reintegrating race to assess the effects of racism quantitatively. The variable selection combined tree-based methods (random forest) and conventional techniques, supported by variance inflation factor and Pearson correlation analysis for multicollinearity mitigation. The geographically weighted random forest model was used to investigate spatial heterogeneity and dependence. Self-organizing maps, combined with K-means clustering, were used to analyze data from Milwaukee communities, focusing on quantifying the impact of structural racism on the prevalence of poor mental health.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"While 12 influential factors collectively accounted for 95.11% of the variability in mental health across communities, the top 6 factors?smoking, poverty, insufficient sleep, lack of health insurance, employment, and age?were particularly impactful. Predominantly, African American neighborhoods were disproportionately affected, which is 2.23 times more likely to encounter high-risk clusters for poor mental health.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"The findings demonstrate that structural racism shapes mental health disparities, with Black community members disproportionately impacted. The multifaceted methodological approach underscores the value of integrating geospatial analysis and deep learning to understand complex social determinants of mental health. These insights highlight the need for targeted interventions, addressing both individual and systemic factors to mitigate mental health disparities rooted in structural racism.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Structural Racism and Discrimination (SRD) is a fundamental determinant of health disparities and poor health outcomes among historically marginalized communities in the United States [1]. SRD refers to systemic or institutional racism and societal norms that constrain the chances, resources, influence, and welfare of people and communities due to their racial and ethnic background and other characteristics. Racial segregation in urban centers is an outcome of SRD-driven policy inequalities such as discriminatory mortgage lending practices (redlining), confining Black Americans to central city neighborhoods, which became sites of concentrated poverty and heightened inequities. Residents of segregated neighborhoods experience disproportionate exposure, susceptibility, and vulnerability to economic and social inequality, environmental pollution, toxic substances, and unsafe conditions, thereby affecting individual health conditions, health practices, and access to health care services [2]. Further, neighborhood-level racial and ethnic segregation determines and limits access to educational, employment, and health-related resources [1]. Studies have emphasized the significance of neighborhood segregation on health inequity [3].",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Past research has focused on the relationship between interpersonal discrimination and health; however, SRD is likely to have broad downstream effects on psychological, biological, physiological, and behavioral processes [4]. Mental health is of particular importance, especially since the start of the COVID-19 pandemic, where estimates of pooled prevalence of depression are 7 times higher than expected [5], with minority Americans experiencing more severe and chronic symptoms across time [6]. As individuals are embedded within larger systems of influence, it is essential to understand the relationship between SRD and mental health at a community level [5]. The socioecological model of health provides a framework to examine how individual health and behavior are impacted by interpersonal, neighborhood, and societal factors [7]. The National Institute on Minority Health and Health Disparities (NIMHD) has encouraged a place-based approach, as ?relationships between SRD and physical/mental health are influenced by numerous place-based factors? individual-level factors (i.e., health-related behaviors, ways of coping) are understood best within the context of the lived environment and structural policies that perpetuate inequities? [1].",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"To examine the contribution of SRD to inequalities, various measures have been used including racial residential segregation [8]. However, as no domain of structural racism operates in isolation, multiple index measures of SRD have been created and applied. Dougherty et al [9] developed a structural racism index measure by combining 7 measures of SRD: housing dissimilarity index, school dissimilarity index, high school graduation ratio, incarceration ratio, poverty ratio, primary care ratio, and ambulatory care ratio. Still, there are no consistent, agreed-upon relevant content domains of structural racism [10]. Instead of selecting 1 approach or developing yet another index, we examined mental health disparities without reference to race to determine whether communities experiencing SRD can be identified using an unsupervised retrospective approach.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"This study used the NIMHD framework to explore the relationship between SRD and mental health. By using machine learning algorithms with geodata science, we conducted spatial modeling and geovisualization to investigate how location-based factors, indicative of SRD, impact mental and physical health. This approach allows for a statistical analysis of these dynamics over time and space, offering a comprehensive analysis of the effects of place on health outcomes [11]. Data were analyzed at multiple geographic scales?county, city, and census tracts. Understanding mental health at the community level is important, given the complex intersectionality of factors that promote or hinder health in the United States [12].",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Our study site is Milwaukee County (population of 918,661), the most populous county in Wisconsin, with a racially diverse population of Black (n=241,608, 26.3%), Hispanic or Latino (n=143,311, 15.6%), and White origin (n=541,091, 58.9%) [13]. The county includes the hypersegregated city of Milwaukee (population 563,305), where redlining confined the African American population to its central city neighborhoods. Devastated by deindustrialization and disinvestments, these neighborhoods exhibit concentrated urban poverty, heightened sociospatial inequalities, and dramatic health disparities [14], where Black residents experience a poverty rate 5 times higher than that of White residents and White residents outlive Black residents by almost 14 years [13]. Acknowledging the damaging legacy of SRD on health, Milwaukee County was among the first jurisdictions in the United States to declare racism as a public health crisis in 2019, with 170 jurisdictions following its suit.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"To identify geospatial determinants of health across behavioral indicators, built environment, sociocultural environment, and health care (based on the NIMHD framework), georeferenced data sets were acquired from the United States Census Bureau. The United States Census Bureau anonymizes and deidentifies data before releasing them to the public. Detailed demographic data can be obtained only at the Census Tract level (each tract comprises 4000 residents) and not at an individual level. In accordance with census policies, we analyzed all data at the census tract level, and no individual-level data have been obtained or used. Selected variables (eg, age, gender, population, race, ethnicity, marital status, educational attainment, educational enrollment, employment, neighborhood stability, and poverty) were compiled into a data set of 217 explanatory variables. Notably, race-based factors were deliberately withheld during the initial stages of our unsupervised machine learning analysis. This approach allowed the model to operate without the assumption that racial disparities significantly influence mental health outcomes. It was only in the final stage of the analysis that race and ethnicity variables were incorporated, providing an opportunity to observe whether the emerging patterns of poor mental health prevalence correlated with racial factors. All variables were joined to the administrative boundary shapefile of Milwaukee County census tracts collected from the TIGER/Line database11 (using ArcGIS Desktop 10.7; Environmental Systems Research Institute).",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Variable selection minimizes the number of predictors in quantitative models to improve efficiency and reduce complexity. Public health research commonly uses conventional techniques such as subject matter expert selection and regression-based stepwise selection. However, tree-based methods such as random forest can handle nonlinear, nonparametric relationships and provide more robust results [15].",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Extreme multicollinearity can cause parameter estimate instability, unintuitive parameter signs, highÿR2ÿdiagnostics despite few or no significant parameters, and inflated standard errors of the parameter estimates [16]. To avoid this, variance inflation factor (VIF) and Pearson correlation analysis are used to detect multicollinearity and select the most uncorrelated variables for the random forest variable selection model. The variable selection method [17] implemented in the Variable Selection Using Random Forest (VSURF) R package (R Foundation for Statistical Computing) yields the best results compared with other variable selection and baseline methods [18]. The method ranks variables by their importance, eliminating the least important ones and constructing a sequence of random forest models. Eventually, variables of the most optimized model are selected.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Spatial modeling enables the examination of how variables behave across geographical space to identify spatial heterogeneity and dependence. Local spatial modeling offers a more informed approach to understanding complex phenomena compared with conventional global approaches [19]. The geographically weighted random forest (GWRF), a localized model, is ideal for conducting public health research. However, GWRF has not been used to examine the variability in relationships between place-based risk factors and the prevalence of poor mental health. This study used GWRF to investigate nonstationarity and localized associations between risk factors and the prevalence of poor mental health.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Local feature importance in GWRF measures how much each feature contributes to the accuracy of the model within a specific region, calculated by the increase in mean squared error or the decrease in node impurities averaged over all trees in the model. These measures are derived from the out-of-bag (OOB) error, which is a measure of the model?s performance on data not used during training [20].",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Self-organizing maps (SOMs) are unsupervised artificial ?neural? networks that create a 2D space topographic map of a data set. ?Neurons,? or relational clusters, are organized to preserve their context or neighborhood, and SOMs use closeness or neighborhood function to display input space properties. We implemented a SOM model to explore a data set containing 296 census tracts in Milwaukee County?12 determinant factors of poor mental health. The SOM was trained on this data set using a 5?5 hexagonal grid, selected for its ability to create a more comprehensive and representative map of the data. After training the SOM, we delved deeper into the clusters formed on the map by combining the SOM with k-means clustering, an algorithm known for its efficiency in partitioning data into distinct groups or clusters. We determined the optimal number of clusters for our data set by evaluating the ?within-cluster sums of squares? and the ?average silhouette? statistics [21].",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"This study uses anonymized and deidentified publicly available data sets that were released by federal or state agencies for public consumption. All publicly available government data are aggregated at the census tract level, where each tract is composed of 4000 individuals. We received full approval from the Medical College of Wisconsin institutional review board with exemption from oversight by Code of Federal Regulations 46.104 (d) 4, as we conducted secondary analyses of publicly available anonymized and deidentified data sets that do not contain any personally identifiable information and do not pose any risk to ethical violations. Given that the project did not involve direct contact with subjects, an informed consent process was not required and no compensation was provided. Moreover, the project did not require a waiver of HIPAA (Health Insurance Portability and Accountability Act) authorization as outlined in 45 Code of Federal Regulations 164.514(e) because it used a Limited Data Set.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"We compiled a database of 217 geospatial determinants of health across behavioral indicators, built environment, sociocultural environment, and health care to analyze the relationship between place-based factors and mental health. Next, we excluded all race-based factors and used the remaining 184 variables to identify highly colinear variables, VIF, and Pearson correlation analysis was applied (VIF threshold=7.5; Pearson correlation threshold=0.75). As a result, 105 uncorrelated factors were selected to be used as the input for the variable selection (VSURF) procedure.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"The VSURF procedure was applied to the 105 place-based factors to find a sufficiently parsimonious set of significant indicators of poor community mental health (ie, the percentage of adults who stated that their mental health was not good 14 or more days in the past month) and measures of SRD. The VSURF selected 98 variables at the thresholding step, then 24 variables at the interpretation step, and 12 variables at the prediction step. The most important place-based factors of mental health were adults who smoke, insufficient sleep, adults without health insurance, adults who are obese, adults who are sedentary, marriage rate, people living below the poverty level, childhood opportunity index score, median age, homeownership, full-time employment, and educational attainment (all variables are percentages except for Age and Childhood Opportunity Index score). These variables account for 95.11% of the variability in poor mental health in communities, with a mean of squared residuals of 0.74.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Partial dependence plots depicting the relationship of each of the 12 predictive variables for poor mental health were constructed.ÿFigure 1ÿillustrates the correlation between the selected 12 variables and poor mental health. The results of the partial dependence plot approach showed that the relationship among the prevalence of smoking, poverty, insufficient sleep, lack of health insurance, single households, sedentariness, and poor mental health was positive. In contrast, the childhood opportunity index, median age, homeownership, and employment rate exhibit negative relationships with poor mental health. Notably, obesity and educational attainment did not follow linear trends in relation to poor mental health, illustrating the complexity of these factors. The largest difference makers were the prevalence of smoking, lack of insurance, poverty, insufficient sleep, employment, and age.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Next, we used GWRF to investigate and visualize local associations between poor mental health prevalence and the 12 identified place-based risk factors at multiple scales?the county, the city, and census tract levels. Six place-based risk factors (prevalence of smoking, lack of insurance, poverty, insufficient sleep, employment, and age) were identified as having a spatially heterogeneous impact. We trained the GWRF with 45 nearest neighbors (census tracts) with bootstrapped 5000 ?ntrees? and 4 ?mtry? in each tree. It yielded a local model with anÿR2ÿsquare (OOB) of 94.91%, mean squared error (OOB) of 0.051, and Akaike Information Criterion (OOB) of ?856.447. Spatial variation of the local contribution of the 6 risk factors to the prediction of poor mental health is shown inÿFigure 2.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"A SOM approach was used to determine impactful clusters of the 12 most significant place-based factors related to mental health. Census tracts were grouped based on similarities in these mental health?related factors. The SOM was integrated with k-means clustering to further delineate and group census tracts based on their similarity. The original 25 SOM grid codes were condensed into 3 clusters, depicted inÿFigure 3. Each cluster represents a collection of census tracts displaying similar patterns or characteristics across the 12 mental health?related factors. Clusters 1, 2, and 3 differ markedly in their composition, each corresponding to varying levels of mental health risk. Although a more detailed understanding of each cluster necessitates additional data, particularly in terms of specific demographic, socioeconomic, and environmental variables that may influence these risk levels, these clusters can be generally categorized as representing high (cluster 3), moderate (cluster 2), and low (cluster 1) risk for poor mental health. This categorization is based on the aggregated mental health factors within each cluster. Deeper analysis with more comprehensive data could reveal more nuanced distinctions and cluster-specific contributing factors.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Figure 4ÿrepresents the geospatial distribution of the 3 mental health risk clusters across Milwaukee County. Classification into low-, moderate-, and high-risk labels refers to the collective intensity of the 12 key place-based mental health factors within each cluster. For instance, the ?high-risk? label indicates the prevalence of higher levels of risk factors (ie, smoking prevalence, lack of health insurance, and poverty) known to contribute to poor mental health but does not necessarily mean that all individuals in this cluster have poor mental health.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"To examine racial disparities within community clusters, we calculated a disproportionality index, the ratio of the percentage of a specific racial demographic within each cluster compared with that within a base population. Within the low-risk group (cluster 1), the disproportionality index is 1.5 for the White population, indicating an overrepresentation; the Black and Hispanic populations are underrepresented with indices of 0.21 and 0.6, respectively.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"In the moderate risk group (cluster 2), the White population is underrepresented, with an index of 0.6; the Black and Hispanic populations are overrepresented, with indices of 1.52 and 1.51, respectively. The most significant disparity was found in the high-risk group (cluster 3), where the Black population?s disproportionality index was 2.23, and the White and Hispanic populations were underrepresented with indices of 0.34 and 0.51, respectively.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"The findings of our unsupervised approach demonstrate significant mental health disparities that align with the racial demographics in Milwaukee County, despite our exclusion of race-related factors. The overrepresentation of Black populations in the high-risk cluster combined with the overrepresentation of the White population in the low-risk cluster indicates that disparities observed across clusters are not isolated occurrences but rather are indicative of underlying socioeconomic disparities likely caused by structural racism and discrimination. Notably, while Hispanic community members were underrepresented in the low-risk cluster 1 and overrepresented in the moderate-risk cluster 2, they were underrepresented in the high-risk cluster 3. This highlights that there are differences across racial minority demographics that influence mental health. For example, differences in upward financial mobility have been identified between Black and Hispanic communities [22].",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"The spatial dependency of risk areas was investigated to discover the locationality of poor mental health areas. To examine the degree of similarity, the Global Moran I index was calculated to measure the degree of similarity between an area and its neighboring areas. The calculated Moran Index is 0.53 with aÿzÿscore of 21.63, indicating that there is <1% likelihood that the clustering of poor mental health risk was the result of random chance. The findings, displayed inÿFigure 4, show that clusters 2 and 3 are primarily located in central city neighborhoods of Milwaukee County, aligning with predominantly Black communities in the central and north side of the city and with the Hispanic community in Milwaukee?s south side.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Although generated without incorporating location as a factor,ÿFigure 4ÿdemonstrates spatial autocorrelation, signifying the presence of spatial dependency in mental health outcomes. This suggests that mental health issues are not randomly distributed but rather display geographically linked patterns. Spatial dependency confirms the influence of location or spatial context on mental health. Our results align with previous findings, further demonstrating that mental health outcomes are partly a product of spatially located phenomena such as socioeconomic conditions, access to health care, environmental factors, and SRD. The observations reinforce the assertion that conventional global models are not ideal for examining complex phenomena such as community mental health or SRD [19,23]. Local spatial modeling offers more precise outcomes when processes are affected by both their geographical location and the fluctuating conditions of underlying variables across different times and locations.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"To address the complex issue of SRD and its impact on mental health disparities, our study used a 5-step process. First, we compiled a comprehensive database of place-based explanatory factors, also known as ?geospatial determinants of health,? at the census tract scale [24]. Second, we deliberately eliminated all race-based factors, an unprecedented approach to assess whether SRD effects on mental health disparities could be examined without directly referencing race. Third, we conducted a variable selection process, identifying the most defining place-based characteristics that shape the mental health conditions of an affected community. Fourth, using SOMs, we clustered census tracts based on mental health risk factor similarity. Finally, we investigated the racial composition, demographic characteristics, and spatial dependency of risk areas to shed light on racial disparities, confirmed SRD, and illuminated the locationality of mental health and SRD (Table 1).",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Our study introduces a novel approach to analyzing mental health disparities and their structural underpinnings, diverging from traditional models. By integrating advanced geospatial and machine learning techniques, it provides a more granular, community-specific insight into these disparities. This method contrasts with conventional approaches that may not fully capture the intricate, locality-specific interactions of factors impacting mental health [8]. In line with the study by Groos et al [8] based on the exploration of structural racism quantification methods, this study exemplifies the shift toward more sophisticated, nuanced methodologies in understanding the complex effects of SRD on health outcomes.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Several relationships were identified, demonstrating the complex determinants of mental health in different contexts. A link between smoking prevalence and mental health was noted, revealing regional variation and reflecting broader patterns in mental health research. While the percentage of adults reporting poor mental health increased with smoking [25,26], the trend flattened at a prevalence of 17%. Smoking was more significantly associated with poor mental health in central city neighborhoods and northern suburbs of Milwaukee County but had a lower effect in the south side.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Access to health insurance is vital for mental health resource use. Our analysis emphasizes the necessity of removing structural barriers to mental health such as insurance coverage [27,28]. We find a strong correlation between poor mental health and the percentage of adults without health insurance. However, the trend flattens at a 16.6% prevalence of poor mental health, indicating that when more than 20% of a community lacks health insurance, other factors may contribute to poor mental health. The lack of health insurance affects mental health more significantly in central and northern neighborhoods of Milwaukee City.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"The connection between poverty and mental health not only emphasizes the importance of a comprehensive investigation into policy, poverty, inequality, and mental health outcomes but also highlights the multifaceted nature of mental health challenges [29]. Our study shows that the relationship is complex and plateaus when more than 50% of community lives below the poverty level. Overall, poverty is a stronger defining characteristic of poor mental health in the central neighborhoods of Milwaukee.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Sleep deprivation and unemployment were identified as significant predictors of mental health [30-32]; sleep deprivation is a stronger predictor of poor mental health in central city neighborhoods and northern parts of Milwaukee County but is less of a predictor in southern communities. Our study shows that community employment has a strong negative association with poor mental health, but the relationship plateaus after 52% employment prevalence. Employment is more predictive of poor mental health in both the central city neighborhoods and the affluent shoreline areas of Milwaukee County.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Age is a determinant of mental health. Adult mental health diagnoses often begin in adolescence, with approximately half of all adult mental health disorders emerging in the teenage years [33]. The median onset age ranges from 8 to 35 years, and increased age is associated with better mental health [34]. Chen et al [35] found that the relationship between census tracts? median age and prevalence of poor mental health follows a negative curvilinear trend, consistent with a large-scale meta-analysis of 192 epidemiological studies. Our results demonstrate that poor mental health in the central city neighborhoods of Milwaukee County is more significantly associated with age than in other parts of the county, indicating that the influence of age on mental health varies locally.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Although high-risk clusters showed high spatial alignment with socioeconomically disadvantaged communities in Milwaukee, several individual factors were strong predictors of mental health in more affluent and socioeconomically secure areas (eg, in Milwaukee?s lakefront communities). These include unemployment, lack of insurance, sleep deprivation, and smoking. These observations suggest that while these communities are not locations of high-risk clusters, mental health associations are evident in subgroups of community members.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Insights gained from the disproportionality indices reveal the need for targeted interventions and policy adjustments in Milwaukee communities. These indices do not only demonstrate disparities but are also critical for guiding approaches that can address racial imbalances in mental health, steering toward a more equitable health care system. Our findings align with research demonstrating that mental health outcomes are the products of spatially located phenomena, including socioeconomic conditions, access to health care, environmental factors, and deeply rooted SRD [36]. This confluence of factors reinforces the assertion that conventional global ?one-size-fits-all? approaches fall short of understanding complex phenomena such as community mental health or the intricacies of structural racism and discrimination [19,23]. When processes are governed by their location and by conditions that fluctuate over time, the use of localized spatial modeling approaches offers a more realistic alignment, yielding more accurate and nuanced results. This perspective challenges traditional frameworks and calls for a tailored approach that considers the unique characteristics of each community, reflecting a more comprehensive understanding of mental health disparities (Table 1) [37-39].",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"While our approach introduces innovative methods for analyzing mental health disparities, it is crucial to acknowledge the inherent limitations of observational studies. Such limitations highlight the need for caution in interpreting causality from our findings. Our study?s results, therefore, should be considered indicative of associations rather than definitive causal relationships. For example, the relationships of several factors with mental health (eg, smoking, sleep deprivation, and unemployment) are likely bidirectional. This acknowledgment is vital in guiding future research and formulating public health policies that are based on a comprehensive understanding of mental health determinants.",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Finally, while our study demonstrates that Black residents are overrepresented in neighborhoods where high-risk factors for poor mental health are localized, our approach does not address risk for Black community members who live in non-Black majority communities. Moreover, our classification of communities as Black, Hispanic, and White does not recognize diversity within these racial demographics (eg, Puerto Rican vs Mexican heritage) [40].",,,,,
Exploring the Association Between Structural Racism and Mental Health: Geospatial and Machine Learning Analysis,"Understanding the complex interplay between SRD and mental health is vital to informing public health policies and interventions. For example, acknowledging that SRD places additional burdens on an individual?s ability to cope with life?s demands calls for targeted support in areas such as mental health services, education, employment, and community infrastructure. Our study, deploying advanced Geographic Information System and unsupervised machine learning analyses, unravels complex spatiotemporal relationships predicting poor mental health while excluding explicit race-related variables. The findings highlight that the risk for poor mental health is intertwined with structural and spatially localized factors that correspond with disproportional racial representation within communities. These insights illustrate a need for reinvestment strategies that recognize, protect, and promote mental health, with a focus on communities disproportionately affected by SRD. Such strategies must be implemented in a manner that considers the multifaceted risks and includes protections against further exacerbating disparities. In an era where mental health disparities persist, our research emphasizes the importance of a targeted and localized approach, prioritizing communities with historical burdens of discrimination, ensuring equitable access to resources, and ultimately fostering a more resilient and inclusive mental health care system.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Bipolar disorder (BD) patients present an increased risk of suicide attempts. Most current machine learning (ML) studies predicting suicide attempts are cross-sectional, do not employ time-dependent variables, and do not assess more than one modality. Therefore, we aimed to predict 12-month suicide attempts in a sample of BD patients, using clinical and brain imaging data.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"A sample of 163 BD patients were recruited and followed up for 12?months. Gray matter volumes and cortical thickness were extracted from the T1-weighted images. Based on previous literature, we extracted 56 clinical and demographic features from digital health records. Support Vector Machine was used to differentiate BD subjects who attempted suicide. First, we explored single modality prediction (clinical features, GM, and thickness). Second, we implemented a multimodal stacking-based data fusion framework.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"During the 12 months, 6.13% of patients attempted suicide. The unimodal classifier based on clinical data reached an area under the curve (AUC) of 0.83 and balanced accuracy (BAC) of 72.7%. The model based on GM reached an AUC of 0.86 and BAC of 76.4%. The multimodal classifier (clinical + GM) reached an AUC of 0.88 and BAC of 83.4%, significantly increasing the sensitivity. The most important features were related to suicide attempts history, medications, comorbidities, and depressive polarity. In the GM model, the most relevant features mapped in the frontal, temporal, and cerebellar regions.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"By combining models, we increased the detection of suicide attempts, reaching a sensitivity of 80%. Combining more than one modality proved a valid method to overcome limitations from single-modality models and increasing overall accuracy.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Suicidal behaviors are a major global public health issue, challenging psychiatry and society, with more than 720.000 suicide-related deaths occurring annually in the general population [1] and with the global rate of suicide estimated to be 9.4 per 100,000 individuals (95% CI 8.5?10.3) [2]. An extensive range of factors has been reported to influence suicidal behavior rates, including gender, age, temporal factors, ethnic and socio-economic backgrounds, and medical history, particularly with regard to mental health [3].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Undoubtedly, psychiatric conditions are significant risk factors for suicidal behavior. Wide-ranging research indicates that almost 90% of the attempted and completed suicides have been committed by individuals suffering from at least one Axis I psychiatric disorder, often un- or misdiagnosed and treated [4-11].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Specifically, mood disorders are the most frequently reported diagnoses leading to suicidal behavior, with individuals diagnosed with bipolar disorder (BD) appearing at an even greater risk. In fact, it has been reported that 40% of individuals with BD attempt suicide at least once in their lifetime [12,ÿ13], with the annual risk of suicide attempts among BD patients estimated to be 400?1400 per 100,000, or approximately 0.9%, which is 30?60 times higher than the rate observed in the general population [14-22]. Moreover, a recent review of the literature indicates that the standardized mortality ratio is approximately 20- to 30-fold higher compared to the general population, with the estimated suicide mortality rate among BD patients being roughly 0.2?0.4 per 100 person-year [6], indicating a higher lethality of suicide attempts within this population [23].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Several factors have been extensively studied and identified as potential contributors to suicidal behavior in individuals with BD. Sociodemographic variables such as male gender and age (particularly those under 35 or over 75), caucasian ethnicity, marital and familial status (e.g., being divorced, living alone, or having no children), and unemployment have been associated to an increased risk of suicide [4,ÿ6,ÿ24-30]. Furthermore, early adverse life events?including experiences of separation, emotional, physical, and sexual abuse?along with acute psychosocial stressors, like the death or separation from a significant other, loss of health, possessions, autonomy, employment, educational opportunities, or financial stability, and ongoing adverse life circumstances, have been implicated in precipitating suicidal behavior [4,ÿ6,ÿ24,ÿ27,ÿ31-34]. Additionally, as emphasized in Mann and colleagues' stress-diathesis model [35], a predisposition to suicide may also stem from genetic vulnerability, impaired serotonergic functioning, and specific temperamental traits, including aggressiveness, impulsivity, and hopelessness [11,ÿ27,ÿ28,ÿ30,ÿ35].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Nevertheless, the most critical determinants appear to be illness-related. These include a history of previous suicide attempts (especially with violent/highly lethal methods), a family history of suicide, and predominantly depressive episodes, particularly when accompanied by mixed affective states [29,ÿ36-41]. Rapid cycling, a high number of previous episodes, early onset and early stage of the illness, a long duration of untreated illness and scarce adherence to treatment, and comorbid conditions such as anxiety disorders, substance abuse, or personality disorders have also been reported to further elevate risk [4,ÿ6,ÿ23,ÿ42-45].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"However, despite the identified risk factors, predicting and thereby preventing suicide in patients with bipolar disorder remains a considerable challenge in clinical practice, primarily due to the lack of reliable and verified biomarkers that can accurately and promptly signal the risk of suicidal behavior [46-48].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"At the current state, the identification of at-risk patients still relies primarily on clinical assessments and patient history. However, studies have shown that traditional suicide risk factors have only limited clinical predictive value and present a relatively poor clinical utility in predicting suicide occurrence, even in high-risk populations, such as depressed patients [49,ÿ50].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"In this context, machine learning (ML) is emerging as a promising technology. By analyzing and integrating extensive datasets, including clinical, neuroimaging, behavioral, and genetic information, ML algorithms have been proven increasingly useful in uncovering complex patterns and correlations. Recent studies have demonstrated the use of ML in investigating BD, improving diagnostic accuracy [51,ÿ52], and predicting depressive relapses [53] and adverse outcomes [54], including suicidal behavior [55].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Several ML studies also tried to predict suicide in different populations [56], reaching good prediction accuracies. The most common populations assessed are mood disorders, especially major depression and BD, but several studies predicted suicide behaviors in a transdiagnostic fashion, without stratifying the sample by diagnoses [56]. Nevertheless, the current literature on suicide risk in BD appears constrained by several limitations. First of all, most of the studies [57,ÿ58] assessed suicide attempts in a cross-sectional fashion (e.g., prediction of lifetime suicide attempts), without defining prospectively a time window of analysis; second, most of the studies [59,ÿ60] employed unimodal approaches, not exploiting the full potential of ML approaches that allow handling multimodal data; moreover, ML models usually implement time-fixed variables, even though it is clear that some features tend to vary across time (e.g., a suicide attempt few months ago might have a higher weight in the prediction of future attempts, when compared to a suicide attempt occurred 20?years ago), in the end failing to fully capture the dynamic and multifaceted nature of suicide risk.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"To address these limitations, our study adopts a prospective design with a 12-month observation period, using a multimodal approach integrating clinical data with MRI features and incorporating time-variant variables, accounting for the varying influence of recent versus historical aspects of the disorder.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Specifically, our aims are to: (1) develop unimodal models for predicting 12-month suicide risk in patients with BD, utilizing clinical and MRI features; (2) evaluate the impact of time-dynamic features on prediction accuracy; and (3) investigate whether integrating multimodal features can improve the prediction of suicide attempts. We hypothesized that a multimodal approach could improve the prediction of suicide attempts, therefore fully exploiting ML potential, and that time-dynamic features would results among the most predictive.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"By employing a prospective approach and leveraging advanced ML techniques, our research intends to enhance the accuracy of suicide risk prediction and to facilitate more timely and personalized interventions, potentially informing more effective prevention and treatment strategies in clinical settings, thereby improving patient outcomes.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"One hundred and sixty-three subjects with BD (mean age 44.81?+??15.28; 88%/53.9% females) were recruited at the Department of Mental Health of the IRCCS Ca? Granda, Policlinico Hospital in Milan (Italy). The enrolment was approved by the Et125hical Committee of the IRCCS Fondazione Ca? Granda Policlinico Hospital (Neuron-051, GR-2019-12369100, Cariplo2019?3415, GR-2016-02361283, Neuroinno, CANMAN). The diagnoses were confirmed by a trained psychiatrist, using the Structured Clinical Interview (SCID) from the DSM-IV [61].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"The overall analytic strategy (Figureÿ1) entailed initially quantifying the unimodal prognostic performance of each classifier (clinical, GM volumes, CT), and subsequently understanding whether integrating MRI information with the clinical model would improve prediction performance. Therefore, four unimodal models were created (two clinical models, with and without composite score, one with GM volumes as features, and one with CT as features). All the ML analyses were performed with Neurominer version 1.1 for Matlab (Nikolaos Koutsouleris, Munich, Germany; seeÿhttps://github.com/neurominer-git).",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"For both unimodal and multimodal models, a double-nested cross-validation (CV) scheme was created, in which k-fold CV (3 repetitions, 3 folds) at the inner and outer CV levels was created. The number of folds was determined based on the limited occurrence of events (suicide attempts) to ensure that each fold consistently included a sufficient number of patients who had attempted suicide.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Inside the CV scheme, the following feature engineering pipelines were applied to the clinical models:",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Since many machine learning algorithms are sensitive to differences in feature scales, each variable was scaled to a [0,1] range to remove these effects from the training sample matrices.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,Imputation was performed for missing data using Euclidean distance between the 7-nearest observations.,,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,Our preprocessing pipeline for the structural MRI classifiers (same pipeline for GM and thickness) consists of the following steps:,,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Each variable was scaled to a [0,1] range.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Covariates nuisance was removed using Pearson correlations. Specifically, age, sex, MRI group, and TIV (only for GM) were removed.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"A Support Vector Machine (SVM) was used as the algorithm of choice. SVM is considered among the best-performing algorithms in psychiatric complex problemsÿ[56,ÿ65] and one of the easiest to interpret. Given the unbalance between the groups (suicide vs. non-suicide patients), the hyperplane was weighted for uneven group sizes, therefore minimizing the risk that the algorithm might predict only non-suicide patients (the larger group). The C parameter was optimized within a range (11 parameters, from 0.015625 to 16).",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,Permutations were used to define the significance of the model (SeeÿSupporting Informationsÿand FigureÿS1).,,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"To measure the discriminative utility of the input variables within each unimodal classifier, we computed the probability of being selected for classification purposes within the inner cross-validation loop for each feature [66].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"After training the individual classifiers, we implemented a stacking-based data fusion framework [67,ÿ68] to assess whether the combination of these unimodal classifiers would generate superior predictive systems for suicide attempts compared to using each classifier individually.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"To rule out any information leakage between the training and test samples, we employed the identical repeated k-fold CV scheme for unimodal and multimodal classification. The stacking procedure started by combining decision scores of the individual classifiers' committees within a given CV1 partition, standardizing the resulting matrices, and subsequently using them as new sets of predictive features, which replaced the original features in a given CV1 partition.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"SVM was employed to find a parsimonious combination of decision scores maximizing BAC across the C parameter range. As for the unimodal classifiers described above, we determined an ensemble of optimized SVM models across the C range that conjointly maximized BAC in the given CV1 training and test data. Then, the CV2 validation predictions of the previously trained individual classifiers' SVM ensembles were combined and standardized. Each SVM ensemble was then applied to this standardized CV2 decision score matrix to generate probability estimates. Majority voting was used to predict the CV2 outcome targets, and this procedure was repeated until all CV2 cases had received a multimodal prediction.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,The analyses and the results were reported following the Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis (TRIPOD) guidelines [69]. See TableÿS2ÿfor the TRIPOD Checklist.,,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"During the 12?months of observation, 10 patients (6.13%) attempted suicide; luckily, none of the attempts were lethal. The demographic characteristics of the sample are described in Tableÿ1. No significant differences between attempters and non-attempters were found in demographics (sex, ages, education), psychiatric family history, use of substances and clinical scales. The only significant difference was in chlorpromazine equivalents, with non-attempters having higher scores (p?=?0.009).",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Moreover, we created a composite score based on intermediate visits at 1, 3, and 6?months after discharge, including information regarding treatment variations, admissions in the ER, or any other mental health service. All the information regarding an index case (e.g., ER admission due to suicide attempts) was not included in the score, so as not to create bias in the prediction. This score serves as a proxy for the patient's trajectory, mimicking the clinician's assessment (See Supplementary for a complete description).",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Two separate models were then created, one including only baseline features and one also including the 3 timepoints composite scores.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"A structural MRI model, based on GM volumes and CT features at baseline. Before extracting the morphological parameters, all T1-weighted images were segmented according to GM, white matter and cerebrospinal fluid, bone, soft tissue, and air/background. Second, the Dartel (Diffeomorphic Anatomical Registration Through Exponentiated Lie algebra) (http://www.fil.ion.ucl.ac.uk/spm/) tools were then used to determine the nonlinear deformations for registering the GM and white matter images of all subjects. Finally, the resulting images were spatially normalized into the Montreal Neurological Institute (MNI) space and smoothed with an isotropic Gaussian kernel of 6?mm full width at half maximum Gaussian kernel to increase the signal-to-noise ratio and to account for subtle variations in anatomic structures. The total intracranial volume was also extracted using CAT12. Thus, smoothed, modulated, and normalized GM volumes were employed for the extraction of GMV and CT from brain regions defined according to probabilistic atlases. For each subject, mean GMV values were extracted for regions of the volume-based Neuromorphometrics (n?=?136) atlas [63] whereas mean CT values were extracted for regions of the surface-based Desikan-Killiany (n?=?72) atlas [64]. Among them, GMV features from 122 ROIs of the Neuromorphometrics atlas were extracted, after having excluded the ROIs with only white matter (WM). 68 ROIs of the Desikan-Killiany atlas were selected based on the availability of CT regional measures across subjects. The MRI acquisition parameters can be found in theÿSupporting Information.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Regarding clinical data, the unimodal classifier created without the composite score of the intermediate visits reached an area under the curve (AUC) of 0.71, with a BAC of 68%, sensitivity of 40%, and specificity of 97.4%. Instead, the second model including scores derived from the intermediate visits overcame the first classifier, reaching an AUC of 0.83, BAC of 72.7%, sensitivity of 50%, and specificity of 95.4%. This model was able to correctly individuate one additional subject compared to the first model. However, the ability to identify individuals at risk of suicide (represented here by the sensitivity) remained low (50%). The model was significant withÿp?<?0.01 (see Supplementary Figures?Supporting Informations).",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"The model based on GM volumes data reached an AUC of 0.86, BAC 76.4%, sensitivity 60%, and specificity 92.8%. Also, in this case, the model was significant withÿp?<?0.01 (see Supplementary Figures?Supporting Informations).",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Finally, the model based on thickness features yielded fewer results in terms of suicide prediction, with an AUC of 0.61, BAC 62.2%, sensitivity 40%, and specificity 84.9%.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Regarding the clinical features' pool, in the Neurominer model, the most significant features by weight order were: 6?months composite score, lifetime suicide, suicide in the past 12?months, use of antiepileptics, suicide modality,ÿn. of lifetime attempts, prevalent polarity, use of atypical antipsychotics, suicide ideation in the past 12?months, 3?months composite score, psychiatric family history, alcohol use (actual), chlorpromazine equivalents, compulsory treatment, and neurologic comorbidities. See FiguresÿS2ÿandÿS3ÿfor further details.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"In the GM volumes model, the most relevant features for the prediction werethe left frontal pole, bilateral thalamus, right planum temporale, left cerebellum, right posterior orbital gyrus, left accumbens, right opercular part of the inferior frontal gyrus, bilateral ventral diencephalon, right cerebellum, right cuneus, right postcentral gyrus, and right planum polare. The most important areas are represented in Figureÿ3.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Given the low prediction accuracy, the features' weights of the thickness model were not calculated.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Given the results of the unimodal classifiers, we implemented a stacking-based data fusion model combining clinical and GM predictive decision scores, as described in the Method section.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"The multimodal classifier (clinical + GM) reached an AUC of 0.88, BAC 83.4%, sensitivity 80%, and specificity 86.8%. Interestingly, the combination of the 2 modalities allowed for the correct identification of 8 out of 10 suicide attempts, significantly increasing the sensitivity.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"With our study, we aimed to employ different ML approaches combining different modalities to explore their ability to predict 12-month suicide attempts in BD patients. Firstly, we created unimodal models using either clinical or MRI features, which reached good accuracies, in line with other studies [70,ÿ71]. Nevertheless, as could be expected inÿsituations characterized by uneven group distributions, unimodal models persistently demonstrated a disproportionate relationship between sensitivity and specificity.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Taking this into consideration, we subsequently combined unimodal prediction into an integrated multimodal model to exploit the different predictive abilities of the two unimodal models. This approach resulted not only in improved overall accuracy but, crucially, in a significant enhancement of sensitivity, with the algorithm correctly predicting 8 suicide attempts out of 10 within the designated time frame. The possibility to enhance the prediction ability by combining clinical and MRI data is in line with the recent study of Shao and colleagues [72], presenting how the addition of MRI may increase the overall classification of suicide attempts in mood disorders. Of note, our study is the first to evaluate this pipeline prospectively, overcoming one of the most common pitfalls of ML prediction of suicidal behaviors: a cross-over design.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Interestingly, our results support the hypothesis that time-variant features could be very predictive in the model. For example, among the most predictive features there were ?suicide in the past 12 months? and ?suicide ideation in the past 12 months?, suggesting how the weight of features tends to vary according to different time windows. Furthermore, they encourage future research to employ, set up, or redefine ML algorithms for worse outcome prediction in a complex, superordinate, and multimodal, rather than unimodal perspective [67].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"In the clinical model, the most significant features were those related to the history of suicide (suicide attempts lifetime, suicide attempts in the last 12?months, suicide modality, number of suicide attempts lifetime, and suicidal ideation in the last 12?months), to the severity trajectory (6?months composite score), to depressive polarity, to the prescribed treatment (especially use of antiepileptics), and to comorbidities, including alcohol abuse and neurological comorbidities.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"From our results emerged a vulnerability based on a history of prior suicide attempts, with their significance likely escalating as the number of these attempts accumulates over a lifetime. This vulnerability appears to be further accentuated by the methods employed in suicide attempts, which may serve as an indicator of underlying intentionality. Indeed, as previously mentioned, among individuals with BD, the ratio of attempts to completed suicides is markedly lower than in the general population, revealing a proclivity for more violent and lethal means [23].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"In this context, it is also worth highlighting, as Boudreaux and colleagues [62] suggested, that the features' weights may vary over time. From this perspective, suicide attempts and suicidal ideation within the past 12?months may contribute significantly more to suicidal risk susceptibility, emphasizing the critical importance of comprehensive clinical assessment and precise, timely monitoring.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Among the other salient clinical features, prevalent polarity is particularly noteworthy, affirming that a predominant depressive polarity (as well as mixed affective states) may significantly elevate the risk of suicidal behavior in individuals with BD [36,ÿ39,ÿ41]. Furthermore, it is pertinent to mention that a familial history of psychiatric disorders and suicidal behaviors may also influence suicide risk, implying a possible genetic predisposition [37,ÿ40].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"In our study, features related to the use of specific medications, such as antiepileptics and atypical antipsychotics (considered as dichotomous variables), as well as chlorpromazine equivalents (treated as a continuous variable), in conjunction with compulsory treatment, may be viewed as proxies for illness severity rather than as direct contributors to increased suicide risk. Intuitively, more severe episodes necessitating complex therapies and a compulsory treatment regimen are likely to be associated with a heightened risk of suicidal behavior.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"However, the use of antiepileptics in BD has long been a point of contention, particularly in relation to suicide risk [73-77].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"A recent review of the literature [78] confirmed valproate's therapeutic advantage over no treatment with respect to suicide attempts and completions, though it emphasized the need for further data. However, compared to lithium, valproate has been associated with a higher risk of suicide attempts and completions. Other antiepileptics, such as lamotrigine and carbamazepine, have been noted as requiring further investigation regarding their association with suicide-related outcomes [78].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Similarly, research has explored the impact of atypical antipsychotics on suicide risk in BD [79]. Some studies have indicated the potential for these drugs to exacerbate suicide risk in certain patients when compared to mood stabilizers such as lithium or valproate [80,ÿ81]. However, these findings remain inconsistent and often overlook the role of illness severit [82-89].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Given the widespread use of atypical antipsychotics in the treatment of BD, particularly in the management of acute phases where combination therapies with mood stabilizers are considered effective for severe cases, further investigation into the relationship between atypical antipsychotics and suicide risk appears essential [86].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Lastly, our findings have identified current alcohol use as a significant clinical feature in predicting suicidal behavior among individuals with BD [90]. As a matter of fact, literature has evidenced that alcohol consumption may exacerbate mood instability, increase impulsivity, and impair judgment, all of which may contribute to heightened vulnerability to suicidal thoughts and actions [91,ÿ92]. Moreover, alcohol's depressant effects may worsen depressive episodes, deepening feelings of hopelessness [93]. Studies have demonstrated that comorbid alcohol use disorder in bipolar patients is associated with a higher incidence of suicide attempts, underscoring the critical need for addressing alcohol use in suicide prevention strategies [94,ÿ95].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"In conclusion, our results confirm some of the previously known risk factors, extensively documented in the literature, as significant contributors in the ML model prediction accuracy, particularly highlighting aspects related to illness severity and history of suicide attempts, either personal or familiar. These results underline the importance of a complete assessment of suicide potentially helping to identify individuals at heightened risk.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"The MRI features that mostly contributed to the prediction are mapped in the frontal (frontal pole, orbital gyrus, inferior frontal gyrus), temporal (planum temporale, and planum polare), and cerebellar regions.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"With regards to frontal regions, these findings are not surprising as these areas are among the most implicated neural structures in suicidality [72,ÿ96]. The ventral areas of the frontal lobe are essential for guiding goal-directed response selection, especially in unpredictable environments where actions must be adjusted flexibly based on both recent and past reinforcement histories [97]. Notably, in line with the GM loss in the suicide attempters reported by Shao and colleagues, the opercular part of the inferior frontal gyrus resulted among the most selected features. This region is heavily involved in making goal-directed decisions guided by adaptive reinforcement processing [98]. Additionally, these areas show extensive connections with the caudate nucleus [99], which plays a significant role in implementing instrumental processing and goal-directed behaviors [98,ÿ100]. Therefore, our findings support the idea that taking the critical step toward suicide may result from a failure to choose the most beneficial (or least harmful) action inÿsituations where difficulties appear to overshadow any positive outlook. This notion aligns with the proposed specialized function of the lateral orbitofrontal cortex and ventrolateral-prefrontal-insular systems in signaling and regulating responses to nonrewarding or aversive experiences, which is a key aspect of the broader top-down inhibitory control over emotions, cognition, and actions [101].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Consistent with our findings, structural alterations in temporal cortices were associated with suicide in a range of psychiatric disorders and related to high lethality attempts and higher impulsivity [96]. Specifically, alterations in middle and superior temporal gyrus volume were described in suicide attempters with primary psychotic disorders [102,ÿ103], mood disorders [104], but also borderline personality disorders [105]. Reduced middle and superior temporal volumes were also associated with increased lethality [106] and higher impulsivity in individuals with suicidal behaviors with different mental disorders [107]. fMRI studies also pointed out the association between the superior temporal gyrus and suicidal behaviors. Specifically, suicidal ideation was associated with increased superior temporal activation during error processing in veterans with traumas [108], while lower perfusion in these temporal regions during rest was reported in mood disorders with suicidal ideation [109]. Moreover, the functional connectivity of the superior temporal gyrus was found to be associated with psychological risk factors, including loneliness and purpose in life, in a recent fMRI study [110].",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Finally, the cerebellum is increasingly recognized for its involvement in emotional processes [111,ÿ112]. Volumetric alterations of the cerebellum were reported in adults and adolescents with mood disorders and suicide behaviors [113]. Functionally, recent studies suggested an involvement of the cerebellum in the recollection of memories related to suicide attempts. In a recent publication [114], participants who had attempted suicide had greater fMRI task-related activation in visual areas and the cerebellum, with the number of suicide attempts associated with the difference in BOLD response. The cerebellum seems to be also relevant in emotional pain, which can lead to suicidal conduct especially in young individuals [115]. A recent review [116] proposed a model that integrates the previous notions of brain imaging in suicidal studies. In the model, two systems interplay in shaping suicide risk: the emotional pain circuit, including the cerebellum, hippocampus, and amygdala, and the social disconnect circuit, which comprises the lateral OFC and temporal gyri, as well as the connections between them (the frontotemporal system). Emotional pain can be caused by a combination of predisposition and stressful life events and can lead to suicidal ideation, especially in adolescents. If, in addition, the subject is experiencing social disconnect, this can lead to a suicide attempt.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"In summary, the brain areas from frontal, temporal, and cerebellar regions that were selected in our model proved to have a role in the neurobiology of suicide, highlighting the relevance of the ML algorithm's feature selection from both a clinical and neurobiological perspective. However, it is important to mention that MRI scans present some critical issues in psychiatry. First of all, MRI scans present an important cost compared to clinical-demographic variables, and they require a relevant amount of time. Moreover, it is likely that very severe patients in acute wards are not able to endure an MRI scan, possibly creating a bias in terms of sample selection. These are critical aspects that should be further investigated in the future. Nonetheless, our results support the idea that MRI features can improve the ability of the algorithm to recognize patients at increased risk for suicide; future studies need to assess whether this increase in algorithm performance is feasible in terms of cost and time, compared to a simpler model based on clinical and demographic features.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"The above-exposed results should be regarded in light of some limitations. First, the sample size is small, although it is in line with similar ML studies [70,ÿ117,ÿ118]. This appears particularly relevant as machine learning needs an important amount of data to be trained properly; therefore, despite having performed a double-nested CV, the risk of overfitting cannot be completely ruled out. ML studies should find a tradeoff between very large databases, often not well characterized, and smaller studies. In our study, we preferred to have a well-characterized sample, although it might pose some problems regarding overfitting. Similarly, the index event (namely, suicide) is luckily a rare occurrence, and this reflects on a highly unbalanced sample, which is a common finding in suicide literature [56]. However, balanced samples (similar size for attempters and non-attempters) are something very far from reality, and we believe it should be avoided. To avoid this bias, we tried to assess this aspect by weighting the hyperplane for uneven groups and considering different metrics, such as sensitivity and specificity, given that accuracy in these cases could be misleading. Another important limitation is the absence of an external validation sample that would confirm the generalizability of our results.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Finally, it is important to mention that the selected features do not include all the possible risk factors for suicide. For example, we did not have data regarding traumas or adverse events available for our sample. These non-disease related factors are well documented in the literature [119,ÿ120] and could add important value to ML prediction. Similarly, a more in-depth description of some clinical aspects of the disorder might be important. For example, recent studies suggested that specific sleep and circadian disturbance variables might confer unique risk for suicide in BD [121]. This highlights the importance of conducting a thorough sleep and circadian assessment in clinical practice and include such variables in ML models.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Bearing the above-exposed limitations in mind, we plan to design and conduct future studies including features designed to assess other domains (e.g., adverse life events and traumas), further broader validation samples of patients with BD, as well as transdiagnostic psychiatric cases, to test whether the prediction model's applicability extends across diverse diagnoses [122]. Finally, even though modalities such as cognitive functions or additional MRI sequences have not been implemented in our study, we believe that incorporating them in future research could significantly enhance the precision in defining suicide risk among BD patients.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"Incorporating ML models into clinical practice for predicting suicide risk in patients with BD appears promising, especially when using a multimodal, time-variant approach. As our findings have evidenced, integrating MRI features with clinical data may notably improve predictive accuracy for 12-month suicide risk in this population.",,,,,
Multimodal Machine Learning Prediction of 12-Month Suicide Attempts in Bipolar Disorder,"These advanced techniques have the potential to enhance predictive precision, assisting clinicians in obtaining a more nuanced evaluation of individual risk profiles and thereby facilitating earlier and more targeted interventions. Such advancements could significantly improve patient outcomes and further develop management strategies within mental health care.",,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
,,,,,,
